{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, time, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "    \n",
    "print('Using TensorFlow version: %s' % tf.__version__)\n",
    "\n",
    "RSEED = 1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/tensorflow/docs\n",
    "    \n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "\n",
    "#data = pd.read_csv('data/data_prep_reg.csv', index_col=[0]) # includes the statistics of the features only location D\n",
    "data = pd.read_csv('data/data_prep_feat.csv', index_col=[0]) # includes all values as a new features only location D\n",
    "#data = pd.read_csv('data/data_prep_reg_all.csv', index_col=[0]) # include the statistics of the features an all locations\n",
    "\n",
    "print(f'Data: {data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fillna\n",
    "data = data.fillna(data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = list(data.columns)[2:44]\n",
    "columns_to_drop.append('target')\n",
    "columns_to_drop.append('location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# = ['target', 'location', feature_stats]\n",
    "# define features and target\n",
    "X = data.drop(columns_to_drop, axis=1)\n",
    "y = data.target\n",
    "\n",
    "# test train split: \n",
    "X_train, X_test, y_train, y_test = train_test_split(  \n",
    "                                    X, y, test_size = 0.3, \n",
    "                                    random_state = RSEED) \n",
    "\n",
    "print (f'X: {X.shape}')\n",
    "print (f'y: {y.shape}')\n",
    "\n",
    "print (f'X_train: {X_train.shape}')\n",
    "print (f'y_train: {y_train.shape}')\n",
    "\n",
    "print (f'X_test: {X_test.shape}')\n",
    "print (f'y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre selecting\n",
    "\n",
    "N_VAL =  len(X_test)\n",
    "N_TRAIN = len(X_train)\n",
    "BATCH_SIZE = 96\n",
    "STEPS_PER_EPOCH = N_TRAIN // BATCH_SIZE\n",
    "EPOCHS = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparation for Tensorboard\n",
    "\n",
    "# Define path for new directory \n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "# Define function for creating a new folder for each run\n",
    "def get_run_logdir():\n",
    "    run_id = time.strftime('run_%d_%m_%Y-%H_%M_%S')\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "    \n",
    "run_logdir = get_run_logdir()\n",
    "#def get_callbacks():\n",
    "\n",
    "def get_callbacks(name):\n",
    "    return tf.keras.callbacks.TensorBoard(run_logdir+name, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint \n",
    "\n",
    "# Define path where checkpoints should be stored\n",
    "checkpoint_path = \"DNN/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=False,\n",
    "                                                 verbose=1) # Set verbose != 0 if you want output during training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting function for MSE\n",
    "def plot_metric(history):\n",
    "    plt.plot(history.history['mse'])\n",
    "    plt.plot(history.history['val_mse'])\n",
    "    plt.title('Model MSE')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting function for loss\n",
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylim([0, 10])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def error_analysis(y_test, y_pred_test):\n",
    "    \"\"\"Generated true vs. predicted values and residual scatter plot for models\n",
    "\n",
    "    Args:\n",
    "        y_test (array): true values for y_test\n",
    "        y_pred_test (array): predicted values of model for y_test\n",
    "    \"\"\"     \n",
    "    # Calculate residuals\n",
    "    residuals = y_test - y_pred_test\n",
    "    \n",
    "    # Plot real vs. predicted values \n",
    "    fig, ax = plt.subplots(1,2, figsize=(15, 5))\n",
    "    plt.subplots_adjust(right=1)\n",
    "    plt.suptitle('Error Analysis')\n",
    "    \n",
    "    ax[0].scatter(y_pred_test, y_test, color=\"#FF5A36\", alpha=0.7)\n",
    "    ax[0].plot([-400, 350], [-400, 350], color=\"#193251\")\n",
    "    ax[0].set_title(\"True vs. predicted values\", fontsize=16)\n",
    "    ax[0].set_xlabel(\"predicted values\")\n",
    "    ax[0].set_ylabel(\"true values\")\n",
    "    #ax[0].set_xlim((y_pred_test.min()-10), (y_pred_test.max()+10))\n",
    "    ax[0].set_ylim((y_test.min()-40), (y_test.max()+40))\n",
    "    \n",
    "    ax[1].scatter(y_pred_test, residuals, color=\"#FF5A36\", alpha=0.7)\n",
    "    ax[1].plot([-400, 350], [0,0], color=\"#193251\")\n",
    "    ax[1].set_title(\"Residual Scatter Plot\", fontsize=16)\n",
    "    ax[1].set_xlabel(\"predicted values\")\n",
    "    ax[1].set_ylabel(\"residuals\")\n",
    "    #ax[1].set_xlim((y_pred_test.min()-10), (y_pred_test.max()+10))\n",
    "    #ax[1].set_ylim((residuals.min()-10), (residuals.max()+10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_test, y_test, X_train, y_train):\n",
    "    # plot MSE history\n",
    "    plot_metric(model)\n",
    "    # plot loss history\n",
    "    plot_loss(model)\n",
    "\n",
    "    # evaluate the model:\n",
    "    # Evaluate the small model on test set using .evaluate\n",
    "    loss, mse = model.evaluate(X_test, y_test, verbose=2)\n",
    "    print(f'Model MSE: {mse}')\n",
    "    print('--------'*5)\n",
    "\n",
    "    # Predict values for test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    test_results['first model'] =  [rmse_train, rmse_test]\n",
    "\n",
    "    print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    print('RMSE:', np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
    "\n",
    "    fig, ax = plt.subplots(1,2, figsize=(15, 5))\n",
    "\n",
    "    plt.subplots_adjust(right=1)\n",
    "    plt.suptitle('Error Analysis')\n",
    "\n",
    "\n",
    "    ax[0].scatter(y_pred, y_test, color=\"#FF5A36\", alpha=0.7)\n",
    "    ax[0].plot([-400, 350], [-400, 350], color=\"#193251\")\n",
    "    ax[0].set_title(\"True vs. predicted values\", fontsize=16)\n",
    "    ax[0].set_xlabel(\"predicted values\")\n",
    "    ax[0].set_ylabel(\"true values TEST\")\n",
    "    #ax[0].set_xlim((y_pred_test.min()-10), (y_pred_test.max()+10))\n",
    "    ax[0].set_ylim((y_test.min()-40), (y_test.max()+40))\n",
    "\n",
    "    ax[1].scatter(y_pred_train, y_test, color=\"#FF5A36\", alpha=0.7)\n",
    "    ax[1].plot([-400, 350], [-400, 350], color=\"#193251\")\n",
    "    ax[1].set_title(\"True vs. predicted values\", fontsize=16)\n",
    "    ax[1].set_xlabel(\"predicted values\")\n",
    "    ax[1].set_ylabel(\"true values Train\")\n",
    "    #ax[0].set_xlim((y_pred_test.min()-10), (y_pred_test.max()+10))\n",
    "    ax[1].set_ylim((y_test.min()-40), (y_test.max()+40))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionary to store results\n",
    "training_history = {}\n",
    "test_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_compile_and_fit(X, y, model, name, optimizer, max_epochs=30):\n",
    "    # Get optimizer\n",
    "    #optimizer=tf.keras.optimizers.Adam()\n",
    "\n",
    "    # model.compile\n",
    "    model.compile(optimizer=optimizer,\n",
    "                metrics='mse', # [tf.keras.metrics.RootMeanSquaredError()]\n",
    "                loss='mae')\n",
    "    # model.fit\n",
    "    training_history[name] = model.fit(X, \n",
    "                        y,\n",
    "                        validation_split=0.2,\n",
    "                        verbose=1,\n",
    "                        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                        epochs=EPOCHS, \n",
    "                        callbacks=get_callbacks(name))\n",
    "    # return results\n",
    "    return training_history[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "      all_features_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu', input_dim = 726),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dense(1,kernel_initializer = 'uniform')\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    all_features_model_history = model_compile_and_fit(X=X_train, \n",
    "                                            y=y_train,\n",
    "                                            model= all_features_model,\n",
    "                                            name='all_features_model',\n",
    "                                            optimizer='Adam', \n",
    "                                            max_epochs= EPOCHS )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    evaluate(all_features_model, X_test, y_test, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire small model as a SavedModel.\n",
    "!mkdir -p saved_model\n",
    "all_features_model.save('saved_model/dnn_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_results"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8f548114482b487876add26679caae41a2a9f4541ddf007921bd7bf3c60f478"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
