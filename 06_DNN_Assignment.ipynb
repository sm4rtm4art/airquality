{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35455b7",
   "metadata": {},
   "source": [
    "# DNN Assignment\n",
    "In this assignment you are working together with your teammates from the second project. You will apply your new knowledge about dense neural networks to the data from your ML project to investigate, if you can make further improvements on prediction performance. Your data is (hopefully) already cleaned and transformed (this was part of your ML project) such that you can focus fully on feeding it to your neural network. Use TensorFlow 2.x in this assignment as it makes training with real-life data much more easier with many implemented features (e.g. early-stopping, tensorboard, regularization, etc.). \n",
    "\n",
    "In this notebook you will learn\n",
    "- how to apply a neural network to your own data using TensorFlow 2.x\n",
    "- how to tune the network and monitor learning\n",
    "- how to train several networks and ensemble them into a stronger model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f967c6d",
   "metadata": {},
   "source": [
    "# Module loading\n",
    "Load all the necessary packages for your assignment. We give you some modules in advance, feel free to add more, if you need them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e0d764d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow version: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "import datetime, time, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "    \n",
    "print('Using TensorFlow version: %s' % tf.__version__)\n",
    "\n",
    "RSEED = 1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28b25ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/tensorflow/docs\n",
    "    \n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a12ef62",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "Load here your data from your ML project. You can use either `pandas` or `numpy` to format your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eb56623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: (4990, 44)\n"
     ]
    }
   ],
   "source": [
    "# Import Data\n",
    "\n",
    "data = pd.read_csv('data/data_prep_reg.csv', index_col=[0]) # includes the statistics of the features only location D\n",
    "#data = pd.read_csv('data/data_prep_feat.csv', index_col=[0]) # includes all values as a new features only location D\n",
    "#data = pd.read_csv('data/data_prep_reg_all.csv', index_col=[0]) # include the statistics of the features an all locations\n",
    "\n",
    "print(f'Data: {data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "373b02f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fillna\n",
    "data = data.fillna(data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "698f82cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>target</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>mean_temp</th>\n",
       "      <th>std_temp</th>\n",
       "      <th>var_temp</th>\n",
       "      <th>median_temp</th>\n",
       "      <th>ptp_temp</th>\n",
       "      <th>max_precip</th>\n",
       "      <th>...</th>\n",
       "      <th>var_wind_spd</th>\n",
       "      <th>median_wind_spd</th>\n",
       "      <th>ptp_wind_spd</th>\n",
       "      <th>max_atmos_press</th>\n",
       "      <th>min_atmos_press</th>\n",
       "      <th>mean_atmos_press</th>\n",
       "      <th>std_atmos_press</th>\n",
       "      <th>var_atmos_press</th>\n",
       "      <th>median_atmos_press</th>\n",
       "      <th>ptp_atmos_press</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>79.131702</td>\n",
       "      <td>33.616667</td>\n",
       "      <td>17.983333</td>\n",
       "      <td>24.679063</td>\n",
       "      <td>4.266955</td>\n",
       "      <td>18.206903</td>\n",
       "      <td>23.791667</td>\n",
       "      <td>15.633333</td>\n",
       "      <td>0.561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290736</td>\n",
       "      <td>0.744167</td>\n",
       "      <td>2.760833</td>\n",
       "      <td>90.725000</td>\n",
       "      <td>90.056667</td>\n",
       "      <td>90.429924</td>\n",
       "      <td>0.156000</td>\n",
       "      <td>0.024336</td>\n",
       "      <td>90.429167</td>\n",
       "      <td>0.668333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>55.638261</td>\n",
       "      <td>34.041667</td>\n",
       "      <td>17.191667</td>\n",
       "      <td>23.189507</td>\n",
       "      <td>4.432786</td>\n",
       "      <td>19.649595</td>\n",
       "      <td>22.033333</td>\n",
       "      <td>16.850000</td>\n",
       "      <td>10.302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533776</td>\n",
       "      <td>0.840833</td>\n",
       "      <td>3.285000</td>\n",
       "      <td>90.986667</td>\n",
       "      <td>90.211667</td>\n",
       "      <td>90.624814</td>\n",
       "      <td>0.179998</td>\n",
       "      <td>0.032399</td>\n",
       "      <td>90.641667</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>32.240851</td>\n",
       "      <td>29.608333</td>\n",
       "      <td>19.166667</td>\n",
       "      <td>23.151446</td>\n",
       "      <td>2.808773</td>\n",
       "      <td>7.889204</td>\n",
       "      <td>22.291667</td>\n",
       "      <td>10.441667</td>\n",
       "      <td>2.229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195908</td>\n",
       "      <td>0.627500</td>\n",
       "      <td>1.705000</td>\n",
       "      <td>90.744167</td>\n",
       "      <td>90.102500</td>\n",
       "      <td>90.454477</td>\n",
       "      <td>0.149374</td>\n",
       "      <td>0.022312</td>\n",
       "      <td>90.471667</td>\n",
       "      <td>0.641667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>72.717021</td>\n",
       "      <td>29.133333</td>\n",
       "      <td>17.516667</td>\n",
       "      <td>22.341529</td>\n",
       "      <td>3.161073</td>\n",
       "      <td>9.992384</td>\n",
       "      <td>21.683333</td>\n",
       "      <td>11.616667</td>\n",
       "      <td>13.588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124645</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.608333</td>\n",
       "      <td>90.873333</td>\n",
       "      <td>90.284167</td>\n",
       "      <td>90.607307</td>\n",
       "      <td>0.139059</td>\n",
       "      <td>0.019337</td>\n",
       "      <td>90.620833</td>\n",
       "      <td>0.589167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>35.833571</td>\n",
       "      <td>30.558333</td>\n",
       "      <td>16.983333</td>\n",
       "      <td>22.401240</td>\n",
       "      <td>3.592899</td>\n",
       "      <td>12.908921</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>13.575000</td>\n",
       "      <td>43.080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186272</td>\n",
       "      <td>0.678333</td>\n",
       "      <td>2.197500</td>\n",
       "      <td>91.004167</td>\n",
       "      <td>90.217500</td>\n",
       "      <td>90.600544</td>\n",
       "      <td>0.172882</td>\n",
       "      <td>0.029888</td>\n",
       "      <td>90.600833</td>\n",
       "      <td>0.786667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    location     target   max_temp   min_temp  mean_temp  std_temp   var_temp  \\\n",
       "1          3  79.131702  33.616667  17.983333  24.679063  4.266955  18.206903   \n",
       "10         3  55.638261  34.041667  17.191667  23.189507  4.432786  19.649595   \n",
       "13         3  32.240851  29.608333  19.166667  23.151446  2.808773   7.889204   \n",
       "15         3  72.717021  29.133333  17.516667  22.341529  3.161073   9.992384   \n",
       "22         3  35.833571  30.558333  16.983333  22.401240  3.592899  12.908921   \n",
       "\n",
       "    median_temp   ptp_temp  max_precip  ...  var_wind_spd  median_wind_spd  \\\n",
       "1     23.791667  15.633333       0.561  ...      0.290736         0.744167   \n",
       "10    22.033333  16.850000      10.302  ...      0.533776         0.840833   \n",
       "13    22.291667  10.441667       2.229  ...      0.195908         0.627500   \n",
       "15    21.683333  11.616667      13.588  ...      0.124645         0.625000   \n",
       "22    21.333333  13.575000      43.080  ...      0.186272         0.678333   \n",
       "\n",
       "    ptp_wind_spd  max_atmos_press  min_atmos_press  mean_atmos_press  \\\n",
       "1       2.760833        90.725000        90.056667         90.429924   \n",
       "10      3.285000        90.986667        90.211667         90.624814   \n",
       "13      1.705000        90.744167        90.102500         90.454477   \n",
       "15      1.608333        90.873333        90.284167         90.607307   \n",
       "22      2.197500        91.004167        90.217500         90.600544   \n",
       "\n",
       "    std_atmos_press  var_atmos_press  median_atmos_press  ptp_atmos_press  \n",
       "1          0.156000         0.024336           90.429167         0.668333  \n",
       "10         0.179998         0.032399           90.641667         0.775000  \n",
       "13         0.149374         0.022312           90.471667         0.641667  \n",
       "15         0.139059         0.019337           90.620833         0.589167  \n",
       "22         0.172882         0.029888           90.600833         0.786667  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c198ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (4990, 42)\n",
      "y: (4990,)\n",
      "X_train: (3493, 42)\n",
      "y_train: (3493,)\n",
      "X_test: (1497, 42)\n",
      "y_test: (1497,)\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['target', 'location']\n",
    "# define features and target\n",
    "X = data.drop(columns_to_drop, axis=1)\n",
    "y = data.target\n",
    "\n",
    "# test train split: \n",
    "X_train, X_test, y_train, y_test = train_test_split(  \n",
    "                                    X, y, test_size = 0.3, \n",
    "                                    random_state = RSEED) \n",
    "\n",
    "print (f'X: {X.shape}')\n",
    "print (f'y: {y.shape}')\n",
    "\n",
    "print (f'X_train: {X_train.shape}')\n",
    "print (f'y_train: {y_train.shape}')\n",
    "\n",
    "print (f'X_test: {X_test.shape}')\n",
    "print (f'y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26098865",
   "metadata": {},
   "source": [
    "## Training\n",
    "For training you need a train/val split (hopefully you did a train/test split before (and you should use the same as in your ML project to make results comparable). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "467c0dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_VAL =  len(X_test)\n",
    "N_TRAIN = len(X_train)\n",
    "BATCH_SIZE = 96\n",
    "STEPS_PER_EPOCH = N_TRAIN // BATCH_SIZE\n",
    "EPOCHS = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afda48b9",
   "metadata": {},
   "source": [
    "### Build, compile and fit your model\n",
    "To become fast at retraining your (different) models it is good practice to define a function that gets fed by a model, its name, an optimizer to use and the number of epochs you want the model to be trained. \n",
    "\n",
    "If your model trains for many epochs you will receive a lot of logging from TensorFlow. To reduce the logging noise you can use a callback (provided by the `tensorflow_docs` module we installed and imported for you) named `EpochDots()` that simply prints a `.` for each epoch and a full set of metrics after a number of epochs have been trained. \n",
    "\n",
    "If you want to produce logs for using Tensorboard you also need to include the `callbacks.Tensorboard()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80056b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aktiviert\n",
    "#!rm -rf my_logs/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce0a2e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparation for Tensorboard\n",
    "\n",
    "# Define path for new directory \n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "# Define function for creating a new folder for each run\n",
    "def get_run_logdir():\n",
    "    run_id = time.strftime('run_%d_%m_%Y-%H_%M_%S')\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "    \n",
    "run_logdir = get_run_logdir()\n",
    "#def get_callbacks():\n",
    "\n",
    "def get_callbacks(name):\n",
    "    return tf.keras.callbacks.TensorBoard(run_logdir+name, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54c05fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint \n",
    "\n",
    "# Define path where checkpoints should be stored\n",
    "checkpoint_path = \"DNN/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=False,\n",
    "                                                 verbose=1) # Set verbose != 0 if you want output during training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c140b140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting function for MSE\n",
    "def plot_metric(history):\n",
    "    plt.plot(history.history['mse'])\n",
    "    plt.plot(history.history['val_mse'])\n",
    "    plt.title('Model MSE')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7246703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting function for loss\n",
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylim([0, 10])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b79aa92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def error_analysis(y_test, y_pred_test):\n",
    "    \"\"\"Generated true vs. predicted values and residual scatter plot for models\n",
    "\n",
    "    Args:\n",
    "        y_test (array): true values for y_test\n",
    "        y_pred_test (array): predicted values of model for y_test\n",
    "    \"\"\"     \n",
    "    # Calculate residuals\n",
    "    residuals = y_test - y_pred_test\n",
    "    \n",
    "    # Plot real vs. predicted values \n",
    "    fig, ax = plt.subplots(1,2, figsize=(15, 5))\n",
    "    plt.subplots_adjust(right=1)\n",
    "    plt.suptitle('Error Analysis')\n",
    "    \n",
    "    ax[0].scatter(y_pred_test, y_test, color=\"#FF5A36\", alpha=0.7)\n",
    "    ax[0].plot([-400, 350], [-400, 350], color=\"#193251\")\n",
    "    ax[0].set_title(\"True vs. predicted values\", fontsize=16)\n",
    "    ax[0].set_xlabel(\"predicted values\")\n",
    "    ax[0].set_ylabel(\"true values\")\n",
    "    #ax[0].set_xlim((y_pred_test.min()-10), (y_pred_test.max()+10))\n",
    "    ax[0].set_ylim((y_test.min()-40), (y_test.max()+40))\n",
    "    \n",
    "    ax[1].scatter(y_pred_test, residuals, color=\"#FF5A36\", alpha=0.7)\n",
    "    ax[1].plot([-400, 350], [0,0], color=\"#193251\")\n",
    "    ax[1].set_title(\"Residual Scatter Plot\", fontsize=16)\n",
    "    ax[1].set_xlabel(\"predicted values\")\n",
    "    ax[1].set_ylabel(\"residuals\")\n",
    "    #ax[1].set_xlim((y_pred_test.min()-10), (y_pred_test.max()+10))\n",
    "    #ax[1].set_ylim((residuals.min()-10), (residuals.max()+10));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfcdd8a",
   "metadata": {},
   "source": [
    "You can implement your callbacks in the `model.fit()` method below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73f412e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionary to store results\n",
    "training_history = {}\n",
    "test_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f042f336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_compile_and_fit(X, y, model, name, optimizer, max_epochs=30):\n",
    "    # Get optimizer\n",
    "    #optimizer=tf.keras.optimizers.Adam()\n",
    "\n",
    "    # model.compile\n",
    "    model.compile(optimizer=optimizer,\n",
    "                metrics='mse', # [tf.keras.metrics.RootMeanSquaredError()]\n",
    "                loss='mae')\n",
    "    # model.fit\n",
    "    training_history[name] = model.fit(X, \n",
    "                        y,\n",
    "                        validation_split=0.2,\n",
    "                        verbose=1,\n",
    "                        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                        epochs=EPOCHS, \n",
    "                        callbacks=get_callbacks(name))\n",
    "    # return results\n",
    "    return training_history[name]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b436f486",
   "metadata": {},
   "source": [
    "#### Build your model\n",
    "You can build your model by using `tf.keras.Sequential()` that helps you to sequentially define your different layers from input to output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535bfd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-07 21:45:22.841762: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-07 21:45:22.842069: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "      first_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu', input_dim = 42),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dense(1,kernel_initializer = 'uniform')\n",
    "      ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31056e5",
   "metadata": {},
   "source": [
    "#### Train your model\n",
    "Train your model by using your `model_compile_and_fit()` function you defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df56c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    first_model_history = model_compile_and_fit(X=X_train, \n",
    "                                            y=y_train,\n",
    "                                            model= first_model,\n",
    "                                            name='first_model',\n",
    "                                            optimizer='Adam', \n",
    "                                            max_epochs= EPOCHS )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a0e282",
   "metadata": {},
   "source": [
    "#### Evaluate your model training\n",
    "TensorFlow offers now (this was more cumbersome before) a simple history plotter that you can use to plot training histories and see how the model performed on training and validation data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aec80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    # plot MSE history \n",
    "    plot_metric(first_model_history)\n",
    "\n",
    "    # Evaluate the small model on test set using .evaluate\n",
    "    loss, mse = first_model.evaluate(X_test, y_test, verbose=2)\n",
    "    print(f'Model MSE: {mse}')\n",
    "    print('--------'*5)\n",
    "\n",
    "# Predict values for test set\n",
    "y_pred = first_model.predict(X_test)\n",
    "y_pred_train = first_model.predict(X_train)\n",
    "\n",
    "\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "test_results['first model'] =  [rmse_train, rmse_test]\n",
    "\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85938cce",
   "metadata": {},
   "source": [
    "## Model tuning\n",
    "You might have no luck with your first model (most surely you did not). In this section you will apply methods you know to tune your model's performance. An obvious way of course is to change your model's architecture (removing or adding layers or layer dimensions, changing activation functions). \n",
    "\n",
    "However, after this you might still be able to detect some overfitting and there are some more methods you can apply to improve your neural network. Some of them are regularization, learning rate decay, early stopping, or dropout. \n",
    "\n",
    "If you want to add regularization you can apply directly layer-wise L2- or L1-regularization by using a layer's `kernel_regularization` argument and an appropriate regularizer from the [`tensorflow.keras.regularizers`](https://www.tensorflow.org/api_docs/python/tf/keras/regularizers) module we imported for you.  \n",
    "\n",
    "__Optimizer schedules__<br>\n",
    "Quite often your optimizer does not run efficiently through the loss function surface. Remember that theory ensures a convergence of mini-batch SGD if and only if the learing rate decreases sufficiently fast. A way to apply this to your model training is to use a learning rate scheduler (learning rate decay) that reduces the learning rate over the number of update steps. The [`tf.keras.optimizers.schedules`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules) module offers you some approaches to do that. \n",
    "\n",
    "Note that to apply this to your `model_compile_and_fit()` function you defined above you need to implement the learning rate schedule either in there or with a helper function that your function calls inside. \n",
    "\n",
    "If you want to visualize different schedulers you can define them and call them on a range of values and plot them in a line plot. \n",
    "\n",
    "__Early stopping__<br>\n",
    "Earyl stopping is a procedure that enables you to stop your training earlier than defined by your `max_epochs` argument. It is used in practices to \n",
    "1. determine the optimal parameter vector by monitoring the validation error closely (if it rises again too much stuck with the best parameters found until then) and\n",
    "2. to save expensive resources (either in terms of monetary costs or ecological costs).\n",
    "\n",
    "To implement early stopping in TensorFlow the `tf.keras` module offers you a `callback` named [`tf.keras.callback.EarlyStopping()`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) that monitors for you a certain metric (it makes sense here to use a validation metric) and to stop training after a certain number of epochs with no improvement or by defining a certain `min_delta` that defines a minimum value of improvement - if below the callback stops your training. \n",
    "\n",
    "You can add this callback simply to the callbacks defined in your `get_callbacks()` function you defined above.\n",
    "\n",
    "__Dropout__<br>\n",
    "Dropout was one of the important developments in regularization for neural networks. It was developed by Geoffrey Hinton and his team at Toronto University. \n",
    "\n",
    "Dropout can be applied to each layer in your network and is implemented in `tf.keras` by an own layer named `Dropout()` awaiting a dropout rate set by you. So to introduce dropout you have to rework your model design.  \n",
    "\n",
    "Make use of your knowledge and apply tuning techniques to improve your network. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3107bc",
   "metadata": {},
   "source": [
    "### Normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61df2721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "with tf.device('/cpu:0'):\n",
    "    normal_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Normalization(axis=1),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu', input_dim = 42),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dense(1,kernel_initializer = 'uniform')\n",
    "      ])\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    normal_model_history = model_compile_and_fit(X=X_train, \n",
    "                                            y=y_train,\n",
    "                                            model= normal_model,\n",
    "                                            name='normal_model',\n",
    "                                            optimizer='Adam', \n",
    "                                            max_epochs= EPOCHS )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88e34c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    # plot MSE history \n",
    "    plot_metric(normal_model_history)\n",
    "\n",
    "    # Evaluate the small model on test set using .evaluate\n",
    "    loss, mse = normal_model.evaluate(X_test, y_test, verbose=2)\n",
    "    print(f'Model MSE: {mse}')\n",
    "    print('--------'*5)\n",
    "\n",
    "# Predict values for test set\n",
    "y_pred = normal_model.predict(X_test)\n",
    "y_pred_train = normal_model.predict(X_train)\n",
    "\n",
    "\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "test_results['normal model'] =  [rmse_train, rmse_test]\n",
    "\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e81d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_results, index=['RMSE Train', 'RMSE Test']).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd66d116",
   "metadata": {},
   "source": [
    "### Regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b691a59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l2 regularisation\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    l2_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Normalization(axis=1),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu',\n",
    "            kernel_regularizer=regularizers.l2(0.01), input_dim = 42),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu',\n",
    "            kernel_regularizer=regularizers.l2(0.01)),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu',\n",
    "            kernel_regularizer=regularizers.l2(0.01)),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu',\n",
    "            kernel_regularizer=regularizers.l2(0.01)),\n",
    "            tf.keras.layers.Dense(1,kernel_initializer = 'uniform')\n",
    "      ])\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    l2_model_history = model_compile_and_fit(X=X_train, \n",
    "                                            y=y_train,\n",
    "                                            model= l2_model,\n",
    "                                            name='l2_model',\n",
    "                                            optimizer='Adam', \n",
    "                                            max_epochs= EPOCHS )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5718e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    # plot MSE history \n",
    "    plot_metric(l2_model_history)\n",
    "\n",
    "    # Evaluate the small model on test set using .evaluate\n",
    "    loss, mse = l2_model.evaluate(X_test, y_test, verbose=2)\n",
    "    print(f'Model MSE: {mse}')\n",
    "    print('--------'*5)\n",
    "\n",
    "# Predict values for test set\n",
    "y_pred = l2_model.predict(X_test)\n",
    "y_pred_train = l2_model.predict(X_train)\n",
    "\n",
    "\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "test_results['l2 model'] =  [rmse_train, rmse_test]\n",
    "\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd51041",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_results, index=['RMSE Train', 'RMSE Test']).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd09b62",
   "metadata": {},
   "source": [
    "### Schedules learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a344a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# schedules https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules\n",
    "\n",
    "\n",
    "initial_learning_rate = 0.1\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=lr_schedule,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False,\n",
    "    name='Adam',\n",
    ")\n",
    "\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    sch_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Normalization(axis=1),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu',\n",
    "            kernel_regularizer=regularizers.l2(0.01), input_dim = 42),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu',\n",
    "            kernel_regularizer=regularizers.l2(0.01)),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu',\n",
    "            kernel_regularizer=regularizers.l2(0.01)),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu',\n",
    "            kernel_regularizer=regularizers.l2(0.01)),\n",
    "            tf.keras.layers.Dense(1,kernel_initializer = 'uniform')\n",
    "      ])\n",
    "\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    sch_model_history = model_compile_and_fit(X=X_train, \n",
    "                                            y=y_train,\n",
    "                                            model= sch_model,\n",
    "                                            name='sch_model',\n",
    "                                            optimizer=optimizer, \n",
    "                                            max_epochs= EPOCHS )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77197aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    # plot MSE history \n",
    "    plot_metric(sch_model_history)\n",
    "\n",
    "    # Evaluate the small model on test set using .evaluate\n",
    "    loss, mse = sch_model.evaluate(X_test, y_test, verbose=2)\n",
    "    print(f'Model MSE: {mse}')\n",
    "    print('--------'*5)\n",
    "\n",
    "# Predict values for test set\n",
    "y_pred = sch_model.predict(X_test)\n",
    "y_pred_train = sch_model.predict(X_train)\n",
    "\n",
    "\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "test_results['schedule model'] =  [rmse_train, rmse_test]\n",
    "\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e8c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping : https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\n",
    "### TODO two callbacks\n",
    "# callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369781d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_results, index=['RMSE Train', 'RMSE Test']).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f1e23e",
   "metadata": {},
   "source": [
    "### Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2a4f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop\n",
    "\n",
    "initial_learning_rate = 0.1\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=lr_schedule,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False,\n",
    "    name='Adam',\n",
    ")\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    drop_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Normalization(axis=1),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu',\n",
    "            kernel_regularizer=regularizers.l2(0.01), input_dim = 42),\n",
    "            tf.keras.layers.Dropout(0.25),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu',\n",
    "            kernel_regularizer=regularizers.l2(0.01)),\n",
    "            tf.keras.layers.Dropout(0.25),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu',\n",
    "            kernel_regularizer=regularizers.l2(0.01)),\n",
    "            tf.keras.layers.Dropout(0.25),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu',\n",
    "            kernel_regularizer=regularizers.l2(0.01)),\n",
    "            tf.keras.layers.Dropout(0.25),\n",
    "            tf.keras.layers.Dense(1,kernel_initializer = 'uniform')\n",
    "      ])\n",
    "\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    drop_model_history = model_compile_and_fit(X=X_train, \n",
    "                                            y=y_train,\n",
    "                                            model= drop_model,\n",
    "                                            name='drop_model',\n",
    "                                            optimizer=optimizer, \n",
    "                                            max_epochs= EPOCHS )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c3a6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    # plot MSE history \n",
    "    plot_metric(drop_model_history)  #\n",
    "\n",
    "    # Evaluate the small model on test set using .evaluate\n",
    "    loss, mse = drop_model.evaluate(X_test, y_test, verbose=2)  #\n",
    "    print(f'Model MSE: {mse}')\n",
    "    print('--------'*5)\n",
    "\n",
    "# Predict values for test set\n",
    "y_pred = drop_model.predict(X_test)\n",
    "y_pred_train = drop_model.predict(X_train)\n",
    "\n",
    "\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "test_results['drop model'] =  [rmse_train, rmse_test]\n",
    "\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166d1d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_results, index=['RMSE Train', 'RMSE Test']).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fa41ce",
   "metadata": {},
   "source": [
    "### leaky relu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f0f9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel initializer leaky Relu : https://keras.io/api/layers/activation_layers/leaky_relu/\n",
    "\n",
    "\n",
    "initial_learning_rate = 0.1\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=lr_schedule,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False,\n",
    "    name='Adam',\n",
    ")\n",
    "leaky_relu = tf.keras.layers.LeakyReLU()\n",
    "#  f(x) = alpha * x if x < 0\n",
    "#  f(x) = x if x >= 0\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    leaky_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Normalization(axis=1),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation=leaky_relu,\n",
    "            kernel_regularizer=regularizers.l2(0.01), input_dim = 42),\n",
    "            tf.keras.layers.Dropout(0.25),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation=leaky_relu,\n",
    "            kernel_regularizer=regularizers.l2(0.01)),\n",
    "            tf.keras.layers.Dropout(0.25),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation=leaky_relu,\n",
    "            kernel_regularizer=regularizers.l2(0.01)),\n",
    "            tf.keras.layers.Dropout(0.25),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation=leaky_relu,\n",
    "            kernel_regularizer=regularizers.l2(0.01)),\n",
    "            tf.keras.layers.Dropout(0.25),\n",
    "            tf.keras.layers.Dense(1,kernel_initializer = 'uniform')\n",
    "      ])\n",
    "\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    leaky_model_history = model_compile_and_fit(X=X_train, \n",
    "                                            y=y_train,\n",
    "                                            model= leaky_model,\n",
    "                                            name='leaky_model',\n",
    "                                            optimizer=optimizer, \n",
    "                                            max_epochs= EPOCHS )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b63ba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    # plot MSE history \n",
    "    plot_metric(leaky_model_history)  #\n",
    "\n",
    "    # Evaluate the small model on test set using .evaluate\n",
    "    loss, mse = drop_model.evaluate(X_test, y_test, verbose=2)  #\n",
    "    print(f'Model MSE: {mse}')\n",
    "    print('--------'*5)\n",
    "\n",
    "# Predict values for test set\n",
    "y_pred = leaky_model.predict(X_test)\n",
    "y_pred_train = leaky_model.predict(X_train)\n",
    "\n",
    "\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "test_results['leaky model'] =  [rmse_train, rmse_test]\n",
    "\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecca4bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_results, index=['RMSE Train', 'RMSE Test']).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6ca8a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n",
      "Epoch 1/5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 06:46:50.656915: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-08 06:46:50.657049: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-04-08 06:46:50.739671: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 1s 16ms/step - loss: 28.6750 - mse: 1612.3982 - val_loss: 21.3275 - val_mse: 924.5296\n",
      "Epoch 2/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.8406 - mse: 973.1659 - val_loss: 21.3687 - val_mse: 920.0355\n",
      "Epoch 3/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.8475 - mse: 972.1642 - val_loss: 21.8871 - val_mse: 913.9721\n",
      "Epoch 4/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.8224 - mse: 968.0291 - val_loss: 21.0370 - val_mse: 961.8446\n",
      "Epoch 5/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 21.4393 - mse: 948.8069 - val_loss: 21.8956 - val_mse: 1070.2122\n",
      "Epoch 6/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 21.5851 - mse: 967.4009 - val_loss: 22.1525 - val_mse: 907.3807\n",
      "Epoch 7/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 22.5007 - mse: 1000.3322 - val_loss: 26.7123 - val_mse: 1446.5366\n",
      "Epoch 8/5000\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 23.3448 - mse: 1066.2283 - val_loss: 23.5845 - val_mse: 1214.7184\n",
      "Epoch 9/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 22.0001 - mse: 981.3208 - val_loss: 21.2606 - val_mse: 1012.7788\n",
      "Epoch 10/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 21.8959 - mse: 976.0662 - val_loss: 21.6096 - val_mse: 1053.9562\n",
      "Epoch 11/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 21.4220 - mse: 951.6129 - val_loss: 20.7748 - val_mse: 911.5577\n",
      "Epoch 12/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 21.2670 - mse: 943.5594 - val_loss: 21.5537 - val_mse: 1059.6603\n",
      "Epoch 13/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 21.6283 - mse: 957.8318 - val_loss: 20.9826 - val_mse: 1001.4449\n",
      "Epoch 14/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2687 - mse: 941.2187 - val_loss: 20.5472 - val_mse: 896.7044\n",
      "Epoch 15/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 21.2906 - mse: 934.6671 - val_loss: 20.5056 - val_mse: 948.5931\n",
      "Epoch 16/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 21.1384 - mse: 944.7822 - val_loss: 21.1178 - val_mse: 1033.0974\n",
      "Epoch 17/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1211 - mse: 934.9282 - val_loss: 20.3418 - val_mse: 937.0063\n",
      "Epoch 18/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.7695 - mse: 917.6638 - val_loss: 20.7068 - val_mse: 991.5754\n",
      "Epoch 19/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 20.7418 - mse: 916.7426 - val_loss: 20.7255 - val_mse: 994.4899\n",
      "Epoch 20/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.8190 - mse: 913.5021 - val_loss: 22.9166 - val_mse: 1181.0833\n",
      "Epoch 21/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.7245 - mse: 914.0320 - val_loss: 21.6259 - val_mse: 1077.9635\n",
      "Epoch 22/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.8058 - mse: 926.3364 - val_loss: 20.2507 - val_mse: 931.2722\n",
      "Epoch 23/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 20.9034 - mse: 929.7668 - val_loss: 20.4572 - val_mse: 963.4846\n",
      "Epoch 24/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.5792 - mse: 904.5192 - val_loss: 20.2595 - val_mse: 886.3544\n",
      "Epoch 25/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 20.8030 - mse: 919.0774 - val_loss: 20.3228 - val_mse: 869.8704\n",
      "Epoch 26/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.7813 - mse: 973.5380 - val_loss: 20.9470 - val_mse: 1016.9185\n",
      "Epoch 27/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.9269 - mse: 935.2772 - val_loss: 20.6246 - val_mse: 856.1025\n",
      "Epoch 28/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.6437 - mse: 913.8781 - val_loss: 20.7763 - val_mse: 998.8218\n",
      "Epoch 29/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2998 - mse: 938.9407 - val_loss: 21.3870 - val_mse: 1057.6582\n",
      "Epoch 30/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2000 - mse: 953.1653 - val_loss: 20.3462 - val_mse: 869.1523\n",
      "Epoch 31/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.5494 - mse: 897.6452 - val_loss: 20.6626 - val_mse: 853.1939\n",
      "Epoch 32/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 20.4995 - mse: 910.1142 - val_loss: 20.3343 - val_mse: 874.2823\n",
      "Epoch 33/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.4717 - mse: 898.4675 - val_loss: 20.6992 - val_mse: 850.9385\n",
      "Epoch 34/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.4478 - mse: 895.9472 - val_loss: 20.4995 - val_mse: 863.8933\n",
      "Epoch 35/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.4909 - mse: 903.5290 - val_loss: 20.2354 - val_mse: 879.3427\n",
      "Epoch 36/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.5989 - mse: 903.6849 - val_loss: 20.1457 - val_mse: 905.7088\n",
      "Epoch 37/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.9627 - mse: 921.8359 - val_loss: 20.1290 - val_mse: 887.5881\n",
      "Epoch 38/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.9558 - mse: 944.8910 - val_loss: 20.2764 - val_mse: 920.9277\n",
      "Epoch 39/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1524 - mse: 936.8819 - val_loss: 21.7311 - val_mse: 1082.7386\n",
      "Epoch 40/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.5936 - mse: 905.5781 - val_loss: 20.1449 - val_mse: 880.0999\n",
      "Epoch 41/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.4900 - mse: 906.8184 - val_loss: 20.2009 - val_mse: 921.3624\n",
      "Epoch 42/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.4437 - mse: 895.5249 - val_loss: 20.3445 - val_mse: 950.3706\n",
      "Epoch 43/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.3936 - mse: 906.0322 - val_loss: 20.3491 - val_mse: 858.5281\n",
      "Epoch 44/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.5240 - mse: 902.3398 - val_loss: 20.3940 - val_mse: 921.3265\n",
      "Epoch 45/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.5579 - mse: 909.2247 - val_loss: 21.2256 - val_mse: 1037.7821\n",
      "Epoch 46/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.6947 - mse: 919.8238 - val_loss: 20.9871 - val_mse: 850.3705\n",
      "Epoch 47/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.5187 - mse: 908.0741 - val_loss: 20.3004 - val_mse: 873.6497\n",
      "Epoch 48/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.4751 - mse: 902.5520 - val_loss: 20.3157 - val_mse: 859.5236\n",
      "Epoch 49/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.9707 - mse: 931.2029 - val_loss: 20.2198 - val_mse: 933.8775\n",
      "Epoch 50/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.4151 - mse: 898.0457 - val_loss: 20.7256 - val_mse: 991.3087\n",
      "Epoch 51/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.5729 - mse: 906.9428 - val_loss: 20.3487 - val_mse: 951.6756\n",
      "Epoch 52/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.3572 - mse: 901.2802 - val_loss: 20.1135 - val_mse: 887.8417\n",
      "Epoch 53/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.3699 - mse: 895.6174 - val_loss: 20.0964 - val_mse: 898.0801\n",
      "Epoch 54/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.7680 - mse: 919.7375 - val_loss: 20.3909 - val_mse: 860.7742\n",
      "Epoch 55/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.5504 - mse: 912.9562 - val_loss: 20.4673 - val_mse: 852.5930\n",
      "Epoch 56/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.8969 - mse: 931.9222 - val_loss: 20.1951 - val_mse: 929.1467\n",
      "Epoch 57/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.6043 - mse: 912.0389 - val_loss: 20.1087 - val_mse: 896.1595\n",
      "Epoch 58/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.5395 - mse: 909.4166 - val_loss: 21.1077 - val_mse: 844.7127\n",
      "Epoch 59/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.3243 - mse: 894.6100 - val_loss: 20.8597 - val_mse: 1003.7882\n",
      "Epoch 60/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.4566 - mse: 900.1874 - val_loss: 20.1532 - val_mse: 872.6400\n",
      "Epoch 61/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.8291 - mse: 911.3701 - val_loss: 21.8756 - val_mse: 1094.7534\n",
      "Epoch 62/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 20.6406 - mse: 919.2385 - val_loss: 20.7129 - val_mse: 992.2404\n",
      "Epoch 63/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 20.3198 - mse: 886.8752 - val_loss: 20.2192 - val_mse: 860.4200\n",
      "Epoch 64/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 20.4352 - mse: 901.1557 - val_loss: 20.1096 - val_mse: 899.9361\n",
      "Epoch 65/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.3131 - mse: 897.5416 - val_loss: 20.4098 - val_mse: 954.8640\n",
      "Epoch 66/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.5576 - mse: 904.6701 - val_loss: 20.3331 - val_mse: 940.5479\n",
      "Epoch 67/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 20.4269 - mse: 902.3210 - val_loss: 20.4261 - val_mse: 963.2012\n",
      "Epoch 68/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.3165 - mse: 901.4009 - val_loss: 20.2031 - val_mse: 924.1290\n",
      "Epoch 69/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.2871 - mse: 891.9302 - val_loss: 20.1422 - val_mse: 924.7957\n",
      "Epoch 70/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.4057 - mse: 897.4073 - val_loss: 20.2942 - val_mse: 942.8959\n",
      "Epoch 71/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.4990 - mse: 904.6121 - val_loss: 20.4891 - val_mse: 966.4850\n",
      "Epoch 72/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.5517 - mse: 911.0795 - val_loss: 20.3171 - val_mse: 861.5071\n",
      "Epoch 73/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.3131 - mse: 892.6344 - val_loss: 20.0799 - val_mse: 901.0467\n",
      "Epoch 74/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.4696 - mse: 896.6106 - val_loss: 20.2301 - val_mse: 934.8802\n",
      "Epoch 75/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.7088 - mse: 918.2131 - val_loss: 21.2222 - val_mse: 1035.1475\n",
      "Epoch 76/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.5417 - mse: 910.5810 - val_loss: 20.2623 - val_mse: 853.3428\n",
      "Epoch 77/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.5458 - mse: 897.6962 - val_loss: 20.2075 - val_mse: 903.1168\n",
      "Epoch 78/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.3106 - mse: 895.9501 - val_loss: 20.2139 - val_mse: 855.9527\n",
      "Epoch 79/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.2725 - mse: 888.8270 - val_loss: 20.0643 - val_mse: 884.5707\n",
      "Epoch 80/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.4592 - mse: 909.2863 - val_loss: 20.2061 - val_mse: 934.0851\n",
      "Epoch 81/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.3024 - mse: 889.6138 - val_loss: 20.2559 - val_mse: 935.7646\n",
      "Epoch 82/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.2729 - mse: 888.8519 - val_loss: 20.1810 - val_mse: 929.6082\n",
      "Epoch 83/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.6489 - mse: 915.8685 - val_loss: 20.3681 - val_mse: 844.1725\n",
      "Epoch 84/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.2749 - mse: 885.7102 - val_loss: 20.7183 - val_mse: 989.5117\n",
      "Epoch 85/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.3665 - mse: 902.2229 - val_loss: 20.1739 - val_mse: 867.7971\n",
      "Epoch 86/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.2662 - mse: 890.3875 - val_loss: 20.2215 - val_mse: 861.6148\n",
      "Epoch 87/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.4723 - mse: 898.9336 - val_loss: 20.5068 - val_mse: 852.0233\n",
      "Epoch 88/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.2767 - mse: 896.5659 - val_loss: 20.7453 - val_mse: 839.9608\n",
      "Epoch 89/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.5497 - mse: 895.5366 - val_loss: 20.0765 - val_mse: 895.3585\n",
      "Epoch 90/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.2722 - mse: 897.2521 - val_loss: 20.0835 - val_mse: 873.3738\n",
      "Epoch 91/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.3234 - mse: 893.3132 - val_loss: 20.0411 - val_mse: 877.4398\n",
      "Epoch 92/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.6024 - mse: 913.7345 - val_loss: 20.3588 - val_mse: 945.6345\n",
      "Epoch 93/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.4827 - mse: 902.8608 - val_loss: 20.0981 - val_mse: 868.2878\n",
      "Epoch 94/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.7244 - mse: 918.3864 - val_loss: 21.8941 - val_mse: 1093.7585\n",
      "Epoch 95/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0726 - mse: 936.6746 - val_loss: 20.4894 - val_mse: 842.7335\n",
      "Epoch 96/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.3356 - mse: 892.9436 - val_loss: 20.3012 - val_mse: 857.3294\n",
      "Epoch 97/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.2689 - mse: 890.4528 - val_loss: 20.1733 - val_mse: 932.3895\n",
      "Epoch 98/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.4428 - mse: 895.5845 - val_loss: 21.2708 - val_mse: 1040.6434\n",
      "Epoch 99/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.2535 - mse: 894.4222 - val_loss: 20.1397 - val_mse: 872.7694\n",
      "Epoch 100/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.3005 - mse: 890.6354 - val_loss: 20.2778 - val_mse: 919.9187\n",
      "Epoch 101/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.2518 - mse: 889.8365 - val_loss: 20.2249 - val_mse: 940.2221\n",
      "Epoch 102/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.3019 - mse: 893.9348 - val_loss: 20.0144 - val_mse: 886.6744\n",
      "Epoch 103/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.2587 - mse: 891.7000 - val_loss: 20.3145 - val_mse: 940.1356\n",
      "Epoch 104/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.2653 - mse: 888.4711 - val_loss: 20.1144 - val_mse: 901.9887\n",
      "Epoch 105/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.2438 - mse: 885.2352 - val_loss: 19.9982 - val_mse: 889.3359\n",
      "Epoch 106/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.3788 - mse: 884.9208 - val_loss: 20.0213 - val_mse: 874.1786\n",
      "Epoch 107/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.3277 - mse: 897.0121 - val_loss: 20.5602 - val_mse: 953.2739\n",
      "Epoch 108/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.5307 - mse: 901.7112 - val_loss: 20.3821 - val_mse: 840.6610\n",
      "Epoch 109/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.8300 - mse: 916.6669 - val_loss: 21.1750 - val_mse: 1033.7932\n",
      "Epoch 110/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.2199 - mse: 887.8769 - val_loss: 20.0633 - val_mse: 889.5505\n",
      "Epoch 111/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.1108 - mse: 879.0809 - val_loss: 19.9636 - val_mse: 884.1879\n",
      "Epoch 112/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.1739 - mse: 887.6257 - val_loss: 20.1648 - val_mse: 880.7019\n",
      "Epoch 113/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.7721 - mse: 916.9234 - val_loss: 20.1245 - val_mse: 920.5787\n",
      "Epoch 114/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.7076 - mse: 909.9026 - val_loss: 20.1599 - val_mse: 907.9072\n",
      "Epoch 115/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.2976 - mse: 890.5065 - val_loss: 21.9619 - val_mse: 1102.6042\n",
      "Epoch 116/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.8293 - mse: 911.7133 - val_loss: 20.1838 - val_mse: 921.3731\n",
      "Epoch 117/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.1034 - mse: 881.5471 - val_loss: 20.4960 - val_mse: 964.4005\n",
      "Epoch 118/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.3859 - mse: 893.3049 - val_loss: 19.9834 - val_mse: 874.7160\n",
      "Epoch 119/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.2797 - mse: 889.7541 - val_loss: 21.4873 - val_mse: 842.3250\n",
      "Epoch 120/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.6035 - mse: 895.2490 - val_loss: 20.0216 - val_mse: 904.5244\n",
      "Epoch 121/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.1557 - mse: 883.4855 - val_loss: 19.9919 - val_mse: 884.8906\n",
      "Epoch 122/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.1714 - mse: 884.5377 - val_loss: 20.2249 - val_mse: 898.3652\n",
      "Epoch 123/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.1218 - mse: 876.8103 - val_loss: 20.6027 - val_mse: 978.6033\n",
      "Epoch 124/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.4363 - mse: 900.3882 - val_loss: 20.3279 - val_mse: 954.3478\n",
      "Epoch 125/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.2618 - mse: 888.9103 - val_loss: 20.1505 - val_mse: 915.6052\n",
      "Epoch 126/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.2532 - mse: 882.2404 - val_loss: 19.9455 - val_mse: 884.3398\n",
      "Epoch 127/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.3816 - mse: 894.4025 - val_loss: 20.0499 - val_mse: 854.6924\n",
      "Epoch 128/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.1971 - mse: 873.6848 - val_loss: 20.4256 - val_mse: 961.3621\n",
      "Epoch 129/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.4151 - mse: 894.1619 - val_loss: 20.1940 - val_mse: 936.5081\n",
      "Epoch 130/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.2199 - mse: 890.1317 - val_loss: 20.0840 - val_mse: 911.2043\n",
      "Epoch 131/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 20.1019 - mse: 880.4119 - val_loss: 19.9319 - val_mse: 871.2506\n",
      "Epoch 132/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 20.3038 - mse: 891.5410 - val_loss: 19.9491 - val_mse: 858.8398\n",
      "Epoch 133/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 20.2633 - mse: 882.8495 - val_loss: 19.9253 - val_mse: 889.7173\n",
      "Epoch 134/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.1874 - mse: 884.0549 - val_loss: 20.1178 - val_mse: 930.1478\n",
      "Epoch 135/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 20.0696 - mse: 877.1142 - val_loss: 20.2377 - val_mse: 834.3523\n",
      "Epoch 136/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.3974 - mse: 893.6405 - val_loss: 19.9458 - val_mse: 876.3350\n",
      "Epoch 137/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 20.0912 - mse: 878.4472 - val_loss: 20.2889 - val_mse: 838.7304\n",
      "Epoch 138/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.2477 - mse: 885.2672 - val_loss: 20.2282 - val_mse: 915.8174\n",
      "Epoch 139/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 20.1630 - mse: 885.5934 - val_loss: 19.8939 - val_mse: 859.1514\n",
      "Epoch 140/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.2207 - mse: 879.6767 - val_loss: 19.8986 - val_mse: 887.2115\n",
      "Epoch 141/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 20.3818 - mse: 893.4791 - val_loss: 20.3438 - val_mse: 841.0590\n",
      "Epoch 142/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.1374 - mse: 883.6650 - val_loss: 20.3297 - val_mse: 830.2748\n",
      "Epoch 143/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 20.6592 - mse: 898.3183 - val_loss: 20.0905 - val_mse: 919.0592\n",
      "Epoch 144/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.0215 - mse: 870.7161 - val_loss: 20.1140 - val_mse: 905.8812\n",
      "Epoch 145/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.1947 - mse: 889.7223 - val_loss: 19.9644 - val_mse: 868.2842\n",
      "Epoch 146/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.3467 - mse: 884.8955 - val_loss: 20.0192 - val_mse: 893.7770\n",
      "Epoch 147/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.1216 - mse: 883.3771 - val_loss: 19.9014 - val_mse: 877.7126\n",
      "Epoch 148/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 20.5088 - mse: 903.9028 - val_loss: 19.9878 - val_mse: 867.9589\n",
      "Epoch 149/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.1085 - mse: 874.6324 - val_loss: 20.0203 - val_mse: 885.3898\n",
      "Epoch 150/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 20.0170 - mse: 881.8329 - val_loss: 20.2454 - val_mse: 841.2642\n",
      "Epoch 151/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.7168 - mse: 903.8197 - val_loss: 19.9680 - val_mse: 870.2825\n",
      "Epoch 152/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.4918 - mse: 903.8320 - val_loss: 20.5577 - val_mse: 975.3062\n",
      "Epoch 153/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.1873 - mse: 887.0574 - val_loss: 19.9430 - val_mse: 884.7750\n",
      "Epoch 154/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.1681 - mse: 879.8421 - val_loss: 20.0406 - val_mse: 840.4441\n",
      "Epoch 155/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.4121 - mse: 899.7581 - val_loss: 20.1178 - val_mse: 930.3102\n",
      "Epoch 156/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.2823 - mse: 883.8896 - val_loss: 20.0297 - val_mse: 899.8936\n",
      "Epoch 157/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.4242 - mse: 895.1342 - val_loss: 20.5666 - val_mse: 829.2855\n",
      "Epoch 158/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.2511 - mse: 878.8327 - val_loss: 19.9764 - val_mse: 851.8144\n",
      "Epoch 159/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.9968 - mse: 875.1566 - val_loss: 20.4346 - val_mse: 955.5816\n",
      "Epoch 160/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.1084 - mse: 875.3116 - val_loss: 19.9426 - val_mse: 866.1309\n",
      "Epoch 161/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.2635 - mse: 891.3760 - val_loss: 20.3256 - val_mse: 947.2314\n",
      "Epoch 162/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.5890 - mse: 901.7714 - val_loss: 20.1172 - val_mse: 900.6510\n",
      "Epoch 163/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.1419 - mse: 888.7688 - val_loss: 20.2907 - val_mse: 838.9035\n",
      "Epoch 164/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.1740 - mse: 884.9152 - val_loss: 20.2349 - val_mse: 917.2056\n",
      "Epoch 165/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.2097 - mse: 887.3890 - val_loss: 20.1962 - val_mse: 934.1152\n",
      "Epoch 166/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.1109 - mse: 874.1370 - val_loss: 20.3787 - val_mse: 945.7928\n",
      "Epoch 167/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.3403 - mse: 887.3525 - val_loss: 19.9128 - val_mse: 846.8615\n",
      "Epoch 168/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.9720 - mse: 869.3676 - val_loss: 20.0701 - val_mse: 918.1437\n",
      "Epoch 169/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.0627 - mse: 867.3691 - val_loss: 20.1422 - val_mse: 928.3646\n",
      "Epoch 170/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.4888 - mse: 903.8115 - val_loss: 20.7156 - val_mse: 820.1149\n",
      "Epoch 171/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.5353 - mse: 876.6623 - val_loss: 20.0167 - val_mse: 885.2418\n",
      "Epoch 172/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.0167 - mse: 874.1196 - val_loss: 20.1996 - val_mse: 826.1982\n",
      "Epoch 173/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.0393 - mse: 867.1757 - val_loss: 20.0852 - val_mse: 917.6154\n",
      "Epoch 174/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.9890 - mse: 872.0480 - val_loss: 19.8497 - val_mse: 852.0098\n",
      "Epoch 175/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.1332 - mse: 872.2057 - val_loss: 19.8771 - val_mse: 902.4321\n",
      "Epoch 176/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.4250 - mse: 904.3051 - val_loss: 19.8534 - val_mse: 863.4355\n",
      "Epoch 177/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.1242 - mse: 872.3999 - val_loss: 19.8435 - val_mse: 888.9687\n",
      "Epoch 178/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.9909 - mse: 874.9731 - val_loss: 20.2933 - val_mse: 830.5114\n",
      "Epoch 179/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.2248 - mse: 874.0207 - val_loss: 19.8939 - val_mse: 842.8709\n",
      "Epoch 180/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 19.9690 - mse: 871.5441 - val_loss: 19.8622 - val_mse: 840.9994\n",
      "Epoch 181/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.3481 - mse: 880.6646 - val_loss: 20.1493 - val_mse: 823.9897\n",
      "Epoch 182/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.0319 - mse: 871.5717 - val_loss: 20.4329 - val_mse: 956.4850\n",
      "Epoch 183/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.2126 - mse: 878.5528 - val_loss: 19.9654 - val_mse: 915.4764\n",
      "Epoch 184/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.9446 - mse: 870.2711 - val_loss: 19.8737 - val_mse: 899.0956\n",
      "Epoch 185/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.8755 - mse: 855.9045 - val_loss: 20.0440 - val_mse: 922.7051\n",
      "Epoch 186/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.8853 - mse: 863.5142 - val_loss: 19.8045 - val_mse: 847.6483\n",
      "Epoch 187/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.0185 - mse: 866.6125 - val_loss: 20.1270 - val_mse: 924.4542\n",
      "Epoch 188/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.0960 - mse: 874.2513 - val_loss: 19.9654 - val_mse: 823.7728\n",
      "Epoch 189/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.9707 - mse: 854.8566 - val_loss: 19.7553 - val_mse: 847.3791\n",
      "Epoch 190/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.8369 - mse: 857.0605 - val_loss: 19.8873 - val_mse: 898.6409\n",
      "Epoch 191/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.9067 - mse: 864.3456 - val_loss: 19.6867 - val_mse: 839.3277\n",
      "Epoch 192/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.3270 - mse: 891.3329 - val_loss: 19.6692 - val_mse: 862.9633\n",
      "Epoch 193/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.2054 - mse: 887.3527 - val_loss: 20.0860 - val_mse: 821.9448\n",
      "Epoch 194/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.4827 - mse: 889.2880 - val_loss: 19.7656 - val_mse: 880.1319\n",
      "Epoch 195/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.8924 - mse: 863.6594 - val_loss: 20.4732 - val_mse: 965.2778\n",
      "Epoch 196/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.2803 - mse: 877.1387 - val_loss: 20.0556 - val_mse: 817.3113\n",
      "Epoch 197/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.0212 - mse: 868.8416 - val_loss: 19.7106 - val_mse: 857.2590\n",
      "Epoch 198/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.8377 - mse: 854.3376 - val_loss: 19.7831 - val_mse: 888.1244\n",
      "Epoch 199/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.2891 - mse: 888.1555 - val_loss: 19.9409 - val_mse: 831.0220\n",
      "Epoch 200/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.1187 - mse: 865.4645 - val_loss: 20.4740 - val_mse: 815.4391\n",
      "Epoch 201/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.3178 - mse: 879.9818 - val_loss: 21.5879 - val_mse: 1066.7028\n",
      "Epoch 202/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.2518 - mse: 893.1777 - val_loss: 19.8727 - val_mse: 908.1113\n",
      "Epoch 203/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.5066 - mse: 893.8848 - val_loss: 20.2236 - val_mse: 830.3928\n",
      "Epoch 204/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 20.1181 - mse: 874.8948 - val_loss: 19.7229 - val_mse: 860.0254\n",
      "Epoch 205/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.1359 - mse: 877.9825 - val_loss: 20.0378 - val_mse: 824.3523\n",
      "Epoch 206/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 20.0236 - mse: 859.3856 - val_loss: 19.7352 - val_mse: 853.4265\n",
      "Epoch 207/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.8664 - mse: 851.2916 - val_loss: 19.6934 - val_mse: 856.9634\n",
      "Epoch 208/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.1529 - mse: 878.4528 - val_loss: 20.4184 - val_mse: 965.9304\n",
      "Epoch 209/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 19.9165 - mse: 855.1344 - val_loss: 19.8752 - val_mse: 832.9509\n",
      "Epoch 210/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.0324 - mse: 874.2857 - val_loss: 19.6611 - val_mse: 841.7694\n",
      "Epoch 211/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.8165 - mse: 853.9078 - val_loss: 20.3165 - val_mse: 933.8027\n",
      "Epoch 212/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.1235 - mse: 879.4971 - val_loss: 20.0754 - val_mse: 807.0952\n",
      "Epoch 213/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.8525 - mse: 909.4975 - val_loss: 19.8459 - val_mse: 856.7953\n",
      "Epoch 214/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.9733 - mse: 873.5775 - val_loss: 19.8659 - val_mse: 840.7008\n",
      "Epoch 215/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.9624 - mse: 863.5249 - val_loss: 19.7083 - val_mse: 835.3204\n",
      "Epoch 216/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.9940 - mse: 869.3535 - val_loss: 20.1301 - val_mse: 816.8256\n",
      "Epoch 217/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.1755 - mse: 880.9755 - val_loss: 20.7256 - val_mse: 994.2546\n",
      "Epoch 218/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 19.9051 - mse: 863.8932 - val_loss: 19.9301 - val_mse: 827.8456\n",
      "Epoch 219/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.1380 - mse: 878.8406 - val_loss: 19.6671 - val_mse: 868.0154\n",
      "Epoch 220/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.8142 - mse: 857.9267 - val_loss: 20.8834 - val_mse: 1008.7439\n",
      "Epoch 221/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.9917 - mse: 866.3441 - val_loss: 19.6409 - val_mse: 875.3890\n",
      "Epoch 222/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.0119 - mse: 872.1337 - val_loss: 19.6394 - val_mse: 864.6154\n",
      "Epoch 223/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.2119 - mse: 887.4612 - val_loss: 19.7751 - val_mse: 881.1116\n",
      "Epoch 224/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.0362 - mse: 872.3842 - val_loss: 20.4493 - val_mse: 966.6495\n",
      "Epoch 225/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.1699 - mse: 874.6288 - val_loss: 19.9065 - val_mse: 815.0190\n",
      "Epoch 226/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.9573 - mse: 865.6198 - val_loss: 19.6332 - val_mse: 851.8791\n",
      "Epoch 227/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.8846 - mse: 861.0123 - val_loss: 20.2566 - val_mse: 945.8364\n",
      "Epoch 228/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.0211 - mse: 875.5194 - val_loss: 20.3690 - val_mse: 962.0576\n",
      "Epoch 229/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.9817 - mse: 864.2368 - val_loss: 19.6654 - val_mse: 832.4330\n",
      "Epoch 230/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.7889 - mse: 854.6221 - val_loss: 19.8109 - val_mse: 850.4626\n",
      "Epoch 231/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.8279 - mse: 858.9395 - val_loss: 19.5551 - val_mse: 854.0791\n",
      "Epoch 232/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.0649 - mse: 870.3441 - val_loss: 20.0438 - val_mse: 903.1874\n",
      "Epoch 233/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.6927 - mse: 848.2076 - val_loss: 19.7668 - val_mse: 880.8430\n",
      "Epoch 234/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.8120 - mse: 858.3885 - val_loss: 19.5356 - val_mse: 821.4108\n",
      "Epoch 235/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.7492 - mse: 846.2558 - val_loss: 20.0297 - val_mse: 842.2045\n",
      "Epoch 236/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.9500 - mse: 862.0693 - val_loss: 19.9353 - val_mse: 811.1071\n",
      "Epoch 237/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.8207 - mse: 852.7357 - val_loss: 19.4569 - val_mse: 845.0068\n",
      "Epoch 238/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.7524 - mse: 842.6183 - val_loss: 20.8578 - val_mse: 1004.7872\n",
      "Epoch 239/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.9257 - mse: 851.8241 - val_loss: 19.9623 - val_mse: 809.6190\n",
      "Epoch 240/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.7279 - mse: 844.5872 - val_loss: 19.5351 - val_mse: 855.0582\n",
      "Epoch 241/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.6435 - mse: 850.7122 - val_loss: 19.4667 - val_mse: 810.4334\n",
      "Epoch 242/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.6843 - mse: 833.7587 - val_loss: 19.6765 - val_mse: 809.6161\n",
      "Epoch 243/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.7674 - mse: 847.5840 - val_loss: 19.5228 - val_mse: 799.0208\n",
      "Epoch 244/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.8073 - mse: 840.8177 - val_loss: 20.7060 - val_mse: 989.5231\n",
      "Epoch 245/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.9768 - mse: 853.1484 - val_loss: 19.8807 - val_mse: 796.3314\n",
      "Epoch 246/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.6722 - mse: 837.9886 - val_loss: 19.8413 - val_mse: 900.2694\n",
      "Epoch 247/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.0683 - mse: 860.7412 - val_loss: 20.0873 - val_mse: 904.6619\n",
      "Epoch 248/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.0511 - mse: 868.0790 - val_loss: 19.4203 - val_mse: 834.5909\n",
      "Epoch 249/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.5655 - mse: 834.2941 - val_loss: 19.3984 - val_mse: 837.8873\n",
      "Epoch 250/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.5752 - mse: 846.1558 - val_loss: 19.7690 - val_mse: 899.4902\n",
      "Epoch 251/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.5678 - mse: 830.0299 - val_loss: 20.0185 - val_mse: 930.4979\n",
      "Epoch 252/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.5304 - mse: 837.2211 - val_loss: 19.3895 - val_mse: 842.4127\n",
      "Epoch 253/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.6427 - mse: 845.1707 - val_loss: 19.5014 - val_mse: 828.0156\n",
      "Epoch 254/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.1698 - mse: 880.4977 - val_loss: 20.2579 - val_mse: 794.7156\n",
      "Epoch 255/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.8047 - mse: 844.9760 - val_loss: 21.1643 - val_mse: 1033.6329\n",
      "Epoch 256/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.9504 - mse: 866.5797 - val_loss: 19.3930 - val_mse: 861.3969\n",
      "Epoch 257/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.6321 - mse: 834.6082 - val_loss: 19.5458 - val_mse: 816.8448\n",
      "Epoch 258/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.5701 - mse: 841.1655 - val_loss: 20.2368 - val_mse: 789.4448\n",
      "Epoch 259/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.7202 - mse: 846.5142 - val_loss: 19.4638 - val_mse: 809.9541\n",
      "Epoch 260/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.5925 - mse: 833.5849 - val_loss: 19.3331 - val_mse: 813.7384\n",
      "Epoch 261/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.5608 - mse: 830.0554 - val_loss: 19.3288 - val_mse: 858.4158\n",
      "Epoch 262/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.6057 - mse: 833.2517 - val_loss: 20.0959 - val_mse: 913.1057\n",
      "Epoch 263/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.4551 - mse: 829.1677 - val_loss: 19.3799 - val_mse: 867.7874\n",
      "Epoch 264/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.8389 - mse: 841.4202 - val_loss: 19.8448 - val_mse: 783.1390\n",
      "Epoch 265/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.8210 - mse: 847.0015 - val_loss: 19.5019 - val_mse: 876.9344\n",
      "Epoch 266/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.6736 - mse: 833.4918 - val_loss: 19.8307 - val_mse: 779.8672\n",
      "Epoch 267/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.9417 - mse: 860.5892 - val_loss: 19.2606 - val_mse: 805.3123\n",
      "Epoch 268/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.7399 - mse: 835.7266 - val_loss: 19.3229 - val_mse: 809.9698\n",
      "Epoch 269/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.5534 - mse: 838.6751 - val_loss: 19.3535 - val_mse: 804.2589\n",
      "Epoch 270/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.6982 - mse: 832.5910 - val_loss: 19.6966 - val_mse: 873.6348\n",
      "Epoch 271/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.5097 - mse: 832.0638 - val_loss: 19.2590 - val_mse: 842.8398\n",
      "Epoch 272/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.5056 - mse: 833.4833 - val_loss: 19.5257 - val_mse: 858.4606\n",
      "Epoch 273/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.4886 - mse: 820.7149 - val_loss: 19.7591 - val_mse: 889.4379\n",
      "Epoch 274/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.4088 - mse: 824.1653 - val_loss: 19.2352 - val_mse: 834.8574\n",
      "Epoch 275/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.6114 - mse: 828.3837 - val_loss: 19.8662 - val_mse: 892.3444\n",
      "Epoch 276/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.6107 - mse: 829.0428 - val_loss: 19.2573 - val_mse: 790.0383\n",
      "Epoch 277/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.4773 - mse: 825.3067 - val_loss: 19.6052 - val_mse: 836.7867\n",
      "Epoch 278/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 19.5255 - mse: 824.9896 - val_loss: 19.4574 - val_mse: 800.0864\n",
      "Epoch 279/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.6933 - mse: 838.9101 - val_loss: 20.3979 - val_mse: 775.9950\n",
      "Epoch 280/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 19.6535 - mse: 833.3718 - val_loss: 20.1084 - val_mse: 929.4048\n",
      "Epoch 281/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.6986 - mse: 845.2120 - val_loss: 19.2772 - val_mse: 812.4456\n",
      "Epoch 282/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.5127 - mse: 828.8190 - val_loss: 19.9646 - val_mse: 772.0513\n",
      "Epoch 283/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.7947 - mse: 846.8773 - val_loss: 19.1472 - val_mse: 823.9150\n",
      "Epoch 284/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3500 - mse: 814.6181 - val_loss: 19.5022 - val_mse: 778.2151\n",
      "Epoch 285/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.4202 - mse: 809.6334 - val_loss: 20.0480 - val_mse: 925.1494\n",
      "Epoch 286/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.4741 - mse: 821.0038 - val_loss: 19.2029 - val_mse: 797.4617\n",
      "Epoch 287/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3652 - mse: 813.7155 - val_loss: 19.1861 - val_mse: 821.9346\n",
      "Epoch 288/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.6609 - mse: 835.6623 - val_loss: 19.0689 - val_mse: 805.5974\n",
      "Epoch 289/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3562 - mse: 814.9455 - val_loss: 20.4064 - val_mse: 966.1152\n",
      "Epoch 290/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 19.3470 - mse: 815.4847 - val_loss: 19.0776 - val_mse: 827.3655\n",
      "Epoch 291/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.5659 - mse: 826.3179 - val_loss: 20.6212 - val_mse: 982.4289\n",
      "Epoch 292/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.5027 - mse: 835.5430 - val_loss: 19.0290 - val_mse: 809.5052\n",
      "Epoch 293/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2853 - mse: 819.4886 - val_loss: 19.1490 - val_mse: 801.8883\n",
      "Epoch 294/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.9751 - mse: 855.1077 - val_loss: 19.0184 - val_mse: 794.6723\n",
      "Epoch 295/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2424 - mse: 810.9198 - val_loss: 18.9918 - val_mse: 808.0735\n",
      "Epoch 296/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2380 - mse: 806.6362 - val_loss: 18.9847 - val_mse: 799.0284\n",
      "Epoch 297/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1852 - mse: 803.8487 - val_loss: 19.1967 - val_mse: 827.3471\n",
      "Epoch 298/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1768 - mse: 802.4461 - val_loss: 18.8786 - val_mse: 800.1353\n",
      "Epoch 299/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2978 - mse: 807.6651 - val_loss: 18.8896 - val_mse: 808.7642\n",
      "Epoch 300/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0806 - mse: 794.1392 - val_loss: 19.2412 - val_mse: 854.6429\n",
      "Epoch 301/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.4237 - mse: 823.1235 - val_loss: 19.3806 - val_mse: 880.2202\n",
      "Epoch 302/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2490 - mse: 808.3880 - val_loss: 19.5110 - val_mse: 763.1294\n",
      "Epoch 303/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.6324 - mse: 837.4089 - val_loss: 19.4303 - val_mse: 845.4442\n",
      "Epoch 304/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.0217 - mse: 858.8689 - val_loss: 19.2988 - val_mse: 864.9854\n",
      "Epoch 305/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.3951 - mse: 832.6878 - val_loss: 19.0627 - val_mse: 807.3817\n",
      "Epoch 306/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.5971 - mse: 825.2289 - val_loss: 19.2215 - val_mse: 776.0736\n",
      "Epoch 307/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3735 - mse: 813.5668 - val_loss: 19.1000 - val_mse: 805.5878\n",
      "Epoch 308/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.4059 - mse: 819.9808 - val_loss: 19.1469 - val_mse: 774.2767\n",
      "Epoch 309/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.2367 - mse: 805.8773 - val_loss: 19.1354 - val_mse: 848.3580\n",
      "Epoch 310/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.2920 - mse: 813.4930 - val_loss: 19.6552 - val_mse: 900.0397\n",
      "Epoch 311/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2544 - mse: 815.9361 - val_loss: 19.1656 - val_mse: 823.7870\n",
      "Epoch 312/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.4658 - mse: 818.6365 - val_loss: 19.4346 - val_mse: 810.2158\n",
      "Epoch 313/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.4002 - mse: 816.3940 - val_loss: 18.9759 - val_mse: 816.3285\n",
      "Epoch 314/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.2296 - mse: 808.1387 - val_loss: 19.4530 - val_mse: 865.5337\n",
      "Epoch 315/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1629 - mse: 802.6698 - val_loss: 19.4942 - val_mse: 859.3077\n",
      "Epoch 316/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3352 - mse: 817.9994 - val_loss: 19.3367 - val_mse: 872.5183\n",
      "Epoch 317/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.2855 - mse: 804.8867 - val_loss: 19.1362 - val_mse: 805.0212\n",
      "Epoch 318/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.5181 - mse: 820.8136 - val_loss: 19.7562 - val_mse: 910.4207\n",
      "Epoch 319/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.6337 - mse: 843.3992 - val_loss: 19.4133 - val_mse: 768.5576\n",
      "Epoch 320/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.4069 - mse: 809.2712 - val_loss: 18.9388 - val_mse: 820.3340\n",
      "Epoch 321/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 19.2344 - mse: 807.3783 - val_loss: 19.6462 - val_mse: 908.6246\n",
      "Epoch 322/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.2099 - mse: 803.2509 - val_loss: 19.1478 - val_mse: 825.7715\n",
      "Epoch 323/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.5169 - mse: 823.0287 - val_loss: 19.7102 - val_mse: 914.7532\n",
      "Epoch 324/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.3193 - mse: 815.9470 - val_loss: 19.2210 - val_mse: 838.6697\n",
      "Epoch 325/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2812 - mse: 807.6185 - val_loss: 18.9486 - val_mse: 784.0893\n",
      "Epoch 326/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.3043 - mse: 808.8947 - val_loss: 19.0561 - val_mse: 789.2737\n",
      "Epoch 327/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3983 - mse: 811.3525 - val_loss: 19.1164 - val_mse: 826.1555\n",
      "Epoch 328/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1844 - mse: 802.0237 - val_loss: 19.1433 - val_mse: 840.7992\n",
      "Epoch 329/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.3242 - mse: 818.4818 - val_loss: 18.9135 - val_mse: 770.2029\n",
      "Epoch 330/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3358 - mse: 805.0411 - val_loss: 20.6331 - val_mse: 982.8516\n",
      "Epoch 331/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.8199 - mse: 842.3877 - val_loss: 19.3986 - val_mse: 760.3756\n",
      "Epoch 332/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.8013 - mse: 836.8641 - val_loss: 20.4146 - val_mse: 964.7363\n",
      "Epoch 333/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.3709 - mse: 816.7441 - val_loss: 19.3709 - val_mse: 776.0085\n",
      "Epoch 334/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.5019 - mse: 827.1644 - val_loss: 19.5908 - val_mse: 754.5455\n",
      "Epoch 335/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.6719 - mse: 845.6315 - val_loss: 18.9438 - val_mse: 807.3562\n",
      "Epoch 336/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2355 - mse: 810.7635 - val_loss: 19.0985 - val_mse: 818.4691\n",
      "Epoch 337/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1703 - mse: 799.2051 - val_loss: 19.2537 - val_mse: 771.2434\n",
      "Epoch 338/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 19.2200 - mse: 804.7471 - val_loss: 20.0317 - val_mse: 928.3801\n",
      "Epoch 339/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.5978 - mse: 833.7168 - val_loss: 19.1219 - val_mse: 781.0461\n",
      "Epoch 340/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1351 - mse: 794.6993 - val_loss: 19.0532 - val_mse: 799.0208\n",
      "Epoch 341/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1954 - mse: 809.0626 - val_loss: 19.3128 - val_mse: 852.9840\n",
      "Epoch 342/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.3000 - mse: 814.5684 - val_loss: 19.5077 - val_mse: 762.2875\n",
      "Epoch 343/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2253 - mse: 798.9359 - val_loss: 19.5700 - val_mse: 871.4034\n",
      "Epoch 344/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1512 - mse: 802.7988 - val_loss: 19.0694 - val_mse: 841.9404\n",
      "Epoch 345/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.3610 - mse: 799.2455 - val_loss: 19.3453 - val_mse: 863.0102\n",
      "Epoch 346/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1765 - mse: 795.9038 - val_loss: 18.9853 - val_mse: 785.6375\n",
      "Epoch 347/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 19.1451 - mse: 795.7883 - val_loss: 19.8101 - val_mse: 903.8956\n",
      "Epoch 348/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.9931 - mse: 848.0123 - val_loss: 19.8804 - val_mse: 774.6567\n",
      "Epoch 349/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.6239 - mse: 835.4318 - val_loss: 19.1710 - val_mse: 794.4678\n",
      "Epoch 350/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.4776 - mse: 821.1779 - val_loss: 19.5862 - val_mse: 767.2352\n",
      "Epoch 351/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2086 - mse: 808.4968 - val_loss: 19.5852 - val_mse: 880.5985\n",
      "Epoch 352/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0968 - mse: 803.8352 - val_loss: 19.1628 - val_mse: 766.9811\n",
      "Epoch 353/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2005 - mse: 801.5724 - val_loss: 19.2113 - val_mse: 789.8390\n",
      "Epoch 354/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.3534 - mse: 810.2196 - val_loss: 19.1266 - val_mse: 768.5910\n",
      "Epoch 355/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2038 - mse: 801.2120 - val_loss: 18.9426 - val_mse: 803.0450\n",
      "Epoch 356/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2913 - mse: 812.6412 - val_loss: 19.6951 - val_mse: 914.4631\n",
      "Epoch 357/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3055 - mse: 814.6492 - val_loss: 19.5189 - val_mse: 892.7062\n",
      "Epoch 358/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0395 - mse: 796.1799 - val_loss: 18.9340 - val_mse: 831.9235\n",
      "Epoch 359/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2279 - mse: 797.5568 - val_loss: 19.1998 - val_mse: 770.2608\n",
      "Epoch 360/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3516 - mse: 811.5304 - val_loss: 19.2121 - val_mse: 759.6331\n",
      "Epoch 361/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0735 - mse: 788.5342 - val_loss: 19.1019 - val_mse: 835.5880\n",
      "Epoch 362/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2608 - mse: 802.3701 - val_loss: 19.4220 - val_mse: 758.0682\n",
      "Epoch 363/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1502 - mse: 795.5330 - val_loss: 18.8346 - val_mse: 796.1927\n",
      "Epoch 364/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2827 - mse: 798.7043 - val_loss: 19.2611 - val_mse: 762.9601\n",
      "Epoch 365/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2023 - mse: 790.1607 - val_loss: 19.0114 - val_mse: 788.3482\n",
      "Epoch 366/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1237 - mse: 792.4224 - val_loss: 18.9998 - val_mse: 774.2740\n",
      "Epoch 367/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9171 - mse: 775.0090 - val_loss: 18.8828 - val_mse: 788.3660\n",
      "Epoch 368/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0937 - mse: 787.7173 - val_loss: 19.9479 - val_mse: 897.3254\n",
      "Epoch 369/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0262 - mse: 792.2005 - val_loss: 18.8796 - val_mse: 788.7518\n",
      "Epoch 370/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.9503 - mse: 836.5601 - val_loss: 19.2100 - val_mse: 770.6032\n",
      "Epoch 371/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2397 - mse: 785.6113 - val_loss: 19.7330 - val_mse: 904.7733\n",
      "Epoch 372/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1388 - mse: 784.8015 - val_loss: 19.6604 - val_mse: 763.7029\n",
      "Epoch 373/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0237 - mse: 790.1817 - val_loss: 19.0776 - val_mse: 782.6815\n",
      "Epoch 374/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0292 - mse: 779.1150 - val_loss: 18.9836 - val_mse: 832.4919\n",
      "Epoch 375/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.1617 - mse: 792.3598 - val_loss: 19.5642 - val_mse: 761.3254\n",
      "Epoch 376/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.2745 - mse: 805.9656 - val_loss: 19.4571 - val_mse: 877.3593\n",
      "Epoch 377/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.2984 - mse: 794.6744 - val_loss: 18.9466 - val_mse: 806.7663\n",
      "Epoch 378/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8797 - mse: 771.7787 - val_loss: 19.3156 - val_mse: 843.7684\n",
      "Epoch 379/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1740 - mse: 796.9860 - val_loss: 19.8153 - val_mse: 909.5488\n",
      "Epoch 380/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.1569 - mse: 785.0738 - val_loss: 20.1259 - val_mse: 759.1923\n",
      "Epoch 381/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.5353 - mse: 807.4418 - val_loss: 18.9129 - val_mse: 807.3920\n",
      "Epoch 382/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3744 - mse: 806.8658 - val_loss: 19.1165 - val_mse: 812.6773\n",
      "Epoch 383/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.8447 - mse: 851.2100 - val_loss: 19.7193 - val_mse: 907.2671\n",
      "Epoch 384/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.5255 - mse: 822.9303 - val_loss: 19.2148 - val_mse: 845.8885\n",
      "Epoch 385/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3056 - mse: 807.2337 - val_loss: 20.8564 - val_mse: 784.6038\n",
      "Epoch 386/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.3502 - mse: 799.2396 - val_loss: 19.8033 - val_mse: 901.9948\n",
      "Epoch 387/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.2586 - mse: 794.4409 - val_loss: 19.0550 - val_mse: 791.3585\n",
      "Epoch 388/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.1821 - mse: 804.1028 - val_loss: 18.9279 - val_mse: 808.3631\n",
      "Epoch 389/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.0301 - mse: 785.9053 - val_loss: 19.0424 - val_mse: 789.1185\n",
      "Epoch 390/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9213 - mse: 770.1995 - val_loss: 20.6603 - val_mse: 983.9416\n",
      "Epoch 391/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.4065 - mse: 796.6597 - val_loss: 19.1379 - val_mse: 847.7489\n",
      "Epoch 392/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.0242 - mse: 786.4067 - val_loss: 18.9904 - val_mse: 836.3142\n",
      "Epoch 393/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.1963 - mse: 784.7462 - val_loss: 19.4813 - val_mse: 754.4950\n",
      "Epoch 394/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1222 - mse: 784.9631 - val_loss: 19.1990 - val_mse: 852.1963\n",
      "Epoch 395/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.7945 - mse: 773.9910 - val_loss: 19.2524 - val_mse: 856.0006\n",
      "Epoch 396/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.4669 - mse: 818.0157 - val_loss: 19.3556 - val_mse: 792.7046\n",
      "Epoch 397/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3157 - mse: 819.7675 - val_loss: 19.4433 - val_mse: 775.9254\n",
      "Epoch 398/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3896 - mse: 813.0031 - val_loss: 19.4505 - val_mse: 755.4031\n",
      "Epoch 399/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2044 - mse: 791.0709 - val_loss: 18.9477 - val_mse: 794.5314\n",
      "Epoch 400/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 19.1785 - mse: 799.2143 - val_loss: 19.2086 - val_mse: 766.8298\n",
      "Epoch 401/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3251 - mse: 779.8560 - val_loss: 21.0709 - val_mse: 999.8002\n",
      "Epoch 402/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9903 - mse: 792.5378 - val_loss: 19.0095 - val_mse: 808.0099\n",
      "Epoch 403/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.3871 - mse: 805.5048 - val_loss: 19.2178 - val_mse: 771.0609\n",
      "Epoch 404/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1751 - mse: 806.0202 - val_loss: 19.2610 - val_mse: 865.7463\n",
      "Epoch 405/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3023 - mse: 805.5066 - val_loss: 19.1672 - val_mse: 855.5594\n",
      "Epoch 406/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.4649 - mse: 817.9426 - val_loss: 19.1465 - val_mse: 754.5650\n",
      "Epoch 407/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1425 - mse: 794.2529 - val_loss: 18.9421 - val_mse: 812.0463\n",
      "Epoch 408/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1478 - mse: 788.8089 - val_loss: 19.3752 - val_mse: 870.6677\n",
      "Epoch 409/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.6987 - mse: 833.5551 - val_loss: 19.3627 - val_mse: 872.2073\n",
      "Epoch 410/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0929 - mse: 793.6517 - val_loss: 19.0844 - val_mse: 746.2916\n",
      "Epoch 411/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0983 - mse: 789.2120 - val_loss: 19.5292 - val_mse: 877.0063\n",
      "Epoch 412/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 19.2078 - mse: 790.5623 - val_loss: 18.9122 - val_mse: 814.1861\n",
      "Epoch 413/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9575 - mse: 782.4282 - val_loss: 19.7011 - val_mse: 900.3802\n",
      "Epoch 414/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 19.7779 - mse: 837.2133 - val_loss: 18.8443 - val_mse: 806.9445\n",
      "Epoch 415/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 19.3501 - mse: 803.3207 - val_loss: 18.8917 - val_mse: 768.8512\n",
      "Epoch 416/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2807 - mse: 801.3207 - val_loss: 19.2155 - val_mse: 752.3923\n",
      "Epoch 417/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 19.0463 - mse: 783.6143 - val_loss: 19.4770 - val_mse: 856.1538\n",
      "Epoch 418/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 19.0072 - mse: 789.1318 - val_loss: 18.9563 - val_mse: 810.2385\n",
      "Epoch 419/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.9519 - mse: 775.6916 - val_loss: 18.9379 - val_mse: 761.3723\n",
      "Epoch 420/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.3728 - mse: 813.7100 - val_loss: 19.0042 - val_mse: 816.6814\n",
      "Epoch 421/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9739 - mse: 786.4572 - val_loss: 19.0191 - val_mse: 750.3856\n",
      "Epoch 422/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9252 - mse: 786.5096 - val_loss: 19.2593 - val_mse: 767.9842\n",
      "Epoch 423/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1367 - mse: 795.7131 - val_loss: 18.8463 - val_mse: 770.2885\n",
      "Epoch 424/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0526 - mse: 790.4998 - val_loss: 18.8522 - val_mse: 810.4995\n",
      "Epoch 425/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9118 - mse: 783.6837 - val_loss: 18.9319 - val_mse: 806.8110\n",
      "Epoch 426/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8240 - mse: 774.9512 - val_loss: 18.7649 - val_mse: 787.3204\n",
      "Epoch 427/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9731 - mse: 779.1544 - val_loss: 18.8116 - val_mse: 804.2283\n",
      "Epoch 428/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1635 - mse: 795.2698 - val_loss: 18.7901 - val_mse: 754.3764\n",
      "Epoch 429/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9363 - mse: 786.1456 - val_loss: 18.7215 - val_mse: 774.0854\n",
      "Epoch 430/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1027 - mse: 786.0247 - val_loss: 19.1487 - val_mse: 839.8196\n",
      "Epoch 431/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9596 - mse: 789.8369 - val_loss: 18.8660 - val_mse: 750.5497\n",
      "Epoch 432/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1663 - mse: 799.7289 - val_loss: 18.9423 - val_mse: 813.3724\n",
      "Epoch 433/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0881 - mse: 792.0662 - val_loss: 19.1351 - val_mse: 845.9212\n",
      "Epoch 434/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8195 - mse: 770.4894 - val_loss: 18.8542 - val_mse: 818.0967\n",
      "Epoch 435/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8891 - mse: 777.8076 - val_loss: 18.7512 - val_mse: 762.0537\n",
      "Epoch 436/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9193 - mse: 783.4485 - val_loss: 18.8292 - val_mse: 771.4859\n",
      "Epoch 437/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9766 - mse: 785.3355 - val_loss: 19.1723 - val_mse: 839.3691\n",
      "Epoch 438/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2179 - mse: 802.1802 - val_loss: 18.8031 - val_mse: 750.2158\n",
      "Epoch 439/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8812 - mse: 784.6668 - val_loss: 18.6963 - val_mse: 770.7556\n",
      "Epoch 440/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.6564 - mse: 827.0764 - val_loss: 19.3808 - val_mse: 867.2142\n",
      "Epoch 441/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1679 - mse: 806.9507 - val_loss: 20.0286 - val_mse: 759.5613\n",
      "Epoch 442/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3980 - mse: 817.7253 - val_loss: 19.8787 - val_mse: 765.7960\n",
      "Epoch 443/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.4371 - mse: 803.4604 - val_loss: 18.9344 - val_mse: 775.1335\n",
      "Epoch 444/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.2485 - mse: 810.7586 - val_loss: 20.5519 - val_mse: 981.6413\n",
      "Epoch 445/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.8622 - mse: 846.1398 - val_loss: 19.2369 - val_mse: 839.6165\n",
      "Epoch 446/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1028 - mse: 799.5027 - val_loss: 19.4106 - val_mse: 867.8183\n",
      "Epoch 447/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.5686 - mse: 816.9518 - val_loss: 19.9302 - val_mse: 928.0164\n",
      "Epoch 448/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2003 - mse: 801.9951 - val_loss: 18.8422 - val_mse: 787.6830\n",
      "Epoch 449/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3364 - mse: 807.2005 - val_loss: 19.8389 - val_mse: 918.5001\n",
      "Epoch 450/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1672 - mse: 790.4572 - val_loss: 18.9312 - val_mse: 775.6544\n",
      "Epoch 451/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.1316 - mse: 801.0314 - val_loss: 18.8783 - val_mse: 765.7763\n",
      "Epoch 452/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.0076 - mse: 788.4301 - val_loss: 19.3941 - val_mse: 861.6187\n",
      "Epoch 453/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0648 - mse: 787.4797 - val_loss: 18.8811 - val_mse: 796.4862\n",
      "Epoch 454/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3525 - mse: 814.3749 - val_loss: 19.0105 - val_mse: 823.9060\n",
      "Epoch 455/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0033 - mse: 787.6546 - val_loss: 18.8788 - val_mse: 774.3600\n",
      "Epoch 456/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9558 - mse: 781.5737 - val_loss: 18.8256 - val_mse: 772.3960\n",
      "Epoch 457/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.0172 - mse: 791.2953 - val_loss: 18.8354 - val_mse: 775.8190\n",
      "Epoch 458/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9171 - mse: 783.6652 - val_loss: 18.8915 - val_mse: 820.5303\n",
      "Epoch 459/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.2412 - mse: 807.0157 - val_loss: 18.9738 - val_mse: 773.3940\n",
      "Epoch 460/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.9829 - mse: 780.3196 - val_loss: 18.9026 - val_mse: 812.9035\n",
      "Epoch 461/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.9841 - mse: 794.1400 - val_loss: 18.7086 - val_mse: 773.5756\n",
      "Epoch 462/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.7557 - mse: 771.8431 - val_loss: 18.6972 - val_mse: 764.1394\n",
      "Epoch 463/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1426 - mse: 797.9785 - val_loss: 19.6156 - val_mse: 755.7173\n",
      "Epoch 464/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.2101 - mse: 804.8007 - val_loss: 19.1619 - val_mse: 853.3164\n",
      "Epoch 465/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0081 - mse: 788.8259 - val_loss: 18.7715 - val_mse: 778.8356\n",
      "Epoch 466/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.9121 - mse: 779.8318 - val_loss: 18.7249 - val_mse: 785.9277\n",
      "Epoch 467/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.2149 - mse: 792.6030 - val_loss: 18.9418 - val_mse: 812.8658\n",
      "Epoch 468/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0121 - mse: 790.6430 - val_loss: 18.9306 - val_mse: 749.3357\n",
      "Epoch 469/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3534 - mse: 805.0897 - val_loss: 19.4129 - val_mse: 893.2385\n",
      "Epoch 470/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.4181 - mse: 808.2736 - val_loss: 19.0232 - val_mse: 760.5118\n",
      "Epoch 471/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.2212 - mse: 810.9456 - val_loss: 19.0757 - val_mse: 846.7317\n",
      "Epoch 472/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1310 - mse: 797.0324 - val_loss: 18.9861 - val_mse: 769.5089\n",
      "Epoch 473/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8679 - mse: 779.8688 - val_loss: 19.1599 - val_mse: 754.2330\n",
      "Epoch 474/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9998 - mse: 787.5497 - val_loss: 19.3866 - val_mse: 868.3719\n",
      "Epoch 475/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.9315 - mse: 789.8713 - val_loss: 19.0847 - val_mse: 751.3958\n",
      "Epoch 476/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8310 - mse: 769.4267 - val_loss: 18.6444 - val_mse: 793.9444\n",
      "Epoch 477/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1578 - mse: 800.8211 - val_loss: 20.5093 - val_mse: 972.2561\n",
      "Epoch 478/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.2944 - mse: 805.8215 - val_loss: 18.9142 - val_mse: 744.2499\n",
      "Epoch 479/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0380 - mse: 791.2611 - val_loss: 19.1393 - val_mse: 854.7879\n",
      "Epoch 480/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2286 - mse: 805.3781 - val_loss: 19.7877 - val_mse: 740.2145\n",
      "Epoch 481/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.3440 - mse: 822.0058 - val_loss: 18.7792 - val_mse: 792.7390\n",
      "Epoch 482/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1394 - mse: 796.6759 - val_loss: 20.4793 - val_mse: 978.3300\n",
      "Epoch 483/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1762 - mse: 803.0605 - val_loss: 19.7525 - val_mse: 915.6186\n",
      "Epoch 484/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 19.0874 - mse: 798.0205 - val_loss: 18.8896 - val_mse: 769.9025\n",
      "Epoch 485/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8399 - mse: 781.2640 - val_loss: 18.9171 - val_mse: 831.6714\n",
      "Epoch 486/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9923 - mse: 790.8652 - val_loss: 19.2903 - val_mse: 875.2991\n",
      "Epoch 487/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1521 - mse: 794.1902 - val_loss: 18.7104 - val_mse: 764.9225\n",
      "Epoch 488/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8280 - mse: 775.4616 - val_loss: 18.7797 - val_mse: 791.2036\n",
      "Epoch 489/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0268 - mse: 798.8342 - val_loss: 19.4219 - val_mse: 891.8813\n",
      "Epoch 490/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2649 - mse: 794.1465 - val_loss: 19.0995 - val_mse: 754.8846\n",
      "Epoch 491/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.3561 - mse: 814.2114 - val_loss: 20.1519 - val_mse: 924.9747\n",
      "Epoch 492/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9055 - mse: 786.7988 - val_loss: 18.6366 - val_mse: 768.5856\n",
      "Epoch 493/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7494 - mse: 772.2166 - val_loss: 18.6129 - val_mse: 766.4777\n",
      "Epoch 494/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8714 - mse: 777.9593 - val_loss: 18.9683 - val_mse: 735.0506\n",
      "Epoch 495/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3725 - mse: 815.9672 - val_loss: 20.4576 - val_mse: 972.4014\n",
      "Epoch 496/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.3761 - mse: 808.6600 - val_loss: 18.7938 - val_mse: 783.9818\n",
      "Epoch 497/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.9715 - mse: 788.9828 - val_loss: 18.5551 - val_mse: 767.9531\n",
      "Epoch 498/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7142 - mse: 777.3287 - val_loss: 19.3842 - val_mse: 750.3163\n",
      "Epoch 499/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7068 - mse: 760.9049 - val_loss: 18.7825 - val_mse: 759.4919\n",
      "Epoch 500/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.6254 - mse: 823.7538 - val_loss: 19.5145 - val_mse: 770.0910\n",
      "Epoch 501/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9065 - mse: 778.2338 - val_loss: 18.7072 - val_mse: 790.8746\n",
      "Epoch 502/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7472 - mse: 774.7603 - val_loss: 18.8904 - val_mse: 743.7468\n",
      "Epoch 503/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0613 - mse: 788.4245 - val_loss: 18.8466 - val_mse: 804.8414\n",
      "Epoch 504/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7308 - mse: 766.2432 - val_loss: 18.6514 - val_mse: 743.6469\n",
      "Epoch 505/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7066 - mse: 766.6198 - val_loss: 18.6570 - val_mse: 792.9735\n",
      "Epoch 506/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7029 - mse: 764.0755 - val_loss: 20.0518 - val_mse: 754.0319\n",
      "Epoch 507/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7512 - mse: 772.4574 - val_loss: 19.3520 - val_mse: 870.0538\n",
      "Epoch 508/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9802 - mse: 782.8362 - val_loss: 19.5852 - val_mse: 878.6945\n",
      "Epoch 509/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1929 - mse: 801.8040 - val_loss: 18.9562 - val_mse: 793.2778\n",
      "Epoch 510/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1494 - mse: 788.4340 - val_loss: 19.1501 - val_mse: 812.5779\n",
      "Epoch 511/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1175 - mse: 795.7631 - val_loss: 18.8775 - val_mse: 812.4802\n",
      "Epoch 512/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6995 - mse: 769.6022 - val_loss: 19.0762 - val_mse: 856.7962\n",
      "Epoch 513/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8340 - mse: 775.0634 - val_loss: 19.7608 - val_mse: 735.6602\n",
      "Epoch 514/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1922 - mse: 799.8813 - val_loss: 19.2024 - val_mse: 732.7614\n",
      "Epoch 515/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.9951 - mse: 791.6665 - val_loss: 18.8284 - val_mse: 751.0113\n",
      "Epoch 516/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3318 - mse: 806.4971 - val_loss: 20.9354 - val_mse: 1005.9223\n",
      "Epoch 517/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.6415 - mse: 831.1534 - val_loss: 18.8708 - val_mse: 782.3914\n",
      "Epoch 518/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7274 - mse: 773.1680 - val_loss: 19.2272 - val_mse: 725.9922\n",
      "Epoch 519/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8523 - mse: 787.6849 - val_loss: 18.9805 - val_mse: 836.2090\n",
      "Epoch 520/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8180 - mse: 778.2600 - val_loss: 18.6700 - val_mse: 747.8823\n",
      "Epoch 521/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7641 - mse: 782.2874 - val_loss: 18.6564 - val_mse: 749.2667\n",
      "Epoch 522/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7325 - mse: 768.3807 - val_loss: 18.6979 - val_mse: 751.6988\n",
      "Epoch 523/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.7989 - mse: 776.1235 - val_loss: 19.8075 - val_mse: 732.1281\n",
      "Epoch 524/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.7910 - mse: 767.7601 - val_loss: 19.1316 - val_mse: 862.2443\n",
      "Epoch 525/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.7207 - mse: 767.1207 - val_loss: 18.6240 - val_mse: 744.4526\n",
      "Epoch 526/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.6811 - mse: 770.1359 - val_loss: 18.6915 - val_mse: 730.9481\n",
      "Epoch 527/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6223 - mse: 763.8364 - val_loss: 18.7964 - val_mse: 730.7891\n",
      "Epoch 528/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1396 - mse: 794.5394 - val_loss: 19.7509 - val_mse: 774.9177\n",
      "Epoch 529/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0550 - mse: 795.3882 - val_loss: 18.4816 - val_mse: 777.2332\n",
      "Epoch 530/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8082 - mse: 772.7893 - val_loss: 18.8102 - val_mse: 773.6158\n",
      "Epoch 531/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8055 - mse: 776.7427 - val_loss: 18.6933 - val_mse: 809.3102\n",
      "Epoch 532/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4884 - mse: 750.7451 - val_loss: 18.6403 - val_mse: 747.8495\n",
      "Epoch 533/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.4833 - mse: 750.1823 - val_loss: 19.2407 - val_mse: 858.5496\n",
      "Epoch 534/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8582 - mse: 781.6006 - val_loss: 18.5796 - val_mse: 774.2076\n",
      "Epoch 535/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3723 - mse: 809.5726 - val_loss: 18.8544 - val_mse: 825.1160\n",
      "Epoch 536/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6695 - mse: 765.9211 - val_loss: 18.5115 - val_mse: 765.3842\n",
      "Epoch 537/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6835 - mse: 772.8352 - val_loss: 18.4372 - val_mse: 757.9435\n",
      "Epoch 538/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 19.0106 - mse: 779.4418 - val_loss: 18.6209 - val_mse: 779.3623\n",
      "Epoch 539/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0908 - mse: 787.9949 - val_loss: 18.6184 - val_mse: 770.0729\n",
      "Epoch 540/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6600 - mse: 763.4672 - val_loss: 18.5023 - val_mse: 746.2141\n",
      "Epoch 541/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6439 - mse: 770.6249 - val_loss: 18.6252 - val_mse: 762.4617\n",
      "Epoch 542/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.7273 - mse: 761.0329 - val_loss: 19.8715 - val_mse: 919.0566\n",
      "Epoch 543/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.5610 - mse: 762.9063 - val_loss: 19.7214 - val_mse: 730.3433\n",
      "Epoch 544/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.1366 - mse: 780.3394 - val_loss: 18.8647 - val_mse: 780.4289\n",
      "Epoch 545/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6937 - mse: 774.9319 - val_loss: 18.8449 - val_mse: 737.6199\n",
      "Epoch 546/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.6971 - mse: 830.2241 - val_loss: 19.1360 - val_mse: 800.6699\n",
      "Epoch 547/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.1436 - mse: 801.4207 - val_loss: 19.0787 - val_mse: 816.7068\n",
      "Epoch 548/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.2746 - mse: 815.1086 - val_loss: 19.2325 - val_mse: 756.2504\n",
      "Epoch 549/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.2112 - mse: 801.7891 - val_loss: 19.3803 - val_mse: 880.1443\n",
      "Epoch 550/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.2941 - mse: 806.8735 - val_loss: 19.4231 - val_mse: 766.8211\n",
      "Epoch 551/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1887 - mse: 801.7357 - val_loss: 19.0886 - val_mse: 846.9464\n",
      "Epoch 552/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.2550 - mse: 809.1415 - val_loss: 18.8653 - val_mse: 760.9579\n",
      "Epoch 553/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.2118 - mse: 808.0951 - val_loss: 19.0507 - val_mse: 820.9583\n",
      "Epoch 554/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8944 - mse: 787.8293 - val_loss: 18.7431 - val_mse: 809.9358\n",
      "Epoch 555/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1619 - mse: 806.2252 - val_loss: 18.8695 - val_mse: 807.1369\n",
      "Epoch 556/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.5588 - mse: 835.0728 - val_loss: 19.0371 - val_mse: 749.9857\n",
      "Epoch 557/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.2388 - mse: 806.6402 - val_loss: 18.8118 - val_mse: 762.9214\n",
      "Epoch 558/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9689 - mse: 787.8311 - val_loss: 18.6603 - val_mse: 788.4312\n",
      "Epoch 559/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0525 - mse: 803.5831 - val_loss: 19.0579 - val_mse: 757.7020\n",
      "Epoch 560/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9079 - mse: 776.9289 - val_loss: 18.9863 - val_mse: 799.2797\n",
      "Epoch 561/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0700 - mse: 796.0326 - val_loss: 18.7159 - val_mse: 765.1615\n",
      "Epoch 562/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.4028 - mse: 817.6367 - val_loss: 18.9002 - val_mse: 763.9511\n",
      "Epoch 563/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.8786 - mse: 779.4390 - val_loss: 18.9221 - val_mse: 767.9500\n",
      "Epoch 564/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8328 - mse: 783.1671 - val_loss: 19.3477 - val_mse: 825.4766\n",
      "Epoch 565/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9883 - mse: 787.3647 - val_loss: 20.5138 - val_mse: 947.4592\n",
      "Epoch 566/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2372 - mse: 799.3033 - val_loss: 18.7269 - val_mse: 791.3074\n",
      "Epoch 567/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0005 - mse: 786.9449 - val_loss: 18.7454 - val_mse: 746.8081\n",
      "Epoch 568/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9620 - mse: 787.3879 - val_loss: 19.4712 - val_mse: 758.7820\n",
      "Epoch 569/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.4052 - mse: 810.9860 - val_loss: 18.8360 - val_mse: 807.2143\n",
      "Epoch 570/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9819 - mse: 781.4062 - val_loss: 19.2985 - val_mse: 799.4786\n",
      "Epoch 571/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0690 - mse: 791.5787 - val_loss: 18.8327 - val_mse: 824.4221\n",
      "Epoch 572/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.9447 - mse: 789.0510 - val_loss: 18.9948 - val_mse: 753.5405\n",
      "Epoch 573/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8979 - mse: 781.6317 - val_loss: 18.6795 - val_mse: 775.6162\n",
      "Epoch 574/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.3144 - mse: 817.0679 - val_loss: 19.0561 - val_mse: 776.7975\n",
      "Epoch 575/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0564 - mse: 784.4910 - val_loss: 18.6441 - val_mse: 753.2277\n",
      "Epoch 576/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3824 - mse: 810.5584 - val_loss: 19.2553 - val_mse: 866.9203\n",
      "Epoch 577/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1154 - mse: 798.2711 - val_loss: 18.7690 - val_mse: 758.2425\n",
      "Epoch 578/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8898 - mse: 782.9912 - val_loss: 19.0167 - val_mse: 742.0703\n",
      "Epoch 579/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9335 - mse: 789.9589 - val_loss: 19.0688 - val_mse: 768.4890\n",
      "Epoch 580/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8618 - mse: 781.3915 - val_loss: 18.7078 - val_mse: 774.4306\n",
      "Epoch 581/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2877 - mse: 814.9974 - val_loss: 19.9423 - val_mse: 913.9723\n",
      "Epoch 582/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.2128 - mse: 793.0733 - val_loss: 18.8850 - val_mse: 749.2024\n",
      "Epoch 583/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8304 - mse: 781.1563 - val_loss: 19.3837 - val_mse: 824.6979\n",
      "Epoch 584/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1147 - mse: 795.5469 - val_loss: 19.2084 - val_mse: 783.1164\n",
      "Epoch 585/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.4556 - mse: 807.1498 - val_loss: 19.9614 - val_mse: 916.4864\n",
      "Epoch 586/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3584 - mse: 810.5706 - val_loss: 19.2750 - val_mse: 875.6829\n",
      "Epoch 587/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0697 - mse: 798.2774 - val_loss: 19.0568 - val_mse: 760.9540\n",
      "Epoch 588/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9244 - mse: 782.0900 - val_loss: 18.8881 - val_mse: 750.8329\n",
      "Epoch 589/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8153 - mse: 780.1079 - val_loss: 18.8159 - val_mse: 750.0912\n",
      "Epoch 590/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0801 - mse: 799.2729 - val_loss: 18.7298 - val_mse: 782.2783\n",
      "Epoch 591/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0184 - mse: 780.7319 - val_loss: 18.7530 - val_mse: 810.7848\n",
      "Epoch 592/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.4409 - mse: 805.2601 - val_loss: 19.1299 - val_mse: 853.8061\n",
      "Epoch 593/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0013 - mse: 794.8754 - val_loss: 18.8215 - val_mse: 774.7883\n",
      "Epoch 594/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8500 - mse: 778.9656 - val_loss: 18.6753 - val_mse: 783.4875\n",
      "Epoch 595/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9036 - mse: 783.2625 - val_loss: 18.7837 - val_mse: 779.0101\n",
      "Epoch 596/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9764 - mse: 782.1117 - val_loss: 19.3994 - val_mse: 879.4008\n",
      "Epoch 597/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7622 - mse: 778.4407 - val_loss: 18.6828 - val_mse: 764.8225\n",
      "Epoch 598/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1367 - mse: 784.4577 - val_loss: 18.6526 - val_mse: 761.0731\n",
      "Epoch 599/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0745 - mse: 792.5426 - val_loss: 19.1313 - val_mse: 855.2350\n",
      "Epoch 600/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0998 - mse: 787.6861 - val_loss: 18.5700 - val_mse: 772.6504\n",
      "Epoch 601/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8547 - mse: 777.7613 - val_loss: 18.8299 - val_mse: 794.5422\n",
      "Epoch 602/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8425 - mse: 781.1221 - val_loss: 19.5195 - val_mse: 832.5564\n",
      "Epoch 603/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3132 - mse: 801.3044 - val_loss: 18.7373 - val_mse: 775.3450\n",
      "Epoch 604/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0642 - mse: 786.9462 - val_loss: 19.0688 - val_mse: 796.3556\n",
      "Epoch 605/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.7504 - mse: 829.9642 - val_loss: 18.9937 - val_mse: 846.5129\n",
      "Epoch 606/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1265 - mse: 801.8652 - val_loss: 18.8353 - val_mse: 822.3549\n",
      "Epoch 607/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0394 - mse: 797.8453 - val_loss: 18.9432 - val_mse: 773.3043\n",
      "Epoch 608/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7425 - mse: 776.7663 - val_loss: 18.7207 - val_mse: 801.9028\n",
      "Epoch 609/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9398 - mse: 776.7304 - val_loss: 18.7307 - val_mse: 766.9235\n",
      "Epoch 610/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9580 - mse: 790.6425 - val_loss: 19.0468 - val_mse: 765.5671\n",
      "Epoch 611/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.8408 - mse: 778.2590 - val_loss: 18.6288 - val_mse: 785.3340\n",
      "Epoch 612/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8322 - mse: 777.8038 - val_loss: 19.2321 - val_mse: 838.3033\n",
      "Epoch 613/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9498 - mse: 795.3110 - val_loss: 18.9133 - val_mse: 838.2128\n",
      "Epoch 614/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9305 - mse: 778.7166 - val_loss: 18.8511 - val_mse: 767.2029\n",
      "Epoch 615/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7396 - mse: 778.3988 - val_loss: 18.9024 - val_mse: 733.7943\n",
      "Epoch 616/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7080 - mse: 768.0636 - val_loss: 18.9022 - val_mse: 748.2527\n",
      "Epoch 617/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0788 - mse: 786.3967 - val_loss: 18.9364 - val_mse: 797.8115\n",
      "Epoch 618/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8698 - mse: 778.3459 - val_loss: 20.4032 - val_mse: 753.5506\n",
      "Epoch 619/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8691 - mse: 768.9939 - val_loss: 19.1368 - val_mse: 842.5952\n",
      "Epoch 620/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7925 - mse: 787.5425 - val_loss: 18.9619 - val_mse: 730.7119\n",
      "Epoch 621/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7064 - mse: 770.3447 - val_loss: 18.7228 - val_mse: 752.3397\n",
      "Epoch 622/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.8005 - mse: 772.8091 - val_loss: 18.9272 - val_mse: 836.1562\n",
      "Epoch 623/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8257 - mse: 775.9338 - val_loss: 19.0511 - val_mse: 844.9454\n",
      "Epoch 624/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9036 - mse: 783.9900 - val_loss: 18.5972 - val_mse: 761.8385\n",
      "Epoch 625/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7395 - mse: 769.0726 - val_loss: 19.3795 - val_mse: 735.0471\n",
      "Epoch 626/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1445 - mse: 793.8730 - val_loss: 18.8923 - val_mse: 772.6042\n",
      "Epoch 627/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9860 - mse: 777.4779 - val_loss: 19.1319 - val_mse: 750.7164\n",
      "Epoch 628/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9174 - mse: 775.0319 - val_loss: 18.5555 - val_mse: 785.6127\n",
      "Epoch 629/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6942 - mse: 769.4499 - val_loss: 18.5960 - val_mse: 766.0729\n",
      "Epoch 630/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0711 - mse: 792.6985 - val_loss: 19.3743 - val_mse: 743.4864\n",
      "Epoch 631/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9325 - mse: 781.3274 - val_loss: 18.6007 - val_mse: 779.7314\n",
      "Epoch 632/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8643 - mse: 775.5336 - val_loss: 19.5004 - val_mse: 887.0491\n",
      "Epoch 633/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0649 - mse: 785.9092 - val_loss: 18.9297 - val_mse: 820.7814\n",
      "Epoch 634/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1068 - mse: 798.3971 - val_loss: 18.7115 - val_mse: 766.6813\n",
      "Epoch 635/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8666 - mse: 778.3820 - val_loss: 19.2876 - val_mse: 742.1666\n",
      "Epoch 636/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7614 - mse: 773.3976 - val_loss: 20.1743 - val_mse: 928.3621\n",
      "Epoch 637/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1522 - mse: 797.7357 - val_loss: 18.8436 - val_mse: 770.7902\n",
      "Epoch 638/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8494 - mse: 779.0836 - val_loss: 20.5446 - val_mse: 974.6409\n",
      "Epoch 639/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.2378 - mse: 812.1293 - val_loss: 19.2136 - val_mse: 840.9222\n",
      "Epoch 640/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0463 - mse: 789.4405 - val_loss: 19.5944 - val_mse: 732.8678\n",
      "Epoch 641/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.3917 - mse: 805.7537 - val_loss: 18.7004 - val_mse: 818.3781\n",
      "Epoch 642/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2184 - mse: 805.7489 - val_loss: 18.6999 - val_mse: 788.9924\n",
      "Epoch 643/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2081 - mse: 810.5200 - val_loss: 18.6960 - val_mse: 756.7953\n",
      "Epoch 644/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.0284 - mse: 788.2588 - val_loss: 19.0566 - val_mse: 783.9769\n",
      "Epoch 645/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1154 - mse: 790.4756 - val_loss: 19.3701 - val_mse: 830.0980\n",
      "Epoch 646/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0842 - mse: 795.4583 - val_loss: 18.6138 - val_mse: 789.8201\n",
      "Epoch 647/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8108 - mse: 772.6771 - val_loss: 18.7515 - val_mse: 816.4052\n",
      "Epoch 648/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7818 - mse: 787.3437 - val_loss: 19.9112 - val_mse: 739.9141\n",
      "Epoch 649/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2515 - mse: 801.0689 - val_loss: 18.9091 - val_mse: 806.1898\n",
      "Epoch 650/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8935 - mse: 778.5798 - val_loss: 18.9330 - val_mse: 828.3774\n",
      "Epoch 651/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0126 - mse: 786.3228 - val_loss: 18.6946 - val_mse: 813.3233\n",
      "Epoch 652/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8109 - mse: 777.5729 - val_loss: 18.9591 - val_mse: 740.0476\n",
      "Epoch 653/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8888 - mse: 782.4879 - val_loss: 19.5499 - val_mse: 897.3719\n",
      "Epoch 654/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8687 - mse: 775.2673 - val_loss: 18.9375 - val_mse: 731.8343\n",
      "Epoch 655/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6743 - mse: 766.7573 - val_loss: 18.5848 - val_mse: 782.0721\n",
      "Epoch 656/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7727 - mse: 773.5173 - val_loss: 18.8607 - val_mse: 837.3378\n",
      "Epoch 657/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6620 - mse: 764.9698 - val_loss: 18.5730 - val_mse: 780.3931\n",
      "Epoch 658/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7648 - mse: 777.4509 - val_loss: 18.9557 - val_mse: 820.4796\n",
      "Epoch 659/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8082 - mse: 773.1231 - val_loss: 18.6332 - val_mse: 797.6886\n",
      "Epoch 660/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6585 - mse: 762.8266 - val_loss: 19.3839 - val_mse: 859.2081\n",
      "Epoch 661/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9527 - mse: 780.8796 - val_loss: 18.5469 - val_mse: 775.3444\n",
      "Epoch 662/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9490 - mse: 781.9763 - val_loss: 18.8828 - val_mse: 825.6118\n",
      "Epoch 663/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8576 - mse: 785.2763 - val_loss: 18.7536 - val_mse: 739.2482\n",
      "Epoch 664/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7678 - mse: 766.7103 - val_loss: 18.8802 - val_mse: 787.9529\n",
      "Epoch 665/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9713 - mse: 784.7368 - val_loss: 18.9131 - val_mse: 749.9739\n",
      "Epoch 666/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0856 - mse: 791.6680 - val_loss: 18.6489 - val_mse: 778.1760\n",
      "Epoch 667/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8791 - mse: 777.6749 - val_loss: 19.1437 - val_mse: 742.2061\n",
      "Epoch 668/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6805 - mse: 765.1172 - val_loss: 19.3185 - val_mse: 735.3607\n",
      "Epoch 669/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2347 - mse: 799.3748 - val_loss: 18.6004 - val_mse: 749.9637\n",
      "Epoch 670/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8388 - mse: 774.6901 - val_loss: 18.6695 - val_mse: 809.2464\n",
      "Epoch 671/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6093 - mse: 768.7462 - val_loss: 18.5528 - val_mse: 771.1205\n",
      "Epoch 672/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7911 - mse: 776.4352 - val_loss: 18.7263 - val_mse: 761.7847\n",
      "Epoch 673/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8309 - mse: 778.8784 - val_loss: 18.9342 - val_mse: 766.2007\n",
      "Epoch 674/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0487 - mse: 791.5906 - val_loss: 19.1968 - val_mse: 728.0247\n",
      "Epoch 675/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1471 - mse: 798.0928 - val_loss: 19.1918 - val_mse: 838.6644\n",
      "Epoch 676/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8137 - mse: 778.0447 - val_loss: 18.7638 - val_mse: 763.9337\n",
      "Epoch 677/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7970 - mse: 774.9316 - val_loss: 18.8431 - val_mse: 735.9767\n",
      "Epoch 678/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7931 - mse: 777.1371 - val_loss: 18.6590 - val_mse: 797.1060\n",
      "Epoch 679/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8665 - mse: 771.7137 - val_loss: 18.9830 - val_mse: 841.5480\n",
      "Epoch 680/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.7956 - mse: 775.5346 - val_loss: 18.6314 - val_mse: 746.6341\n",
      "Epoch 681/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8924 - mse: 790.0056 - val_loss: 18.5219 - val_mse: 787.9427\n",
      "Epoch 682/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1449 - mse: 794.5490 - val_loss: 18.6407 - val_mse: 787.4001\n",
      "Epoch 683/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9259 - mse: 783.5730 - val_loss: 18.6700 - val_mse: 799.4517\n",
      "Epoch 684/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1882 - mse: 806.1488 - val_loss: 18.7196 - val_mse: 785.6281\n",
      "Epoch 685/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1104 - mse: 794.8178 - val_loss: 18.8029 - val_mse: 749.3401\n",
      "Epoch 686/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6821 - mse: 767.5657 - val_loss: 18.5675 - val_mse: 789.0610\n",
      "Epoch 687/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6786 - mse: 766.5107 - val_loss: 19.3951 - val_mse: 770.8129\n",
      "Epoch 688/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1271 - mse: 792.6174 - val_loss: 18.8595 - val_mse: 761.4386\n",
      "Epoch 689/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7788 - mse: 778.8962 - val_loss: 18.8680 - val_mse: 829.8086\n",
      "Epoch 690/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1788 - mse: 795.3520 - val_loss: 18.6320 - val_mse: 744.8856\n",
      "Epoch 691/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8902 - mse: 778.8017 - val_loss: 18.7156 - val_mse: 762.8711\n",
      "Epoch 692/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9212 - mse: 781.9595 - val_loss: 19.1816 - val_mse: 857.9611\n",
      "Epoch 693/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6283 - mse: 766.5079 - val_loss: 18.6338 - val_mse: 801.8686\n",
      "Epoch 694/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6663 - mse: 762.1932 - val_loss: 18.6446 - val_mse: 803.3890\n",
      "Epoch 695/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7647 - mse: 774.7260 - val_loss: 18.4863 - val_mse: 776.4147\n",
      "Epoch 696/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0983 - mse: 791.2608 - val_loss: 19.6789 - val_mse: 734.8967\n",
      "Epoch 697/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0726 - mse: 786.2432 - val_loss: 18.6317 - val_mse: 774.9612\n",
      "Epoch 698/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7343 - mse: 771.4185 - val_loss: 18.6747 - val_mse: 759.1367\n",
      "Epoch 699/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7502 - mse: 772.2444 - val_loss: 18.8191 - val_mse: 811.6345\n",
      "Epoch 700/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9659 - mse: 788.1367 - val_loss: 18.8719 - val_mse: 740.9159\n",
      "Epoch 701/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.3959 - mse: 808.8867 - val_loss: 19.9927 - val_mse: 746.4350\n",
      "Epoch 702/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8383 - mse: 783.7024 - val_loss: 18.6206 - val_mse: 747.1386\n",
      "Epoch 703/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0858 - mse: 790.3049 - val_loss: 18.9006 - val_mse: 746.1680\n",
      "Epoch 704/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7093 - mse: 768.1524 - val_loss: 19.2174 - val_mse: 845.1134\n",
      "Epoch 705/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0840 - mse: 783.0424 - val_loss: 19.0670 - val_mse: 861.3529\n",
      "Epoch 706/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8552 - mse: 779.5596 - val_loss: 18.9343 - val_mse: 754.0029\n",
      "Epoch 707/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6620 - mse: 766.1087 - val_loss: 18.8176 - val_mse: 739.3801\n",
      "Epoch 708/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9043 - mse: 784.0559 - val_loss: 18.5032 - val_mse: 770.0700\n",
      "Epoch 709/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.6683 - mse: 767.9237 - val_loss: 18.9555 - val_mse: 757.9821\n",
      "Epoch 710/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8618 - mse: 786.0974 - val_loss: 19.2654 - val_mse: 834.4750\n",
      "Epoch 711/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9924 - mse: 779.9653 - val_loss: 18.6584 - val_mse: 771.1084\n",
      "Epoch 712/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9803 - mse: 781.4541 - val_loss: 21.4635 - val_mse: 1041.8766\n",
      "Epoch 713/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1897 - mse: 802.4485 - val_loss: 18.9281 - val_mse: 743.1812\n",
      "Epoch 714/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8891 - mse: 779.2009 - val_loss: 20.1171 - val_mse: 942.7404\n",
      "Epoch 715/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7835 - mse: 772.0710 - val_loss: 18.8225 - val_mse: 828.6617\n",
      "Epoch 716/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6165 - mse: 767.9237 - val_loss: 18.6066 - val_mse: 772.7656\n",
      "Epoch 717/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.3730 - mse: 806.8414 - val_loss: 18.6626 - val_mse: 778.8458\n",
      "Epoch 718/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6601 - mse: 770.3931 - val_loss: 19.4244 - val_mse: 731.6974\n",
      "Epoch 719/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.7554 - mse: 776.0114 - val_loss: 18.8063 - val_mse: 828.8793\n",
      "Epoch 720/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.8501 - mse: 777.4910 - val_loss: 19.8153 - val_mse: 736.0408\n",
      "Epoch 721/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8383 - mse: 780.1844 - val_loss: 19.0452 - val_mse: 836.3108\n",
      "Epoch 722/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1471 - mse: 788.4619 - val_loss: 18.4741 - val_mse: 762.8828\n",
      "Epoch 723/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7741 - mse: 773.6999 - val_loss: 19.1494 - val_mse: 727.4218\n",
      "Epoch 724/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7688 - mse: 777.8431 - val_loss: 18.7037 - val_mse: 764.6715\n",
      "Epoch 725/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6452 - mse: 766.3496 - val_loss: 18.6845 - val_mse: 759.5640\n",
      "Epoch 726/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8705 - mse: 778.8231 - val_loss: 19.2184 - val_mse: 756.4767\n",
      "Epoch 727/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7409 - mse: 775.9481 - val_loss: 19.0494 - val_mse: 844.5946\n",
      "Epoch 728/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0759 - mse: 785.7431 - val_loss: 18.5703 - val_mse: 743.5634\n",
      "Epoch 729/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7832 - mse: 775.7452 - val_loss: 18.6012 - val_mse: 791.8304\n",
      "Epoch 730/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8714 - mse: 780.7379 - val_loss: 18.5911 - val_mse: 764.6958\n",
      "Epoch 731/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7877 - mse: 764.0607 - val_loss: 18.5367 - val_mse: 761.3989\n",
      "Epoch 732/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7476 - mse: 771.6750 - val_loss: 18.8103 - val_mse: 822.3308\n",
      "Epoch 733/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.2128 - mse: 792.9160 - val_loss: 19.7408 - val_mse: 768.9879\n",
      "Epoch 734/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9428 - mse: 781.5408 - val_loss: 18.6508 - val_mse: 750.2045\n",
      "Epoch 735/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7735 - mse: 766.9969 - val_loss: 18.8649 - val_mse: 815.4188\n",
      "Epoch 736/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.8893 - mse: 777.6146 - val_loss: 18.7549 - val_mse: 740.6449\n",
      "Epoch 737/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6636 - mse: 769.0870 - val_loss: 18.5316 - val_mse: 750.9631\n",
      "Epoch 738/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8883 - mse: 780.9326 - val_loss: 18.8511 - val_mse: 800.5337\n",
      "Epoch 739/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9357 - mse: 789.4250 - val_loss: 18.6076 - val_mse: 752.6579\n",
      "Epoch 740/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7137 - mse: 766.7471 - val_loss: 18.6527 - val_mse: 769.4250\n",
      "Epoch 741/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8201 - mse: 775.0922 - val_loss: 18.6380 - val_mse: 797.7021\n",
      "Epoch 742/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6604 - mse: 765.9438 - val_loss: 19.3531 - val_mse: 732.2750\n",
      "Epoch 743/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8367 - mse: 776.9215 - val_loss: 19.0645 - val_mse: 735.3091\n",
      "Epoch 744/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8550 - mse: 775.5150 - val_loss: 18.6469 - val_mse: 792.8336\n",
      "Epoch 745/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7916 - mse: 772.3204 - val_loss: 18.5117 - val_mse: 752.5617\n",
      "Epoch 746/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6896 - mse: 769.5839 - val_loss: 18.5598 - val_mse: 769.1456\n",
      "Epoch 747/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.2687 - mse: 796.9139 - val_loss: 19.4662 - val_mse: 893.0663\n",
      "Epoch 748/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8670 - mse: 782.6058 - val_loss: 18.6164 - val_mse: 797.0175\n",
      "Epoch 749/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7867 - mse: 780.4852 - val_loss: 18.9530 - val_mse: 736.6841\n",
      "Epoch 750/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.8097 - mse: 772.8554 - val_loss: 18.8112 - val_mse: 737.8807\n",
      "Epoch 751/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.8606 - mse: 769.4373 - val_loss: 19.3927 - val_mse: 870.5836\n",
      "Epoch 752/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.0198 - mse: 785.9182 - val_loss: 18.5223 - val_mse: 797.1125\n",
      "Epoch 753/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9950 - mse: 784.8278 - val_loss: 19.0082 - val_mse: 755.5641\n",
      "Epoch 754/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1133 - mse: 800.2275 - val_loss: 18.9753 - val_mse: 836.8824\n",
      "Epoch 755/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.7776 - mse: 774.2072 - val_loss: 18.8122 - val_mse: 796.8437\n",
      "Epoch 756/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.7766 - mse: 778.5854 - val_loss: 18.5710 - val_mse: 740.0275\n",
      "Epoch 757/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7119 - mse: 767.4592 - val_loss: 19.3716 - val_mse: 876.2148\n",
      "Epoch 758/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.6031 - mse: 763.0464 - val_loss: 18.5077 - val_mse: 760.9827\n",
      "Epoch 759/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.8953 - mse: 781.0818 - val_loss: 18.7303 - val_mse: 733.6327\n",
      "Epoch 760/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8145 - mse: 772.8767 - val_loss: 18.6066 - val_mse: 788.7037\n",
      "Epoch 761/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6036 - mse: 769.2898 - val_loss: 18.5825 - val_mse: 752.5779\n",
      "Epoch 762/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7296 - mse: 766.7900 - val_loss: 18.9519 - val_mse: 748.1295\n",
      "Epoch 763/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9007 - mse: 781.5371 - val_loss: 18.9872 - val_mse: 722.5026\n",
      "Epoch 764/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0685 - mse: 794.6639 - val_loss: 18.9445 - val_mse: 735.1716\n",
      "Epoch 765/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9145 - mse: 777.5049 - val_loss: 18.8191 - val_mse: 829.6351\n",
      "Epoch 766/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7636 - mse: 775.4217 - val_loss: 19.1165 - val_mse: 724.2766\n",
      "Epoch 767/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8347 - mse: 768.9133 - val_loss: 19.3877 - val_mse: 871.7534\n",
      "Epoch 768/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9265 - mse: 782.2058 - val_loss: 18.9966 - val_mse: 721.5217\n",
      "Epoch 769/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0375 - mse: 784.5668 - val_loss: 18.6655 - val_mse: 743.6848\n",
      "Epoch 770/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.6166 - mse: 767.3180 - val_loss: 18.4677 - val_mse: 773.0623\n",
      "Epoch 771/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6840 - mse: 767.5545 - val_loss: 19.2611 - val_mse: 839.6270\n",
      "Epoch 772/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.9673 - mse: 783.2010 - val_loss: 19.7300 - val_mse: 771.7940\n",
      "Epoch 773/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8913 - mse: 781.0023 - val_loss: 19.4090 - val_mse: 760.1703\n",
      "Epoch 774/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8786 - mse: 779.5264 - val_loss: 18.6747 - val_mse: 738.6052\n",
      "Epoch 775/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9498 - mse: 788.3168 - val_loss: 18.5526 - val_mse: 745.2599\n",
      "Epoch 776/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.5453 - mse: 807.1774 - val_loss: 18.9000 - val_mse: 744.3845\n",
      "Epoch 777/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7279 - mse: 766.4516 - val_loss: 18.5926 - val_mse: 758.7672\n",
      "Epoch 778/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5176 - mse: 769.2690 - val_loss: 18.5701 - val_mse: 779.6261\n",
      "Epoch 779/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9808 - mse: 779.5595 - val_loss: 19.0022 - val_mse: 754.3360\n",
      "Epoch 780/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7979 - mse: 788.2667 - val_loss: 18.5685 - val_mse: 789.5202\n",
      "Epoch 781/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5738 - mse: 762.1428 - val_loss: 18.5901 - val_mse: 781.2642\n",
      "Epoch 782/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8655 - mse: 778.9897 - val_loss: 18.6800 - val_mse: 766.1995\n",
      "Epoch 783/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5417 - mse: 760.3030 - val_loss: 18.4755 - val_mse: 758.1583\n",
      "Epoch 784/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.8385 - mse: 782.2443 - val_loss: 18.7524 - val_mse: 810.7310\n",
      "Epoch 785/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7296 - mse: 768.6365 - val_loss: 18.6081 - val_mse: 801.4011\n",
      "Epoch 786/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6600 - mse: 762.8537 - val_loss: 19.0535 - val_mse: 858.1110\n",
      "Epoch 787/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7856 - mse: 777.3080 - val_loss: 20.0716 - val_mse: 738.0172\n",
      "Epoch 788/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.6099 - mse: 823.9741 - val_loss: 18.8273 - val_mse: 821.4636\n",
      "Epoch 789/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5807 - mse: 766.6688 - val_loss: 18.5955 - val_mse: 794.7456\n",
      "Epoch 790/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9764 - mse: 783.2623 - val_loss: 18.6314 - val_mse: 791.9533\n",
      "Epoch 791/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8110 - mse: 777.0382 - val_loss: 18.6850 - val_mse: 808.8605\n",
      "Epoch 792/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8126 - mse: 774.7665 - val_loss: 19.4746 - val_mse: 885.0831\n",
      "Epoch 793/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0262 - mse: 792.2690 - val_loss: 19.0610 - val_mse: 733.6075\n",
      "Epoch 794/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9212 - mse: 777.8815 - val_loss: 18.7560 - val_mse: 755.6786\n",
      "Epoch 795/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9154 - mse: 784.7460 - val_loss: 18.8015 - val_mse: 739.4725\n",
      "Epoch 796/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8733 - mse: 783.8742 - val_loss: 18.6734 - val_mse: 754.1665\n",
      "Epoch 797/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6451 - mse: 760.9056 - val_loss: 18.8693 - val_mse: 815.7765\n",
      "Epoch 798/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5094 - mse: 758.8066 - val_loss: 18.6368 - val_mse: 807.7485\n",
      "Epoch 799/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7612 - mse: 769.3242 - val_loss: 18.7563 - val_mse: 812.2667\n",
      "Epoch 800/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6642 - mse: 770.5503 - val_loss: 18.3984 - val_mse: 769.4155\n",
      "Epoch 801/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6994 - mse: 764.3846 - val_loss: 18.9372 - val_mse: 837.9116\n",
      "Epoch 802/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8291 - mse: 783.4943 - val_loss: 19.1166 - val_mse: 842.0761\n",
      "Epoch 803/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9126 - mse: 784.1323 - val_loss: 18.7015 - val_mse: 816.0731\n",
      "Epoch 804/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.7469 - mse: 768.2999 - val_loss: 18.4406 - val_mse: 744.5115\n",
      "Epoch 805/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7854 - mse: 780.2383 - val_loss: 18.5236 - val_mse: 747.2630\n",
      "Epoch 806/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9745 - mse: 778.3312 - val_loss: 18.5859 - val_mse: 785.0157\n",
      "Epoch 807/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5913 - mse: 764.5589 - val_loss: 18.4833 - val_mse: 781.1700\n",
      "Epoch 808/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.8549 - mse: 774.1684 - val_loss: 18.7443 - val_mse: 760.3516\n",
      "Epoch 809/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.2552 - mse: 790.9675 - val_loss: 19.0153 - val_mse: 840.3017\n",
      "Epoch 810/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.8687 - mse: 783.5101 - val_loss: 18.7397 - val_mse: 742.2720\n",
      "Epoch 811/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6297 - mse: 758.6306 - val_loss: 18.4858 - val_mse: 755.0817\n",
      "Epoch 812/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7187 - mse: 770.7354 - val_loss: 18.6053 - val_mse: 739.7896\n",
      "Epoch 813/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5975 - mse: 760.7318 - val_loss: 19.2158 - val_mse: 873.9133\n",
      "Epoch 814/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8269 - mse: 771.7891 - val_loss: 18.6534 - val_mse: 737.4600\n",
      "Epoch 815/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.5760 - mse: 759.7573 - val_loss: 18.4165 - val_mse: 766.1711\n",
      "Epoch 816/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6493 - mse: 769.8402 - val_loss: 18.5070 - val_mse: 756.5539\n",
      "Epoch 817/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9694 - mse: 779.6882 - val_loss: 18.9523 - val_mse: 833.6180\n",
      "Epoch 818/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9952 - mse: 783.5025 - val_loss: 19.0730 - val_mse: 861.2632\n",
      "Epoch 819/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8319 - mse: 768.8644 - val_loss: 19.1793 - val_mse: 873.6505\n",
      "Epoch 820/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9089 - mse: 776.0931 - val_loss: 19.5623 - val_mse: 879.7679\n",
      "Epoch 821/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8899 - mse: 780.5639 - val_loss: 18.5836 - val_mse: 783.0665\n",
      "Epoch 822/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5973 - mse: 764.8097 - val_loss: 18.5427 - val_mse: 747.9655\n",
      "Epoch 823/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7867 - mse: 771.4948 - val_loss: 18.4650 - val_mse: 771.0181\n",
      "Epoch 824/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6635 - mse: 768.9117 - val_loss: 18.5319 - val_mse: 752.9139\n",
      "Epoch 825/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7147 - mse: 773.5173 - val_loss: 18.9836 - val_mse: 847.1971\n",
      "Epoch 826/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.4258 - mse: 807.7303 - val_loss: 18.8616 - val_mse: 733.3302\n",
      "Epoch 827/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8606 - mse: 767.3392 - val_loss: 19.0536 - val_mse: 850.4235\n",
      "Epoch 828/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8288 - mse: 782.1212 - val_loss: 18.4515 - val_mse: 765.3302\n",
      "Epoch 829/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7236 - mse: 765.2209 - val_loss: 19.6839 - val_mse: 736.0157\n",
      "Epoch 830/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1119 - mse: 786.1432 - val_loss: 19.0920 - val_mse: 773.3951\n",
      "Epoch 831/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0972 - mse: 788.3552 - val_loss: 18.5250 - val_mse: 808.3566\n",
      "Epoch 832/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6338 - mse: 764.0889 - val_loss: 18.7823 - val_mse: 803.0063\n",
      "Epoch 833/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5018 - mse: 764.5574 - val_loss: 18.5589 - val_mse: 752.8901\n",
      "Epoch 834/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.6748 - mse: 761.3385 - val_loss: 18.5649 - val_mse: 743.1209\n",
      "Epoch 835/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7166 - mse: 771.9341 - val_loss: 19.1617 - val_mse: 866.4785\n",
      "Epoch 836/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.9844 - mse: 796.5238 - val_loss: 20.8307 - val_mse: 755.4504\n",
      "Epoch 837/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1095 - mse: 793.2360 - val_loss: 19.4852 - val_mse: 727.8608\n",
      "Epoch 838/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.8979 - mse: 784.2507 - val_loss: 18.5840 - val_mse: 798.6746\n",
      "Epoch 839/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5838 - mse: 767.4330 - val_loss: 18.4602 - val_mse: 772.8829\n",
      "Epoch 840/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6010 - mse: 757.5717 - val_loss: 19.7167 - val_mse: 913.9619\n",
      "Epoch 841/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8097 - mse: 778.4948 - val_loss: 18.5011 - val_mse: 773.6992\n",
      "Epoch 842/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6394 - mse: 757.1777 - val_loss: 18.4717 - val_mse: 786.3454\n",
      "Epoch 843/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6315 - mse: 771.6027 - val_loss: 19.4876 - val_mse: 879.4494\n",
      "Epoch 844/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9332 - mse: 788.3573 - val_loss: 18.4338 - val_mse: 762.6309\n",
      "Epoch 845/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5283 - mse: 756.2953 - val_loss: 18.8372 - val_mse: 725.2073\n",
      "Epoch 846/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7491 - mse: 773.6642 - val_loss: 18.4864 - val_mse: 779.8379\n",
      "Epoch 847/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.6462 - mse: 759.5467 - val_loss: 18.4818 - val_mse: 752.6554\n",
      "Epoch 848/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6731 - mse: 765.8232 - val_loss: 18.5238 - val_mse: 740.5698\n",
      "Epoch 849/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0945 - mse: 793.9968 - val_loss: 19.2432 - val_mse: 797.2751\n",
      "Epoch 850/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9065 - mse: 779.4200 - val_loss: 19.1575 - val_mse: 866.5854\n",
      "Epoch 851/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8583 - mse: 775.0818 - val_loss: 18.5196 - val_mse: 744.0768\n",
      "Epoch 852/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6664 - mse: 772.0396 - val_loss: 18.6296 - val_mse: 768.6334\n",
      "Epoch 853/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9317 - mse: 773.8751 - val_loss: 18.9584 - val_mse: 725.5820\n",
      "Epoch 854/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.7164 - mse: 767.7437 - val_loss: 18.3975 - val_mse: 743.8849\n",
      "Epoch 855/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5453 - mse: 760.4687 - val_loss: 19.2423 - val_mse: 720.9108\n",
      "Epoch 856/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7894 - mse: 763.7765 - val_loss: 18.5257 - val_mse: 790.8152\n",
      "Epoch 857/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5782 - mse: 757.1658 - val_loss: 18.6561 - val_mse: 735.9709\n",
      "Epoch 858/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6874 - mse: 761.5908 - val_loss: 18.4727 - val_mse: 741.0415\n",
      "Epoch 859/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8070 - mse: 770.0084 - val_loss: 18.8209 - val_mse: 839.2590\n",
      "Epoch 860/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6485 - mse: 759.8796 - val_loss: 18.6351 - val_mse: 740.1252\n",
      "Epoch 861/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6581 - mse: 764.9733 - val_loss: 19.0850 - val_mse: 722.6504\n",
      "Epoch 862/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0692 - mse: 786.8342 - val_loss: 18.5220 - val_mse: 753.8260\n",
      "Epoch 863/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6080 - mse: 765.0875 - val_loss: 18.6857 - val_mse: 732.7522\n",
      "Epoch 864/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6776 - mse: 754.0645 - val_loss: 18.8300 - val_mse: 822.6977\n",
      "Epoch 865/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6281 - mse: 766.7079 - val_loss: 18.4953 - val_mse: 790.1837\n",
      "Epoch 866/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6491 - mse: 765.6754 - val_loss: 18.6364 - val_mse: 813.6746\n",
      "Epoch 867/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7698 - mse: 761.0382 - val_loss: 18.8612 - val_mse: 759.0511\n",
      "Epoch 868/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7710 - mse: 770.7684 - val_loss: 18.5642 - val_mse: 808.8148\n",
      "Epoch 869/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.6510 - mse: 766.7112 - val_loss: 18.3811 - val_mse: 740.0447\n",
      "Epoch 870/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7770 - mse: 769.6759 - val_loss: 18.9265 - val_mse: 764.8738\n",
      "Epoch 871/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7229 - mse: 767.9294 - val_loss: 19.4372 - val_mse: 724.4534\n",
      "Epoch 872/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.3397 - mse: 802.5306 - val_loss: 18.9153 - val_mse: 794.0394\n",
      "Epoch 873/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1957 - mse: 786.8604 - val_loss: 20.8133 - val_mse: 984.3390\n",
      "Epoch 874/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7431 - mse: 780.5874 - val_loss: 18.5831 - val_mse: 745.3893\n",
      "Epoch 875/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7073 - mse: 770.3412 - val_loss: 19.4051 - val_mse: 880.4946\n",
      "Epoch 876/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6858 - mse: 767.2689 - val_loss: 18.9426 - val_mse: 730.9601\n",
      "Epoch 877/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6973 - mse: 763.8406 - val_loss: 19.2710 - val_mse: 734.5413\n",
      "Epoch 878/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7875 - mse: 771.9658 - val_loss: 19.0085 - val_mse: 726.5909\n",
      "Epoch 879/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.8191 - mse: 769.2667 - val_loss: 18.7016 - val_mse: 793.4538\n",
      "Epoch 880/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.7816 - mse: 772.6420 - val_loss: 18.4911 - val_mse: 788.5133\n",
      "Epoch 881/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6583 - mse: 770.7859 - val_loss: 18.4520 - val_mse: 788.7623\n",
      "Epoch 882/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8639 - mse: 777.3865 - val_loss: 19.2028 - val_mse: 774.8331\n",
      "Epoch 883/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0061 - mse: 784.2905 - val_loss: 18.5158 - val_mse: 781.5978\n",
      "Epoch 884/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5061 - mse: 762.7496 - val_loss: 19.1592 - val_mse: 721.0775\n",
      "Epoch 885/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7239 - mse: 754.8464 - val_loss: 18.5028 - val_mse: 769.9059\n",
      "Epoch 886/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6884 - mse: 767.2728 - val_loss: 18.8147 - val_mse: 722.7161\n",
      "Epoch 887/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7274 - mse: 771.2330 - val_loss: 18.4637 - val_mse: 763.2783\n",
      "Epoch 888/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5206 - mse: 752.8342 - val_loss: 19.5580 - val_mse: 873.6500\n",
      "Epoch 889/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8518 - mse: 774.9430 - val_loss: 18.3775 - val_mse: 747.7552\n",
      "Epoch 890/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8627 - mse: 779.4410 - val_loss: 19.4806 - val_mse: 729.4694\n",
      "Epoch 891/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.7360 - mse: 766.1215 - val_loss: 18.5604 - val_mse: 796.2975\n",
      "Epoch 892/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7491 - mse: 772.5591 - val_loss: 18.8580 - val_mse: 829.3963\n",
      "Epoch 893/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0112 - mse: 791.7790 - val_loss: 18.6934 - val_mse: 777.8315\n",
      "Epoch 894/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8252 - mse: 779.2457 - val_loss: 18.7812 - val_mse: 781.3824\n",
      "Epoch 895/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7400 - mse: 783.1747 - val_loss: 18.5759 - val_mse: 739.7808\n",
      "Epoch 896/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4401 - mse: 756.3058 - val_loss: 18.8343 - val_mse: 806.7871\n",
      "Epoch 897/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6537 - mse: 762.7345 - val_loss: 18.6595 - val_mse: 820.4439\n",
      "Epoch 898/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.4946 - mse: 754.3107 - val_loss: 18.6664 - val_mse: 810.2490\n",
      "Epoch 899/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4972 - mse: 758.0981 - val_loss: 18.4884 - val_mse: 728.0865\n",
      "Epoch 900/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6839 - mse: 756.4874 - val_loss: 18.5667 - val_mse: 749.1357\n",
      "Epoch 901/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5231 - mse: 761.9785 - val_loss: 18.7376 - val_mse: 806.7996\n",
      "Epoch 902/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.8862 - mse: 771.5088 - val_loss: 19.5933 - val_mse: 744.8671\n",
      "Epoch 903/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.7839 - mse: 779.5524 - val_loss: 18.8085 - val_mse: 731.8196\n",
      "Epoch 904/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5171 - mse: 754.8253 - val_loss: 18.5915 - val_mse: 771.3629\n",
      "Epoch 905/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7990 - mse: 776.7565 - val_loss: 18.9838 - val_mse: 720.9520\n",
      "Epoch 906/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7641 - mse: 769.7028 - val_loss: 18.6690 - val_mse: 753.5952\n",
      "Epoch 907/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8049 - mse: 769.3022 - val_loss: 18.3817 - val_mse: 784.8903\n",
      "Epoch 908/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.5369 - mse: 763.8397 - val_loss: 18.6929 - val_mse: 737.3397\n",
      "Epoch 909/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.5074 - mse: 763.1042 - val_loss: 19.0883 - val_mse: 722.6370\n",
      "Epoch 910/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.5031 - mse: 758.3654 - val_loss: 19.9525 - val_mse: 926.8791\n",
      "Epoch 911/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 19.0145 - mse: 787.7264 - val_loss: 19.0070 - val_mse: 826.6492\n",
      "Epoch 912/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.9655 - mse: 778.9854 - val_loss: 18.6572 - val_mse: 773.0491\n",
      "Epoch 913/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8269 - mse: 777.4863 - val_loss: 18.6029 - val_mse: 754.0527\n",
      "Epoch 914/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5382 - mse: 757.3024 - val_loss: 19.3357 - val_mse: 865.6590\n",
      "Epoch 915/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7163 - mse: 768.9015 - val_loss: 19.0302 - val_mse: 860.9956\n",
      "Epoch 916/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9110 - mse: 783.9054 - val_loss: 19.5452 - val_mse: 901.9595\n",
      "Epoch 917/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.9302 - mse: 788.9024 - val_loss: 18.3282 - val_mse: 754.3843\n",
      "Epoch 918/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7439 - mse: 762.4897 - val_loss: 18.4618 - val_mse: 785.1547\n",
      "Epoch 919/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 19.2342 - mse: 796.9255 - val_loss: 19.5581 - val_mse: 908.8942\n",
      "Epoch 920/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 19.2262 - mse: 805.7416 - val_loss: 18.8114 - val_mse: 803.0027\n",
      "Epoch 921/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6625 - mse: 760.2291 - val_loss: 19.1496 - val_mse: 843.7054\n",
      "Epoch 922/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8565 - mse: 782.2836 - val_loss: 18.8199 - val_mse: 748.6340\n",
      "Epoch 923/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4802 - mse: 751.1852 - val_loss: 18.4703 - val_mse: 734.6246\n",
      "Epoch 924/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4840 - mse: 746.3716 - val_loss: 18.5716 - val_mse: 754.2452\n",
      "Epoch 925/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6442 - mse: 774.8276 - val_loss: 18.4852 - val_mse: 776.5777\n",
      "Epoch 926/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7333 - mse: 772.3935 - val_loss: 18.4986 - val_mse: 766.6636\n",
      "Epoch 927/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8658 - mse: 770.1749 - val_loss: 18.5218 - val_mse: 801.2554\n",
      "Epoch 928/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7018 - mse: 760.9009 - val_loss: 18.9471 - val_mse: 776.3010\n",
      "Epoch 929/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7404 - mse: 773.2544 - val_loss: 18.4192 - val_mse: 758.7288\n",
      "Epoch 930/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5765 - mse: 772.9843 - val_loss: 18.4258 - val_mse: 789.9164\n",
      "Epoch 931/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5342 - mse: 762.1027 - val_loss: 18.9661 - val_mse: 788.9715\n",
      "Epoch 932/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5350 - mse: 765.3521 - val_loss: 18.3977 - val_mse: 748.4926\n",
      "Epoch 933/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3361 - mse: 747.5509 - val_loss: 18.3728 - val_mse: 754.1437\n",
      "Epoch 934/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5370 - mse: 763.2487 - val_loss: 19.7126 - val_mse: 743.6615\n",
      "Epoch 935/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4929 - mse: 758.8500 - val_loss: 18.5561 - val_mse: 751.4880\n",
      "Epoch 936/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4449 - mse: 748.4282 - val_loss: 19.3413 - val_mse: 786.4424\n",
      "Epoch 937/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.4758 - mse: 820.7172 - val_loss: 18.7999 - val_mse: 736.4825\n",
      "Epoch 938/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4981 - mse: 758.6566 - val_loss: 19.1880 - val_mse: 791.9495\n",
      "Epoch 939/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7239 - mse: 770.2757 - val_loss: 19.6043 - val_mse: 731.9104\n",
      "Epoch 940/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9512 - mse: 778.8387 - val_loss: 18.9355 - val_mse: 721.7888\n",
      "Epoch 941/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5211 - mse: 748.4261 - val_loss: 18.9944 - val_mse: 828.8715\n",
      "Epoch 942/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5882 - mse: 764.8347 - val_loss: 18.5603 - val_mse: 803.0312\n",
      "Epoch 943/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9842 - mse: 790.4711 - val_loss: 18.7463 - val_mse: 831.9993\n",
      "Epoch 944/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6788 - mse: 767.5721 - val_loss: 18.4342 - val_mse: 788.6871\n",
      "Epoch 945/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4831 - mse: 754.8635 - val_loss: 18.3493 - val_mse: 764.5177\n",
      "Epoch 946/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3069 - mse: 744.9126 - val_loss: 18.4705 - val_mse: 803.4477\n",
      "Epoch 947/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4379 - mse: 757.9921 - val_loss: 18.3046 - val_mse: 775.1436\n",
      "Epoch 948/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4321 - mse: 751.2613 - val_loss: 18.4470 - val_mse: 750.3965\n",
      "Epoch 949/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6848 - mse: 768.0460 - val_loss: 19.1097 - val_mse: 738.1890\n",
      "Epoch 950/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5948 - mse: 767.9703 - val_loss: 18.6440 - val_mse: 723.3975\n",
      "Epoch 951/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 19.3409 - mse: 803.6148 - val_loss: 18.7986 - val_mse: 754.8224\n",
      "Epoch 952/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6936 - mse: 765.0019 - val_loss: 18.4439 - val_mse: 786.7026\n",
      "Epoch 953/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3430 - mse: 752.6065 - val_loss: 18.2506 - val_mse: 749.6177\n",
      "Epoch 954/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5807 - mse: 757.3485 - val_loss: 18.7297 - val_mse: 744.9631\n",
      "Epoch 955/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5005 - mse: 756.1078 - val_loss: 19.5233 - val_mse: 899.2908\n",
      "Epoch 956/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5216 - mse: 763.2767 - val_loss: 18.2462 - val_mse: 745.5076\n",
      "Epoch 957/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5140 - mse: 765.3199 - val_loss: 18.4973 - val_mse: 777.7194\n",
      "Epoch 958/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4576 - mse: 759.0701 - val_loss: 18.8849 - val_mse: 840.8739\n",
      "Epoch 959/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8101 - mse: 771.5078 - val_loss: 18.5180 - val_mse: 765.5502\n",
      "Epoch 960/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.5044 - mse: 749.0776 - val_loss: 19.1319 - val_mse: 862.6698\n",
      "Epoch 961/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1691 - mse: 786.6846 - val_loss: 18.7109 - val_mse: 761.0464\n",
      "Epoch 962/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5826 - mse: 772.5879 - val_loss: 18.3712 - val_mse: 766.0450\n",
      "Epoch 963/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8532 - mse: 773.1646 - val_loss: 18.8523 - val_mse: 824.1179\n",
      "Epoch 964/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4367 - mse: 759.7021 - val_loss: 18.7928 - val_mse: 837.3482\n",
      "Epoch 965/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2510 - mse: 740.6405 - val_loss: 19.4239 - val_mse: 828.2114\n",
      "Epoch 966/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7428 - mse: 770.6156 - val_loss: 18.6921 - val_mse: 717.4149\n",
      "Epoch 967/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2824 - mse: 745.6995 - val_loss: 18.6566 - val_mse: 713.5958\n",
      "Epoch 968/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9563 - mse: 777.3499 - val_loss: 18.5288 - val_mse: 723.6630\n",
      "Epoch 969/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5458 - mse: 761.1576 - val_loss: 18.4513 - val_mse: 796.8804\n",
      "Epoch 970/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5435 - mse: 761.3769 - val_loss: 19.1416 - val_mse: 737.3208\n",
      "Epoch 971/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8179 - mse: 772.9963 - val_loss: 18.2855 - val_mse: 784.2045\n",
      "Epoch 972/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.4028 - mse: 761.9842 - val_loss: 18.6267 - val_mse: 763.5601\n",
      "Epoch 973/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4254 - mse: 756.5909 - val_loss: 18.2317 - val_mse: 787.4218\n",
      "Epoch 974/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5567 - mse: 750.6012 - val_loss: 18.2913 - val_mse: 723.4258\n",
      "Epoch 975/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5049 - mse: 765.7816 - val_loss: 18.3760 - val_mse: 718.0511\n",
      "Epoch 976/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3217 - mse: 749.4858 - val_loss: 18.2294 - val_mse: 780.1598\n",
      "Epoch 977/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6908 - mse: 771.2185 - val_loss: 19.2021 - val_mse: 718.0269\n",
      "Epoch 978/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4558 - mse: 755.6830 - val_loss: 18.1458 - val_mse: 756.7344\n",
      "Epoch 979/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9717 - mse: 780.5960 - val_loss: 18.4663 - val_mse: 807.6742\n",
      "Epoch 980/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4124 - mse: 758.6821 - val_loss: 18.5688 - val_mse: 724.2406\n",
      "Epoch 981/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.6582 - mse: 767.1405 - val_loss: 18.1593 - val_mse: 777.3933\n",
      "Epoch 982/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8957 - mse: 770.9781 - val_loss: 19.6915 - val_mse: 920.7670\n",
      "Epoch 983/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.2964 - mse: 857.8852 - val_loss: 19.6836 - val_mse: 910.3962\n",
      "Epoch 984/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1762 - mse: 807.8426 - val_loss: 18.8125 - val_mse: 798.8085\n",
      "Epoch 985/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6481 - mse: 767.4194 - val_loss: 19.7279 - val_mse: 726.9610\n",
      "Epoch 986/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.6467 - mse: 760.6882 - val_loss: 18.6939 - val_mse: 725.9073\n",
      "Epoch 987/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9258 - mse: 776.5762 - val_loss: 18.6891 - val_mse: 820.6027\n",
      "Epoch 988/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0604 - mse: 786.3128 - val_loss: 19.1121 - val_mse: 858.2761\n",
      "Epoch 989/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1360 - mse: 796.0330 - val_loss: 18.2927 - val_mse: 769.5785\n",
      "Epoch 990/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3593 - mse: 747.8196 - val_loss: 19.0171 - val_mse: 876.6856\n",
      "Epoch 991/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3920 - mse: 759.4249 - val_loss: 18.4692 - val_mse: 728.7686\n",
      "Epoch 992/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.3399 - mse: 747.1058 - val_loss: 18.1771 - val_mse: 773.4388\n",
      "Epoch 993/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3702 - mse: 753.0167 - val_loss: 18.8533 - val_mse: 708.1256\n",
      "Epoch 994/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3638 - mse: 741.5597 - val_loss: 18.1995 - val_mse: 771.8811\n",
      "Epoch 995/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9375 - mse: 792.7592 - val_loss: 18.4088 - val_mse: 806.7588\n",
      "Epoch 996/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.1137 - mse: 799.4957 - val_loss: 18.7494 - val_mse: 846.6790\n",
      "Epoch 997/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.5463 - mse: 758.2185 - val_loss: 18.3968 - val_mse: 816.7822\n",
      "Epoch 998/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2684 - mse: 745.9761 - val_loss: 18.4615 - val_mse: 714.0875\n",
      "Epoch 999/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5319 - mse: 742.7341 - val_loss: 19.1065 - val_mse: 871.9127\n",
      "Epoch 1000/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.9162 - mse: 797.4840 - val_loss: 18.1976 - val_mse: 732.8746\n",
      "Epoch 1001/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6733 - mse: 762.2408 - val_loss: 18.5011 - val_mse: 813.8036\n",
      "Epoch 1002/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3902 - mse: 756.7900 - val_loss: 18.2405 - val_mse: 770.8123\n",
      "Epoch 1003/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3879 - mse: 756.4136 - val_loss: 18.5597 - val_mse: 764.2997\n",
      "Epoch 1004/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4775 - mse: 757.5168 - val_loss: 18.1434 - val_mse: 725.3995\n",
      "Epoch 1005/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2598 - mse: 739.9721 - val_loss: 18.2034 - val_mse: 760.4575\n",
      "Epoch 1006/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3561 - mse: 738.5712 - val_loss: 18.3500 - val_mse: 808.6181\n",
      "Epoch 1007/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.4278 - mse: 755.2168 - val_loss: 18.3359 - val_mse: 771.3141\n",
      "Epoch 1008/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4563 - mse: 759.8987 - val_loss: 18.2389 - val_mse: 746.0804\n",
      "Epoch 1009/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0683 - mse: 794.6556 - val_loss: 18.3894 - val_mse: 752.1602\n",
      "Epoch 1010/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6162 - mse: 764.0316 - val_loss: 18.1438 - val_mse: 766.1190\n",
      "Epoch 1011/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4511 - mse: 762.7747 - val_loss: 18.2715 - val_mse: 794.0356\n",
      "Epoch 1012/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3416 - mse: 746.4908 - val_loss: 18.3620 - val_mse: 807.1365\n",
      "Epoch 1013/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1406 - mse: 739.8806 - val_loss: 18.7036 - val_mse: 759.1086\n",
      "Epoch 1014/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6220 - mse: 755.6721 - val_loss: 19.8348 - val_mse: 935.3558\n",
      "Epoch 1015/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8383 - mse: 774.6212 - val_loss: 18.1559 - val_mse: 752.8123\n",
      "Epoch 1016/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5812 - mse: 754.4950 - val_loss: 18.1970 - val_mse: 795.5766\n",
      "Epoch 1017/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1558 - mse: 737.3337 - val_loss: 18.6640 - val_mse: 710.6180\n",
      "Epoch 1018/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5763 - mse: 758.4272 - val_loss: 18.5469 - val_mse: 771.3702\n",
      "Epoch 1019/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6032 - mse: 763.4095 - val_loss: 18.5820 - val_mse: 806.9401\n",
      "Epoch 1020/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4417 - mse: 758.0361 - val_loss: 19.0834 - val_mse: 876.6622\n",
      "Epoch 1021/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5057 - mse: 757.9225 - val_loss: 19.2266 - val_mse: 713.0439\n",
      "Epoch 1022/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4007 - mse: 747.4290 - val_loss: 18.2419 - val_mse: 721.2960\n",
      "Epoch 1023/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3240 - mse: 749.8687 - val_loss: 18.0655 - val_mse: 762.5362\n",
      "Epoch 1024/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2092 - mse: 734.2436 - val_loss: 18.3103 - val_mse: 732.2924\n",
      "Epoch 1025/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3207 - mse: 753.1842 - val_loss: 18.6590 - val_mse: 768.7010\n",
      "Epoch 1026/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3408 - mse: 731.5123 - val_loss: 19.0233 - val_mse: 847.1561\n",
      "Epoch 1027/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3422 - mse: 740.6662 - val_loss: 18.2558 - val_mse: 718.6417\n",
      "Epoch 1028/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3398 - mse: 746.9958 - val_loss: 18.0993 - val_mse: 748.6103\n",
      "Epoch 1029/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2782 - mse: 743.0258 - val_loss: 18.1375 - val_mse: 767.4188\n",
      "Epoch 1030/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5204 - mse: 771.2792 - val_loss: 19.1340 - val_mse: 746.7538\n",
      "Epoch 1031/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8274 - mse: 769.3671 - val_loss: 19.3219 - val_mse: 740.1097\n",
      "Epoch 1032/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2720 - mse: 747.1190 - val_loss: 18.2060 - val_mse: 760.7859\n",
      "Epoch 1033/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.7467 - mse: 766.6544 - val_loss: 18.0463 - val_mse: 761.9025\n",
      "Epoch 1034/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1948 - mse: 739.8859 - val_loss: 18.0217 - val_mse: 715.8258\n",
      "Epoch 1035/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2782 - mse: 744.7938 - val_loss: 18.2667 - val_mse: 777.5969\n",
      "Epoch 1036/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3508 - mse: 748.5938 - val_loss: 18.3758 - val_mse: 786.0038\n",
      "Epoch 1037/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6240 - mse: 765.2808 - val_loss: 18.3156 - val_mse: 716.4657\n",
      "Epoch 1038/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0083 - mse: 789.3798 - val_loss: 19.7163 - val_mse: 928.0206\n",
      "Epoch 1039/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4149 - mse: 752.0380 - val_loss: 18.1837 - val_mse: 735.4800\n",
      "Epoch 1040/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6405 - mse: 770.8198 - val_loss: 18.4169 - val_mse: 814.5408\n",
      "Epoch 1041/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3292 - mse: 744.3307 - val_loss: 18.3619 - val_mse: 723.2129\n",
      "Epoch 1042/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5188 - mse: 758.7341 - val_loss: 18.1710 - val_mse: 738.3672\n",
      "Epoch 1043/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2058 - mse: 737.4999 - val_loss: 18.2828 - val_mse: 775.9860\n",
      "Epoch 1044/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7130 - mse: 777.9637 - val_loss: 20.9510 - val_mse: 778.3540\n",
      "Epoch 1045/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.2060 - mse: 793.1871 - val_loss: 18.7540 - val_mse: 750.7600\n",
      "Epoch 1046/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5132 - mse: 752.6942 - val_loss: 18.6910 - val_mse: 788.5542\n",
      "Epoch 1047/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0030 - mse: 791.6506 - val_loss: 18.8625 - val_mse: 827.4879\n",
      "Epoch 1048/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3855 - mse: 751.3886 - val_loss: 18.0415 - val_mse: 752.1365\n",
      "Epoch 1049/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4993 - mse: 753.4666 - val_loss: 18.3490 - val_mse: 734.2261\n",
      "Epoch 1050/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5664 - mse: 759.6227 - val_loss: 18.6687 - val_mse: 807.7697\n",
      "Epoch 1051/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3351 - mse: 740.6374 - val_loss: 18.2583 - val_mse: 802.4675\n",
      "Epoch 1052/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2092 - mse: 737.9733 - val_loss: 18.2233 - val_mse: 759.8026\n",
      "Epoch 1053/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.3048 - mse: 740.5810 - val_loss: 18.9052 - val_mse: 714.1246\n",
      "Epoch 1054/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6286 - mse: 759.6052 - val_loss: 18.0688 - val_mse: 753.3592\n",
      "Epoch 1055/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0296 - mse: 729.9950 - val_loss: 18.2591 - val_mse: 715.0637\n",
      "Epoch 1056/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4778 - mse: 749.9307 - val_loss: 18.0269 - val_mse: 749.4015\n",
      "Epoch 1057/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.3385 - mse: 753.0441 - val_loss: 18.3792 - val_mse: 754.1590\n",
      "Epoch 1058/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2900 - mse: 743.7272 - val_loss: 18.8813 - val_mse: 859.3760\n",
      "Epoch 1059/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6442 - mse: 771.7517 - val_loss: 18.7100 - val_mse: 703.4735\n",
      "Epoch 1060/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4297 - mse: 757.3447 - val_loss: 18.5857 - val_mse: 720.2889\n",
      "Epoch 1061/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2880 - mse: 746.8677 - val_loss: 18.2579 - val_mse: 804.5816\n",
      "Epoch 1062/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4631 - mse: 760.0305 - val_loss: 20.2817 - val_mse: 737.2784\n",
      "Epoch 1063/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3756 - mse: 756.2047 - val_loss: 18.3215 - val_mse: 799.5093\n",
      "Epoch 1064/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9879 - mse: 727.7463 - val_loss: 18.6680 - val_mse: 748.1487\n",
      "Epoch 1065/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3477 - mse: 741.8903 - val_loss: 18.4516 - val_mse: 702.9106\n",
      "Epoch 1066/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1359 - mse: 737.4131 - val_loss: 18.1584 - val_mse: 726.7081\n",
      "Epoch 1067/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2224 - mse: 746.0153 - val_loss: 18.1305 - val_mse: 742.2127\n",
      "Epoch 1068/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6478 - mse: 758.4408 - val_loss: 17.9633 - val_mse: 723.7183\n",
      "Epoch 1069/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0863 - mse: 725.9896 - val_loss: 18.5687 - val_mse: 700.7743\n",
      "Epoch 1070/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4093 - mse: 753.0483 - val_loss: 18.0253 - val_mse: 749.2729\n",
      "Epoch 1071/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2925 - mse: 745.1095 - val_loss: 18.4395 - val_mse: 746.4583\n",
      "Epoch 1072/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2675 - mse: 742.2354 - val_loss: 18.0180 - val_mse: 733.8475\n",
      "Epoch 1073/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8835 - mse: 784.5340 - val_loss: 22.0248 - val_mse: 1081.5195\n",
      "Epoch 1074/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6556 - mse: 779.4000 - val_loss: 18.4501 - val_mse: 812.1259\n",
      "Epoch 1075/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4283 - mse: 751.3566 - val_loss: 18.3495 - val_mse: 737.9940\n",
      "Epoch 1076/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3154 - mse: 748.1924 - val_loss: 18.4084 - val_mse: 707.0894\n",
      "Epoch 1077/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3231 - mse: 749.2668 - val_loss: 18.4509 - val_mse: 708.1314\n",
      "Epoch 1078/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2054 - mse: 730.4873 - val_loss: 19.3993 - val_mse: 732.5156\n",
      "Epoch 1079/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6344 - mse: 764.4150 - val_loss: 18.9028 - val_mse: 849.7977\n",
      "Epoch 1080/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3168 - mse: 746.7490 - val_loss: 18.0777 - val_mse: 727.7996\n",
      "Epoch 1081/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4679 - mse: 755.7316 - val_loss: 18.6732 - val_mse: 745.7311\n",
      "Epoch 1082/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2402 - mse: 740.3215 - val_loss: 18.2978 - val_mse: 706.5420\n",
      "Epoch 1083/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6866 - mse: 764.4474 - val_loss: 18.1826 - val_mse: 788.0168\n",
      "Epoch 1084/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0634 - mse: 796.9282 - val_loss: 19.2087 - val_mse: 890.9125\n",
      "Epoch 1085/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3917 - mse: 750.9750 - val_loss: 18.1086 - val_mse: 731.2404\n",
      "Epoch 1086/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2901 - mse: 743.6832 - val_loss: 18.1821 - val_mse: 781.4702\n",
      "Epoch 1087/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.1515 - mse: 731.6332 - val_loss: 18.8398 - val_mse: 704.4560\n",
      "Epoch 1088/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5537 - mse: 767.9541 - val_loss: 18.3035 - val_mse: 738.1275\n",
      "Epoch 1089/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1802 - mse: 723.9636 - val_loss: 18.1785 - val_mse: 735.3571\n",
      "Epoch 1090/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3941 - mse: 755.9653 - val_loss: 19.5856 - val_mse: 727.0674\n",
      "Epoch 1091/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8428 - mse: 781.7197 - val_loss: 18.1639 - val_mse: 784.5349\n",
      "Epoch 1092/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1616 - mse: 743.9471 - val_loss: 18.3692 - val_mse: 714.5407\n",
      "Epoch 1093/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1885 - mse: 730.5470 - val_loss: 18.3212 - val_mse: 795.6818\n",
      "Epoch 1094/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3528 - mse: 745.4581 - val_loss: 18.1632 - val_mse: 727.5850\n",
      "Epoch 1095/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3000 - mse: 745.3563 - val_loss: 18.2331 - val_mse: 757.2410\n",
      "Epoch 1096/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7935 - mse: 777.1300 - val_loss: 18.7495 - val_mse: 705.3911\n",
      "Epoch 1097/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0383 - mse: 727.7363 - val_loss: 18.3609 - val_mse: 749.1326\n",
      "Epoch 1098/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4945 - mse: 756.6187 - val_loss: 18.6656 - val_mse: 832.1010\n",
      "Epoch 1099/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0984 - mse: 733.7581 - val_loss: 18.3601 - val_mse: 808.0912\n",
      "Epoch 1100/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2632 - mse: 743.5346 - val_loss: 18.1020 - val_mse: 764.7817\n",
      "Epoch 1101/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2047 - mse: 730.1398 - val_loss: 18.3030 - val_mse: 738.0378\n",
      "Epoch 1102/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.9708 - mse: 778.2050 - val_loss: 18.9380 - val_mse: 798.6056\n",
      "Epoch 1103/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4211 - mse: 756.1459 - val_loss: 18.4930 - val_mse: 710.9644\n",
      "Epoch 1104/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1825 - mse: 737.4576 - val_loss: 18.1572 - val_mse: 763.8717\n",
      "Epoch 1105/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2425 - mse: 746.1851 - val_loss: 18.4122 - val_mse: 712.1485\n",
      "Epoch 1106/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3008 - mse: 743.9503 - val_loss: 18.0607 - val_mse: 732.0415\n",
      "Epoch 1107/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3656 - mse: 752.9827 - val_loss: 18.5776 - val_mse: 828.0290\n",
      "Epoch 1108/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2070 - mse: 737.1515 - val_loss: 18.0406 - val_mse: 741.6832\n",
      "Epoch 1109/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3949 - mse: 754.1951 - val_loss: 18.0907 - val_mse: 742.9194\n",
      "Epoch 1110/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2280 - mse: 740.7990 - val_loss: 18.5401 - val_mse: 706.0202\n",
      "Epoch 1111/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2078 - mse: 735.6951 - val_loss: 17.9128 - val_mse: 730.5322\n",
      "Epoch 1112/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2043 - mse: 735.0984 - val_loss: 18.2384 - val_mse: 710.5128\n",
      "Epoch 1113/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1993 - mse: 741.1567 - val_loss: 17.9355 - val_mse: 739.9993\n",
      "Epoch 1114/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9871 - mse: 725.4489 - val_loss: 18.0808 - val_mse: 740.8553\n",
      "Epoch 1115/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0613 - mse: 727.7263 - val_loss: 18.0782 - val_mse: 712.4545\n",
      "Epoch 1116/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7103 - mse: 771.3460 - val_loss: 18.1714 - val_mse: 707.9165\n",
      "Epoch 1117/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7453 - mse: 760.1450 - val_loss: 18.0554 - val_mse: 728.2459\n",
      "Epoch 1118/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.3655 - mse: 758.4739 - val_loss: 18.0132 - val_mse: 749.9800\n",
      "Epoch 1119/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0879 - mse: 729.2303 - val_loss: 18.5602 - val_mse: 827.0444\n",
      "Epoch 1120/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2108 - mse: 740.5443 - val_loss: 18.2902 - val_mse: 777.8839\n",
      "Epoch 1121/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2499 - mse: 751.3389 - val_loss: 18.4439 - val_mse: 700.3170\n",
      "Epoch 1122/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1274 - mse: 723.4526 - val_loss: 18.4064 - val_mse: 722.0463\n",
      "Epoch 1123/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5727 - mse: 759.0749 - val_loss: 18.1567 - val_mse: 775.8572\n",
      "Epoch 1124/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4807 - mse: 750.1534 - val_loss: 18.4307 - val_mse: 708.5607\n",
      "Epoch 1125/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4802 - mse: 762.0280 - val_loss: 18.3821 - val_mse: 803.4429\n",
      "Epoch 1126/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3840 - mse: 757.9882 - val_loss: 18.4589 - val_mse: 702.0930\n",
      "Epoch 1127/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2432 - mse: 734.2819 - val_loss: 19.6663 - val_mse: 717.7938\n",
      "Epoch 1128/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2748 - mse: 742.2709 - val_loss: 18.2259 - val_mse: 775.1182\n",
      "Epoch 1129/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2485 - mse: 741.2024 - val_loss: 18.0607 - val_mse: 756.7798\n",
      "Epoch 1130/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9573 - mse: 723.9354 - val_loss: 18.3379 - val_mse: 757.8588\n",
      "Epoch 1131/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9718 - mse: 719.6611 - val_loss: 18.1904 - val_mse: 748.6444\n",
      "Epoch 1132/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2400 - mse: 749.0185 - val_loss: 18.2652 - val_mse: 701.1935\n",
      "Epoch 1133/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1890 - mse: 731.9955 - val_loss: 18.2974 - val_mse: 713.6127\n",
      "Epoch 1134/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1151 - mse: 735.2458 - val_loss: 17.9527 - val_mse: 728.6854\n",
      "Epoch 1135/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5114 - mse: 753.6264 - val_loss: 18.9129 - val_mse: 780.6234\n",
      "Epoch 1136/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4545 - mse: 760.1316 - val_loss: 18.4147 - val_mse: 799.1944\n",
      "Epoch 1137/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.1366 - mse: 742.4885 - val_loss: 19.1629 - val_mse: 788.8717\n",
      "Epoch 1138/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.3523 - mse: 744.6262 - val_loss: 18.3927 - val_mse: 766.7165\n",
      "Epoch 1139/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8320 - mse: 768.9416 - val_loss: 18.4070 - val_mse: 732.6722\n",
      "Epoch 1140/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.4232 - mse: 746.3117 - val_loss: 18.0912 - val_mse: 726.1340\n",
      "Epoch 1141/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.1408 - mse: 732.8416 - val_loss: 18.0528 - val_mse: 747.1536\n",
      "Epoch 1142/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0428 - mse: 723.6919 - val_loss: 18.4284 - val_mse: 780.3229\n",
      "Epoch 1143/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4158 - mse: 746.8950 - val_loss: 18.1377 - val_mse: 757.7894\n",
      "Epoch 1144/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5104 - mse: 753.0741 - val_loss: 18.2634 - val_mse: 754.4948\n",
      "Epoch 1145/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.1328 - mse: 731.2390 - val_loss: 18.7305 - val_mse: 843.1445\n",
      "Epoch 1146/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3701 - mse: 749.8481 - val_loss: 17.9687 - val_mse: 725.5947\n",
      "Epoch 1147/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.4270 - mse: 816.1761 - val_loss: 18.3930 - val_mse: 754.4850\n",
      "Epoch 1148/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1513 - mse: 741.6171 - val_loss: 18.1689 - val_mse: 732.1777\n",
      "Epoch 1149/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4345 - mse: 751.0311 - val_loss: 18.2938 - val_mse: 791.6558\n",
      "Epoch 1150/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4693 - mse: 758.8091 - val_loss: 18.0601 - val_mse: 739.7950\n",
      "Epoch 1151/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5455 - mse: 768.2162 - val_loss: 18.3226 - val_mse: 706.7856\n",
      "Epoch 1152/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1062 - mse: 734.2538 - val_loss: 18.1295 - val_mse: 709.9413\n",
      "Epoch 1153/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.3920 - mse: 745.5688 - val_loss: 18.1935 - val_mse: 776.1754\n",
      "Epoch 1154/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6264 - mse: 768.0524 - val_loss: 19.5010 - val_mse: 910.0906\n",
      "Epoch 1155/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1816 - mse: 743.0322 - val_loss: 18.7733 - val_mse: 703.4006\n",
      "Epoch 1156/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5181 - mse: 759.7412 - val_loss: 18.4072 - val_mse: 769.8014\n",
      "Epoch 1157/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3303 - mse: 753.8679 - val_loss: 18.0796 - val_mse: 763.2651\n",
      "Epoch 1158/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3948 - mse: 761.0103 - val_loss: 20.2057 - val_mse: 724.8123\n",
      "Epoch 1159/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4482 - mse: 755.3369 - val_loss: 18.0844 - val_mse: 716.5204\n",
      "Epoch 1160/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4967 - mse: 755.1174 - val_loss: 18.8779 - val_mse: 815.0189\n",
      "Epoch 1161/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4861 - mse: 768.0200 - val_loss: 18.1172 - val_mse: 773.7717\n",
      "Epoch 1162/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4328 - mse: 745.0681 - val_loss: 18.8300 - val_mse: 722.1566\n",
      "Epoch 1163/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8104 - mse: 774.1598 - val_loss: 18.0448 - val_mse: 758.4166\n",
      "Epoch 1164/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9452 - mse: 727.8627 - val_loss: 18.1258 - val_mse: 698.4264\n",
      "Epoch 1165/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4282 - mse: 757.5348 - val_loss: 18.6491 - val_mse: 826.5377\n",
      "Epoch 1166/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3264 - mse: 743.2314 - val_loss: 18.5905 - val_mse: 732.7758\n",
      "Epoch 1167/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2225 - mse: 727.0129 - val_loss: 18.0695 - val_mse: 746.3837\n",
      "Epoch 1168/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1760 - mse: 742.8154 - val_loss: 18.3384 - val_mse: 759.0609\n",
      "Epoch 1169/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2217 - mse: 733.9717 - val_loss: 17.9939 - val_mse: 726.3339\n",
      "Epoch 1170/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5151 - mse: 761.6805 - val_loss: 19.5238 - val_mse: 901.2648\n",
      "Epoch 1171/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2972 - mse: 748.4355 - val_loss: 18.0943 - val_mse: 760.0007\n",
      "Epoch 1172/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9979 - mse: 720.7415 - val_loss: 19.2822 - val_mse: 863.0945\n",
      "Epoch 1173/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6050 - mse: 760.8885 - val_loss: 18.9803 - val_mse: 825.8688\n",
      "Epoch 1174/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1688 - mse: 741.6623 - val_loss: 18.2393 - val_mse: 755.3260\n",
      "Epoch 1175/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3975 - mse: 746.1577 - val_loss: 18.4103 - val_mse: 702.3917\n",
      "Epoch 1176/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9764 - mse: 719.6613 - val_loss: 18.3024 - val_mse: 782.3621\n",
      "Epoch 1177/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.1937 - mse: 737.4362 - val_loss: 18.1989 - val_mse: 760.3254\n",
      "Epoch 1178/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9595 - mse: 726.3886 - val_loss: 18.1139 - val_mse: 772.4568\n",
      "Epoch 1179/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0093 - mse: 725.8575 - val_loss: 18.5749 - val_mse: 798.5295\n",
      "Epoch 1180/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.4188 - mse: 754.5573 - val_loss: 18.2345 - val_mse: 706.6227\n",
      "Epoch 1181/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9828 - mse: 716.1495 - val_loss: 18.0055 - val_mse: 735.7140\n",
      "Epoch 1182/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9523 - mse: 726.8715 - val_loss: 18.1215 - val_mse: 711.2711\n",
      "Epoch 1183/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0989 - mse: 731.1826 - val_loss: 18.3490 - val_mse: 707.5621\n",
      "Epoch 1184/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1384 - mse: 730.9905 - val_loss: 18.0651 - val_mse: 736.6749\n",
      "Epoch 1185/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1515 - mse: 728.0051 - val_loss: 18.6207 - val_mse: 779.8096\n",
      "Epoch 1186/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4875 - mse: 764.9501 - val_loss: 18.8821 - val_mse: 706.2444\n",
      "Epoch 1187/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3272 - mse: 748.1229 - val_loss: 18.0186 - val_mse: 717.8880\n",
      "Epoch 1188/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3276 - mse: 749.7877 - val_loss: 18.4362 - val_mse: 695.1458\n",
      "Epoch 1189/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4640 - mse: 740.9931 - val_loss: 18.3149 - val_mse: 706.4871\n",
      "Epoch 1190/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2680 - mse: 750.1058 - val_loss: 18.8505 - val_mse: 763.1898\n",
      "Epoch 1191/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.6071 - mse: 751.4789 - val_loss: 18.7932 - val_mse: 696.2611\n",
      "Epoch 1192/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.1197 - mse: 729.9330 - val_loss: 18.1185 - val_mse: 708.2692\n",
      "Epoch 1193/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0748 - mse: 726.7246 - val_loss: 18.3786 - val_mse: 694.9817\n",
      "Epoch 1194/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1985 - mse: 797.5146 - val_loss: 19.4559 - val_mse: 874.4902\n",
      "Epoch 1195/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4116 - mse: 741.4105 - val_loss: 18.2404 - val_mse: 755.6863\n",
      "Epoch 1196/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2905 - mse: 745.9332 - val_loss: 18.3590 - val_mse: 807.0856\n",
      "Epoch 1197/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2766 - mse: 733.7105 - val_loss: 18.0967 - val_mse: 761.2352\n",
      "Epoch 1198/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7321 - mse: 776.2180 - val_loss: 18.5220 - val_mse: 707.8976\n",
      "Epoch 1199/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0485 - mse: 728.9427 - val_loss: 18.0759 - val_mse: 712.8804\n",
      "Epoch 1200/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1253 - mse: 738.4669 - val_loss: 18.4169 - val_mse: 794.8599\n",
      "Epoch 1201/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1343 - mse: 731.9399 - val_loss: 19.2660 - val_mse: 873.0458\n",
      "Epoch 1202/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1658 - mse: 731.1141 - val_loss: 18.0152 - val_mse: 723.9246\n",
      "Epoch 1203/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0797 - mse: 733.1031 - val_loss: 18.2415 - val_mse: 777.0071\n",
      "Epoch 1204/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0874 - mse: 726.9479 - val_loss: 19.1587 - val_mse: 816.9160\n",
      "Epoch 1205/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4818 - mse: 752.4718 - val_loss: 20.3500 - val_mse: 960.2147\n",
      "Epoch 1206/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8687 - mse: 784.9044 - val_loss: 18.1022 - val_mse: 770.8021\n",
      "Epoch 1207/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4487 - mse: 749.5315 - val_loss: 18.9788 - val_mse: 696.0587\n",
      "Epoch 1208/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0609 - mse: 777.6843 - val_loss: 18.6490 - val_mse: 730.4363\n",
      "Epoch 1209/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1610 - mse: 739.7800 - val_loss: 18.2249 - val_mse: 768.0449\n",
      "Epoch 1210/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0183 - mse: 725.1186 - val_loss: 17.9092 - val_mse: 713.5908\n",
      "Epoch 1211/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9383 - mse: 718.3010 - val_loss: 18.0809 - val_mse: 758.6940\n",
      "Epoch 1212/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0998 - mse: 727.3804 - val_loss: 18.2054 - val_mse: 736.6510\n",
      "Epoch 1213/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2282 - mse: 741.6283 - val_loss: 18.1745 - val_mse: 718.7751\n",
      "Epoch 1214/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5067 - mse: 739.7642 - val_loss: 18.4284 - val_mse: 803.4317\n",
      "Epoch 1215/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4033 - mse: 749.7963 - val_loss: 18.4494 - val_mse: 808.8193\n",
      "Epoch 1216/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2994 - mse: 746.1398 - val_loss: 18.1270 - val_mse: 728.6092\n",
      "Epoch 1217/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2493 - mse: 742.2012 - val_loss: 18.6227 - val_mse: 738.3243\n",
      "Epoch 1218/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2041 - mse: 741.1663 - val_loss: 18.2081 - val_mse: 702.2706\n",
      "Epoch 1219/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0878 - mse: 729.5181 - val_loss: 18.3018 - val_mse: 707.2252\n",
      "Epoch 1220/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9969 - mse: 721.5844 - val_loss: 18.1760 - val_mse: 756.7456\n",
      "Epoch 1221/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1462 - mse: 728.6033 - val_loss: 18.7748 - val_mse: 721.9193\n",
      "Epoch 1222/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1881 - mse: 750.6768 - val_loss: 18.0324 - val_mse: 726.4434\n",
      "Epoch 1223/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0105 - mse: 722.9044 - val_loss: 18.4460 - val_mse: 755.4529\n",
      "Epoch 1224/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7142 - mse: 769.9860 - val_loss: 18.2850 - val_mse: 787.6734\n",
      "Epoch 1225/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0048 - mse: 729.7562 - val_loss: 18.2066 - val_mse: 699.5521\n",
      "Epoch 1226/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0617 - mse: 721.1973 - val_loss: 18.4986 - val_mse: 729.7131\n",
      "Epoch 1227/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4064 - mse: 755.6707 - val_loss: 18.6472 - val_mse: 699.8010\n",
      "Epoch 1228/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.2375 - mse: 798.7379 - val_loss: 20.1252 - val_mse: 750.9187\n",
      "Epoch 1229/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0589 - mse: 792.8105 - val_loss: 18.3901 - val_mse: 760.6575\n",
      "Epoch 1230/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5784 - mse: 765.9460 - val_loss: 18.2649 - val_mse: 742.4290\n",
      "Epoch 1231/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7822 - mse: 762.3022 - val_loss: 18.3435 - val_mse: 783.9304\n",
      "Epoch 1232/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7194 - mse: 774.9188 - val_loss: 19.0065 - val_mse: 847.6021\n",
      "Epoch 1233/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6135 - mse: 758.3932 - val_loss: 19.3316 - val_mse: 729.6284\n",
      "Epoch 1234/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4550 - mse: 757.0347 - val_loss: 18.2369 - val_mse: 727.0038\n",
      "Epoch 1235/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4471 - mse: 758.5939 - val_loss: 18.3104 - val_mse: 744.2865\n",
      "Epoch 1236/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4418 - mse: 759.0215 - val_loss: 18.4908 - val_mse: 772.6350\n",
      "Epoch 1237/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2503 - mse: 746.6285 - val_loss: 18.5338 - val_mse: 723.9664\n",
      "Epoch 1238/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6081 - mse: 759.3876 - val_loss: 18.2600 - val_mse: 778.0828\n",
      "Epoch 1239/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.4811 - mse: 753.5345 - val_loss: 18.2489 - val_mse: 787.0704\n",
      "Epoch 1240/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4538 - mse: 757.8971 - val_loss: 20.1131 - val_mse: 736.6416\n",
      "Epoch 1241/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7601 - mse: 773.6031 - val_loss: 18.2575 - val_mse: 751.4910\n",
      "Epoch 1242/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3045 - mse: 750.5758 - val_loss: 18.8942 - val_mse: 722.0678\n",
      "Epoch 1243/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7227 - mse: 759.7498 - val_loss: 18.1649 - val_mse: 734.4597\n",
      "Epoch 1244/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2524 - mse: 739.7308 - val_loss: 18.4371 - val_mse: 799.6671\n",
      "Epoch 1245/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2080 - mse: 731.4900 - val_loss: 18.2347 - val_mse: 746.6722\n",
      "Epoch 1246/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3734 - mse: 743.8505 - val_loss: 18.6039 - val_mse: 810.4992\n",
      "Epoch 1247/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2000 - mse: 724.4857 - val_loss: 18.1877 - val_mse: 777.5156\n",
      "Epoch 1248/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1087 - mse: 721.2885 - val_loss: 18.1912 - val_mse: 769.7940\n",
      "Epoch 1249/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.3782 - mse: 728.5084 - val_loss: 18.6987 - val_mse: 760.8373\n",
      "Epoch 1250/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9791 - mse: 788.7545 - val_loss: 18.3803 - val_mse: 724.2429\n",
      "Epoch 1251/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2798 - mse: 728.4260 - val_loss: 18.0126 - val_mse: 742.3463\n",
      "Epoch 1252/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8889 - mse: 773.7884 - val_loss: 18.3328 - val_mse: 758.9983\n",
      "Epoch 1253/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4866 - mse: 746.5238 - val_loss: 18.6171 - val_mse: 707.8598\n",
      "Epoch 1254/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9583 - mse: 784.7541 - val_loss: 18.8318 - val_mse: 723.1682\n",
      "Epoch 1255/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1016 - mse: 719.3096 - val_loss: 18.2928 - val_mse: 769.3411\n",
      "Epoch 1256/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0856 - mse: 720.9845 - val_loss: 19.4471 - val_mse: 730.4658\n",
      "Epoch 1257/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3232 - mse: 733.7426 - val_loss: 18.1038 - val_mse: 730.0583\n",
      "Epoch 1258/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9760 - mse: 720.6655 - val_loss: 19.1794 - val_mse: 713.0765\n",
      "Epoch 1259/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3921 - mse: 737.8035 - val_loss: 18.1331 - val_mse: 735.8729\n",
      "Epoch 1260/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2730 - mse: 746.2429 - val_loss: 18.2884 - val_mse: 768.3606\n",
      "Epoch 1261/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3322 - mse: 740.8190 - val_loss: 18.2155 - val_mse: 775.2892\n",
      "Epoch 1262/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0950 - mse: 717.9799 - val_loss: 18.0278 - val_mse: 745.7294\n",
      "Epoch 1263/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2057 - mse: 729.4169 - val_loss: 18.5953 - val_mse: 705.8456\n",
      "Epoch 1264/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9347 - mse: 710.7816 - val_loss: 18.1500 - val_mse: 761.8666\n",
      "Epoch 1265/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9007 - mse: 711.0317 - val_loss: 18.2220 - val_mse: 724.2192\n",
      "Epoch 1266/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9581 - mse: 717.0685 - val_loss: 18.1182 - val_mse: 765.2594\n",
      "Epoch 1267/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8354 - mse: 703.3019 - val_loss: 18.7680 - val_mse: 704.8972\n",
      "Epoch 1268/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8940 - mse: 709.0912 - val_loss: 18.6087 - val_mse: 715.3822\n",
      "Epoch 1269/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1813 - mse: 720.5422 - val_loss: 18.1268 - val_mse: 750.9931\n",
      "Epoch 1270/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0817 - mse: 721.7406 - val_loss: 18.5585 - val_mse: 726.4199\n",
      "Epoch 1271/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1008 - mse: 718.2802 - val_loss: 18.4512 - val_mse: 754.6379\n",
      "Epoch 1272/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0558 - mse: 720.5308 - val_loss: 18.1872 - val_mse: 783.6929\n",
      "Epoch 1273/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9251 - mse: 710.0071 - val_loss: 18.0266 - val_mse: 751.1873\n",
      "Epoch 1274/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2515 - mse: 736.0458 - val_loss: 18.9549 - val_mse: 810.1389\n",
      "Epoch 1275/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0618 - mse: 719.7234 - val_loss: 18.2360 - val_mse: 716.6742\n",
      "Epoch 1276/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.2215 - mse: 726.7025 - val_loss: 17.9787 - val_mse: 740.8856\n",
      "Epoch 1277/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9319 - mse: 718.1043 - val_loss: 18.1003 - val_mse: 755.8737\n",
      "Epoch 1278/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1805 - mse: 730.0258 - val_loss: 18.4573 - val_mse: 729.2968\n",
      "Epoch 1279/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7012 - mse: 763.5885 - val_loss: 18.1717 - val_mse: 732.6759\n",
      "Epoch 1280/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.4042 - mse: 747.2251 - val_loss: 19.1593 - val_mse: 743.9901\n",
      "Epoch 1281/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2277 - mse: 726.3005 - val_loss: 18.2743 - val_mse: 744.5948\n",
      "Epoch 1282/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0473 - mse: 711.1403 - val_loss: 17.9985 - val_mse: 736.4897\n",
      "Epoch 1283/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0287 - mse: 721.6899 - val_loss: 18.5463 - val_mse: 794.7950\n",
      "Epoch 1284/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0377 - mse: 719.8716 - val_loss: 18.2168 - val_mse: 708.6542\n",
      "Epoch 1285/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9496 - mse: 708.3738 - val_loss: 18.0535 - val_mse: 723.9401\n",
      "Epoch 1286/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0809 - mse: 715.7590 - val_loss: 19.6449 - val_mse: 908.6283\n",
      "Epoch 1287/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4619 - mse: 754.2099 - val_loss: 18.1380 - val_mse: 750.0368\n",
      "Epoch 1288/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9937 - mse: 716.2698 - val_loss: 18.0478 - val_mse: 740.2513\n",
      "Epoch 1289/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1598 - mse: 724.7767 - val_loss: 18.1754 - val_mse: 732.1714\n",
      "Epoch 1290/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0210 - mse: 713.5087 - val_loss: 18.3369 - val_mse: 770.1667\n",
      "Epoch 1291/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0611 - mse: 711.5237 - val_loss: 18.5519 - val_mse: 764.1379\n",
      "Epoch 1292/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0444 - mse: 718.9968 - val_loss: 18.3969 - val_mse: 778.8169\n",
      "Epoch 1293/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1135 - mse: 729.6483 - val_loss: 18.0483 - val_mse: 704.9321\n",
      "Epoch 1294/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8145 - mse: 694.8162 - val_loss: 17.9754 - val_mse: 742.7354\n",
      "Epoch 1295/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0486 - mse: 726.7348 - val_loss: 18.5331 - val_mse: 735.0418\n",
      "Epoch 1296/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5537 - mse: 744.5887 - val_loss: 18.4921 - val_mse: 716.9412\n",
      "Epoch 1297/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1962 - mse: 732.1949 - val_loss: 18.2199 - val_mse: 723.3252\n",
      "Epoch 1298/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1574 - mse: 725.0347 - val_loss: 17.9809 - val_mse: 715.0359\n",
      "Epoch 1299/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7015 - mse: 758.0447 - val_loss: 19.9184 - val_mse: 937.1360\n",
      "Epoch 1300/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3325 - mse: 732.3587 - val_loss: 18.3212 - val_mse: 793.7535\n",
      "Epoch 1301/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0919 - mse: 719.8566 - val_loss: 18.1451 - val_mse: 751.9189\n",
      "Epoch 1302/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0902 - mse: 721.1371 - val_loss: 18.0829 - val_mse: 769.5696\n",
      "Epoch 1303/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9689 - mse: 711.0554 - val_loss: 18.2295 - val_mse: 702.9396\n",
      "Epoch 1304/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7894 - mse: 708.4684 - val_loss: 18.4301 - val_mse: 696.1876\n",
      "Epoch 1305/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9383 - mse: 709.8586 - val_loss: 18.7597 - val_mse: 772.7750\n",
      "Epoch 1306/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0470 - mse: 718.1451 - val_loss: 18.4894 - val_mse: 719.4273\n",
      "Epoch 1307/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7446 - mse: 700.6114 - val_loss: 18.2484 - val_mse: 720.8284\n",
      "Epoch 1308/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0452 - mse: 723.8237 - val_loss: 19.3071 - val_mse: 713.2497\n",
      "Epoch 1309/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8397 - mse: 707.5189 - val_loss: 18.4104 - val_mse: 702.4291\n",
      "Epoch 1310/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0860 - mse: 719.0865 - val_loss: 17.9901 - val_mse: 718.3446\n",
      "Epoch 1311/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3445 - mse: 736.6012 - val_loss: 18.9598 - val_mse: 719.8430\n",
      "Epoch 1312/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6113 - mse: 741.6182 - val_loss: 19.1380 - val_mse: 729.9966\n",
      "Epoch 1313/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5127 - mse: 746.3594 - val_loss: 18.6977 - val_mse: 722.3448\n",
      "Epoch 1314/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1929 - mse: 726.1565 - val_loss: 18.6767 - val_mse: 758.2090\n",
      "Epoch 1315/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2607 - mse: 735.4573 - val_loss: 18.2786 - val_mse: 772.6350\n",
      "Epoch 1316/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1131 - mse: 732.0868 - val_loss: 17.9265 - val_mse: 729.9023\n",
      "Epoch 1317/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4354 - mse: 743.1809 - val_loss: 18.0086 - val_mse: 728.4299\n",
      "Epoch 1318/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0928 - mse: 717.5546 - val_loss: 18.3521 - val_mse: 784.1082\n",
      "Epoch 1319/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6745 - mse: 757.7068 - val_loss: 18.5254 - val_mse: 808.9601\n",
      "Epoch 1320/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.4742 - mse: 754.9572 - val_loss: 18.3501 - val_mse: 753.2400\n",
      "Epoch 1321/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4313 - mse: 736.4868 - val_loss: 18.0941 - val_mse: 745.6075\n",
      "Epoch 1322/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9851 - mse: 723.3240 - val_loss: 18.6515 - val_mse: 693.6635\n",
      "Epoch 1323/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1797 - mse: 723.6895 - val_loss: 20.6428 - val_mse: 746.9175\n",
      "Epoch 1324/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7212 - mse: 771.9589 - val_loss: 18.5185 - val_mse: 739.9875\n",
      "Epoch 1325/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.9749 - mse: 767.9175 - val_loss: 19.5885 - val_mse: 899.7152\n",
      "Epoch 1326/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7614 - mse: 767.0052 - val_loss: 18.3818 - val_mse: 735.6338\n",
      "Epoch 1327/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0281 - mse: 720.9059 - val_loss: 18.3857 - val_mse: 804.6600\n",
      "Epoch 1328/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0241 - mse: 715.2638 - val_loss: 18.3308 - val_mse: 756.9413\n",
      "Epoch 1329/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0700 - mse: 722.1777 - val_loss: 18.1688 - val_mse: 778.6148\n",
      "Epoch 1330/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1881 - mse: 733.9013 - val_loss: 17.9751 - val_mse: 746.1162\n",
      "Epoch 1331/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0416 - mse: 721.5730 - val_loss: 17.9950 - val_mse: 734.6230\n",
      "Epoch 1332/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0911 - mse: 724.9470 - val_loss: 18.8295 - val_mse: 830.6049\n",
      "Epoch 1333/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2993 - mse: 735.3162 - val_loss: 18.4453 - val_mse: 727.3892\n",
      "Epoch 1334/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2452 - mse: 725.7238 - val_loss: 18.1504 - val_mse: 744.7603\n",
      "Epoch 1335/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8256 - mse: 706.5054 - val_loss: 18.0301 - val_mse: 755.6440\n",
      "Epoch 1336/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3179 - mse: 734.2696 - val_loss: 18.0439 - val_mse: 729.0421\n",
      "Epoch 1337/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0535 - mse: 715.1705 - val_loss: 19.5839 - val_mse: 740.9296\n",
      "Epoch 1338/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2544 - mse: 729.3770 - val_loss: 18.1883 - val_mse: 761.1706\n",
      "Epoch 1339/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3746 - mse: 735.7757 - val_loss: 18.1318 - val_mse: 727.4680\n",
      "Epoch 1340/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8143 - mse: 707.4730 - val_loss: 17.9993 - val_mse: 732.2392\n",
      "Epoch 1341/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7572 - mse: 697.5101 - val_loss: 18.2934 - val_mse: 746.8158\n",
      "Epoch 1342/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0766 - mse: 726.1752 - val_loss: 18.3344 - val_mse: 706.2030\n",
      "Epoch 1343/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0138 - mse: 719.3637 - val_loss: 18.0947 - val_mse: 770.1649\n",
      "Epoch 1344/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1027 - mse: 709.9500 - val_loss: 18.4715 - val_mse: 807.1533\n",
      "Epoch 1345/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2913 - mse: 732.6152 - val_loss: 18.1198 - val_mse: 737.6165\n",
      "Epoch 1346/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9172 - mse: 707.2816 - val_loss: 18.5067 - val_mse: 801.7839\n",
      "Epoch 1347/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8576 - mse: 707.7615 - val_loss: 18.6478 - val_mse: 816.7721\n",
      "Epoch 1348/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8862 - mse: 702.5071 - val_loss: 18.4923 - val_mse: 807.5444\n",
      "Epoch 1349/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1282 - mse: 721.6509 - val_loss: 18.1562 - val_mse: 756.9194\n",
      "Epoch 1350/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8948 - mse: 712.5133 - val_loss: 18.5433 - val_mse: 828.0801\n",
      "Epoch 1351/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0449 - mse: 715.8422 - val_loss: 18.2455 - val_mse: 728.3030\n",
      "Epoch 1352/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8804 - mse: 707.7643 - val_loss: 18.3843 - val_mse: 767.9643\n",
      "Epoch 1353/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6773 - mse: 747.0462 - val_loss: 18.0020 - val_mse: 725.6500\n",
      "Epoch 1354/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8786 - mse: 699.3436 - val_loss: 18.2224 - val_mse: 712.1300\n",
      "Epoch 1355/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2372 - mse: 728.5665 - val_loss: 18.6272 - val_mse: 805.4831\n",
      "Epoch 1356/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.1935 - mse: 730.1507 - val_loss: 18.6083 - val_mse: 797.5682\n",
      "Epoch 1357/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8220 - mse: 701.8964 - val_loss: 17.9463 - val_mse: 716.1534\n",
      "Epoch 1358/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8996 - mse: 699.3325 - val_loss: 18.6337 - val_mse: 704.0396\n",
      "Epoch 1359/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9444 - mse: 701.2950 - val_loss: 18.3289 - val_mse: 805.4802\n",
      "Epoch 1360/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.1649 - mse: 718.5058 - val_loss: 18.3764 - val_mse: 739.2330\n",
      "Epoch 1361/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.1351 - mse: 725.8430 - val_loss: 18.5218 - val_mse: 748.5593\n",
      "Epoch 1362/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2760 - mse: 736.2336 - val_loss: 18.2372 - val_mse: 705.3119\n",
      "Epoch 1363/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1307 - mse: 720.0765 - val_loss: 19.5914 - val_mse: 911.5302\n",
      "Epoch 1364/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3337 - mse: 740.2505 - val_loss: 18.2763 - val_mse: 800.9869\n",
      "Epoch 1365/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9934 - mse: 717.6429 - val_loss: 18.2020 - val_mse: 783.4442\n",
      "Epoch 1366/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0254 - mse: 716.8525 - val_loss: 18.8594 - val_mse: 719.7180\n",
      "Epoch 1367/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9877 - mse: 711.2930 - val_loss: 17.8829 - val_mse: 737.3014\n",
      "Epoch 1368/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8591 - mse: 707.1960 - val_loss: 18.3468 - val_mse: 708.1591\n",
      "Epoch 1369/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9559 - mse: 710.8092 - val_loss: 18.0867 - val_mse: 713.2126\n",
      "Epoch 1370/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9207 - mse: 711.2646 - val_loss: 17.8943 - val_mse: 718.4963\n",
      "Epoch 1371/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7229 - mse: 702.5938 - val_loss: 18.2364 - val_mse: 756.8395\n",
      "Epoch 1372/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1000 - mse: 730.5823 - val_loss: 18.1714 - val_mse: 725.1443\n",
      "Epoch 1373/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1126 - mse: 716.9352 - val_loss: 19.7880 - val_mse: 727.6323\n",
      "Epoch 1374/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.2645 - mse: 794.5320 - val_loss: 18.1907 - val_mse: 752.9738\n",
      "Epoch 1375/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3158 - mse: 737.2795 - val_loss: 18.2323 - val_mse: 716.7880\n",
      "Epoch 1376/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1533 - mse: 725.9517 - val_loss: 17.9236 - val_mse: 723.3286\n",
      "Epoch 1377/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8118 - mse: 705.3900 - val_loss: 18.1338 - val_mse: 755.5969\n",
      "Epoch 1378/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8901 - mse: 705.5396 - val_loss: 18.0538 - val_mse: 750.5825\n",
      "Epoch 1379/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1111 - mse: 713.8010 - val_loss: 18.0365 - val_mse: 755.2579\n",
      "Epoch 1380/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9603 - mse: 717.0826 - val_loss: 17.8508 - val_mse: 729.5585\n",
      "Epoch 1381/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9805 - mse: 708.4241 - val_loss: 17.8669 - val_mse: 732.2950\n",
      "Epoch 1382/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9286 - mse: 713.5718 - val_loss: 18.3252 - val_mse: 704.2145\n",
      "Epoch 1383/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6125 - mse: 741.0969 - val_loss: 19.5805 - val_mse: 904.8819\n",
      "Epoch 1384/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1910 - mse: 734.1714 - val_loss: 18.1431 - val_mse: 759.4217\n",
      "Epoch 1385/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8974 - mse: 709.6284 - val_loss: 17.8368 - val_mse: 725.5576\n",
      "Epoch 1386/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7223 - mse: 694.3459 - val_loss: 18.1042 - val_mse: 772.1254\n",
      "Epoch 1387/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8616 - mse: 776.6008 - val_loss: 18.2775 - val_mse: 728.1147\n",
      "Epoch 1388/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1733 - mse: 728.8717 - val_loss: 18.4093 - val_mse: 744.5571\n",
      "Epoch 1389/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1509 - mse: 723.2869 - val_loss: 18.0858 - val_mse: 730.1050\n",
      "Epoch 1390/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3593 - mse: 735.7558 - val_loss: 18.4172 - val_mse: 767.6946\n",
      "Epoch 1391/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9519 - mse: 719.1427 - val_loss: 18.3248 - val_mse: 704.6727\n",
      "Epoch 1392/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.1160 - mse: 725.9018 - val_loss: 18.4362 - val_mse: 791.5144\n",
      "Epoch 1393/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9623 - mse: 710.7856 - val_loss: 18.5677 - val_mse: 755.0956\n",
      "Epoch 1394/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6971 - mse: 697.8420 - val_loss: 17.8550 - val_mse: 732.5673\n",
      "Epoch 1395/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.1693 - mse: 727.5845 - val_loss: 17.8854 - val_mse: 733.3099\n",
      "Epoch 1396/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0307 - mse: 716.6177 - val_loss: 17.9582 - val_mse: 756.6370\n",
      "Epoch 1397/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9676 - mse: 712.8710 - val_loss: 18.1583 - val_mse: 757.6207\n",
      "Epoch 1398/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9169 - mse: 719.0424 - val_loss: 18.4864 - val_mse: 810.3168\n",
      "Epoch 1399/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0755 - mse: 717.1666 - val_loss: 17.9919 - val_mse: 756.9467\n",
      "Epoch 1400/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8941 - mse: 709.8683 - val_loss: 18.5138 - val_mse: 718.2036\n",
      "Epoch 1401/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8035 - mse: 703.0293 - val_loss: 17.8226 - val_mse: 706.8602\n",
      "Epoch 1402/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0215 - mse: 707.0303 - val_loss: 17.9670 - val_mse: 757.0853\n",
      "Epoch 1403/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8966 - mse: 699.9855 - val_loss: 18.2054 - val_mse: 775.3522\n",
      "Epoch 1404/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0690 - mse: 722.8566 - val_loss: 18.8532 - val_mse: 699.6486\n",
      "Epoch 1405/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2950 - mse: 734.0465 - val_loss: 18.4859 - val_mse: 776.4467\n",
      "Epoch 1406/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8544 - mse: 705.9833 - val_loss: 17.9484 - val_mse: 702.4585\n",
      "Epoch 1407/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8140 - mse: 708.2042 - val_loss: 17.8892 - val_mse: 729.6221\n",
      "Epoch 1408/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8711 - mse: 707.7330 - val_loss: 18.3976 - val_mse: 701.6563\n",
      "Epoch 1409/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7532 - mse: 694.0013 - val_loss: 18.6221 - val_mse: 693.2863\n",
      "Epoch 1410/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4245 - mse: 740.9159 - val_loss: 18.1041 - val_mse: 761.7795\n",
      "Epoch 1411/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0059 - mse: 704.9711 - val_loss: 18.2521 - val_mse: 767.4415\n",
      "Epoch 1412/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8253 - mse: 709.2370 - val_loss: 18.2225 - val_mse: 697.0480\n",
      "Epoch 1413/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8391 - mse: 715.0190 - val_loss: 18.4045 - val_mse: 771.7065\n",
      "Epoch 1414/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4176 - mse: 742.1360 - val_loss: 22.6467 - val_mse: 1126.4175\n",
      "Epoch 1415/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.7962 - mse: 841.0559 - val_loss: 18.6499 - val_mse: 746.2815\n",
      "Epoch 1416/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1285 - mse: 725.2516 - val_loss: 17.8578 - val_mse: 718.7122\n",
      "Epoch 1417/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8681 - mse: 706.6406 - val_loss: 18.1350 - val_mse: 737.2870\n",
      "Epoch 1418/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8955 - mse: 708.1436 - val_loss: 18.4563 - val_mse: 714.4818\n",
      "Epoch 1419/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0666 - mse: 712.1360 - val_loss: 19.3802 - val_mse: 896.5440\n",
      "Epoch 1420/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3059 - mse: 727.3664 - val_loss: 18.8307 - val_mse: 832.4469\n",
      "Epoch 1421/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2369 - mse: 728.0455 - val_loss: 18.0097 - val_mse: 762.9092\n",
      "Epoch 1422/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8842 - mse: 778.2078 - val_loss: 20.5937 - val_mse: 749.0776\n",
      "Epoch 1423/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0307 - mse: 789.8846 - val_loss: 18.5525 - val_mse: 781.1537\n",
      "Epoch 1424/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9801 - mse: 709.8195 - val_loss: 18.0174 - val_mse: 730.7025\n",
      "Epoch 1425/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8526 - mse: 708.3961 - val_loss: 18.3974 - val_mse: 715.5421\n",
      "Epoch 1426/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7943 - mse: 698.3870 - val_loss: 18.2889 - val_mse: 774.1572\n",
      "Epoch 1427/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8196 - mse: 705.8500 - val_loss: 18.5631 - val_mse: 825.9334\n",
      "Epoch 1428/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0170 - mse: 721.5281 - val_loss: 18.0191 - val_mse: 749.0266\n",
      "Epoch 1429/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8915 - mse: 706.1246 - val_loss: 18.3652 - val_mse: 754.1254\n",
      "Epoch 1430/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9689 - mse: 707.3724 - val_loss: 18.1614 - val_mse: 765.3102\n",
      "Epoch 1431/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.1667 - mse: 733.8378 - val_loss: 18.2277 - val_mse: 699.4130\n",
      "Epoch 1432/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0513 - mse: 717.7291 - val_loss: 18.8871 - val_mse: 837.2134\n",
      "Epoch 1433/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5262 - mse: 751.0171 - val_loss: 18.7136 - val_mse: 824.8348\n",
      "Epoch 1434/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2066 - mse: 732.1431 - val_loss: 18.4746 - val_mse: 803.5761\n",
      "Epoch 1435/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5312 - mse: 749.6161 - val_loss: 18.2977 - val_mse: 703.0756\n",
      "Epoch 1436/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9780 - mse: 723.1794 - val_loss: 18.0008 - val_mse: 735.5096\n",
      "Epoch 1437/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9205 - mse: 717.6827 - val_loss: 18.2528 - val_mse: 705.7426\n",
      "Epoch 1438/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0053 - mse: 709.1577 - val_loss: 17.9401 - val_mse: 744.9507\n",
      "Epoch 1439/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0039 - mse: 719.6553 - val_loss: 19.5879 - val_mse: 915.3039\n",
      "Epoch 1440/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9109 - mse: 717.2358 - val_loss: 18.3096 - val_mse: 706.4883\n",
      "Epoch 1441/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9434 - mse: 710.2437 - val_loss: 18.1914 - val_mse: 693.2028\n",
      "Epoch 1442/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2527 - mse: 726.6931 - val_loss: 18.0983 - val_mse: 704.0401\n",
      "Epoch 1443/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7157 - mse: 698.3923 - val_loss: 18.1897 - val_mse: 778.4427\n",
      "Epoch 1444/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.1410 - mse: 720.3294 - val_loss: 17.8041 - val_mse: 712.3049\n",
      "Epoch 1445/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.0052 - mse: 708.4795 - val_loss: 17.9547 - val_mse: 754.5029\n",
      "Epoch 1446/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0156 - mse: 717.0748 - val_loss: 18.0194 - val_mse: 694.3175\n",
      "Epoch 1447/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6604 - mse: 704.4019 - val_loss: 18.4536 - val_mse: 687.2976\n",
      "Epoch 1448/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0726 - mse: 713.6688 - val_loss: 18.4979 - val_mse: 761.7636\n",
      "Epoch 1449/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.1907 - mse: 723.1760 - val_loss: 17.8863 - val_mse: 761.0544\n",
      "Epoch 1450/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9184 - mse: 715.2528 - val_loss: 17.7342 - val_mse: 712.6431\n",
      "Epoch 1451/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7786 - mse: 701.8582 - val_loss: 17.9821 - val_mse: 744.8046\n",
      "Epoch 1452/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8243 - mse: 704.3186 - val_loss: 19.0259 - val_mse: 845.6623\n",
      "Epoch 1453/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.5326 - mse: 750.8491 - val_loss: 18.4842 - val_mse: 741.1667\n",
      "Epoch 1454/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1044 - mse: 715.7878 - val_loss: 18.4325 - val_mse: 805.7488\n",
      "Epoch 1455/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.3572 - mse: 726.7655 - val_loss: 18.5411 - val_mse: 754.3633\n",
      "Epoch 1456/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1205 - mse: 721.5205 - val_loss: 18.0197 - val_mse: 774.9714\n",
      "Epoch 1457/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1346 - mse: 728.9765 - val_loss: 20.1564 - val_mse: 946.8478\n",
      "Epoch 1458/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3226 - mse: 744.0447 - val_loss: 17.9747 - val_mse: 732.9426\n",
      "Epoch 1459/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2531 - mse: 725.4952 - val_loss: 19.7753 - val_mse: 905.1768\n",
      "Epoch 1460/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5779 - mse: 754.7028 - val_loss: 17.9281 - val_mse: 750.6696\n",
      "Epoch 1461/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8488 - mse: 711.6990 - val_loss: 18.4170 - val_mse: 786.0410\n",
      "Epoch 1462/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9518 - mse: 714.3951 - val_loss: 18.5192 - val_mse: 699.4655\n",
      "Epoch 1463/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7731 - mse: 695.0573 - val_loss: 18.5420 - val_mse: 809.6534\n",
      "Epoch 1464/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6874 - mse: 700.2678 - val_loss: 17.7282 - val_mse: 708.8202\n",
      "Epoch 1465/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7254 - mse: 690.3410 - val_loss: 17.8675 - val_mse: 737.6279\n",
      "Epoch 1466/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6903 - mse: 691.3502 - val_loss: 17.7764 - val_mse: 742.0121\n",
      "Epoch 1467/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7809 - mse: 707.7052 - val_loss: 19.3835 - val_mse: 728.5733\n",
      "Epoch 1468/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9397 - mse: 708.2565 - val_loss: 19.9933 - val_mse: 930.9423\n",
      "Epoch 1469/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4285 - mse: 744.6232 - val_loss: 17.9315 - val_mse: 751.5596\n",
      "Epoch 1470/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8819 - mse: 706.2784 - val_loss: 18.1961 - val_mse: 736.9399\n",
      "Epoch 1471/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8008 - mse: 703.6440 - val_loss: 17.7795 - val_mse: 728.2552\n",
      "Epoch 1472/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6763 - mse: 700.3949 - val_loss: 18.4822 - val_mse: 694.5436\n",
      "Epoch 1473/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8423 - mse: 712.2299 - val_loss: 17.9493 - val_mse: 762.1846\n",
      "Epoch 1474/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9140 - mse: 711.4807 - val_loss: 19.0467 - val_mse: 724.1010\n",
      "Epoch 1475/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7444 - mse: 706.6724 - val_loss: 18.8108 - val_mse: 784.2042\n",
      "Epoch 1476/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1690 - mse: 728.9897 - val_loss: 18.0599 - val_mse: 702.9452\n",
      "Epoch 1477/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6621 - mse: 696.0400 - val_loss: 18.5503 - val_mse: 699.4819\n",
      "Epoch 1478/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7148 - mse: 694.3500 - val_loss: 18.0459 - val_mse: 707.7558\n",
      "Epoch 1479/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5974 - mse: 685.1571 - val_loss: 18.4402 - val_mse: 739.4618\n",
      "Epoch 1480/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3207 - mse: 786.4092 - val_loss: 18.2515 - val_mse: 716.1968\n",
      "Epoch 1481/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3146 - mse: 821.3865 - val_loss: 18.1821 - val_mse: 774.3254\n",
      "Epoch 1482/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9286 - mse: 718.3212 - val_loss: 17.8333 - val_mse: 698.2443\n",
      "Epoch 1483/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7561 - mse: 701.7496 - val_loss: 18.3650 - val_mse: 695.3323\n",
      "Epoch 1484/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3205 - mse: 738.1643 - val_loss: 17.8954 - val_mse: 724.0366\n",
      "Epoch 1485/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3263 - mse: 747.5889 - val_loss: 19.3007 - val_mse: 842.1406\n",
      "Epoch 1486/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9648 - mse: 710.5073 - val_loss: 18.7430 - val_mse: 825.9305\n",
      "Epoch 1487/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0517 - mse: 713.8505 - val_loss: 17.8020 - val_mse: 719.6743\n",
      "Epoch 1488/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8343 - mse: 696.6819 - val_loss: 17.9521 - val_mse: 706.8546\n",
      "Epoch 1489/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7824 - mse: 698.6378 - val_loss: 18.3503 - val_mse: 798.0121\n",
      "Epoch 1490/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8588 - mse: 706.2094 - val_loss: 18.0933 - val_mse: 750.4709\n",
      "Epoch 1491/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9517 - mse: 713.0807 - val_loss: 18.1665 - val_mse: 696.0500\n",
      "Epoch 1492/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9930 - mse: 709.3867 - val_loss: 18.5128 - val_mse: 810.3085\n",
      "Epoch 1493/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1648 - mse: 731.2221 - val_loss: 18.0328 - val_mse: 708.2141\n",
      "Epoch 1494/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0971 - mse: 731.4232 - val_loss: 18.3752 - val_mse: 702.9992\n",
      "Epoch 1495/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2817 - mse: 725.8714 - val_loss: 17.9573 - val_mse: 717.2071\n",
      "Epoch 1496/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6917 - mse: 699.1157 - val_loss: 19.1133 - val_mse: 867.2665\n",
      "Epoch 1497/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0818 - mse: 722.5609 - val_loss: 18.2362 - val_mse: 782.4912\n",
      "Epoch 1498/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9799 - mse: 711.7978 - val_loss: 18.4561 - val_mse: 740.8542\n",
      "Epoch 1499/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9408 - mse: 709.0872 - val_loss: 18.0778 - val_mse: 741.1879\n",
      "Epoch 1500/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1508 - mse: 732.3130 - val_loss: 18.6598 - val_mse: 777.5963\n",
      "Epoch 1501/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8982 - mse: 709.5823 - val_loss: 17.8361 - val_mse: 741.1592\n",
      "Epoch 1502/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2933 - mse: 735.0663 - val_loss: 18.5654 - val_mse: 696.6273\n",
      "Epoch 1503/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.9608 - mse: 703.8298 - val_loss: 18.5135 - val_mse: 711.0922\n",
      "Epoch 1504/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7017 - mse: 702.0584 - val_loss: 17.7877 - val_mse: 735.9810\n",
      "Epoch 1505/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7326 - mse: 697.6102 - val_loss: 18.1573 - val_mse: 780.3745\n",
      "Epoch 1506/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9241 - mse: 707.7868 - val_loss: 18.3034 - val_mse: 746.5218\n",
      "Epoch 1507/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7692 - mse: 699.6202 - val_loss: 17.9850 - val_mse: 727.9431\n",
      "Epoch 1508/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.1947 - mse: 727.5398 - val_loss: 18.0039 - val_mse: 768.4506\n",
      "Epoch 1509/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8559 - mse: 711.1014 - val_loss: 17.8772 - val_mse: 711.4122\n",
      "Epoch 1510/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9734 - mse: 710.2980 - val_loss: 18.7524 - val_mse: 719.7305\n",
      "Epoch 1511/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6488 - mse: 689.5615 - val_loss: 17.7638 - val_mse: 706.8873\n",
      "Epoch 1512/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9953 - mse: 717.2899 - val_loss: 19.0433 - val_mse: 765.4767\n",
      "Epoch 1513/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8383 - mse: 772.3796 - val_loss: 19.6713 - val_mse: 920.0998\n",
      "Epoch 1514/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8840 - mse: 771.5540 - val_loss: 18.5653 - val_mse: 740.0430\n",
      "Epoch 1515/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9392 - mse: 716.9713 - val_loss: 18.0420 - val_mse: 737.3198\n",
      "Epoch 1516/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2354 - mse: 729.1711 - val_loss: 18.6026 - val_mse: 717.4916\n",
      "Epoch 1517/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5293 - mse: 739.5966 - val_loss: 18.3085 - val_mse: 730.4399\n",
      "Epoch 1518/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6093 - mse: 687.6837 - val_loss: 17.7907 - val_mse: 747.6239\n",
      "Epoch 1519/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5686 - mse: 689.6782 - val_loss: 17.9066 - val_mse: 704.9488\n",
      "Epoch 1520/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6491 - mse: 694.4766 - val_loss: 18.0014 - val_mse: 709.6648\n",
      "Epoch 1521/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2155 - mse: 729.2952 - val_loss: 18.0851 - val_mse: 745.2869\n",
      "Epoch 1522/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1124 - mse: 718.2134 - val_loss: 18.6691 - val_mse: 826.3890\n",
      "Epoch 1523/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.5131 - mse: 757.9109 - val_loss: 18.7019 - val_mse: 777.6627\n",
      "Epoch 1524/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0443 - mse: 718.5137 - val_loss: 17.8085 - val_mse: 728.5501\n",
      "Epoch 1525/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7474 - mse: 700.1967 - val_loss: 18.5271 - val_mse: 811.3209\n",
      "Epoch 1526/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0136 - mse: 712.5505 - val_loss: 18.3911 - val_mse: 706.4957\n",
      "Epoch 1527/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.8444 - mse: 703.0503 - val_loss: 17.8018 - val_mse: 731.4860\n",
      "Epoch 1528/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5843 - mse: 698.6356 - val_loss: 18.5604 - val_mse: 803.4986\n",
      "Epoch 1529/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8745 - mse: 706.4453 - val_loss: 17.8407 - val_mse: 711.3207\n",
      "Epoch 1530/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0185 - mse: 725.1168 - val_loss: 18.8330 - val_mse: 719.2654\n",
      "Epoch 1531/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3815 - mse: 737.5677 - val_loss: 18.7082 - val_mse: 829.7637\n",
      "Epoch 1532/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7959 - mse: 709.5503 - val_loss: 18.0611 - val_mse: 779.1417\n",
      "Epoch 1533/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8929 - mse: 708.4618 - val_loss: 18.1878 - val_mse: 739.7606\n",
      "Epoch 1534/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1103 - mse: 720.4080 - val_loss: 17.8844 - val_mse: 700.9952\n",
      "Epoch 1535/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9412 - mse: 716.4019 - val_loss: 17.8243 - val_mse: 749.5834\n",
      "Epoch 1536/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7819 - mse: 697.8253 - val_loss: 19.0202 - val_mse: 720.2341\n",
      "Epoch 1537/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0057 - mse: 720.9667 - val_loss: 18.9422 - val_mse: 846.3019\n",
      "Epoch 1538/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0156 - mse: 706.1536 - val_loss: 18.3765 - val_mse: 741.7668\n",
      "Epoch 1539/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9957 - mse: 707.0892 - val_loss: 18.7163 - val_mse: 830.8802\n",
      "Epoch 1540/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8615 - mse: 709.9987 - val_loss: 17.9662 - val_mse: 704.2512\n",
      "Epoch 1541/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0705 - mse: 716.2283 - val_loss: 18.8233 - val_mse: 838.9635\n",
      "Epoch 1542/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2534 - mse: 739.7817 - val_loss: 18.3287 - val_mse: 802.6063\n",
      "Epoch 1543/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7885 - mse: 705.3054 - val_loss: 18.7757 - val_mse: 702.8961\n",
      "Epoch 1544/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5794 - mse: 760.1689 - val_loss: 19.1129 - val_mse: 698.0861\n",
      "Epoch 1545/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0569 - mse: 721.4275 - val_loss: 18.0439 - val_mse: 719.9272\n",
      "Epoch 1546/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8840 - mse: 704.3940 - val_loss: 17.8092 - val_mse: 722.4674\n",
      "Epoch 1547/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8606 - mse: 712.6256 - val_loss: 17.9177 - val_mse: 704.3896\n",
      "Epoch 1548/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7729 - mse: 705.0347 - val_loss: 18.5709 - val_mse: 683.2180\n",
      "Epoch 1549/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4053 - mse: 732.4865 - val_loss: 18.7442 - val_mse: 701.2757\n",
      "Epoch 1550/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3843 - mse: 732.9085 - val_loss: 18.3084 - val_mse: 694.8234\n",
      "Epoch 1551/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8784 - mse: 717.1995 - val_loss: 18.1797 - val_mse: 703.5930\n",
      "Epoch 1552/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1075 - mse: 715.1730 - val_loss: 19.8884 - val_mse: 928.4389\n",
      "Epoch 1553/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1488 - mse: 725.8245 - val_loss: 18.1583 - val_mse: 774.6755\n",
      "Epoch 1554/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1166 - mse: 721.6281 - val_loss: 18.1221 - val_mse: 778.1579\n",
      "Epoch 1555/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7294 - mse: 693.7527 - val_loss: 18.1455 - val_mse: 706.3283\n",
      "Epoch 1556/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9439 - mse: 710.4500 - val_loss: 18.7422 - val_mse: 702.1689\n",
      "Epoch 1557/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6259 - mse: 688.9821 - val_loss: 19.0394 - val_mse: 733.5079\n",
      "Epoch 1558/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2321 - mse: 726.0442 - val_loss: 18.1691 - val_mse: 705.8754\n",
      "Epoch 1559/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7596 - mse: 699.4315 - val_loss: 18.4579 - val_mse: 699.6752\n",
      "Epoch 1560/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7146 - mse: 696.5993 - val_loss: 17.8554 - val_mse: 740.3089\n",
      "Epoch 1561/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1006 - mse: 717.6046 - val_loss: 18.9559 - val_mse: 858.8758\n",
      "Epoch 1562/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1534 - mse: 719.8395 - val_loss: 18.5649 - val_mse: 796.0483\n",
      "Epoch 1563/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9942 - mse: 713.0210 - val_loss: 18.3108 - val_mse: 786.1575\n",
      "Epoch 1564/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7199 - mse: 700.1466 - val_loss: 18.3365 - val_mse: 706.6343\n",
      "Epoch 1565/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8581 - mse: 716.9176 - val_loss: 18.1611 - val_mse: 699.5115\n",
      "Epoch 1566/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8502 - mse: 699.8271 - val_loss: 17.7774 - val_mse: 737.0778\n",
      "Epoch 1567/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7646 - mse: 699.0764 - val_loss: 19.5269 - val_mse: 903.6160\n",
      "Epoch 1568/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3280 - mse: 727.4084 - val_loss: 19.0230 - val_mse: 852.8327\n",
      "Epoch 1569/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0627 - mse: 719.6987 - val_loss: 19.1702 - val_mse: 836.8285\n",
      "Epoch 1570/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0081 - mse: 731.7578 - val_loss: 18.0333 - val_mse: 779.2617\n",
      "Epoch 1571/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7310 - mse: 702.4276 - val_loss: 18.4841 - val_mse: 809.0666\n",
      "Epoch 1572/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8103 - mse: 701.2251 - val_loss: 17.7184 - val_mse: 710.2130\n",
      "Epoch 1573/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8080 - mse: 705.2573 - val_loss: 18.0005 - val_mse: 752.8376\n",
      "Epoch 1574/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9697 - mse: 714.5671 - val_loss: 18.3964 - val_mse: 805.0402\n",
      "Epoch 1575/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4093 - mse: 738.5613 - val_loss: 18.3304 - val_mse: 707.8569\n",
      "Epoch 1576/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8753 - mse: 722.5059 - val_loss: 18.1033 - val_mse: 734.5236\n",
      "Epoch 1577/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8412 - mse: 706.0388 - val_loss: 19.7018 - val_mse: 902.3218\n",
      "Epoch 1578/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2620 - mse: 726.1089 - val_loss: 18.3928 - val_mse: 807.9504\n",
      "Epoch 1579/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9100 - mse: 706.9919 - val_loss: 17.7921 - val_mse: 706.1840\n",
      "Epoch 1580/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8251 - mse: 706.0536 - val_loss: 17.7888 - val_mse: 747.4541\n",
      "Epoch 1581/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6613 - mse: 694.1978 - val_loss: 17.8705 - val_mse: 688.0428\n",
      "Epoch 1582/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8332 - mse: 710.0327 - val_loss: 18.3084 - val_mse: 784.3165\n",
      "Epoch 1583/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.4974 - mse: 746.0699 - val_loss: 17.8486 - val_mse: 746.2975\n",
      "Epoch 1584/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8516 - mse: 702.7668 - val_loss: 18.0144 - val_mse: 727.4183\n",
      "Epoch 1585/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0520 - mse: 725.5908 - val_loss: 18.3090 - val_mse: 749.8928\n",
      "Epoch 1586/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9486 - mse: 702.2650 - val_loss: 18.2744 - val_mse: 782.6219\n",
      "Epoch 1587/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1376 - mse: 795.4906 - val_loss: 18.2487 - val_mse: 717.6585\n",
      "Epoch 1588/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9681 - mse: 725.4661 - val_loss: 18.2881 - val_mse: 725.2985\n",
      "Epoch 1589/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1539 - mse: 727.7687 - val_loss: 18.7489 - val_mse: 732.1241\n",
      "Epoch 1590/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3127 - mse: 737.6841 - val_loss: 17.9474 - val_mse: 730.4098\n",
      "Epoch 1591/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1598 - mse: 730.8840 - val_loss: 18.2981 - val_mse: 703.9278\n",
      "Epoch 1592/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9162 - mse: 711.5001 - val_loss: 18.1623 - val_mse: 782.2296\n",
      "Epoch 1593/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9514 - mse: 715.3130 - val_loss: 18.6703 - val_mse: 824.5584\n",
      "Epoch 1594/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9071 - mse: 718.0832 - val_loss: 17.7061 - val_mse: 721.7201\n",
      "Epoch 1595/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8548 - mse: 714.2144 - val_loss: 18.0237 - val_mse: 765.0986\n",
      "Epoch 1596/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1970 - mse: 729.4940 - val_loss: 17.8847 - val_mse: 728.9057\n",
      "Epoch 1597/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8413 - mse: 708.1743 - val_loss: 19.3478 - val_mse: 708.2554\n",
      "Epoch 1598/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1549 - mse: 732.1028 - val_loss: 19.1752 - val_mse: 774.0198\n",
      "Epoch 1599/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9142 - mse: 707.2444 - val_loss: 18.0416 - val_mse: 701.9203\n",
      "Epoch 1600/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0611 - mse: 710.5757 - val_loss: 18.0193 - val_mse: 711.5091\n",
      "Epoch 1601/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8031 - mse: 701.2217 - val_loss: 18.0645 - val_mse: 698.7386\n",
      "Epoch 1602/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9620 - mse: 723.0787 - val_loss: 17.8020 - val_mse: 753.8596\n",
      "Epoch 1603/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4337 - mse: 747.6911 - val_loss: 19.6431 - val_mse: 732.9363\n",
      "Epoch 1604/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1808 - mse: 731.4903 - val_loss: 18.1198 - val_mse: 733.5858\n",
      "Epoch 1605/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9337 - mse: 714.1243 - val_loss: 17.9841 - val_mse: 702.6984\n",
      "Epoch 1606/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6692 - mse: 696.7842 - val_loss: 18.1287 - val_mse: 775.5543\n",
      "Epoch 1607/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9318 - mse: 710.0329 - val_loss: 17.9119 - val_mse: 724.0217\n",
      "Epoch 1608/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0696 - mse: 718.8811 - val_loss: 17.7761 - val_mse: 731.4948\n",
      "Epoch 1609/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7105 - mse: 698.5919 - val_loss: 18.8942 - val_mse: 853.4181\n",
      "Epoch 1610/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2267 - mse: 737.2374 - val_loss: 18.2380 - val_mse: 689.6276\n",
      "Epoch 1611/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0043 - mse: 712.8441 - val_loss: 17.7910 - val_mse: 711.0912\n",
      "Epoch 1612/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8774 - mse: 714.3115 - val_loss: 17.8833 - val_mse: 738.7252\n",
      "Epoch 1613/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9217 - mse: 709.1389 - val_loss: 17.9169 - val_mse: 711.9389\n",
      "Epoch 1614/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3137 - mse: 800.6265 - val_loss: 19.7542 - val_mse: 887.0967\n",
      "Epoch 1615/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2424 - mse: 729.8263 - val_loss: 17.9969 - val_mse: 720.8537\n",
      "Epoch 1616/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7679 - mse: 712.0193 - val_loss: 17.8645 - val_mse: 719.7538\n",
      "Epoch 1617/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0536 - mse: 726.3772 - val_loss: 18.4542 - val_mse: 819.6342\n",
      "Epoch 1618/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9504 - mse: 709.7748 - val_loss: 18.2416 - val_mse: 727.3129\n",
      "Epoch 1619/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8079 - mse: 704.3339 - val_loss: 17.8683 - val_mse: 735.8277\n",
      "Epoch 1620/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7365 - mse: 701.0580 - val_loss: 17.7047 - val_mse: 731.7122\n",
      "Epoch 1621/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6515 - mse: 698.7499 - val_loss: 17.7517 - val_mse: 703.0944\n",
      "Epoch 1622/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6271 - mse: 693.5051 - val_loss: 18.1994 - val_mse: 779.0827\n",
      "Epoch 1623/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7778 - mse: 698.7429 - val_loss: 18.1256 - val_mse: 725.2813\n",
      "Epoch 1624/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7145 - mse: 704.4099 - val_loss: 18.2587 - val_mse: 689.4585\n",
      "Epoch 1625/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8739 - mse: 701.4132 - val_loss: 17.8321 - val_mse: 731.2573\n",
      "Epoch 1626/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8487 - mse: 708.4566 - val_loss: 18.6255 - val_mse: 771.1915\n",
      "Epoch 1627/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8977 - mse: 707.4770 - val_loss: 18.1371 - val_mse: 737.7097\n",
      "Epoch 1628/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.7358 - mse: 701.6144 - val_loss: 17.9859 - val_mse: 730.2249\n",
      "Epoch 1629/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8009 - mse: 702.4914 - val_loss: 17.7858 - val_mse: 748.7341\n",
      "Epoch 1630/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7368 - mse: 702.9500 - val_loss: 19.0738 - val_mse: 738.8393\n",
      "Epoch 1631/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0794 - mse: 716.7988 - val_loss: 18.0114 - val_mse: 710.4290\n",
      "Epoch 1632/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8205 - mse: 708.6652 - val_loss: 18.2782 - val_mse: 695.2053\n",
      "Epoch 1633/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8669 - mse: 697.8297 - val_loss: 18.3381 - val_mse: 707.6041\n",
      "Epoch 1634/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6940 - mse: 691.8234 - val_loss: 18.2242 - val_mse: 719.3320\n",
      "Epoch 1635/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7054 - mse: 693.7541 - val_loss: 17.6333 - val_mse: 706.2588\n",
      "Epoch 1636/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5006 - mse: 688.0976 - val_loss: 17.9323 - val_mse: 693.4943\n",
      "Epoch 1637/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9642 - mse: 709.6873 - val_loss: 18.6975 - val_mse: 812.5833\n",
      "Epoch 1638/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7352 - mse: 702.6198 - val_loss: 17.6371 - val_mse: 711.0944\n",
      "Epoch 1639/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8625 - mse: 702.2554 - val_loss: 19.0416 - val_mse: 825.8569\n",
      "Epoch 1640/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1301 - mse: 721.7726 - val_loss: 18.9031 - val_mse: 719.1470\n",
      "Epoch 1641/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4416 - mse: 730.7194 - val_loss: 18.6378 - val_mse: 777.6660\n",
      "Epoch 1642/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3711 - mse: 744.8441 - val_loss: 18.4301 - val_mse: 713.4461\n",
      "Epoch 1643/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7046 - mse: 695.6891 - val_loss: 17.6963 - val_mse: 707.0665\n",
      "Epoch 1644/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6924 - mse: 694.0812 - val_loss: 17.6364 - val_mse: 721.1525\n",
      "Epoch 1645/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6432 - mse: 692.2122 - val_loss: 17.8192 - val_mse: 687.7222\n",
      "Epoch 1646/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6720 - mse: 688.2815 - val_loss: 17.7191 - val_mse: 727.2538\n",
      "Epoch 1647/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8564 - mse: 704.7060 - val_loss: 17.8290 - val_mse: 688.5845\n",
      "Epoch 1648/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2041 - mse: 718.1487 - val_loss: 19.3482 - val_mse: 885.0615\n",
      "Epoch 1649/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8969 - mse: 711.9171 - val_loss: 18.7757 - val_mse: 837.8768\n",
      "Epoch 1650/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9375 - mse: 714.0048 - val_loss: 17.7192 - val_mse: 714.6681\n",
      "Epoch 1651/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5379 - mse: 686.5193 - val_loss: 17.9491 - val_mse: 741.6301\n",
      "Epoch 1652/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4732 - mse: 684.2451 - val_loss: 17.6486 - val_mse: 721.5632\n",
      "Epoch 1653/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6337 - mse: 690.5781 - val_loss: 17.9522 - val_mse: 741.5490\n",
      "Epoch 1654/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6896 - mse: 697.3575 - val_loss: 19.5110 - val_mse: 723.4376\n",
      "Epoch 1655/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9946 - mse: 775.0941 - val_loss: 18.3423 - val_mse: 717.5783\n",
      "Epoch 1656/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7406 - mse: 704.2704 - val_loss: 18.2916 - val_mse: 717.7339\n",
      "Epoch 1657/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8616 - mse: 706.0700 - val_loss: 17.9071 - val_mse: 767.6857\n",
      "Epoch 1658/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1720 - mse: 728.0994 - val_loss: 19.2029 - val_mse: 882.2977\n",
      "Epoch 1659/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6529 - mse: 710.4709 - val_loss: 18.9804 - val_mse: 703.5594\n",
      "Epoch 1660/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0621 - mse: 718.4559 - val_loss: 18.5692 - val_mse: 768.6362\n",
      "Epoch 1661/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8225 - mse: 714.0431 - val_loss: 17.7186 - val_mse: 700.3137\n",
      "Epoch 1662/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7837 - mse: 704.6390 - val_loss: 17.7322 - val_mse: 723.8544\n",
      "Epoch 1663/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8457 - mse: 703.8524 - val_loss: 18.0308 - val_mse: 710.1897\n",
      "Epoch 1664/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5913 - mse: 687.2398 - val_loss: 18.2725 - val_mse: 705.7634\n",
      "Epoch 1665/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5883 - mse: 693.5646 - val_loss: 18.4218 - val_mse: 741.5522\n",
      "Epoch 1666/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7571 - mse: 704.3719 - val_loss: 18.9596 - val_mse: 834.9425\n",
      "Epoch 1667/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6160 - mse: 695.1060 - val_loss: 17.7731 - val_mse: 709.5721\n",
      "Epoch 1668/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5335 - mse: 690.3516 - val_loss: 18.1207 - val_mse: 691.4244\n",
      "Epoch 1669/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7353 - mse: 691.9278 - val_loss: 17.6652 - val_mse: 697.8937\n",
      "Epoch 1670/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2405 - mse: 732.5637 - val_loss: 19.1861 - val_mse: 708.0773\n",
      "Epoch 1671/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7674 - mse: 703.4219 - val_loss: 17.7502 - val_mse: 698.6832\n",
      "Epoch 1672/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7684 - mse: 705.6263 - val_loss: 18.6233 - val_mse: 811.6920\n",
      "Epoch 1673/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6694 - mse: 693.6254 - val_loss: 18.1178 - val_mse: 699.0463\n",
      "Epoch 1674/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8164 - mse: 705.8342 - val_loss: 18.0890 - val_mse: 685.9993\n",
      "Epoch 1675/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7180 - mse: 694.1177 - val_loss: 17.9604 - val_mse: 704.4788\n",
      "Epoch 1676/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8904 - mse: 708.5104 - val_loss: 18.4081 - val_mse: 775.6895\n",
      "Epoch 1677/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7229 - mse: 694.3001 - val_loss: 18.3572 - val_mse: 766.9161\n",
      "Epoch 1678/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9035 - mse: 702.8523 - val_loss: 18.4076 - val_mse: 802.0970\n",
      "Epoch 1679/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6554 - mse: 699.2234 - val_loss: 18.0583 - val_mse: 706.9302\n",
      "Epoch 1680/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7809 - mse: 694.6114 - val_loss: 18.1550 - val_mse: 741.4786\n",
      "Epoch 1681/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3240 - mse: 736.8299 - val_loss: 18.5189 - val_mse: 815.9863\n",
      "Epoch 1682/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9211 - mse: 711.8552 - val_loss: 17.7072 - val_mse: 701.9301\n",
      "Epoch 1683/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6055 - mse: 683.9448 - val_loss: 17.8286 - val_mse: 710.7476\n",
      "Epoch 1684/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5273 - mse: 689.4385 - val_loss: 18.0477 - val_mse: 690.4114\n",
      "Epoch 1685/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5412 - mse: 682.5846 - val_loss: 18.1996 - val_mse: 738.8519\n",
      "Epoch 1686/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7144 - mse: 698.1049 - val_loss: 18.1567 - val_mse: 761.7151\n",
      "Epoch 1687/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8390 - mse: 708.9025 - val_loss: 18.1375 - val_mse: 770.4739\n",
      "Epoch 1688/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5502 - mse: 685.6246 - val_loss: 17.7547 - val_mse: 725.0377\n",
      "Epoch 1689/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4379 - mse: 677.3062 - val_loss: 18.1042 - val_mse: 697.6829\n",
      "Epoch 1690/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9979 - mse: 716.8486 - val_loss: 17.9602 - val_mse: 750.0802\n",
      "Epoch 1691/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2238 - mse: 740.1792 - val_loss: 17.8099 - val_mse: 729.3377\n",
      "Epoch 1692/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7698 - mse: 692.3692 - val_loss: 18.0067 - val_mse: 769.3282\n",
      "Epoch 1693/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7406 - mse: 695.1653 - val_loss: 18.2481 - val_mse: 688.4467\n",
      "Epoch 1694/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7280 - mse: 701.9892 - val_loss: 17.9948 - val_mse: 749.6633\n",
      "Epoch 1695/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7930 - mse: 703.5259 - val_loss: 17.8232 - val_mse: 698.2722\n",
      "Epoch 1696/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7574 - mse: 701.0369 - val_loss: 17.9281 - val_mse: 683.9744\n",
      "Epoch 1697/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8038 - mse: 707.2020 - val_loss: 17.8234 - val_mse: 693.5209\n",
      "Epoch 1698/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.9782 - mse: 715.0953 - val_loss: 19.2148 - val_mse: 875.0643\n",
      "Epoch 1699/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7580 - mse: 705.7732 - val_loss: 17.8820 - val_mse: 737.4739\n",
      "Epoch 1700/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6023 - mse: 693.3885 - val_loss: 17.7901 - val_mse: 685.7915\n",
      "Epoch 1701/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2744 - mse: 721.5807 - val_loss: 18.4033 - val_mse: 787.3421\n",
      "Epoch 1702/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1699 - mse: 731.1651 - val_loss: 18.3564 - val_mse: 793.1888\n",
      "Epoch 1703/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8262 - mse: 713.2798 - val_loss: 18.0533 - val_mse: 712.8884\n",
      "Epoch 1704/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5029 - mse: 684.9725 - val_loss: 18.1451 - val_mse: 713.2817\n",
      "Epoch 1705/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6298 - mse: 762.9422 - val_loss: 17.9579 - val_mse: 717.7034\n",
      "Epoch 1706/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6883 - mse: 701.2215 - val_loss: 17.8819 - val_mse: 748.1870\n",
      "Epoch 1707/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5637 - mse: 682.3962 - val_loss: 17.8513 - val_mse: 700.3871\n",
      "Epoch 1708/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7826 - mse: 705.9620 - val_loss: 18.1463 - val_mse: 702.4221\n",
      "Epoch 1709/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4765 - mse: 683.6255 - val_loss: 17.7626 - val_mse: 705.6351\n",
      "Epoch 1710/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7130 - mse: 696.8748 - val_loss: 17.7146 - val_mse: 722.2996\n",
      "Epoch 1711/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5460 - mse: 690.7610 - val_loss: 17.8337 - val_mse: 747.2061\n",
      "Epoch 1712/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8127 - mse: 705.0052 - val_loss: 18.7085 - val_mse: 714.9123\n",
      "Epoch 1713/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0411 - mse: 724.1571 - val_loss: 18.0329 - val_mse: 777.4027\n",
      "Epoch 1714/5000\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 18.7459 - mse: 768.2801 - val_loss: 17.9712 - val_mse: 738.1230\n",
      "Epoch 1715/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5879 - mse: 697.2230 - val_loss: 17.7015 - val_mse: 712.9939\n",
      "Epoch 1716/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9508 - mse: 712.7805 - val_loss: 17.8961 - val_mse: 759.7398\n",
      "Epoch 1717/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0891 - mse: 717.9175 - val_loss: 17.9912 - val_mse: 736.5360\n",
      "Epoch 1718/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8165 - mse: 705.6330 - val_loss: 18.1112 - val_mse: 693.7804\n",
      "Epoch 1719/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4775 - mse: 687.1342 - val_loss: 17.6450 - val_mse: 714.7997\n",
      "Epoch 1720/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4332 - mse: 689.3334 - val_loss: 17.6157 - val_mse: 716.4702\n",
      "Epoch 1721/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6363 - mse: 696.4399 - val_loss: 18.6796 - val_mse: 696.8088\n",
      "Epoch 1722/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8477 - mse: 709.4993 - val_loss: 19.2161 - val_mse: 704.3835\n",
      "Epoch 1723/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8199 - mse: 708.0545 - val_loss: 18.1556 - val_mse: 693.8124\n",
      "Epoch 1724/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8752 - mse: 701.2181 - val_loss: 18.2008 - val_mse: 692.2299\n",
      "Epoch 1725/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0701 - mse: 726.3427 - val_loss: 17.8086 - val_mse: 736.4598\n",
      "Epoch 1726/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6935 - mse: 693.8029 - val_loss: 17.7350 - val_mse: 739.5179\n",
      "Epoch 1727/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5325 - mse: 690.7857 - val_loss: 17.6748 - val_mse: 711.7229\n",
      "Epoch 1728/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5077 - mse: 683.9332 - val_loss: 17.8309 - val_mse: 688.6680\n",
      "Epoch 1729/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5112 - mse: 687.7137 - val_loss: 18.0257 - val_mse: 706.7590\n",
      "Epoch 1730/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8250 - mse: 706.1997 - val_loss: 17.6737 - val_mse: 718.1091\n",
      "Epoch 1731/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5077 - mse: 685.2057 - val_loss: 18.6274 - val_mse: 814.9504\n",
      "Epoch 1732/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7338 - mse: 702.1085 - val_loss: 17.8205 - val_mse: 737.1445\n",
      "Epoch 1733/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9470 - mse: 705.4965 - val_loss: 18.1012 - val_mse: 782.8167\n",
      "Epoch 1734/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7440 - mse: 704.6279 - val_loss: 17.6446 - val_mse: 692.3401\n",
      "Epoch 1735/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9743 - mse: 714.0262 - val_loss: 18.6732 - val_mse: 708.2541\n",
      "Epoch 1736/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2358 - mse: 723.1010 - val_loss: 17.7816 - val_mse: 708.6216\n",
      "Epoch 1737/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6632 - mse: 695.4055 - val_loss: 18.4201 - val_mse: 780.5196\n",
      "Epoch 1738/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7286 - mse: 703.4908 - val_loss: 18.0645 - val_mse: 755.1587\n",
      "Epoch 1739/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5895 - mse: 687.4772 - val_loss: 17.6624 - val_mse: 728.8328\n",
      "Epoch 1740/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8367 - mse: 701.8303 - val_loss: 18.5220 - val_mse: 810.9655\n",
      "Epoch 1741/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9784 - mse: 713.6642 - val_loss: 18.9184 - val_mse: 732.3636\n",
      "Epoch 1742/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8874 - mse: 703.8811 - val_loss: 18.9697 - val_mse: 708.1097\n",
      "Epoch 1743/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1789 - mse: 730.1244 - val_loss: 18.3008 - val_mse: 723.0703\n",
      "Epoch 1744/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.8898 - mse: 708.4123 - val_loss: 17.9975 - val_mse: 755.1058\n",
      "Epoch 1745/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.6378 - mse: 688.6475 - val_loss: 18.0136 - val_mse: 769.6437\n",
      "Epoch 1746/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0219 - mse: 722.9001 - val_loss: 18.2242 - val_mse: 698.3022\n",
      "Epoch 1747/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.5097 - mse: 683.3297 - val_loss: 17.7077 - val_mse: 728.5228\n",
      "Epoch 1748/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8027 - mse: 702.1677 - val_loss: 18.9923 - val_mse: 690.4971\n",
      "Epoch 1749/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.8988 - mse: 702.9758 - val_loss: 18.0718 - val_mse: 760.1005\n",
      "Epoch 1750/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.6987 - mse: 697.0054 - val_loss: 18.6763 - val_mse: 804.3087\n",
      "Epoch 1751/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6966 - mse: 692.4002 - val_loss: 17.7777 - val_mse: 697.4133\n",
      "Epoch 1752/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4029 - mse: 679.2448 - val_loss: 17.9266 - val_mse: 705.3960\n",
      "Epoch 1753/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5835 - mse: 686.0334 - val_loss: 17.7409 - val_mse: 741.1675\n",
      "Epoch 1754/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6419 - mse: 696.2911 - val_loss: 18.3929 - val_mse: 798.6816\n",
      "Epoch 1755/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.9234 - mse: 709.6954 - val_loss: 18.8626 - val_mse: 700.1556\n",
      "Epoch 1756/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8695 - mse: 709.5096 - val_loss: 18.0786 - val_mse: 712.1251\n",
      "Epoch 1757/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9612 - mse: 712.3110 - val_loss: 19.2999 - val_mse: 872.9377\n",
      "Epoch 1758/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6746 - mse: 699.8003 - val_loss: 17.6424 - val_mse: 690.0399\n",
      "Epoch 1759/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1751 - mse: 724.1921 - val_loss: 18.8033 - val_mse: 701.4828\n",
      "Epoch 1760/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8967 - mse: 707.9642 - val_loss: 17.9401 - val_mse: 724.1030\n",
      "Epoch 1761/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6952 - mse: 694.7204 - val_loss: 18.5284 - val_mse: 696.8046\n",
      "Epoch 1762/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8035 - mse: 702.5938 - val_loss: 18.1505 - val_mse: 741.9927\n",
      "Epoch 1763/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8134 - mse: 704.3962 - val_loss: 19.1756 - val_mse: 706.1104\n",
      "Epoch 1764/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7483 - mse: 692.9329 - val_loss: 17.7676 - val_mse: 694.0338\n",
      "Epoch 1765/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8080 - mse: 699.9523 - val_loss: 19.1466 - val_mse: 748.3308\n",
      "Epoch 1766/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3150 - mse: 737.3622 - val_loss: 18.9822 - val_mse: 688.0089\n",
      "Epoch 1767/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9747 - mse: 713.1061 - val_loss: 18.2939 - val_mse: 724.1776\n",
      "Epoch 1768/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6235 - mse: 695.3793 - val_loss: 18.0565 - val_mse: 723.0536\n",
      "Epoch 1769/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6281 - mse: 694.4173 - val_loss: 17.7560 - val_mse: 679.3445\n",
      "Epoch 1770/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5066 - mse: 683.8505 - val_loss: 17.6420 - val_mse: 716.3289\n",
      "Epoch 1771/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6392 - mse: 692.3578 - val_loss: 17.7458 - val_mse: 715.9668\n",
      "Epoch 1772/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5328 - mse: 686.7496 - val_loss: 18.1828 - val_mse: 781.8719\n",
      "Epoch 1773/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6515 - mse: 692.9941 - val_loss: 18.0226 - val_mse: 708.5518\n",
      "Epoch 1774/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9082 - mse: 706.2620 - val_loss: 18.6017 - val_mse: 778.6023\n",
      "Epoch 1775/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5163 - mse: 688.8774 - val_loss: 17.9580 - val_mse: 686.5427\n",
      "Epoch 1776/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4601 - mse: 685.7318 - val_loss: 19.7992 - val_mse: 910.7761\n",
      "Epoch 1777/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9372 - mse: 708.3933 - val_loss: 17.9557 - val_mse: 730.5621\n",
      "Epoch 1778/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5924 - mse: 690.1476 - val_loss: 18.0835 - val_mse: 764.4811\n",
      "Epoch 1779/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7974 - mse: 703.6194 - val_loss: 17.7444 - val_mse: 745.8630\n",
      "Epoch 1780/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6691 - mse: 702.1051 - val_loss: 18.0863 - val_mse: 696.5804\n",
      "Epoch 1781/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6929 - mse: 755.1804 - val_loss: 20.5050 - val_mse: 763.2421\n",
      "Epoch 1782/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0994 - mse: 720.9175 - val_loss: 17.8494 - val_mse: 733.9295\n",
      "Epoch 1783/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9518 - mse: 719.5938 - val_loss: 18.3656 - val_mse: 704.5345\n",
      "Epoch 1784/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5579 - mse: 690.9756 - val_loss: 17.9846 - val_mse: 763.6515\n",
      "Epoch 1785/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6169 - mse: 695.3477 - val_loss: 18.4440 - val_mse: 683.9084\n",
      "Epoch 1786/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5364 - mse: 686.6404 - val_loss: 17.9910 - val_mse: 726.8433\n",
      "Epoch 1787/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.7093 - mse: 688.9570 - val_loss: 18.6245 - val_mse: 825.0646\n",
      "Epoch 1788/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6434 - mse: 699.6139 - val_loss: 17.7871 - val_mse: 743.4663\n",
      "Epoch 1789/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.8808 - mse: 713.6093 - val_loss: 17.7915 - val_mse: 716.6664\n",
      "Epoch 1790/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8730 - mse: 726.5179 - val_loss: 18.6500 - val_mse: 746.3445\n",
      "Epoch 1791/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0102 - mse: 716.9777 - val_loss: 18.2355 - val_mse: 759.3837\n",
      "Epoch 1792/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6064 - mse: 692.7829 - val_loss: 17.8556 - val_mse: 722.7823\n",
      "Epoch 1793/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4426 - mse: 681.1894 - val_loss: 17.8145 - val_mse: 698.7603\n",
      "Epoch 1794/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8259 - mse: 710.1257 - val_loss: 17.9628 - val_mse: 714.8952\n",
      "Epoch 1795/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8710 - mse: 723.9511 - val_loss: 17.9791 - val_mse: 748.7009\n",
      "Epoch 1796/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8410 - mse: 700.8131 - val_loss: 19.0046 - val_mse: 690.8524\n",
      "Epoch 1797/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9722 - mse: 707.7211 - val_loss: 18.0683 - val_mse: 684.5557\n",
      "Epoch 1798/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5762 - mse: 759.6717 - val_loss: 18.5163 - val_mse: 755.7691\n",
      "Epoch 1799/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9691 - mse: 726.0190 - val_loss: 18.2957 - val_mse: 787.5639\n",
      "Epoch 1800/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8045 - mse: 704.4249 - val_loss: 18.3745 - val_mse: 716.9364\n",
      "Epoch 1801/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0821 - mse: 724.2161 - val_loss: 18.6787 - val_mse: 684.5278\n",
      "Epoch 1802/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8002 - mse: 711.7410 - val_loss: 17.8386 - val_mse: 715.6270\n",
      "Epoch 1803/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5810 - mse: 689.1520 - val_loss: 17.6708 - val_mse: 704.0938\n",
      "Epoch 1804/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5424 - mse: 683.3666 - val_loss: 18.0960 - val_mse: 693.2323\n",
      "Epoch 1805/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0386 - mse: 715.3669 - val_loss: 18.0224 - val_mse: 732.5367\n",
      "Epoch 1806/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4544 - mse: 682.1001 - val_loss: 18.2163 - val_mse: 685.2552\n",
      "Epoch 1807/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2033 - mse: 723.7002 - val_loss: 18.5845 - val_mse: 782.2339\n",
      "Epoch 1808/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7971 - mse: 700.4611 - val_loss: 17.8458 - val_mse: 714.9208\n",
      "Epoch 1809/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5494 - mse: 696.9562 - val_loss: 18.2321 - val_mse: 684.3546\n",
      "Epoch 1810/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8809 - mse: 706.4993 - val_loss: 17.9020 - val_mse: 744.6071\n",
      "Epoch 1811/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5241 - mse: 684.7030 - val_loss: 18.1295 - val_mse: 771.1060\n",
      "Epoch 1812/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5082 - mse: 680.6228 - val_loss: 18.3917 - val_mse: 729.6096\n",
      "Epoch 1813/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.5273 - mse: 692.7283 - val_loss: 17.5877 - val_mse: 708.1949\n",
      "Epoch 1814/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5841 - mse: 691.8005 - val_loss: 17.8130 - val_mse: 734.6516\n",
      "Epoch 1815/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8342 - mse: 698.7858 - val_loss: 18.3712 - val_mse: 776.4802\n",
      "Epoch 1816/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8646 - mse: 714.2232 - val_loss: 18.0695 - val_mse: 755.8017\n",
      "Epoch 1817/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7215 - mse: 697.5026 - val_loss: 17.6811 - val_mse: 720.8754\n",
      "Epoch 1818/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7501 - mse: 704.3357 - val_loss: 19.0159 - val_mse: 709.9020\n",
      "Epoch 1819/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1569 - mse: 732.6957 - val_loss: 18.8418 - val_mse: 688.4845\n",
      "Epoch 1820/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4973 - mse: 737.4283 - val_loss: 17.9812 - val_mse: 722.2629\n",
      "Epoch 1821/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8058 - mse: 709.0652 - val_loss: 17.6748 - val_mse: 732.5364\n",
      "Epoch 1822/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6209 - mse: 691.3663 - val_loss: 18.3316 - val_mse: 783.9348\n",
      "Epoch 1823/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8282 - mse: 717.6990 - val_loss: 17.7481 - val_mse: 720.4717\n",
      "Epoch 1824/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9337 - mse: 719.8976 - val_loss: 18.0230 - val_mse: 768.2621\n",
      "Epoch 1825/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8757 - mse: 709.1353 - val_loss: 17.8719 - val_mse: 695.8271\n",
      "Epoch 1826/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7856 - mse: 703.4125 - val_loss: 18.2171 - val_mse: 684.0717\n",
      "Epoch 1827/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8457 - mse: 701.1351 - val_loss: 17.7308 - val_mse: 694.6310\n",
      "Epoch 1828/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4262 - mse: 676.4789 - val_loss: 17.7236 - val_mse: 698.9161\n",
      "Epoch 1829/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6473 - mse: 695.4188 - val_loss: 19.1703 - val_mse: 708.4053\n",
      "Epoch 1830/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5588 - mse: 683.9728 - val_loss: 17.7344 - val_mse: 716.7414\n",
      "Epoch 1831/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6892 - mse: 694.6398 - val_loss: 17.6933 - val_mse: 714.3148\n",
      "Epoch 1832/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6164 - mse: 691.7421 - val_loss: 18.3282 - val_mse: 686.2899\n",
      "Epoch 1833/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5130 - mse: 689.6763 - val_loss: 17.6962 - val_mse: 730.0095\n",
      "Epoch 1834/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4697 - mse: 685.1871 - val_loss: 17.8198 - val_mse: 682.8159\n",
      "Epoch 1835/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7856 - mse: 688.9980 - val_loss: 17.8635 - val_mse: 736.0366\n",
      "Epoch 1836/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9827 - mse: 723.5157 - val_loss: 17.9324 - val_mse: 682.1998\n",
      "Epoch 1837/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9056 - mse: 707.5370 - val_loss: 17.8652 - val_mse: 709.0837\n",
      "Epoch 1838/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6342 - mse: 688.5826 - val_loss: 18.2554 - val_mse: 723.3663\n",
      "Epoch 1839/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5323 - mse: 746.7888 - val_loss: 18.1523 - val_mse: 696.6473\n",
      "Epoch 1840/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8418 - mse: 707.9473 - val_loss: 17.8534 - val_mse: 715.3329\n",
      "Epoch 1841/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3724 - mse: 680.3373 - val_loss: 18.1038 - val_mse: 772.1693\n",
      "Epoch 1842/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6125 - mse: 693.8121 - val_loss: 17.9612 - val_mse: 734.1396\n",
      "Epoch 1843/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8105 - mse: 708.0094 - val_loss: 18.8818 - val_mse: 831.1794\n",
      "Epoch 1844/5000\n",
      "36/36 [==============================] - 104s 3s/step - loss: 18.2006 - mse: 726.5015 - val_loss: 17.8140 - val_mse: 741.4317\n",
      "Epoch 1845/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.7334 - mse: 694.8045 - val_loss: 17.7607 - val_mse: 702.7473\n",
      "Epoch 1846/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3734 - mse: 730.9338 - val_loss: 19.1287 - val_mse: 707.3610\n",
      "Epoch 1847/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4443 - mse: 682.5161 - val_loss: 17.8698 - val_mse: 726.6839\n",
      "Epoch 1848/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9274 - mse: 719.9975 - val_loss: 18.0564 - val_mse: 766.7319\n",
      "Epoch 1849/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6520 - mse: 681.2817 - val_loss: 17.7420 - val_mse: 713.6467\n",
      "Epoch 1850/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7879 - mse: 707.2509 - val_loss: 18.0134 - val_mse: 698.7446\n",
      "Epoch 1851/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5588 - mse: 683.9628 - val_loss: 19.1616 - val_mse: 704.1742\n",
      "Epoch 1852/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9628 - mse: 716.2621 - val_loss: 17.7073 - val_mse: 721.4384\n",
      "Epoch 1853/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1344 - mse: 717.5840 - val_loss: 17.9000 - val_mse: 724.5403\n",
      "Epoch 1854/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7401 - mse: 698.5632 - val_loss: 17.7008 - val_mse: 716.7368\n",
      "Epoch 1855/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7488 - mse: 700.6916 - val_loss: 18.2729 - val_mse: 744.7783\n",
      "Epoch 1856/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7066 - mse: 698.7603 - val_loss: 17.6367 - val_mse: 716.5300\n",
      "Epoch 1857/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0862 - mse: 725.4466 - val_loss: 19.3532 - val_mse: 876.6229\n",
      "Epoch 1858/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5830 - mse: 694.9924 - val_loss: 17.6442 - val_mse: 689.0488\n",
      "Epoch 1859/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6747 - mse: 696.1086 - val_loss: 17.8660 - val_mse: 737.8498\n",
      "Epoch 1860/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7324 - mse: 705.6373 - val_loss: 18.2584 - val_mse: 675.4464\n",
      "Epoch 1861/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8972 - mse: 707.4566 - val_loss: 18.5810 - val_mse: 725.8915\n",
      "Epoch 1862/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6954 - mse: 689.9784 - val_loss: 18.2426 - val_mse: 796.0304\n",
      "Epoch 1863/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9958 - mse: 702.3880 - val_loss: 18.6431 - val_mse: 824.6864\n",
      "Epoch 1864/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.6869 - mse: 707.6633 - val_loss: 18.3477 - val_mse: 690.8751\n",
      "Epoch 1865/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6990 - mse: 702.7823 - val_loss: 17.8666 - val_mse: 693.9352\n",
      "Epoch 1866/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.7030 - mse: 695.4553 - val_loss: 18.3482 - val_mse: 688.4323\n",
      "Epoch 1867/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0376 - mse: 705.1116 - val_loss: 20.1406 - val_mse: 940.7221\n",
      "Epoch 1868/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7412 - mse: 701.5814 - val_loss: 18.0148 - val_mse: 755.0494\n",
      "Epoch 1869/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.1904 - mse: 726.8051 - val_loss: 18.5351 - val_mse: 814.9569\n",
      "Epoch 1870/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4390 - mse: 745.9173 - val_loss: 18.2516 - val_mse: 766.6616\n",
      "Epoch 1871/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6418 - mse: 706.2263 - val_loss: 17.8233 - val_mse: 719.7608\n",
      "Epoch 1872/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.0024 - mse: 718.6357 - val_loss: 18.1780 - val_mse: 757.6977\n",
      "Epoch 1873/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9221 - mse: 710.2682 - val_loss: 17.8783 - val_mse: 753.0791\n",
      "Epoch 1874/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5660 - mse: 690.3846 - val_loss: 18.0727 - val_mse: 743.7261\n",
      "Epoch 1875/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6009 - mse: 690.0523 - val_loss: 18.6723 - val_mse: 827.7789\n",
      "Epoch 1876/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0929 - mse: 737.9897 - val_loss: 17.7396 - val_mse: 737.8698\n",
      "Epoch 1877/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7700 - mse: 700.6783 - val_loss: 17.8092 - val_mse: 726.9447\n",
      "Epoch 1878/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0355 - mse: 721.5775 - val_loss: 17.8421 - val_mse: 699.7422\n",
      "Epoch 1879/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8018 - mse: 708.0314 - val_loss: 19.1708 - val_mse: 867.2675\n",
      "Epoch 1880/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9280 - mse: 712.8503 - val_loss: 17.7719 - val_mse: 741.2466\n",
      "Epoch 1881/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4742 - mse: 689.7070 - val_loss: 17.7019 - val_mse: 728.2346\n",
      "Epoch 1882/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6894 - mse: 698.9714 - val_loss: 18.8316 - val_mse: 797.9827\n",
      "Epoch 1883/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8753 - mse: 715.7851 - val_loss: 17.9400 - val_mse: 689.1313\n",
      "Epoch 1884/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4559 - mse: 686.1367 - val_loss: 17.7344 - val_mse: 686.4927\n",
      "Epoch 1885/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5322 - mse: 684.6859 - val_loss: 17.9693 - val_mse: 751.0380\n",
      "Epoch 1886/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4617 - mse: 684.1904 - val_loss: 17.8162 - val_mse: 705.7394\n",
      "Epoch 1887/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7961 - mse: 703.9269 - val_loss: 18.2805 - val_mse: 703.7645\n",
      "Epoch 1888/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6704 - mse: 697.1518 - val_loss: 17.9621 - val_mse: 699.2428\n",
      "Epoch 1889/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7531 - mse: 695.8379 - val_loss: 18.2342 - val_mse: 795.3861\n",
      "Epoch 1890/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7069 - mse: 705.7474 - val_loss: 17.5996 - val_mse: 700.6838\n",
      "Epoch 1891/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4015 - mse: 674.8397 - val_loss: 17.8187 - val_mse: 740.5067\n",
      "Epoch 1892/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8824 - mse: 716.8091 - val_loss: 17.9098 - val_mse: 740.4864\n",
      "Epoch 1893/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9890 - mse: 697.7822 - val_loss: 19.3279 - val_mse: 853.3335\n",
      "Epoch 1894/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5519 - mse: 752.2108 - val_loss: 17.8315 - val_mse: 742.4501\n",
      "Epoch 1895/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7474 - mse: 694.2540 - val_loss: 18.2619 - val_mse: 774.0795\n",
      "Epoch 1896/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6878 - mse: 693.0351 - val_loss: 17.8031 - val_mse: 721.4704\n",
      "Epoch 1897/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9606 - mse: 713.5387 - val_loss: 17.9370 - val_mse: 736.7606\n",
      "Epoch 1898/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7195 - mse: 702.2814 - val_loss: 19.0613 - val_mse: 707.8246\n",
      "Epoch 1899/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7565 - mse: 699.4897 - val_loss: 18.2304 - val_mse: 755.3163\n",
      "Epoch 1900/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6416 - mse: 692.8104 - val_loss: 18.3771 - val_mse: 782.8537\n",
      "Epoch 1901/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6368 - mse: 702.2484 - val_loss: 18.3736 - val_mse: 759.5176\n",
      "Epoch 1902/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7203 - mse: 702.4723 - val_loss: 18.4694 - val_mse: 681.9847\n",
      "Epoch 1903/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6693 - mse: 690.2690 - val_loss: 18.0692 - val_mse: 762.6398\n",
      "Epoch 1904/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5408 - mse: 691.3572 - val_loss: 17.6819 - val_mse: 713.2117\n",
      "Epoch 1905/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5965 - mse: 694.6884 - val_loss: 17.5897 - val_mse: 692.6210\n",
      "Epoch 1906/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9104 - mse: 711.5098 - val_loss: 19.3519 - val_mse: 712.1193\n",
      "Epoch 1907/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2500 - mse: 738.9076 - val_loss: 17.8914 - val_mse: 723.4764\n",
      "Epoch 1908/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8745 - mse: 712.6656 - val_loss: 17.5982 - val_mse: 714.9913\n",
      "Epoch 1909/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6014 - mse: 694.2720 - val_loss: 18.3645 - val_mse: 785.8467\n",
      "Epoch 1910/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.2731 - mse: 735.8658 - val_loss: 19.0681 - val_mse: 819.3115\n",
      "Epoch 1911/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8210 - mse: 711.0149 - val_loss: 17.7314 - val_mse: 716.2942\n",
      "Epoch 1912/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3460 - mse: 675.0727 - val_loss: 17.7950 - val_mse: 737.1079\n",
      "Epoch 1913/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.0346 - mse: 708.0215 - val_loss: 18.3863 - val_mse: 793.8870\n",
      "Epoch 1914/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5730 - mse: 691.3386 - val_loss: 17.6924 - val_mse: 723.0280\n",
      "Epoch 1915/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7240 - mse: 699.3406 - val_loss: 19.1567 - val_mse: 691.4373\n",
      "Epoch 1916/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4798 - mse: 745.1922 - val_loss: 18.6567 - val_mse: 698.7350\n",
      "Epoch 1917/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.9384 - mse: 713.2495 - val_loss: 17.8627 - val_mse: 724.0546\n",
      "Epoch 1918/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.5998 - mse: 768.7419 - val_loss: 19.1214 - val_mse: 796.2763\n",
      "Epoch 1919/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1590 - mse: 723.5869 - val_loss: 18.3346 - val_mse: 706.6943\n",
      "Epoch 1920/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.1636 - mse: 728.1085 - val_loss: 19.8308 - val_mse: 735.7957\n",
      "Epoch 1921/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9672 - mse: 712.9722 - val_loss: 18.0272 - val_mse: 712.5172\n",
      "Epoch 1922/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.8573 - mse: 710.5471 - val_loss: 18.3098 - val_mse: 739.3174\n",
      "Epoch 1923/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7362 - mse: 704.1439 - val_loss: 19.3117 - val_mse: 819.3992\n",
      "Epoch 1924/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.8692 - mse: 714.6995 - val_loss: 18.1763 - val_mse: 774.5656\n",
      "Epoch 1925/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6869 - mse: 690.3488 - val_loss: 18.0461 - val_mse: 778.2454\n",
      "Epoch 1926/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.9424 - mse: 714.1871 - val_loss: 17.9394 - val_mse: 725.0157\n",
      "Epoch 1927/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2482 - mse: 730.3387 - val_loss: 19.0464 - val_mse: 843.2898\n",
      "Epoch 1928/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4478 - mse: 748.9739 - val_loss: 18.3990 - val_mse: 690.1385\n",
      "Epoch 1929/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7610 - mse: 690.1854 - val_loss: 18.3262 - val_mse: 712.8762\n",
      "Epoch 1930/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9549 - mse: 712.0324 - val_loss: 18.3930 - val_mse: 740.5350\n",
      "Epoch 1931/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8707 - mse: 701.3768 - val_loss: 18.5237 - val_mse: 759.2842\n",
      "Epoch 1932/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1006 - mse: 708.1364 - val_loss: 18.4693 - val_mse: 812.3853\n",
      "Epoch 1933/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6743 - mse: 698.7069 - val_loss: 17.9736 - val_mse: 725.9813\n",
      "Epoch 1934/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.7064 - mse: 699.1828 - val_loss: 17.9278 - val_mse: 706.7350\n",
      "Epoch 1935/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.7370 - mse: 700.5383 - val_loss: 17.9524 - val_mse: 731.8821\n",
      "Epoch 1936/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6943 - mse: 695.3327 - val_loss: 18.1510 - val_mse: 765.6602\n",
      "Epoch 1937/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7000 - mse: 691.4950 - val_loss: 18.0367 - val_mse: 725.8088\n",
      "Epoch 1938/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7067 - mse: 694.4550 - val_loss: 19.3194 - val_mse: 882.0302\n",
      "Epoch 1939/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4134 - mse: 746.8156 - val_loss: 18.8160 - val_mse: 770.6230\n",
      "Epoch 1940/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0193 - mse: 716.2336 - val_loss: 17.9571 - val_mse: 716.6318\n",
      "Epoch 1941/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0365 - mse: 721.9744 - val_loss: 17.9243 - val_mse: 684.0172\n",
      "Epoch 1942/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5295 - mse: 681.9237 - val_loss: 17.7015 - val_mse: 723.3729\n",
      "Epoch 1943/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9629 - mse: 707.4443 - val_loss: 18.4048 - val_mse: 798.0621\n",
      "Epoch 1944/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.3578 - mse: 742.2886 - val_loss: 18.8669 - val_mse: 702.5908\n",
      "Epoch 1945/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9110 - mse: 715.3347 - val_loss: 18.0005 - val_mse: 711.1077\n",
      "Epoch 1946/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6395 - mse: 683.1869 - val_loss: 18.1909 - val_mse: 770.6037\n",
      "Epoch 1947/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5682 - mse: 689.7467 - val_loss: 17.6740 - val_mse: 707.1367\n",
      "Epoch 1948/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6217 - mse: 687.8939 - val_loss: 18.2633 - val_mse: 691.9305\n",
      "Epoch 1949/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0391 - mse: 719.3186 - val_loss: 19.2685 - val_mse: 698.7479\n",
      "Epoch 1950/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7122 - mse: 702.8411 - val_loss: 17.9901 - val_mse: 692.4390\n",
      "Epoch 1951/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5027 - mse: 688.9976 - val_loss: 18.0074 - val_mse: 708.9357\n",
      "Epoch 1952/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5119 - mse: 692.9460 - val_loss: 17.8005 - val_mse: 693.4998\n",
      "Epoch 1953/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5505 - mse: 681.7829 - val_loss: 17.7077 - val_mse: 714.8492\n",
      "Epoch 1954/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6721 - mse: 695.8660 - val_loss: 18.2776 - val_mse: 776.0870\n",
      "Epoch 1955/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6166 - mse: 757.7995 - val_loss: 17.8497 - val_mse: 744.9528\n",
      "Epoch 1956/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5703 - mse: 695.1549 - val_loss: 18.1007 - val_mse: 749.6898\n",
      "Epoch 1957/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7128 - mse: 695.0327 - val_loss: 17.6888 - val_mse: 719.5364\n",
      "Epoch 1958/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6446 - mse: 695.8066 - val_loss: 17.8257 - val_mse: 753.1890\n",
      "Epoch 1959/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5325 - mse: 695.4099 - val_loss: 18.3059 - val_mse: 726.1046\n",
      "Epoch 1960/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8258 - mse: 704.7520 - val_loss: 17.8541 - val_mse: 712.3906\n",
      "Epoch 1961/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7922 - mse: 697.3574 - val_loss: 17.7522 - val_mse: 719.8203\n",
      "Epoch 1962/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8279 - mse: 705.0856 - val_loss: 18.1568 - val_mse: 762.8425\n",
      "Epoch 1963/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7588 - mse: 694.7214 - val_loss: 18.0438 - val_mse: 705.2533\n",
      "Epoch 1964/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4961 - mse: 688.0686 - val_loss: 18.9800 - val_mse: 699.2657\n",
      "Epoch 1965/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9470 - mse: 714.5922 - val_loss: 18.5646 - val_mse: 765.7664\n",
      "Epoch 1966/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1667 - mse: 730.5903 - val_loss: 17.9826 - val_mse: 750.6954\n",
      "Epoch 1967/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5923 - mse: 687.3641 - val_loss: 17.8785 - val_mse: 717.6137\n",
      "Epoch 1968/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7471 - mse: 699.7957 - val_loss: 17.7353 - val_mse: 711.1981\n",
      "Epoch 1969/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9842 - mse: 715.0816 - val_loss: 19.0163 - val_mse: 755.4717\n",
      "Epoch 1970/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1724 - mse: 727.8970 - val_loss: 17.7985 - val_mse: 727.3301\n",
      "Epoch 1971/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5730 - mse: 688.4293 - val_loss: 17.8190 - val_mse: 712.8636\n",
      "Epoch 1972/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9564 - mse: 716.3201 - val_loss: 18.2539 - val_mse: 713.1578\n",
      "Epoch 1973/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5337 - mse: 688.9982 - val_loss: 17.8867 - val_mse: 701.0047\n",
      "Epoch 1974/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7299 - mse: 699.2057 - val_loss: 18.1669 - val_mse: 772.4025\n",
      "Epoch 1975/5000\n",
      "36/36 [==============================] - 259s 7s/step - loss: 17.9143 - mse: 713.3847 - val_loss: 17.7310 - val_mse: 694.8997\n",
      "Epoch 1976/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5995 - mse: 690.5262 - val_loss: 17.8139 - val_mse: 699.0186\n",
      "Epoch 1977/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3639 - mse: 676.7183 - val_loss: 17.7418 - val_mse: 689.4358\n",
      "Epoch 1978/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6230 - mse: 695.6188 - val_loss: 17.8445 - val_mse: 747.1807\n",
      "Epoch 1979/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8541 - mse: 697.2634 - val_loss: 18.0080 - val_mse: 747.9476\n",
      "Epoch 1980/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0715 - mse: 727.3782 - val_loss: 17.9532 - val_mse: 681.1407\n",
      "Epoch 1981/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7175 - mse: 704.0828 - val_loss: 17.9051 - val_mse: 687.5464\n",
      "Epoch 1982/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8309 - mse: 693.9796 - val_loss: 17.8419 - val_mse: 690.8016\n",
      "Epoch 1983/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.4534 - mse: 680.1640 - val_loss: 18.2185 - val_mse: 694.0128\n",
      "Epoch 1984/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7114 - mse: 694.2362 - val_loss: 18.6757 - val_mse: 827.8381\n",
      "Epoch 1985/5000\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 17.9697 - mse: 714.3461 - val_loss: 17.8042 - val_mse: 714.4269\n",
      "Epoch 1986/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6415 - mse: 695.9763 - val_loss: 18.1534 - val_mse: 761.5016\n",
      "Epoch 1987/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7133 - mse: 700.6526 - val_loss: 17.9738 - val_mse: 688.5773\n",
      "Epoch 1988/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7189 - mse: 694.1575 - val_loss: 17.7833 - val_mse: 713.6548\n",
      "Epoch 1989/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7018 - mse: 692.7413 - val_loss: 18.6731 - val_mse: 754.4971\n",
      "Epoch 1990/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5115 - mse: 680.4143 - val_loss: 17.7017 - val_mse: 716.9407\n",
      "Epoch 1991/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4595 - mse: 679.9844 - val_loss: 17.5747 - val_mse: 688.9948\n",
      "Epoch 1992/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6788 - mse: 698.3862 - val_loss: 18.6113 - val_mse: 730.3098\n",
      "Epoch 1993/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1137 - mse: 713.8727 - val_loss: 17.9605 - val_mse: 732.7888\n",
      "Epoch 1994/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5102 - mse: 695.3392 - val_loss: 18.3335 - val_mse: 789.2733\n",
      "Epoch 1995/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9358 - mse: 705.0222 - val_loss: 18.6261 - val_mse: 722.5574\n",
      "Epoch 1996/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6644 - mse: 696.5070 - val_loss: 18.0362 - val_mse: 751.0975\n",
      "Epoch 1997/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8379 - mse: 705.8356 - val_loss: 17.9421 - val_mse: 768.3908\n",
      "Epoch 1998/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6845 - mse: 706.0001 - val_loss: 18.3297 - val_mse: 713.5370\n",
      "Epoch 1999/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6712 - mse: 688.3273 - val_loss: 17.9873 - val_mse: 760.7292\n",
      "Epoch 2000/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0487 - mse: 726.4067 - val_loss: 18.4860 - val_mse: 788.3118\n",
      "Epoch 2001/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2537 - mse: 736.2573 - val_loss: 18.4543 - val_mse: 743.3977\n",
      "Epoch 2002/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8832 - mse: 714.1080 - val_loss: 18.3675 - val_mse: 712.2347\n",
      "Epoch 2003/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5856 - mse: 686.5490 - val_loss: 18.0285 - val_mse: 769.2759\n",
      "Epoch 2004/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6022 - mse: 688.9633 - val_loss: 17.8207 - val_mse: 724.3872\n",
      "Epoch 2005/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0815 - mse: 722.9205 - val_loss: 18.4976 - val_mse: 692.2623\n",
      "Epoch 2006/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9045 - mse: 713.8802 - val_loss: 17.9550 - val_mse: 720.4904\n",
      "Epoch 2007/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9441 - mse: 722.3681 - val_loss: 18.2959 - val_mse: 717.5293\n",
      "Epoch 2008/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7551 - mse: 693.9500 - val_loss: 19.4182 - val_mse: 884.5703\n",
      "Epoch 2009/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4277 - mse: 739.5771 - val_loss: 17.7954 - val_mse: 734.1907\n",
      "Epoch 2010/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7248 - mse: 710.5310 - val_loss: 17.9727 - val_mse: 704.4282\n",
      "Epoch 2011/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5542 - mse: 684.6002 - val_loss: 18.4220 - val_mse: 696.3732\n",
      "Epoch 2012/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6402 - mse: 688.8737 - val_loss: 17.6668 - val_mse: 718.3935\n",
      "Epoch 2013/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7370 - mse: 703.4997 - val_loss: 18.4158 - val_mse: 743.3698\n",
      "Epoch 2014/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4794 - mse: 687.0432 - val_loss: 18.5315 - val_mse: 718.5512\n",
      "Epoch 2015/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.7309 - mse: 702.7774 - val_loss: 17.7294 - val_mse: 725.7871\n",
      "Epoch 2016/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.3062 - mse: 674.8354 - val_loss: 17.6253 - val_mse: 692.0510\n",
      "Epoch 2017/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.5244 - mse: 682.9039 - val_loss: 17.7009 - val_mse: 712.2649\n",
      "Epoch 2018/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5045 - mse: 688.6440 - val_loss: 17.8733 - val_mse: 690.9112\n",
      "Epoch 2019/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4663 - mse: 678.9929 - val_loss: 17.8552 - val_mse: 692.2343\n",
      "Epoch 2020/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8300 - mse: 770.2318 - val_loss: 18.5788 - val_mse: 697.9974\n",
      "Epoch 2021/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.6781 - mse: 710.3943 - val_loss: 18.5171 - val_mse: 778.0290\n",
      "Epoch 2022/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8259 - mse: 708.5643 - val_loss: 17.7612 - val_mse: 740.0604\n",
      "Epoch 2023/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4945 - mse: 694.7201 - val_loss: 17.9175 - val_mse: 699.6551\n",
      "Epoch 2024/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3669 - mse: 742.0391 - val_loss: 19.1133 - val_mse: 797.0505\n",
      "Epoch 2025/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3329 - mse: 733.8253 - val_loss: 17.8224 - val_mse: 718.8856\n",
      "Epoch 2026/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.3647 - mse: 677.7920 - val_loss: 17.6554 - val_mse: 706.1547\n",
      "Epoch 2027/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.4437 - mse: 675.1142 - val_loss: 18.3131 - val_mse: 715.4885\n",
      "Epoch 2028/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.7001 - mse: 700.1664 - val_loss: 18.2400 - val_mse: 700.8461\n",
      "Epoch 2029/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.2525 - mse: 730.9534 - val_loss: 18.5176 - val_mse: 808.0311\n",
      "Epoch 2030/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.0037 - mse: 713.2502 - val_loss: 18.3391 - val_mse: 738.7448\n",
      "Epoch 2031/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.6810 - mse: 699.1056 - val_loss: 17.9169 - val_mse: 737.9689\n",
      "Epoch 2032/5000\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 17.6643 - mse: 692.5286 - val_loss: 18.5135 - val_mse: 707.5815\n",
      "Epoch 2033/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.9822 - mse: 714.0526 - val_loss: 17.9718 - val_mse: 700.3381\n",
      "Epoch 2034/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.9743 - mse: 725.9096 - val_loss: 17.8203 - val_mse: 700.5440\n",
      "Epoch 2035/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.8083 - mse: 693.5207 - val_loss: 17.8573 - val_mse: 734.0329\n",
      "Epoch 2036/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.5878 - mse: 696.1514 - val_loss: 17.8771 - val_mse: 706.1461\n",
      "Epoch 2037/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.4605 - mse: 739.6996 - val_loss: 19.3469 - val_mse: 875.0554\n",
      "Epoch 2038/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.7615 - mse: 702.1081 - val_loss: 18.0163 - val_mse: 703.1155\n",
      "Epoch 2039/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4565 - mse: 678.2233 - val_loss: 17.6998 - val_mse: 733.8324\n",
      "Epoch 2040/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.6498 - mse: 701.7354 - val_loss: 17.7043 - val_mse: 696.9879\n",
      "Epoch 2041/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.4742 - mse: 686.0737 - val_loss: 17.6835 - val_mse: 685.4404\n",
      "Epoch 2042/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.5235 - mse: 681.7665 - val_loss: 18.9162 - val_mse: 827.0487\n",
      "Epoch 2043/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.7008 - mse: 693.0310 - val_loss: 17.7453 - val_mse: 702.1080\n",
      "Epoch 2044/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4733 - mse: 686.7590 - val_loss: 18.0564 - val_mse: 689.9432\n",
      "Epoch 2045/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.8831 - mse: 707.4603 - val_loss: 18.3482 - val_mse: 783.6179\n",
      "Epoch 2046/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.6868 - mse: 689.4692 - val_loss: 19.0571 - val_mse: 829.3629\n",
      "Epoch 2047/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.5383 - mse: 676.3971 - val_loss: 18.1993 - val_mse: 750.7427\n",
      "Epoch 2048/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6055 - mse: 696.3903 - val_loss: 17.7658 - val_mse: 693.2333\n",
      "Epoch 2049/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4487 - mse: 687.5737 - val_loss: 18.2641 - val_mse: 782.7305\n",
      "Epoch 2050/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4465 - mse: 676.7601 - val_loss: 17.9451 - val_mse: 735.9069\n",
      "Epoch 2051/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6256 - mse: 693.5445 - val_loss: 18.4691 - val_mse: 803.8480\n",
      "Epoch 2052/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8475 - mse: 715.0445 - val_loss: 18.3468 - val_mse: 724.6742\n",
      "Epoch 2053/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6188 - mse: 694.1646 - val_loss: 18.0136 - val_mse: 690.3986\n",
      "Epoch 2054/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4431 - mse: 685.7795 - val_loss: 18.7906 - val_mse: 704.9197\n",
      "Epoch 2055/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7653 - mse: 698.9478 - val_loss: 17.8855 - val_mse: 685.5176\n",
      "Epoch 2056/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.8269 - mse: 698.3099 - val_loss: 19.3621 - val_mse: 855.2856\n",
      "Epoch 2057/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7833 - mse: 698.7111 - val_loss: 17.6817 - val_mse: 712.0175\n",
      "Epoch 2058/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3967 - mse: 678.7757 - val_loss: 18.1288 - val_mse: 695.3687\n",
      "Epoch 2059/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5837 - mse: 691.4595 - val_loss: 17.6017 - val_mse: 708.9846\n",
      "Epoch 2060/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7856 - mse: 698.2767 - val_loss: 18.4895 - val_mse: 742.9297\n",
      "Epoch 2061/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4388 - mse: 679.9996 - val_loss: 17.9453 - val_mse: 734.3411\n",
      "Epoch 2062/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0793 - mse: 726.9259 - val_loss: 20.7230 - val_mse: 995.2548\n",
      "Epoch 2063/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0686 - mse: 739.0906 - val_loss: 17.7408 - val_mse: 737.8084\n",
      "Epoch 2064/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3292 - mse: 678.9996 - val_loss: 17.6871 - val_mse: 683.9570\n",
      "Epoch 2065/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5570 - mse: 685.9797 - val_loss: 17.8217 - val_mse: 725.0182\n",
      "Epoch 2066/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6690 - mse: 702.9106 - val_loss: 17.6043 - val_mse: 696.5579\n",
      "Epoch 2067/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3521 - mse: 674.3111 - val_loss: 18.2871 - val_mse: 691.1877\n",
      "Epoch 2068/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1774 - mse: 721.3386 - val_loss: 18.1868 - val_mse: 692.1209\n",
      "Epoch 2069/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4024 - mse: 675.6722 - val_loss: 18.4457 - val_mse: 682.9478\n",
      "Epoch 2070/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7040 - mse: 691.8055 - val_loss: 17.6322 - val_mse: 706.5905\n",
      "Epoch 2071/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4087 - mse: 674.6119 - val_loss: 18.8344 - val_mse: 804.0098\n",
      "Epoch 2072/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8616 - mse: 701.6508 - val_loss: 17.6798 - val_mse: 729.6049\n",
      "Epoch 2073/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5694 - mse: 686.8919 - val_loss: 18.0244 - val_mse: 770.8969\n",
      "Epoch 2074/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3832 - mse: 679.0397 - val_loss: 17.7152 - val_mse: 717.6072\n",
      "Epoch 2075/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5743 - mse: 686.7756 - val_loss: 18.0399 - val_mse: 751.9935\n",
      "Epoch 2076/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.7907 - mse: 711.2129 - val_loss: 17.9921 - val_mse: 675.0939\n",
      "Epoch 2077/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8988 - mse: 694.5762 - val_loss: 17.9300 - val_mse: 760.3889\n",
      "Epoch 2078/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7505 - mse: 698.0217 - val_loss: 17.7024 - val_mse: 689.4420\n",
      "Epoch 2079/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0156 - mse: 719.7763 - val_loss: 18.0188 - val_mse: 685.7360\n",
      "Epoch 2080/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5924 - mse: 687.2623 - val_loss: 21.1383 - val_mse: 1041.3832\n",
      "Epoch 2081/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9489 - mse: 766.5859 - val_loss: 18.4342 - val_mse: 756.7192\n",
      "Epoch 2082/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.6972 - mse: 692.5242 - val_loss: 18.4099 - val_mse: 758.1227\n",
      "Epoch 2083/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0040 - mse: 716.2520 - val_loss: 17.8973 - val_mse: 745.9313\n",
      "Epoch 2084/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.9524 - mse: 705.8528 - val_loss: 17.7981 - val_mse: 721.1102\n",
      "Epoch 2085/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.6759 - mse: 697.7974 - val_loss: 18.9095 - val_mse: 839.1985\n",
      "Epoch 2086/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0705 - mse: 723.4671 - val_loss: 18.5062 - val_mse: 746.9608\n",
      "Epoch 2087/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8841 - mse: 712.5632 - val_loss: 18.3254 - val_mse: 694.2960\n",
      "Epoch 2088/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5924 - mse: 685.4232 - val_loss: 18.6352 - val_mse: 808.7911\n",
      "Epoch 2089/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8200 - mse: 713.5885 - val_loss: 17.9766 - val_mse: 711.3886\n",
      "Epoch 2090/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2183 - mse: 731.7960 - val_loss: 18.1840 - val_mse: 771.1016\n",
      "Epoch 2091/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7747 - mse: 705.4156 - val_loss: 18.8324 - val_mse: 829.9098\n",
      "Epoch 2092/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.5670 - mse: 686.4297 - val_loss: 18.2340 - val_mse: 789.3981\n",
      "Epoch 2093/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.4685 - mse: 694.9708 - val_loss: 18.7161 - val_mse: 812.9890\n",
      "Epoch 2094/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9211 - mse: 715.6879 - val_loss: 18.1200 - val_mse: 729.0093\n",
      "Epoch 2095/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5282 - mse: 685.8892 - val_loss: 17.7903 - val_mse: 717.7927\n",
      "Epoch 2096/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.3863 - mse: 675.4575 - val_loss: 19.0740 - val_mse: 849.8752\n",
      "Epoch 2097/5000\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 17.9143 - mse: 708.5341 - val_loss: 19.1134 - val_mse: 857.9090\n",
      "Epoch 2098/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.4171 - mse: 821.6672 - val_loss: 19.0109 - val_mse: 807.8472\n",
      "Epoch 2099/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.4982 - mse: 734.3603 - val_loss: 18.0095 - val_mse: 755.7020\n",
      "Epoch 2100/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.6833 - mse: 693.2200 - val_loss: 18.6595 - val_mse: 796.7073\n",
      "Epoch 2101/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.9519 - mse: 736.4369 - val_loss: 18.9879 - val_mse: 710.1858\n",
      "Epoch 2102/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.9779 - mse: 712.8033 - val_loss: 18.1556 - val_mse: 776.2986\n",
      "Epoch 2103/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4634 - mse: 680.5426 - val_loss: 17.7927 - val_mse: 705.4016\n",
      "Epoch 2104/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.8189 - mse: 705.1659 - val_loss: 18.2212 - val_mse: 711.7374\n",
      "Epoch 2105/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.3593 - mse: 737.5666 - val_loss: 18.4754 - val_mse: 812.9929\n",
      "Epoch 2106/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6724 - mse: 689.9460 - val_loss: 17.6480 - val_mse: 731.8662\n",
      "Epoch 2107/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5506 - mse: 685.9892 - val_loss: 17.8623 - val_mse: 747.0541\n",
      "Epoch 2108/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.6748 - mse: 703.4086 - val_loss: 19.0133 - val_mse: 745.0952\n",
      "Epoch 2109/5000\n",
      "36/36 [==============================] - 927s 26s/step - loss: 18.0625 - mse: 711.1976 - val_loss: 17.8928 - val_mse: 689.6614\n",
      "Epoch 2110/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7051 - mse: 702.4422 - val_loss: 18.2686 - val_mse: 704.6934\n",
      "Epoch 2111/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8165 - mse: 702.6695 - val_loss: 19.3150 - val_mse: 827.5254\n",
      "Epoch 2112/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4225 - mse: 752.1766 - val_loss: 18.6536 - val_mse: 823.4628\n",
      "Epoch 2113/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5299 - mse: 746.8303 - val_loss: 19.3648 - val_mse: 726.3993\n",
      "Epoch 2114/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1306 - mse: 719.4516 - val_loss: 18.1632 - val_mse: 787.3796\n",
      "Epoch 2115/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4467 - mse: 685.6385 - val_loss: 17.8733 - val_mse: 682.3588\n",
      "Epoch 2116/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4581 - mse: 683.9587 - val_loss: 17.7625 - val_mse: 731.5995\n",
      "Epoch 2117/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5962 - mse: 689.1343 - val_loss: 18.6388 - val_mse: 762.3333\n",
      "Epoch 2118/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2331 - mse: 734.5598 - val_loss: 17.8415 - val_mse: 697.5440\n",
      "Epoch 2119/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7565 - mse: 701.8091 - val_loss: 17.8079 - val_mse: 697.5414\n",
      "Epoch 2120/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4073 - mse: 683.8571 - val_loss: 17.8381 - val_mse: 743.3334\n",
      "Epoch 2121/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3602 - mse: 676.0248 - val_loss: 17.7058 - val_mse: 691.6621\n",
      "Epoch 2122/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7558 - mse: 698.5029 - val_loss: 18.3229 - val_mse: 737.3137\n",
      "Epoch 2123/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2964 - mse: 732.5969 - val_loss: 19.6944 - val_mse: 899.8080\n",
      "Epoch 2124/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6166 - mse: 698.9487 - val_loss: 18.0798 - val_mse: 691.0853\n",
      "Epoch 2125/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5997 - mse: 684.8047 - val_loss: 17.8995 - val_mse: 758.3755\n",
      "Epoch 2126/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.2787 - mse: 668.4324 - val_loss: 17.7472 - val_mse: 697.7935\n",
      "Epoch 2127/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3698 - mse: 683.5453 - val_loss: 17.6186 - val_mse: 679.9664\n",
      "Epoch 2128/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5249 - mse: 685.4443 - val_loss: 18.1261 - val_mse: 693.8967\n",
      "Epoch 2129/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4768 - mse: 674.0853 - val_loss: 18.5069 - val_mse: 731.8885\n",
      "Epoch 2130/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4478 - mse: 683.6418 - val_loss: 17.7842 - val_mse: 729.2171\n",
      "Epoch 2131/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.4402 - mse: 679.3662 - val_loss: 18.3322 - val_mse: 677.1296\n",
      "Epoch 2132/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4325 - mse: 681.3911 - val_loss: 17.5984 - val_mse: 690.5078\n",
      "Epoch 2133/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3079 - mse: 673.3411 - val_loss: 17.8838 - val_mse: 745.3455\n",
      "Epoch 2134/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6893 - mse: 707.5806 - val_loss: 17.8733 - val_mse: 700.2462\n",
      "Epoch 2135/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5751 - mse: 691.4752 - val_loss: 17.7910 - val_mse: 678.1158\n",
      "Epoch 2136/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5715 - mse: 694.9164 - val_loss: 17.8589 - val_mse: 715.7119\n",
      "Epoch 2137/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.5100 - mse: 685.7826 - val_loss: 18.5457 - val_mse: 793.0165\n",
      "Epoch 2138/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2313 - mse: 729.3862 - val_loss: 18.0289 - val_mse: 707.0383\n",
      "Epoch 2139/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8936 - mse: 706.9576 - val_loss: 18.0917 - val_mse: 717.0759\n",
      "Epoch 2140/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9346 - mse: 709.8381 - val_loss: 18.1320 - val_mse: 746.7391\n",
      "Epoch 2141/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5381 - mse: 750.6497 - val_loss: 18.2643 - val_mse: 774.0724\n",
      "Epoch 2142/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5639 - mse: 692.6393 - val_loss: 17.8540 - val_mse: 696.6164\n",
      "Epoch 2143/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3171 - mse: 675.4079 - val_loss: 18.1532 - val_mse: 699.0996\n",
      "Epoch 2144/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5212 - mse: 678.0930 - val_loss: 18.2448 - val_mse: 744.8539\n",
      "Epoch 2145/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6497 - mse: 693.7327 - val_loss: 17.9790 - val_mse: 674.0323\n",
      "Epoch 2146/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5401 - mse: 684.9019 - val_loss: 18.0363 - val_mse: 703.8265\n",
      "Epoch 2147/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8713 - mse: 704.6564 - val_loss: 17.9173 - val_mse: 695.0739\n",
      "Epoch 2148/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4888 - mse: 675.6146 - val_loss: 17.5994 - val_mse: 681.6470\n",
      "Epoch 2149/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4674 - mse: 677.8666 - val_loss: 17.6978 - val_mse: 698.6646\n",
      "Epoch 2150/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6350 - mse: 681.7858 - val_loss: 19.3349 - val_mse: 771.0657\n",
      "Epoch 2151/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7949 - mse: 765.4714 - val_loss: 18.4416 - val_mse: 801.7701\n",
      "Epoch 2152/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5948 - mse: 694.5445 - val_loss: 17.7316 - val_mse: 696.7665\n",
      "Epoch 2153/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3993 - mse: 676.0740 - val_loss: 17.7011 - val_mse: 700.4769\n",
      "Epoch 2154/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3365 - mse: 673.2245 - val_loss: 17.8388 - val_mse: 748.3852\n",
      "Epoch 2155/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.0016 - mse: 714.0232 - val_loss: 17.8820 - val_mse: 742.7481\n",
      "Epoch 2156/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.3389 - mse: 672.9502 - val_loss: 17.7291 - val_mse: 680.7377\n",
      "Epoch 2157/5000\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 17.5555 - mse: 687.5138 - val_loss: 18.9958 - val_mse: 857.7960\n",
      "Epoch 2158/5000\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 18.0792 - mse: 724.6209 - val_loss: 18.4144 - val_mse: 805.3419\n",
      "Epoch 2159/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.9668 - mse: 717.7226 - val_loss: 18.8452 - val_mse: 830.9070\n",
      "Epoch 2160/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.8643 - mse: 708.9930 - val_loss: 17.9151 - val_mse: 742.6066\n",
      "Epoch 2161/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.6422 - mse: 692.5252 - val_loss: 17.9447 - val_mse: 705.6058\n",
      "Epoch 2162/5000\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 17.4489 - mse: 685.4014 - val_loss: 18.0871 - val_mse: 713.2548\n",
      "Epoch 2163/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.7993 - mse: 706.1460 - val_loss: 17.7408 - val_mse: 728.1089\n",
      "Epoch 2164/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.4350 - mse: 678.3848 - val_loss: 20.0857 - val_mse: 898.5198\n",
      "Epoch 2165/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.6623 - mse: 692.6750 - val_loss: 17.9009 - val_mse: 727.9113\n",
      "Epoch 2166/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.1852 - mse: 725.2723 - val_loss: 18.1396 - val_mse: 717.6793\n",
      "Epoch 2167/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.6776 - mse: 690.0214 - val_loss: 19.0943 - val_mse: 845.7069\n",
      "Epoch 2168/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 19.2892 - mse: 807.4855 - val_loss: 18.5755 - val_mse: 785.2571\n",
      "Epoch 2169/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.1643 - mse: 724.3256 - val_loss: 18.7801 - val_mse: 830.5915\n",
      "Epoch 2170/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.8849 - mse: 712.3605 - val_loss: 19.4084 - val_mse: 876.4213\n",
      "Epoch 2171/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.3728 - mse: 739.8359 - val_loss: 18.4238 - val_mse: 690.3060\n",
      "Epoch 2172/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8446 - mse: 703.9987 - val_loss: 17.9362 - val_mse: 739.6681\n",
      "Epoch 2173/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.4822 - mse: 675.6222 - val_loss: 17.6778 - val_mse: 721.9924\n",
      "Epoch 2174/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.2792 - mse: 670.0471 - val_loss: 17.9939 - val_mse: 733.5735\n",
      "Epoch 2175/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.6893 - mse: 699.9282 - val_loss: 17.7905 - val_mse: 711.7590\n",
      "Epoch 2176/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.9129 - mse: 714.9911 - val_loss: 19.6219 - val_mse: 822.9106\n",
      "Epoch 2177/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.1755 - mse: 719.5963 - val_loss: 18.0708 - val_mse: 774.5719\n",
      "Epoch 2178/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.7759 - mse: 700.9291 - val_loss: 18.1627 - val_mse: 715.6994\n",
      "Epoch 2179/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.6371 - mse: 692.7566 - val_loss: 18.7161 - val_mse: 830.0063\n",
      "Epoch 2180/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.1027 - mse: 719.8245 - val_loss: 17.8785 - val_mse: 694.3317\n",
      "Epoch 2181/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3768 - mse: 674.4039 - val_loss: 18.0844 - val_mse: 701.3345\n",
      "Epoch 2182/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5552 - mse: 679.6573 - val_loss: 17.8750 - val_mse: 733.2745\n",
      "Epoch 2183/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.4071 - mse: 682.7264 - val_loss: 17.7057 - val_mse: 686.1481\n",
      "Epoch 2184/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.4843 - mse: 683.8079 - val_loss: 17.7544 - val_mse: 698.6599\n",
      "Epoch 2185/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3243 - mse: 742.6768 - val_loss: 17.9283 - val_mse: 723.0665\n",
      "Epoch 2186/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6130 - mse: 692.6851 - val_loss: 18.8655 - val_mse: 707.6346\n",
      "Epoch 2187/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7720 - mse: 693.2134 - val_loss: 17.7567 - val_mse: 711.1425\n",
      "Epoch 2188/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7520 - mse: 762.5591 - val_loss: 18.2764 - val_mse: 755.9991\n",
      "Epoch 2189/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.2327 - mse: 729.8391 - val_loss: 18.2870 - val_mse: 726.8986\n",
      "Epoch 2190/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1884 - mse: 727.3557 - val_loss: 18.1959 - val_mse: 692.6533\n",
      "Epoch 2191/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9655 - mse: 713.5771 - val_loss: 17.9129 - val_mse: 692.0444\n",
      "Epoch 2192/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8634 - mse: 708.6589 - val_loss: 18.6983 - val_mse: 825.9550\n",
      "Epoch 2193/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4234 - mse: 740.1752 - val_loss: 18.0143 - val_mse: 761.0868\n",
      "Epoch 2194/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8313 - mse: 705.7362 - val_loss: 17.7738 - val_mse: 714.7633\n",
      "Epoch 2195/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9933 - mse: 713.8924 - val_loss: 20.2869 - val_mse: 802.6655\n",
      "Epoch 2196/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3737 - mse: 740.7816 - val_loss: 17.8400 - val_mse: 719.3998\n",
      "Epoch 2197/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4483 - mse: 677.7921 - val_loss: 17.9983 - val_mse: 689.7343\n",
      "Epoch 2198/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5399 - mse: 691.9353 - val_loss: 18.1733 - val_mse: 687.9290\n",
      "Epoch 2199/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6399 - mse: 689.2502 - val_loss: 18.9915 - val_mse: 700.0992\n",
      "Epoch 2200/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7522 - mse: 687.8088 - val_loss: 18.1119 - val_mse: 770.1417\n",
      "Epoch 2201/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7441 - mse: 707.2053 - val_loss: 17.9470 - val_mse: 707.1548\n",
      "Epoch 2202/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4349 - mse: 677.8895 - val_loss: 18.2878 - val_mse: 710.3887\n",
      "Epoch 2203/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4450 - mse: 673.2469 - val_loss: 17.9420 - val_mse: 717.5927\n",
      "Epoch 2204/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9860 - mse: 713.5611 - val_loss: 18.1493 - val_mse: 702.9482\n",
      "Epoch 2205/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5725 - mse: 679.1417 - val_loss: 18.0392 - val_mse: 767.5425\n",
      "Epoch 2206/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1766 - mse: 666.5312 - val_loss: 18.3981 - val_mse: 777.5045\n",
      "Epoch 2207/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8114 - mse: 704.6442 - val_loss: 19.4614 - val_mse: 856.4533\n",
      "Epoch 2208/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4771 - mse: 740.7798 - val_loss: 18.6195 - val_mse: 703.9074\n",
      "Epoch 2209/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1734 - mse: 727.2476 - val_loss: 19.2017 - val_mse: 850.8713\n",
      "Epoch 2210/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0656 - mse: 715.4496 - val_loss: 18.9665 - val_mse: 796.0598\n",
      "Epoch 2211/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8347 - mse: 709.6542 - val_loss: 18.1691 - val_mse: 784.8848\n",
      "Epoch 2212/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3963 - mse: 675.6400 - val_loss: 17.9990 - val_mse: 688.6539\n",
      "Epoch 2213/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3240 - mse: 731.3250 - val_loss: 19.1930 - val_mse: 723.7665\n",
      "Epoch 2214/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4995 - mse: 742.6636 - val_loss: 18.0374 - val_mse: 723.2687\n",
      "Epoch 2215/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7093 - mse: 695.6443 - val_loss: 18.3669 - val_mse: 787.9663\n",
      "Epoch 2216/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1233 - mse: 720.3480 - val_loss: 17.9855 - val_mse: 705.7997\n",
      "Epoch 2217/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.5182 - mse: 682.3229 - val_loss: 17.6196 - val_mse: 692.6906\n",
      "Epoch 2218/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4212 - mse: 682.5467 - val_loss: 17.8243 - val_mse: 733.1282\n",
      "Epoch 2219/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4016 - mse: 676.0142 - val_loss: 17.9511 - val_mse: 687.1027\n",
      "Epoch 2220/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6037 - mse: 690.2904 - val_loss: 17.6631 - val_mse: 710.6887\n",
      "Epoch 2221/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5189 - mse: 693.2721 - val_loss: 18.1513 - val_mse: 706.7083\n",
      "Epoch 2222/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.5796 - mse: 685.3014 - val_loss: 17.7026 - val_mse: 682.7095\n",
      "Epoch 2223/5000\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 17.3595 - mse: 677.6299 - val_loss: 17.6800 - val_mse: 698.4066\n",
      "Epoch 2224/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.8449 - mse: 699.8845 - val_loss: 19.5992 - val_mse: 819.4006\n",
      "Epoch 2225/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.4011 - mse: 802.3710 - val_loss: 18.4184 - val_mse: 759.9987\n",
      "Epoch 2226/5000\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 17.8039 - mse: 699.5097 - val_loss: 18.3350 - val_mse: 772.2525\n",
      "Epoch 2227/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.5693 - mse: 688.5496 - val_loss: 17.6827 - val_mse: 708.4133\n",
      "Epoch 2228/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.6753 - mse: 695.3780 - val_loss: 19.7159 - val_mse: 885.9905\n",
      "Epoch 2229/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0223 - mse: 714.9564 - val_loss: 18.7610 - val_mse: 839.6973\n",
      "Epoch 2230/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.0413 - mse: 716.8151 - val_loss: 18.4341 - val_mse: 790.6592\n",
      "Epoch 2231/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2031 - mse: 737.8076 - val_loss: 17.7512 - val_mse: 694.0101\n",
      "Epoch 2232/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.5683 - mse: 684.4791 - val_loss: 18.5253 - val_mse: 759.5614\n",
      "Epoch 2233/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6958 - mse: 698.5666 - val_loss: 17.8621 - val_mse: 705.5524\n",
      "Epoch 2234/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.5136 - mse: 687.4431 - val_loss: 19.1803 - val_mse: 714.6254\n",
      "Epoch 2235/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.2626 - mse: 730.3811 - val_loss: 18.1769 - val_mse: 699.0268\n",
      "Epoch 2236/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8474 - mse: 769.0112 - val_loss: 17.9635 - val_mse: 716.7646\n",
      "Epoch 2237/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6890 - mse: 696.8491 - val_loss: 17.9328 - val_mse: 686.2989\n",
      "Epoch 2238/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4584 - mse: 681.1758 - val_loss: 18.6802 - val_mse: 811.7682\n",
      "Epoch 2239/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.7804 - mse: 750.0267 - val_loss: 20.8840 - val_mse: 981.3729\n",
      "Epoch 2240/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.3821 - mse: 814.0255 - val_loss: 18.9190 - val_mse: 771.4925\n",
      "Epoch 2241/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.6169 - mse: 767.0014 - val_loss: 18.4853 - val_mse: 762.4862\n",
      "Epoch 2242/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6512 - mse: 693.5052 - val_loss: 17.8686 - val_mse: 682.1886\n",
      "Epoch 2243/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5281 - mse: 681.1763 - val_loss: 18.0276 - val_mse: 697.6629\n",
      "Epoch 2244/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3421 - mse: 672.7636 - val_loss: 18.7698 - val_mse: 693.2389\n",
      "Epoch 2245/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5510 - mse: 689.3256 - val_loss: 18.3860 - val_mse: 687.0590\n",
      "Epoch 2246/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6236 - mse: 696.0957 - val_loss: 17.8358 - val_mse: 720.0267\n",
      "Epoch 2247/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8420 - mse: 702.8469 - val_loss: 18.1051 - val_mse: 701.7043\n",
      "Epoch 2248/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8779 - mse: 716.9389 - val_loss: 18.0584 - val_mse: 691.8221\n",
      "Epoch 2249/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3871 - mse: 683.7124 - val_loss: 18.2549 - val_mse: 680.0266\n",
      "Epoch 2250/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3449 - mse: 675.2698 - val_loss: 18.1623 - val_mse: 736.4729\n",
      "Epoch 2251/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4658 - mse: 687.5635 - val_loss: 18.0865 - val_mse: 685.8332\n",
      "Epoch 2252/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5549 - mse: 692.6443 - val_loss: 18.7340 - val_mse: 697.6743\n",
      "Epoch 2253/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7074 - mse: 694.0874 - val_loss: 18.5296 - val_mse: 812.2541\n",
      "Epoch 2254/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4599 - mse: 683.8577 - val_loss: 17.9189 - val_mse: 692.8973\n",
      "Epoch 2255/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4986 - mse: 685.3845 - val_loss: 17.8197 - val_mse: 711.6695\n",
      "Epoch 2256/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6701 - mse: 697.3486 - val_loss: 17.8798 - val_mse: 703.9558\n",
      "Epoch 2257/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5877 - mse: 680.0735 - val_loss: 18.1729 - val_mse: 786.1111\n",
      "Epoch 2258/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7119 - mse: 705.8610 - val_loss: 18.0228 - val_mse: 753.1802\n",
      "Epoch 2259/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6459 - mse: 690.6304 - val_loss: 17.7510 - val_mse: 730.8362\n",
      "Epoch 2260/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.9075 - mse: 773.1998 - val_loss: 20.1183 - val_mse: 960.0573\n",
      "Epoch 2261/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1596 - mse: 738.6368 - val_loss: 17.8368 - val_mse: 729.5051\n",
      "Epoch 2262/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0271 - mse: 720.4792 - val_loss: 17.8878 - val_mse: 708.3362\n",
      "Epoch 2263/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4465 - mse: 679.0947 - val_loss: 17.7789 - val_mse: 735.0051\n",
      "Epoch 2264/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3880 - mse: 683.8012 - val_loss: 17.6640 - val_mse: 711.4500\n",
      "Epoch 2265/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2783 - mse: 675.3589 - val_loss: 17.8654 - val_mse: 721.0989\n",
      "Epoch 2266/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9698 - mse: 714.3776 - val_loss: 19.2695 - val_mse: 709.7269\n",
      "Epoch 2267/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9901 - mse: 705.1475 - val_loss: 17.7342 - val_mse: 729.5455\n",
      "Epoch 2268/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7037 - mse: 689.8356 - val_loss: 19.4922 - val_mse: 713.6428\n",
      "Epoch 2269/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7715 - mse: 697.7077 - val_loss: 18.0293 - val_mse: 756.2850\n",
      "Epoch 2270/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4929 - mse: 683.0590 - val_loss: 19.3028 - val_mse: 848.9719\n",
      "Epoch 2271/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1049 - mse: 717.8915 - val_loss: 17.9980 - val_mse: 738.9318\n",
      "Epoch 2272/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.2294 - mse: 674.0232 - val_loss: 17.7236 - val_mse: 711.7007\n",
      "Epoch 2273/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7623 - mse: 693.3035 - val_loss: 18.2041 - val_mse: 735.9824\n",
      "Epoch 2274/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7677 - mse: 710.1663 - val_loss: 18.0839 - val_mse: 708.3494\n",
      "Epoch 2275/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6098 - mse: 694.4029 - val_loss: 18.5475 - val_mse: 698.3630\n",
      "Epoch 2276/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6542 - mse: 690.0288 - val_loss: 17.8027 - val_mse: 746.5644\n",
      "Epoch 2277/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3855 - mse: 681.1810 - val_loss: 17.8456 - val_mse: 699.3693\n",
      "Epoch 2278/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.2824 - mse: 678.3226 - val_loss: 18.4878 - val_mse: 769.6412\n",
      "Epoch 2279/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.5333 - mse: 683.7364 - val_loss: 18.0534 - val_mse: 756.0791\n",
      "Epoch 2280/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7502 - mse: 697.5110 - val_loss: 20.5904 - val_mse: 966.3174\n",
      "Epoch 2281/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8575 - mse: 776.5202 - val_loss: 18.8223 - val_mse: 701.4341\n",
      "Epoch 2282/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6126 - mse: 689.7402 - val_loss: 18.6813 - val_mse: 682.6832\n",
      "Epoch 2283/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7185 - mse: 692.2466 - val_loss: 17.8410 - val_mse: 708.7250\n",
      "Epoch 2284/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8666 - mse: 698.9631 - val_loss: 17.8958 - val_mse: 739.5786\n",
      "Epoch 2285/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5786 - mse: 701.3356 - val_loss: 18.9962 - val_mse: 845.2875\n",
      "Epoch 2286/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8563 - mse: 700.3717 - val_loss: 18.7901 - val_mse: 699.7121\n",
      "Epoch 2287/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4167 - mse: 728.5444 - val_loss: 19.5503 - val_mse: 909.6185\n",
      "Epoch 2288/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8390 - mse: 708.2745 - val_loss: 19.6202 - val_mse: 889.8170\n",
      "Epoch 2289/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1692 - mse: 721.1450 - val_loss: 18.0967 - val_mse: 750.0053\n",
      "Epoch 2290/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1110 - mse: 731.6017 - val_loss: 17.8873 - val_mse: 714.7379\n",
      "Epoch 2291/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7290 - mse: 700.1683 - val_loss: 17.9844 - val_mse: 711.9010\n",
      "Epoch 2292/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7550 - mse: 694.3992 - val_loss: 17.8269 - val_mse: 752.9438\n",
      "Epoch 2293/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3070 - mse: 676.2081 - val_loss: 17.6043 - val_mse: 710.8916\n",
      "Epoch 2294/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5707 - mse: 683.6394 - val_loss: 18.5290 - val_mse: 769.8809\n",
      "Epoch 2295/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5510 - mse: 752.5110 - val_loss: 18.2182 - val_mse: 769.7104\n",
      "Epoch 2296/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7256 - mse: 700.7554 - val_loss: 17.7345 - val_mse: 698.7627\n",
      "Epoch 2297/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4899 - mse: 688.3367 - val_loss: 17.7094 - val_mse: 689.3953\n",
      "Epoch 2298/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2340 - mse: 661.9360 - val_loss: 17.9866 - val_mse: 736.3373\n",
      "Epoch 2299/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8088 - mse: 708.4463 - val_loss: 18.1404 - val_mse: 692.9464\n",
      "Epoch 2300/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3582 - mse: 732.8008 - val_loss: 18.2198 - val_mse: 800.3442\n",
      "Epoch 2301/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8707 - mse: 705.0443 - val_loss: 17.8660 - val_mse: 721.8798\n",
      "Epoch 2302/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1485 - mse: 663.2003 - val_loss: 17.6433 - val_mse: 696.4449\n",
      "Epoch 2303/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5937 - mse: 692.4955 - val_loss: 17.5847 - val_mse: 713.8135\n",
      "Epoch 2304/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4828 - mse: 682.2498 - val_loss: 17.7905 - val_mse: 734.9734\n",
      "Epoch 2305/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2968 - mse: 671.1013 - val_loss: 17.7312 - val_mse: 706.2461\n",
      "Epoch 2306/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4848 - mse: 683.3289 - val_loss: 18.2215 - val_mse: 680.9888\n",
      "Epoch 2307/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5504 - mse: 678.3934 - val_loss: 17.7811 - val_mse: 720.4592\n",
      "Epoch 2308/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6439 - mse: 697.4470 - val_loss: 17.8449 - val_mse: 725.5962\n",
      "Epoch 2309/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2194 - mse: 672.5601 - val_loss: 17.7095 - val_mse: 689.9379\n",
      "Epoch 2310/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4447 - mse: 685.9874 - val_loss: 17.6766 - val_mse: 711.5378\n",
      "Epoch 2311/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.1850 - mse: 662.3218 - val_loss: 18.7609 - val_mse: 829.8613\n",
      "Epoch 2312/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4938 - mse: 691.7449 - val_loss: 17.7652 - val_mse: 699.1802\n",
      "Epoch 2313/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5831 - mse: 689.8768 - val_loss: 18.0966 - val_mse: 684.3836\n",
      "Epoch 2314/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3345 - mse: 673.0480 - val_loss: 17.6352 - val_mse: 698.3052\n",
      "Epoch 2315/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2068 - mse: 666.7379 - val_loss: 18.0212 - val_mse: 758.0430\n",
      "Epoch 2316/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1202 - mse: 664.6205 - val_loss: 17.8973 - val_mse: 692.1068\n",
      "Epoch 2317/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7852 - mse: 702.6745 - val_loss: 18.0493 - val_mse: 731.8132\n",
      "Epoch 2318/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7916 - mse: 703.2881 - val_loss: 19.4302 - val_mse: 720.9279\n",
      "Epoch 2319/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6933 - mse: 697.4313 - val_loss: 17.8091 - val_mse: 710.7224\n",
      "Epoch 2320/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8815 - mse: 702.5312 - val_loss: 18.3901 - val_mse: 790.5242\n",
      "Epoch 2321/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4869 - mse: 683.1012 - val_loss: 18.0493 - val_mse: 738.4944\n",
      "Epoch 2322/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2077 - mse: 661.9033 - val_loss: 18.3134 - val_mse: 690.7109\n",
      "Epoch 2323/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.2098 - mse: 669.7141 - val_loss: 18.2714 - val_mse: 743.9819\n",
      "Epoch 2324/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6458 - mse: 701.0167 - val_loss: 17.9460 - val_mse: 682.8924\n",
      "Epoch 2325/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4727 - mse: 682.9532 - val_loss: 18.6482 - val_mse: 777.9863\n",
      "Epoch 2326/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2969 - mse: 667.7727 - val_loss: 17.7949 - val_mse: 709.3943\n",
      "Epoch 2327/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5750 - mse: 687.1245 - val_loss: 17.9881 - val_mse: 758.8671\n",
      "Epoch 2328/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7665 - mse: 703.3954 - val_loss: 18.0378 - val_mse: 682.7507\n",
      "Epoch 2329/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3746 - mse: 677.1142 - val_loss: 18.5644 - val_mse: 686.5154\n",
      "Epoch 2330/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4972 - mse: 678.7663 - val_loss: 17.6571 - val_mse: 704.8930\n",
      "Epoch 2331/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2800 - mse: 671.4176 - val_loss: 17.9523 - val_mse: 713.4656\n",
      "Epoch 2332/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3898 - mse: 678.2517 - val_loss: 17.8319 - val_mse: 752.1492\n",
      "Epoch 2333/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2482 - mse: 670.0543 - val_loss: 17.9735 - val_mse: 684.2343\n",
      "Epoch 2334/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2732 - mse: 673.9373 - val_loss: 18.1184 - val_mse: 696.5044\n",
      "Epoch 2335/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2309 - mse: 667.0585 - val_loss: 17.8425 - val_mse: 717.8793\n",
      "Epoch 2336/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5975 - mse: 701.4401 - val_loss: 17.9611 - val_mse: 722.2744\n",
      "Epoch 2337/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4381 - mse: 683.4119 - val_loss: 17.8761 - val_mse: 684.3718\n",
      "Epoch 2338/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.2885 - mse: 658.8943 - val_loss: 18.2852 - val_mse: 780.2684\n",
      "Epoch 2339/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.1669 - mse: 668.7104 - val_loss: 17.5418 - val_mse: 690.4515\n",
      "Epoch 2340/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9963 - mse: 724.6299 - val_loss: 18.7074 - val_mse: 754.3594\n",
      "Epoch 2341/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3390 - mse: 730.6785 - val_loss: 18.0176 - val_mse: 698.1788\n",
      "Epoch 2342/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3663 - mse: 739.7729 - val_loss: 19.1966 - val_mse: 873.4325\n",
      "Epoch 2343/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.1454 - mse: 665.7840 - val_loss: 18.3093 - val_mse: 716.4648\n",
      "Epoch 2344/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4386 - mse: 678.9922 - val_loss: 18.1487 - val_mse: 740.4418\n",
      "Epoch 2345/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3489 - mse: 683.1713 - val_loss: 17.8765 - val_mse: 696.6575\n",
      "Epoch 2346/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4265 - mse: 673.6943 - val_loss: 17.5020 - val_mse: 717.0642\n",
      "Epoch 2347/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.2178 - mse: 671.2580 - val_loss: 18.6972 - val_mse: 687.4366\n",
      "Epoch 2348/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.5766 - mse: 682.4824 - val_loss: 17.7936 - val_mse: 690.0240\n",
      "Epoch 2349/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4656 - mse: 677.8770 - val_loss: 18.2745 - val_mse: 709.5190\n",
      "Epoch 2350/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0683 - mse: 721.9943 - val_loss: 18.0270 - val_mse: 762.5788\n",
      "Epoch 2351/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.6813 - mse: 707.5273 - val_loss: 18.0335 - val_mse: 758.9265\n",
      "Epoch 2352/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.1227 - mse: 670.1346 - val_loss: 18.5805 - val_mse: 709.3240\n",
      "Epoch 2353/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8439 - mse: 698.2357 - val_loss: 18.6089 - val_mse: 812.5896\n",
      "Epoch 2354/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0571 - mse: 717.8585 - val_loss: 17.8981 - val_mse: 715.7131\n",
      "Epoch 2355/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4478 - mse: 766.2866 - val_loss: 19.5196 - val_mse: 694.4611\n",
      "Epoch 2356/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8442 - mse: 704.0981 - val_loss: 17.8373 - val_mse: 698.4069\n",
      "Epoch 2357/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3624 - mse: 676.4024 - val_loss: 17.9183 - val_mse: 706.4716\n",
      "Epoch 2358/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9060 - mse: 707.5583 - val_loss: 18.1623 - val_mse: 778.7401\n",
      "Epoch 2359/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7274 - mse: 699.0895 - val_loss: 18.2790 - val_mse: 748.2889\n",
      "Epoch 2360/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5233 - mse: 688.5923 - val_loss: 17.8025 - val_mse: 712.5569\n",
      "Epoch 2361/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2777 - mse: 668.3565 - val_loss: 18.8244 - val_mse: 751.9966\n",
      "Epoch 2362/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9881 - mse: 719.1499 - val_loss: 18.2207 - val_mse: 693.3232\n",
      "Epoch 2363/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2700 - mse: 725.8132 - val_loss: 18.0192 - val_mse: 709.1487\n",
      "Epoch 2364/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4156 - mse: 682.5516 - val_loss: 17.7423 - val_mse: 735.3864\n",
      "Epoch 2365/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.2827 - mse: 669.7072 - val_loss: 17.9747 - val_mse: 750.9361\n",
      "Epoch 2366/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3632 - mse: 678.9901 - val_loss: 18.0007 - val_mse: 713.9504\n",
      "Epoch 2367/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8610 - mse: 716.7596 - val_loss: 17.7180 - val_mse: 686.7004\n",
      "Epoch 2368/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3103 - mse: 677.7497 - val_loss: 17.6881 - val_mse: 704.7999\n",
      "Epoch 2369/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8436 - mse: 699.8496 - val_loss: 17.9750 - val_mse: 699.3928\n",
      "Epoch 2370/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6655 - mse: 693.3436 - val_loss: 17.6150 - val_mse: 681.6547\n",
      "Epoch 2371/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2245 - mse: 673.1861 - val_loss: 18.0069 - val_mse: 690.6779\n",
      "Epoch 2372/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6663 - mse: 690.0773 - val_loss: 19.7032 - val_mse: 897.6425\n",
      "Epoch 2373/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6972 - mse: 703.4777 - val_loss: 17.7436 - val_mse: 731.6685\n",
      "Epoch 2374/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1675 - mse: 657.3678 - val_loss: 17.8290 - val_mse: 728.3573\n",
      "Epoch 2375/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4906 - mse: 678.2689 - val_loss: 19.8462 - val_mse: 902.0306\n",
      "Epoch 2376/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8897 - mse: 714.0533 - val_loss: 17.7725 - val_mse: 702.8419\n",
      "Epoch 2377/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.1229 - mse: 665.1829 - val_loss: 18.4961 - val_mse: 787.9021\n",
      "Epoch 2378/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3976 - mse: 691.7658 - val_loss: 19.5118 - val_mse: 724.7892\n",
      "Epoch 2379/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2662 - mse: 729.7719 - val_loss: 18.1623 - val_mse: 754.0240\n",
      "Epoch 2380/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4328 - mse: 746.3159 - val_loss: 19.8184 - val_mse: 731.8580\n",
      "Epoch 2381/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.2833 - mse: 800.5182 - val_loss: 18.8045 - val_mse: 744.4102\n",
      "Epoch 2382/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1124 - mse: 725.4028 - val_loss: 18.8660 - val_mse: 847.4490\n",
      "Epoch 2383/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3358 - mse: 684.3784 - val_loss: 17.6950 - val_mse: 727.2816\n",
      "Epoch 2384/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3433 - mse: 671.6647 - val_loss: 17.6946 - val_mse: 708.3458\n",
      "Epoch 2385/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0737 - mse: 709.3146 - val_loss: 17.6824 - val_mse: 692.5698\n",
      "Epoch 2386/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9483 - mse: 728.7214 - val_loss: 17.9737 - val_mse: 717.4783\n",
      "Epoch 2387/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.5037 - mse: 743.0732 - val_loss: 17.6280 - val_mse: 716.9188\n",
      "Epoch 2388/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4192 - mse: 679.0132 - val_loss: 17.8835 - val_mse: 736.9915\n",
      "Epoch 2389/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9446 - mse: 712.3315 - val_loss: 17.7542 - val_mse: 746.2297\n",
      "Epoch 2390/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6146 - mse: 693.0434 - val_loss: 17.8368 - val_mse: 703.2113\n",
      "Epoch 2391/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3300 - mse: 679.1428 - val_loss: 17.6420 - val_mse: 703.2418\n",
      "Epoch 2392/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1270 - mse: 677.0085 - val_loss: 17.7370 - val_mse: 680.9876\n",
      "Epoch 2393/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0505 - mse: 656.4515 - val_loss: 17.8646 - val_mse: 685.2292\n",
      "Epoch 2394/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.1109 - mse: 663.2778 - val_loss: 17.6289 - val_mse: 679.1764\n",
      "Epoch 2395/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6459 - mse: 694.4410 - val_loss: 18.7911 - val_mse: 801.2552\n",
      "Epoch 2396/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3775 - mse: 675.2607 - val_loss: 17.7007 - val_mse: 675.5622\n",
      "Epoch 2397/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5585 - mse: 688.3637 - val_loss: 18.1953 - val_mse: 703.2487\n",
      "Epoch 2398/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.1796 - mse: 664.0195 - val_loss: 17.7628 - val_mse: 679.6222\n",
      "Epoch 2399/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5004 - mse: 676.1920 - val_loss: 18.2902 - val_mse: 769.1852\n",
      "Epoch 2400/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5437 - mse: 682.7833 - val_loss: 17.7790 - val_mse: 705.5681\n",
      "Epoch 2401/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4159 - mse: 670.8111 - val_loss: 17.9632 - val_mse: 744.7567\n",
      "Epoch 2402/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9282 - mse: 703.8421 - val_loss: 18.7310 - val_mse: 824.5670\n",
      "Epoch 2403/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3548 - mse: 736.6365 - val_loss: 18.8023 - val_mse: 835.4273\n",
      "Epoch 2404/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3104 - mse: 728.9717 - val_loss: 19.4515 - val_mse: 810.3923\n",
      "Epoch 2405/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.5462 - mse: 821.6851 - val_loss: 18.8915 - val_mse: 726.5897\n",
      "Epoch 2406/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2040 - mse: 728.8625 - val_loss: 18.2096 - val_mse: 779.8727\n",
      "Epoch 2407/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7784 - mse: 701.6380 - val_loss: 19.1214 - val_mse: 841.3813\n",
      "Epoch 2408/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.8485 - mse: 706.3817 - val_loss: 17.6680 - val_mse: 703.8951\n",
      "Epoch 2409/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.2595 - mse: 667.5912 - val_loss: 17.8573 - val_mse: 719.6096\n",
      "Epoch 2410/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4347 - mse: 680.1268 - val_loss: 17.6907 - val_mse: 689.5285\n",
      "Epoch 2411/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.5332 - mse: 679.3503 - val_loss: 17.5877 - val_mse: 685.9752\n",
      "Epoch 2412/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3974 - mse: 684.2177 - val_loss: 18.6072 - val_mse: 748.1722\n",
      "Epoch 2413/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3891 - mse: 728.0410 - val_loss: 17.9330 - val_mse: 762.6223\n",
      "Epoch 2414/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.0902 - mse: 793.9091 - val_loss: 18.6935 - val_mse: 800.8664\n",
      "Epoch 2415/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7280 - mse: 754.5426 - val_loss: 18.7848 - val_mse: 843.2967\n",
      "Epoch 2416/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8766 - mse: 711.5969 - val_loss: 18.1586 - val_mse: 697.4495\n",
      "Epoch 2417/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8921 - mse: 708.6549 - val_loss: 17.8373 - val_mse: 698.6887\n",
      "Epoch 2418/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6219 - mse: 695.2045 - val_loss: 18.9065 - val_mse: 844.2617\n",
      "Epoch 2419/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6108 - mse: 688.9723 - val_loss: 18.0291 - val_mse: 722.1539\n",
      "Epoch 2420/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3487 - mse: 680.2104 - val_loss: 18.1024 - val_mse: 764.7066\n",
      "Epoch 2421/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5012 - mse: 679.2255 - val_loss: 18.8160 - val_mse: 834.4420\n",
      "Epoch 2422/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2894 - mse: 750.8537 - val_loss: 18.4863 - val_mse: 796.3796\n",
      "Epoch 2423/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5568 - mse: 690.8458 - val_loss: 17.7665 - val_mse: 724.7590\n",
      "Epoch 2424/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8969 - mse: 698.4761 - val_loss: 17.7548 - val_mse: 734.5862\n",
      "Epoch 2425/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5836 - mse: 684.8466 - val_loss: 17.9914 - val_mse: 729.0531\n",
      "Epoch 2426/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4839 - mse: 684.9703 - val_loss: 17.8005 - val_mse: 740.5771\n",
      "Epoch 2427/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9817 - mse: 723.2558 - val_loss: 19.1032 - val_mse: 772.8127\n",
      "Epoch 2428/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5144 - mse: 685.5016 - val_loss: 17.6916 - val_mse: 694.0981\n",
      "Epoch 2429/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7102 - mse: 694.2135 - val_loss: 17.7131 - val_mse: 678.8649\n",
      "Epoch 2430/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4106 - mse: 676.9024 - val_loss: 17.6419 - val_mse: 689.0187\n",
      "Epoch 2431/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6413 - mse: 689.8326 - val_loss: 17.6777 - val_mse: 666.3430\n",
      "Epoch 2432/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3586 - mse: 667.0209 - val_loss: 17.7576 - val_mse: 675.6719\n",
      "Epoch 2433/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3368 - mse: 674.8199 - val_loss: 17.6685 - val_mse: 727.1047\n",
      "Epoch 2434/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.0661 - mse: 656.0883 - val_loss: 17.8800 - val_mse: 680.5135\n",
      "Epoch 2435/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5954 - mse: 687.5648 - val_loss: 18.1199 - val_mse: 773.2274\n",
      "Epoch 2436/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5425 - mse: 687.6802 - val_loss: 18.0887 - val_mse: 702.4443\n",
      "Epoch 2437/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.2792 - mse: 665.8869 - val_loss: 17.5294 - val_mse: 694.0253\n",
      "Epoch 2438/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.0751 - mse: 656.9708 - val_loss: 17.4437 - val_mse: 692.2639\n",
      "Epoch 2439/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.1540 - mse: 658.9622 - val_loss: 17.7791 - val_mse: 713.3935\n",
      "Epoch 2440/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9220 - mse: 704.3156 - val_loss: 19.0359 - val_mse: 756.5898\n",
      "Epoch 2441/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1496 - mse: 807.0905 - val_loss: 18.2312 - val_mse: 742.4416\n",
      "Epoch 2442/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8912 - mse: 705.6321 - val_loss: 17.5347 - val_mse: 714.4056\n",
      "Epoch 2443/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4582 - mse: 685.8739 - val_loss: 18.3904 - val_mse: 749.0681\n",
      "Epoch 2444/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6482 - mse: 702.4903 - val_loss: 19.3256 - val_mse: 703.6786\n",
      "Epoch 2445/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3696 - mse: 677.7322 - val_loss: 17.6263 - val_mse: 678.1985\n",
      "Epoch 2446/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.1675 - mse: 660.2571 - val_loss: 18.3172 - val_mse: 732.9160\n",
      "Epoch 2447/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.2058 - mse: 668.6464 - val_loss: 17.4583 - val_mse: 703.9756\n",
      "Epoch 2448/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8681 - mse: 700.8080 - val_loss: 18.3815 - val_mse: 761.0883\n",
      "Epoch 2449/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9750 - mse: 716.4157 - val_loss: 18.9259 - val_mse: 688.7638\n",
      "Epoch 2450/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7348 - mse: 697.2832 - val_loss: 17.7615 - val_mse: 741.7431\n",
      "Epoch 2451/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9844 - mse: 710.0468 - val_loss: 18.3135 - val_mse: 746.0481\n",
      "Epoch 2452/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4470 - mse: 750.4512 - val_loss: 18.0942 - val_mse: 708.5363\n",
      "Epoch 2453/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3170 - mse: 675.0423 - val_loss: 17.9177 - val_mse: 687.3375\n",
      "Epoch 2454/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.0920 - mse: 663.8907 - val_loss: 18.1881 - val_mse: 673.1958\n",
      "Epoch 2455/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3650 - mse: 670.1276 - val_loss: 17.7044 - val_mse: 691.2275\n",
      "Epoch 2456/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6106 - mse: 690.1182 - val_loss: 17.6627 - val_mse: 730.9217\n",
      "Epoch 2457/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2354 - mse: 674.4406 - val_loss: 17.7889 - val_mse: 680.3765\n",
      "Epoch 2458/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5959 - mse: 685.0328 - val_loss: 18.9374 - val_mse: 782.3096\n",
      "Epoch 2459/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.0949 - mse: 798.2552 - val_loss: 17.8653 - val_mse: 712.1918\n",
      "Epoch 2460/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1464 - mse: 657.9922 - val_loss: 17.6906 - val_mse: 715.7793\n",
      "Epoch 2461/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5543 - mse: 684.6772 - val_loss: 18.0356 - val_mse: 705.7233\n",
      "Epoch 2462/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8085 - mse: 702.6979 - val_loss: 18.3104 - val_mse: 775.9150\n",
      "Epoch 2463/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0714 - mse: 717.0498 - val_loss: 18.6395 - val_mse: 731.6552\n",
      "Epoch 2464/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0299 - mse: 722.2073 - val_loss: 17.9954 - val_mse: 736.0255\n",
      "Epoch 2465/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6195 - mse: 685.4828 - val_loss: 18.6248 - val_mse: 814.6902\n",
      "Epoch 2466/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7567 - mse: 709.7859 - val_loss: 18.4210 - val_mse: 808.2907\n",
      "Epoch 2467/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6278 - mse: 694.8967 - val_loss: 18.8120 - val_mse: 716.4999\n",
      "Epoch 2468/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4744 - mse: 682.3831 - val_loss: 18.0980 - val_mse: 700.4778\n",
      "Epoch 2469/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0853 - mse: 709.6092 - val_loss: 17.8875 - val_mse: 717.8951\n",
      "Epoch 2470/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3991 - mse: 688.9067 - val_loss: 17.6547 - val_mse: 687.2802\n",
      "Epoch 2471/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.2198 - mse: 670.9031 - val_loss: 17.5084 - val_mse: 688.7480\n",
      "Epoch 2472/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2012 - mse: 665.3990 - val_loss: 17.9571 - val_mse: 717.5267\n",
      "Epoch 2473/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9102 - mse: 712.8600 - val_loss: 17.4857 - val_mse: 710.8428\n",
      "Epoch 2474/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2397 - mse: 666.6822 - val_loss: 17.8955 - val_mse: 712.2957\n",
      "Epoch 2475/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4997 - mse: 686.2579 - val_loss: 17.5245 - val_mse: 688.4457\n",
      "Epoch 2476/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5511 - mse: 683.0590 - val_loss: 18.0392 - val_mse: 744.8391\n",
      "Epoch 2477/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7093 - mse: 701.6240 - val_loss: 18.3062 - val_mse: 679.0452\n",
      "Epoch 2478/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.1429 - mse: 666.5944 - val_loss: 17.7864 - val_mse: 717.9999\n",
      "Epoch 2479/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3841 - mse: 683.1068 - val_loss: 17.9631 - val_mse: 667.1400\n",
      "Epoch 2480/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3023 - mse: 666.1226 - val_loss: 18.2694 - val_mse: 707.1359\n",
      "Epoch 2481/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7895 - mse: 702.2010 - val_loss: 19.8325 - val_mse: 865.1796\n",
      "Epoch 2482/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7094 - mse: 697.9852 - val_loss: 19.3275 - val_mse: 863.7297\n",
      "Epoch 2483/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5959 - mse: 695.1298 - val_loss: 18.3526 - val_mse: 680.9226\n",
      "Epoch 2484/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7749 - mse: 706.4314 - val_loss: 18.3063 - val_mse: 688.4715\n",
      "Epoch 2485/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4604 - mse: 682.7583 - val_loss: 17.9004 - val_mse: 705.5831\n",
      "Epoch 2486/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4376 - mse: 677.9326 - val_loss: 18.4673 - val_mse: 683.9686\n",
      "Epoch 2487/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5545 - mse: 685.0110 - val_loss: 18.7150 - val_mse: 804.6104\n",
      "Epoch 2488/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1865 - mse: 717.9855 - val_loss: 17.8339 - val_mse: 701.0206\n",
      "Epoch 2489/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4693 - mse: 679.8726 - val_loss: 18.4087 - val_mse: 799.6113\n",
      "Epoch 2490/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7427 - mse: 705.8770 - val_loss: 17.9216 - val_mse: 710.3965\n",
      "Epoch 2491/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5418 - mse: 685.1917 - val_loss: 17.7373 - val_mse: 707.0898\n",
      "Epoch 2492/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2491 - mse: 668.0447 - val_loss: 17.8525 - val_mse: 669.3606\n",
      "Epoch 2493/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3192 - mse: 667.8862 - val_loss: 18.1233 - val_mse: 708.3755\n",
      "Epoch 2494/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8322 - mse: 714.3064 - val_loss: 18.4314 - val_mse: 695.9708\n",
      "Epoch 2495/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7444 - mse: 711.8966 - val_loss: 19.0538 - val_mse: 778.6360\n",
      "Epoch 2496/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0151 - mse: 713.8310 - val_loss: 19.1502 - val_mse: 841.4454\n",
      "Epoch 2497/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.8678 - mse: 705.8417 - val_loss: 18.6363 - val_mse: 821.7248\n",
      "Epoch 2498/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9247 - mse: 720.5032 - val_loss: 18.3129 - val_mse: 781.4792\n",
      "Epoch 2499/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1356 - mse: 715.9667 - val_loss: 18.4050 - val_mse: 797.0005\n",
      "Epoch 2500/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6119 - mse: 698.0937 - val_loss: 17.6591 - val_mse: 680.5060\n",
      "Epoch 2501/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1528 - mse: 662.1396 - val_loss: 18.0484 - val_mse: 719.5690\n",
      "Epoch 2502/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3775 - mse: 669.6320 - val_loss: 18.3971 - val_mse: 798.7579\n",
      "Epoch 2503/5000\n",
      "36/36 [==============================] - 898s 26s/step - loss: 17.1766 - mse: 670.3040 - val_loss: 17.7583 - val_mse: 730.7298\n",
      "Epoch 2504/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.5120 - mse: 688.3273 - val_loss: 18.0125 - val_mse: 695.4822\n",
      "Epoch 2505/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3144 - mse: 680.9128 - val_loss: 17.6392 - val_mse: 669.9287\n",
      "Epoch 2506/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3079 - mse: 672.7739 - val_loss: 17.9279 - val_mse: 725.1317\n",
      "Epoch 2507/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3477 - mse: 668.0638 - val_loss: 17.7099 - val_mse: 704.4080\n",
      "Epoch 2508/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7120 - mse: 702.8721 - val_loss: 17.9335 - val_mse: 682.6091\n",
      "Epoch 2509/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3880 - mse: 676.8690 - val_loss: 18.0449 - val_mse: 692.0874\n",
      "Epoch 2510/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3005 - mse: 674.0419 - val_loss: 18.2173 - val_mse: 690.2412\n",
      "Epoch 2511/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4192 - mse: 683.1335 - val_loss: 17.8111 - val_mse: 680.1823\n",
      "Epoch 2512/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.8509 - mse: 702.4182 - val_loss: 17.6674 - val_mse: 732.4941\n",
      "Epoch 2513/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.1159 - mse: 662.8974 - val_loss: 17.7330 - val_mse: 719.8143\n",
      "Epoch 2514/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7854 - mse: 702.0708 - val_loss: 17.9751 - val_mse: 770.0378\n",
      "Epoch 2515/5000\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 17.3465 - mse: 668.2123 - val_loss: 18.1939 - val_mse: 699.1743\n",
      "Epoch 2516/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8538 - mse: 715.6336 - val_loss: 18.2179 - val_mse: 728.2516\n",
      "Epoch 2517/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.2982 - mse: 677.6978 - val_loss: 17.5793 - val_mse: 702.6621\n",
      "Epoch 2518/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6659 - mse: 693.8009 - val_loss: 17.9758 - val_mse: 747.2135\n",
      "Epoch 2519/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6548 - mse: 688.9067 - val_loss: 17.6379 - val_mse: 720.6105\n",
      "Epoch 2520/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4889 - mse: 683.7737 - val_loss: 17.9882 - val_mse: 696.4951\n",
      "Epoch 2521/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2700 - mse: 741.9212 - val_loss: 17.7863 - val_mse: 711.3668\n",
      "Epoch 2522/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9183 - mse: 707.9574 - val_loss: 17.6027 - val_mse: 703.0284\n",
      "Epoch 2523/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4120 - mse: 677.9579 - val_loss: 18.0033 - val_mse: 729.9349\n",
      "Epoch 2524/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6638 - mse: 696.0714 - val_loss: 17.6103 - val_mse: 691.9789\n",
      "Epoch 2525/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.6614 - mse: 709.1844 - val_loss: 17.9854 - val_mse: 708.6194\n",
      "Epoch 2526/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.3757 - mse: 669.5362 - val_loss: 17.5028 - val_mse: 689.8494\n",
      "Epoch 2527/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.2388 - mse: 677.0817 - val_loss: 17.7561 - val_mse: 684.8158\n",
      "Epoch 2528/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.0442 - mse: 713.3426 - val_loss: 18.3178 - val_mse: 751.1346\n",
      "Epoch 2529/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3530 - mse: 679.1266 - val_loss: 18.4180 - val_mse: 693.7050\n",
      "Epoch 2530/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.2726 - mse: 677.5587 - val_loss: 19.0557 - val_mse: 762.0589\n",
      "Epoch 2531/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8673 - mse: 705.9818 - val_loss: 18.0524 - val_mse: 727.1116\n",
      "Epoch 2532/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4230 - mse: 677.3054 - val_loss: 17.4673 - val_mse: 715.1744\n",
      "Epoch 2533/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3300 - mse: 675.9249 - val_loss: 17.8184 - val_mse: 688.2822\n",
      "Epoch 2534/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3115 - mse: 678.8658 - val_loss: 18.3503 - val_mse: 697.9706\n",
      "Epoch 2535/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.4435 - mse: 686.2578 - val_loss: 17.7014 - val_mse: 707.9695\n",
      "Epoch 2536/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.1650 - mse: 660.1579 - val_loss: 17.9217 - val_mse: 757.6699\n",
      "Epoch 2537/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4181 - mse: 682.6021 - val_loss: 18.1078 - val_mse: 701.2969\n",
      "Epoch 2538/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4734 - mse: 684.3055 - val_loss: 17.8297 - val_mse: 736.9150\n",
      "Epoch 2539/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.4984 - mse: 762.6759 - val_loss: 19.5985 - val_mse: 788.4753\n",
      "Epoch 2540/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.8570 - mse: 746.0944 - val_loss: 18.0431 - val_mse: 750.3328\n",
      "Epoch 2541/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8828 - mse: 713.7156 - val_loss: 17.8323 - val_mse: 694.3338\n",
      "Epoch 2542/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9613 - mse: 704.0114 - val_loss: 18.1584 - val_mse: 779.0556\n",
      "Epoch 2543/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3732 - mse: 738.6531 - val_loss: 17.6620 - val_mse: 735.0952\n",
      "Epoch 2544/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.5878 - mse: 685.5909 - val_loss: 17.7418 - val_mse: 743.9678\n",
      "Epoch 2545/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6119 - mse: 686.1101 - val_loss: 19.4847 - val_mse: 884.9517\n",
      "Epoch 2546/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0641 - mse: 718.9726 - val_loss: 18.6221 - val_mse: 826.0778\n",
      "Epoch 2547/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4879 - mse: 683.9081 - val_loss: 17.5954 - val_mse: 726.7445\n",
      "Epoch 2548/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5191 - mse: 695.3785 - val_loss: 17.5958 - val_mse: 742.7980\n",
      "Epoch 2549/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4437 - mse: 682.8889 - val_loss: 17.9156 - val_mse: 766.3674\n",
      "Epoch 2550/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9921 - mse: 715.5762 - val_loss: 19.1457 - val_mse: 858.5773\n",
      "Epoch 2551/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7069 - mse: 706.4424 - val_loss: 17.9581 - val_mse: 711.3015\n",
      "Epoch 2552/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.2007 - mse: 673.6667 - val_loss: 18.1713 - val_mse: 686.0887\n",
      "Epoch 2553/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3446 - mse: 676.5223 - val_loss: 17.5782 - val_mse: 704.3970\n",
      "Epoch 2554/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4933 - mse: 680.3039 - val_loss: 17.6618 - val_mse: 703.7964\n",
      "Epoch 2555/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.3952 - mse: 675.0927 - val_loss: 17.8196 - val_mse: 700.2919\n",
      "Epoch 2556/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3681 - mse: 675.5457 - val_loss: 17.6478 - val_mse: 689.9390\n",
      "Epoch 2557/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.2272 - mse: 673.8445 - val_loss: 18.4774 - val_mse: 692.4011\n",
      "Epoch 2558/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.2542 - mse: 671.3527 - val_loss: 17.5143 - val_mse: 682.0006\n",
      "Epoch 2559/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.1863 - mse: 669.3132 - val_loss: 17.6320 - val_mse: 683.0816\n",
      "Epoch 2560/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.1926 - mse: 663.6378 - val_loss: 17.9616 - val_mse: 730.0586\n",
      "Epoch 2561/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4764 - mse: 683.9069 - val_loss: 17.6044 - val_mse: 713.3500\n",
      "Epoch 2562/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8153 - mse: 708.2762 - val_loss: 18.5490 - val_mse: 794.5891\n",
      "Epoch 2563/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9384 - mse: 704.6478 - val_loss: 18.1116 - val_mse: 710.7082\n",
      "Epoch 2564/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.6406 - mse: 693.4854 - val_loss: 17.8229 - val_mse: 716.0267\n",
      "Epoch 2565/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.0556 - mse: 664.2769 - val_loss: 17.8568 - val_mse: 748.5876\n",
      "Epoch 2566/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.3200 - mse: 676.4899 - val_loss: 18.5689 - val_mse: 742.8752\n",
      "Epoch 2567/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.5553 - mse: 693.2787 - val_loss: 17.6220 - val_mse: 713.8148\n",
      "Epoch 2568/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.3114 - mse: 673.9218 - val_loss: 17.6925 - val_mse: 706.3095\n",
      "Epoch 2569/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5882 - mse: 688.7402 - val_loss: 17.6204 - val_mse: 708.3402\n",
      "Epoch 2570/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.3688 - mse: 680.1104 - val_loss: 17.7109 - val_mse: 718.4796\n",
      "Epoch 2571/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.1199 - mse: 662.1316 - val_loss: 18.3058 - val_mse: 714.9616\n",
      "Epoch 2572/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4739 - mse: 691.2836 - val_loss: 17.5860 - val_mse: 681.0555\n",
      "Epoch 2573/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3608 - mse: 679.9111 - val_loss: 17.4906 - val_mse: 687.0804\n",
      "Epoch 2574/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9506 - mse: 716.5815 - val_loss: 17.6546 - val_mse: 710.5203\n",
      "Epoch 2575/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.5040 - mse: 751.9417 - val_loss: 19.3076 - val_mse: 787.0493\n",
      "Epoch 2576/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.8921 - mse: 762.7757 - val_loss: 19.0565 - val_mse: 820.4122\n",
      "Epoch 2577/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.4290 - mse: 745.7885 - val_loss: 17.8382 - val_mse: 696.7714\n",
      "Epoch 2578/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.4173 - mse: 681.6971 - val_loss: 17.8008 - val_mse: 692.8071\n",
      "Epoch 2579/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.0980 - mse: 667.8364 - val_loss: 17.8394 - val_mse: 703.7020\n",
      "Epoch 2580/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 16.9658 - mse: 655.2990 - val_loss: 17.8219 - val_mse: 711.4424\n",
      "Epoch 2581/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.3609 - mse: 677.3710 - val_loss: 17.9654 - val_mse: 708.0603\n",
      "Epoch 2582/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.8582 - mse: 709.0993 - val_loss: 18.9570 - val_mse: 809.5736\n",
      "Epoch 2583/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8156 - mse: 702.1029 - val_loss: 18.3193 - val_mse: 756.0400\n",
      "Epoch 2584/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.3406 - mse: 677.5721 - val_loss: 17.6248 - val_mse: 712.2970\n",
      "Epoch 2585/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3118 - mse: 682.4704 - val_loss: 18.2894 - val_mse: 701.6719\n",
      "Epoch 2586/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.2439 - mse: 670.4234 - val_loss: 17.6018 - val_mse: 677.2291\n",
      "Epoch 2587/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.2982 - mse: 663.8949 - val_loss: 18.1908 - val_mse: 776.8834\n",
      "Epoch 2588/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9481 - mse: 706.5729 - val_loss: 17.8807 - val_mse: 760.2967\n",
      "Epoch 2589/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5217 - mse: 698.4322 - val_loss: 18.3119 - val_mse: 720.0566\n",
      "Epoch 2590/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3119 - mse: 678.4881 - val_loss: 17.6949 - val_mse: 674.5826\n",
      "Epoch 2591/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 16.9814 - mse: 652.9986 - val_loss: 18.4378 - val_mse: 729.4929\n",
      "Epoch 2592/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.2005 - mse: 667.8900 - val_loss: 17.5131 - val_mse: 702.9460\n",
      "Epoch 2593/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.1668 - mse: 663.2737 - val_loss: 17.7277 - val_mse: 681.7845\n",
      "Epoch 2594/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.0544 - mse: 654.3654 - val_loss: 17.4660 - val_mse: 700.2962\n",
      "Epoch 2595/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3811 - mse: 683.9913 - val_loss: 18.3928 - val_mse: 700.1602\n",
      "Epoch 2596/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.3004 - mse: 660.7982 - val_loss: 19.6675 - val_mse: 892.5798\n",
      "Epoch 2597/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.3646 - mse: 752.7435 - val_loss: 17.6687 - val_mse: 688.8021\n",
      "Epoch 2598/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9384 - mse: 719.9882 - val_loss: 18.1727 - val_mse: 730.1177\n",
      "Epoch 2599/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4448 - mse: 686.5213 - val_loss: 17.7865 - val_mse: 681.0868\n",
      "Epoch 2600/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0296 - mse: 716.2280 - val_loss: 18.3112 - val_mse: 785.3817\n",
      "Epoch 2601/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.1089 - mse: 656.3586 - val_loss: 18.3860 - val_mse: 735.2429\n",
      "Epoch 2602/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7061 - mse: 702.0074 - val_loss: 17.6295 - val_mse: 686.4080\n",
      "Epoch 2603/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.2467 - mse: 667.8141 - val_loss: 18.0241 - val_mse: 698.0979\n",
      "Epoch 2604/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.3160 - mse: 670.3937 - val_loss: 18.5112 - val_mse: 741.4495\n",
      "Epoch 2605/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4335 - mse: 672.0720 - val_loss: 17.5209 - val_mse: 687.5716\n",
      "Epoch 2606/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.0949 - mse: 656.7505 - val_loss: 17.6821 - val_mse: 711.4307\n",
      "Epoch 2607/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8262 - mse: 709.3772 - val_loss: 18.8139 - val_mse: 815.8818\n",
      "Epoch 2608/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5932 - mse: 691.4941 - val_loss: 17.6510 - val_mse: 707.8614\n",
      "Epoch 2609/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5066 - mse: 685.7480 - val_loss: 17.3822 - val_mse: 687.0019\n",
      "Epoch 2610/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3016 - mse: 683.4150 - val_loss: 18.2551 - val_mse: 690.8197\n",
      "Epoch 2611/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3203 - mse: 675.0994 - val_loss: 18.0214 - val_mse: 671.9216\n",
      "Epoch 2612/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4687 - mse: 683.5621 - val_loss: 17.6402 - val_mse: 708.6179\n",
      "Epoch 2613/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.5818 - mse: 689.8492 - val_loss: 17.7945 - val_mse: 704.8298\n",
      "Epoch 2614/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8702 - mse: 702.9525 - val_loss: 19.2920 - val_mse: 865.8076\n",
      "Epoch 2615/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6603 - mse: 700.3707 - val_loss: 17.5895 - val_mse: 708.3441\n",
      "Epoch 2616/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.0818 - mse: 660.1854 - val_loss: 17.9437 - val_mse: 739.6194\n",
      "Epoch 2617/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2729 - mse: 681.7156 - val_loss: 17.9882 - val_mse: 763.3215\n",
      "Epoch 2618/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.5742 - mse: 697.6373 - val_loss: 18.7847 - val_mse: 694.7288\n",
      "Epoch 2619/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1985 - mse: 729.9046 - val_loss: 18.0729 - val_mse: 748.7004\n",
      "Epoch 2620/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.2753 - mse: 673.7267 - val_loss: 17.7901 - val_mse: 716.5362\n",
      "Epoch 2621/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.4181 - mse: 689.1156 - val_loss: 18.1446 - val_mse: 778.2112\n",
      "Epoch 2622/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.6853 - mse: 701.1356 - val_loss: 18.7084 - val_mse: 748.8979\n",
      "Epoch 2623/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.6946 - mse: 687.4272 - val_loss: 17.4955 - val_mse: 709.9791\n",
      "Epoch 2624/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.6727 - mse: 683.8136 - val_loss: 18.9417 - val_mse: 779.2016\n",
      "Epoch 2625/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.2380 - mse: 743.1729 - val_loss: 18.4511 - val_mse: 779.4235\n",
      "Epoch 2626/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6280 - mse: 688.1915 - val_loss: 17.7003 - val_mse: 706.9965\n",
      "Epoch 2627/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.5373 - mse: 687.0368 - val_loss: 18.0706 - val_mse: 728.3069\n",
      "Epoch 2628/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.8169 - mse: 701.9275 - val_loss: 18.1436 - val_mse: 684.4702\n",
      "Epoch 2629/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.8961 - mse: 777.3560 - val_loss: 18.4776 - val_mse: 751.1094\n",
      "Epoch 2630/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6192 - mse: 699.8171 - val_loss: 17.8257 - val_mse: 686.1170\n",
      "Epoch 2631/5000\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 17.4673 - mse: 678.8091 - val_loss: 18.1355 - val_mse: 772.0374\n",
      "Epoch 2632/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.2377 - mse: 667.2723 - val_loss: 17.8979 - val_mse: 698.5632\n",
      "Epoch 2633/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.1828 - mse: 669.7382 - val_loss: 18.0482 - val_mse: 699.7369\n",
      "Epoch 2634/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.6050 - mse: 696.6953 - val_loss: 17.9319 - val_mse: 681.7230\n",
      "Epoch 2635/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.2925 - mse: 721.6855 - val_loss: 20.1338 - val_mse: 916.8967\n",
      "Epoch 2636/5000\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 19.1655 - mse: 791.5497 - val_loss: 19.0204 - val_mse: 764.8138\n",
      "Epoch 2637/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.5710 - mse: 757.9233 - val_loss: 19.0219 - val_mse: 715.5350\n",
      "Epoch 2638/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.4223 - mse: 671.2299 - val_loss: 18.0816 - val_mse: 719.5014\n",
      "Epoch 2639/5000\n",
      "36/36 [==============================] - 356s 10s/step - loss: 17.6632 - mse: 691.2145 - val_loss: 17.8097 - val_mse: 757.5788\n",
      "Epoch 2640/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.0355 - mse: 661.0924 - val_loss: 17.9458 - val_mse: 699.5809\n",
      "Epoch 2641/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.0536 - mse: 663.9186 - val_loss: 17.3978 - val_mse: 668.6295\n",
      "Epoch 2642/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1417 - mse: 658.8547 - val_loss: 17.6203 - val_mse: 690.3239\n",
      "Epoch 2643/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.2959 - mse: 673.7843 - val_loss: 18.1517 - val_mse: 766.0942\n",
      "Epoch 2644/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 18.5457 - mse: 748.8888 - val_loss: 18.5167 - val_mse: 759.2294\n",
      "Epoch 2645/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.7297 - mse: 699.8732 - val_loss: 18.9082 - val_mse: 736.4014\n",
      "Epoch 2646/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5652 - mse: 690.1968 - val_loss: 17.9117 - val_mse: 693.7119\n",
      "Epoch 2647/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.6343 - mse: 777.4547 - val_loss: 22.0141 - val_mse: 1069.4473\n",
      "Epoch 2648/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7201 - mse: 760.5840 - val_loss: 18.5932 - val_mse: 738.5357\n",
      "Epoch 2649/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 17.5273 - mse: 687.1621 - val_loss: 18.0058 - val_mse: 765.7534\n",
      "Epoch 2650/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3521 - mse: 673.6711 - val_loss: 18.3077 - val_mse: 713.4281\n",
      "Epoch 2651/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 17.6349 - mse: 696.8517 - val_loss: 17.8510 - val_mse: 748.8205\n",
      "Epoch 2652/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.6628 - mse: 693.2385 - val_loss: 17.4531 - val_mse: 695.3077\n",
      "Epoch 2653/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.0204 - mse: 661.4732 - val_loss: 17.4059 - val_mse: 683.5153\n",
      "Epoch 2654/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.0140 - mse: 664.0696 - val_loss: 17.9123 - val_mse: 674.1080\n",
      "Epoch 2655/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6566 - mse: 698.8284 - val_loss: 18.9476 - val_mse: 801.8512\n",
      "Epoch 2656/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 18.6627 - mse: 758.9493 - val_loss: 18.2827 - val_mse: 717.3580\n",
      "Epoch 2657/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6186 - mse: 694.1929 - val_loss: 17.9529 - val_mse: 690.5452\n",
      "Epoch 2658/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4040 - mse: 682.9880 - val_loss: 17.7203 - val_mse: 736.0795\n",
      "Epoch 2659/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4946 - mse: 681.9543 - val_loss: 17.6842 - val_mse: 738.5266\n",
      "Epoch 2660/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0595 - mse: 669.7253 - val_loss: 17.8367 - val_mse: 688.5978\n",
      "Epoch 2661/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6438 - mse: 686.8520 - val_loss: 17.7998 - val_mse: 703.1229\n",
      "Epoch 2662/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9136 - mse: 649.7322 - val_loss: 17.7370 - val_mse: 730.7795\n",
      "Epoch 2663/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7256 - mse: 696.8970 - val_loss: 17.8355 - val_mse: 688.5431\n",
      "Epoch 2664/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4531 - mse: 684.6628 - val_loss: 18.6947 - val_mse: 696.5801\n",
      "Epoch 2665/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.4601 - mse: 755.7264 - val_loss: 18.5246 - val_mse: 743.4848\n",
      "Epoch 2666/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0944 - mse: 719.1606 - val_loss: 18.9700 - val_mse: 704.4668\n",
      "Epoch 2667/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7295 - mse: 693.6537 - val_loss: 18.1325 - val_mse: 781.0743\n",
      "Epoch 2668/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5292 - mse: 699.9409 - val_loss: 18.5430 - val_mse: 688.3420\n",
      "Epoch 2669/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4949 - mse: 677.9689 - val_loss: 18.1749 - val_mse: 673.0231\n",
      "Epoch 2670/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.4671 - mse: 690.7960 - val_loss: 17.9705 - val_mse: 718.4725\n",
      "Epoch 2671/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8594 - mse: 706.0970 - val_loss: 18.6742 - val_mse: 756.0920\n",
      "Epoch 2672/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8704 - mse: 715.7310 - val_loss: 18.6355 - val_mse: 774.1727\n",
      "Epoch 2673/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.1235 - mse: 725.5377 - val_loss: 18.1292 - val_mse: 771.1152\n",
      "Epoch 2674/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7745 - mse: 707.3274 - val_loss: 17.9506 - val_mse: 728.1127\n",
      "Epoch 2675/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5182 - mse: 686.6591 - val_loss: 17.6408 - val_mse: 682.7102\n",
      "Epoch 2676/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8856 - mse: 706.1566 - val_loss: 17.8609 - val_mse: 739.5500\n",
      "Epoch 2677/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4290 - mse: 739.0787 - val_loss: 19.2905 - val_mse: 849.2837\n",
      "Epoch 2678/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9506 - mse: 722.7144 - val_loss: 17.5575 - val_mse: 686.9842\n",
      "Epoch 2679/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4992 - mse: 690.1282 - val_loss: 18.3596 - val_mse: 790.9256\n",
      "Epoch 2680/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.0998 - mse: 656.6455 - val_loss: 17.8798 - val_mse: 673.3280\n",
      "Epoch 2681/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1777 - mse: 659.9407 - val_loss: 18.0529 - val_mse: 760.6086\n",
      "Epoch 2682/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4579 - mse: 679.4076 - val_loss: 18.1162 - val_mse: 759.3262\n",
      "Epoch 2683/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6452 - mse: 691.9491 - val_loss: 18.6430 - val_mse: 729.8511\n",
      "Epoch 2684/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9178 - mse: 706.2498 - val_loss: 18.1267 - val_mse: 719.3480\n",
      "Epoch 2685/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7113 - mse: 705.4670 - val_loss: 17.9429 - val_mse: 695.4677\n",
      "Epoch 2686/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.1824 - mse: 667.8406 - val_loss: 18.1873 - val_mse: 778.8931\n",
      "Epoch 2687/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4151 - mse: 678.6308 - val_loss: 18.2126 - val_mse: 738.1620\n",
      "Epoch 2688/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0604 - mse: 661.6121 - val_loss: 17.4390 - val_mse: 677.2322\n",
      "Epoch 2689/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8991 - mse: 711.8795 - val_loss: 18.2149 - val_mse: 767.3062\n",
      "Epoch 2690/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6409 - mse: 692.4059 - val_loss: 17.9372 - val_mse: 683.5210\n",
      "Epoch 2691/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3641 - mse: 676.5504 - val_loss: 17.4384 - val_mse: 691.5768\n",
      "Epoch 2692/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0016 - mse: 655.3481 - val_loss: 17.4266 - val_mse: 676.8113\n",
      "Epoch 2693/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1273 - mse: 668.0198 - val_loss: 17.7736 - val_mse: 727.3513\n",
      "Epoch 2694/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 16.8424 - mse: 653.2327 - val_loss: 17.6061 - val_mse: 696.9418\n",
      "Epoch 2695/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6451 - mse: 704.6190 - val_loss: 18.1312 - val_mse: 700.0537\n",
      "Epoch 2696/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3054 - mse: 669.1056 - val_loss: 18.1415 - val_mse: 763.5162\n",
      "Epoch 2697/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3591 - mse: 682.9133 - val_loss: 17.4824 - val_mse: 681.2476\n",
      "Epoch 2698/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0568 - mse: 656.5023 - val_loss: 17.6688 - val_mse: 718.6784\n",
      "Epoch 2699/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1408 - mse: 672.3543 - val_loss: 17.7094 - val_mse: 678.8992\n",
      "Epoch 2700/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.2212 - mse: 671.5746 - val_loss: 17.9002 - val_mse: 754.2299\n",
      "Epoch 2701/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3503 - mse: 688.0858 - val_loss: 18.0791 - val_mse: 689.4540\n",
      "Epoch 2702/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5217 - mse: 688.5060 - val_loss: 17.8217 - val_mse: 684.6314\n",
      "Epoch 2703/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0097 - mse: 653.2769 - val_loss: 17.5864 - val_mse: 694.7434\n",
      "Epoch 2704/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4477 - mse: 692.5928 - val_loss: 17.8100 - val_mse: 683.7922\n",
      "Epoch 2705/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8403 - mse: 701.5425 - val_loss: 18.4456 - val_mse: 714.2393\n",
      "Epoch 2706/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3589 - mse: 685.2938 - val_loss: 17.9905 - val_mse: 686.8497\n",
      "Epoch 2707/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1782 - mse: 731.7932 - val_loss: 19.6152 - val_mse: 720.9047\n",
      "Epoch 2708/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6230 - mse: 690.6791 - val_loss: 17.9892 - val_mse: 695.5248\n",
      "Epoch 2709/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2942 - mse: 670.6025 - val_loss: 18.5063 - val_mse: 678.3740\n",
      "Epoch 2710/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4746 - mse: 679.2319 - val_loss: 17.9791 - val_mse: 718.0412\n",
      "Epoch 2711/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5574 - mse: 683.0350 - val_loss: 18.4776 - val_mse: 698.8157\n",
      "Epoch 2712/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4296 - mse: 689.2070 - val_loss: 18.3710 - val_mse: 719.6335\n",
      "Epoch 2713/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.1866 - mse: 663.2744 - val_loss: 17.5617 - val_mse: 710.4547\n",
      "Epoch 2714/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3497 - mse: 673.6545 - val_loss: 19.0840 - val_mse: 845.6162\n",
      "Epoch 2715/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8178 - mse: 708.3531 - val_loss: 17.9280 - val_mse: 757.0679\n",
      "Epoch 2716/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4317 - mse: 684.0911 - val_loss: 20.0394 - val_mse: 733.1425\n",
      "Epoch 2717/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3624 - mse: 682.0828 - val_loss: 17.4335 - val_mse: 674.3891\n",
      "Epoch 2718/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3611 - mse: 674.6531 - val_loss: 18.1684 - val_mse: 763.2300\n",
      "Epoch 2719/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6998 - mse: 698.4487 - val_loss: 18.6035 - val_mse: 686.4805\n",
      "Epoch 2720/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8034 - mse: 707.4330 - val_loss: 19.3056 - val_mse: 742.3664\n",
      "Epoch 2721/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5704 - mse: 689.8363 - val_loss: 17.5821 - val_mse: 727.1702\n",
      "Epoch 2722/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.2704 - mse: 674.2487 - val_loss: 17.8348 - val_mse: 667.7900\n",
      "Epoch 2723/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1735 - mse: 658.0634 - val_loss: 17.9158 - val_mse: 754.1472\n",
      "Epoch 2724/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4009 - mse: 681.8494 - val_loss: 17.5079 - val_mse: 719.2273\n",
      "Epoch 2725/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8831 - mse: 704.4006 - val_loss: 17.5160 - val_mse: 695.1764\n",
      "Epoch 2726/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4734 - mse: 681.2247 - val_loss: 17.4280 - val_mse: 688.7458\n",
      "Epoch 2727/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.0456 - mse: 660.8605 - val_loss: 17.5019 - val_mse: 711.2856\n",
      "Epoch 2728/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0497 - mse: 663.3580 - val_loss: 17.7429 - val_mse: 722.6383\n",
      "Epoch 2729/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1280 - mse: 662.8691 - val_loss: 17.9644 - val_mse: 736.0427\n",
      "Epoch 2730/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9105 - mse: 715.9647 - val_loss: 18.1284 - val_mse: 780.5330\n",
      "Epoch 2731/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6533 - mse: 694.2420 - val_loss: 17.8679 - val_mse: 676.0760\n",
      "Epoch 2732/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1732 - mse: 665.6249 - val_loss: 17.5312 - val_mse: 677.4094\n",
      "Epoch 2733/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2431 - mse: 664.7419 - val_loss: 17.5626 - val_mse: 702.3755\n",
      "Epoch 2734/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0577 - mse: 662.5297 - val_loss: 17.8560 - val_mse: 713.8217\n",
      "Epoch 2735/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0210 - mse: 656.8089 - val_loss: 17.4224 - val_mse: 679.0012\n",
      "Epoch 2736/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0937 - mse: 657.1208 - val_loss: 18.6074 - val_mse: 813.9762\n",
      "Epoch 2737/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4912 - mse: 690.5306 - val_loss: 17.3779 - val_mse: 674.7709\n",
      "Epoch 2738/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7785 - mse: 705.7327 - val_loss: 17.7277 - val_mse: 714.2017\n",
      "Epoch 2739/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3855 - mse: 685.4739 - val_loss: 17.4751 - val_mse: 692.9210\n",
      "Epoch 2740/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.2903 - mse: 667.2729 - val_loss: 18.5730 - val_mse: 742.9720\n",
      "Epoch 2741/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2276 - mse: 663.2162 - val_loss: 19.0853 - val_mse: 761.1146\n",
      "Epoch 2742/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0619 - mse: 727.2858 - val_loss: 18.0887 - val_mse: 726.6284\n",
      "Epoch 2743/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4826 - mse: 685.8959 - val_loss: 18.5950 - val_mse: 693.1640\n",
      "Epoch 2744/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3554 - mse: 673.4550 - val_loss: 18.0828 - val_mse: 693.3931\n",
      "Epoch 2745/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2101 - mse: 669.5143 - val_loss: 17.6295 - val_mse: 667.9919\n",
      "Epoch 2746/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0509 - mse: 655.7243 - val_loss: 17.6792 - val_mse: 712.8300\n",
      "Epoch 2747/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2024 - mse: 674.4988 - val_loss: 18.2176 - val_mse: 770.8467\n",
      "Epoch 2748/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0707 - mse: 720.9653 - val_loss: 17.6233 - val_mse: 739.8799\n",
      "Epoch 2749/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.0885 - mse: 664.1556 - val_loss: 17.9303 - val_mse: 754.0546\n",
      "Epoch 2750/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5137 - mse: 684.3906 - val_loss: 17.4585 - val_mse: 680.7200\n",
      "Epoch 2751/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9936 - mse: 706.2731 - val_loss: 18.1642 - val_mse: 780.3915\n",
      "Epoch 2752/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6322 - mse: 700.1008 - val_loss: 17.6964 - val_mse: 697.2778\n",
      "Epoch 2753/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0124 - mse: 656.0262 - val_loss: 18.5494 - val_mse: 697.1781\n",
      "Epoch 2754/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.0675 - mse: 664.3632 - val_loss: 17.5396 - val_mse: 677.0654\n",
      "Epoch 2755/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2260 - mse: 670.2727 - val_loss: 19.6340 - val_mse: 880.4017\n",
      "Epoch 2756/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6360 - mse: 758.6434 - val_loss: 17.9940 - val_mse: 713.2326\n",
      "Epoch 2757/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1652 - mse: 726.4629 - val_loss: 17.7111 - val_mse: 694.9326\n",
      "Epoch 2758/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2244 - mse: 663.9758 - val_loss: 17.6806 - val_mse: 710.4966\n",
      "Epoch 2759/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5329 - mse: 696.6743 - val_loss: 17.8659 - val_mse: 702.9663\n",
      "Epoch 2760/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3822 - mse: 684.9565 - val_loss: 18.0139 - val_mse: 767.5306\n",
      "Epoch 2761/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 16.9798 - mse: 652.1086 - val_loss: 17.6074 - val_mse: 672.0658\n",
      "Epoch 2762/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.2923 - mse: 673.7656 - val_loss: 17.5588 - val_mse: 711.4110\n",
      "Epoch 2763/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3788 - mse: 682.4384 - val_loss: 17.8441 - val_mse: 745.1453\n",
      "Epoch 2764/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4910 - mse: 677.7388 - val_loss: 17.7560 - val_mse: 732.0648\n",
      "Epoch 2765/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4852 - mse: 682.3649 - val_loss: 18.3456 - val_mse: 700.6520\n",
      "Epoch 2766/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7439 - mse: 707.1179 - val_loss: 17.4741 - val_mse: 696.2773\n",
      "Epoch 2767/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0796 - mse: 664.1664 - val_loss: 17.7558 - val_mse: 666.1259\n",
      "Epoch 2768/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.1320 - mse: 667.5416 - val_loss: 17.7065 - val_mse: 682.0476\n",
      "Epoch 2769/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4375 - mse: 678.4746 - val_loss: 18.4321 - val_mse: 728.0135\n",
      "Epoch 2770/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3784 - mse: 679.2545 - val_loss: 18.6872 - val_mse: 701.9424\n",
      "Epoch 2771/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2419 - mse: 666.2394 - val_loss: 18.2813 - val_mse: 723.6265\n",
      "Epoch 2772/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3693 - mse: 681.8830 - val_loss: 17.7644 - val_mse: 694.0887\n",
      "Epoch 2773/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1026 - mse: 654.5312 - val_loss: 17.7765 - val_mse: 683.1941\n",
      "Epoch 2774/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2520 - mse: 671.0598 - val_loss: 17.8853 - val_mse: 669.2050\n",
      "Epoch 2775/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6550 - mse: 697.9709 - val_loss: 17.5121 - val_mse: 662.5176\n",
      "Epoch 2776/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2817 - mse: 671.6957 - val_loss: 18.8751 - val_mse: 723.8633\n",
      "Epoch 2777/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9938 - mse: 699.5818 - val_loss: 19.3921 - val_mse: 737.1851\n",
      "Epoch 2778/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6839 - mse: 699.2043 - val_loss: 17.8734 - val_mse: 737.0760\n",
      "Epoch 2779/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.1049 - mse: 662.0580 - val_loss: 17.5665 - val_mse: 703.5554\n",
      "Epoch 2780/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 16.8425 - mse: 653.3223 - val_loss: 17.5181 - val_mse: 683.5225\n",
      "Epoch 2781/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2521 - mse: 664.5168 - val_loss: 19.1187 - val_mse: 773.7819\n",
      "Epoch 2782/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 19.3661 - mse: 810.9897 - val_loss: 19.0396 - val_mse: 756.7269\n",
      "Epoch 2783/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9515 - mse: 725.5612 - val_loss: 17.6717 - val_mse: 710.6780\n",
      "Epoch 2784/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0321 - mse: 707.5588 - val_loss: 17.7367 - val_mse: 736.8118\n",
      "Epoch 2785/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4841 - mse: 694.5461 - val_loss: 18.9280 - val_mse: 747.9448\n",
      "Epoch 2786/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6872 - mse: 695.8074 - val_loss: 17.5530 - val_mse: 696.5790\n",
      "Epoch 2787/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.1162 - mse: 661.0501 - val_loss: 17.5228 - val_mse: 682.7650\n",
      "Epoch 2788/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6339 - mse: 697.3163 - val_loss: 17.8905 - val_mse: 672.3494\n",
      "Epoch 2789/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4794 - mse: 681.1324 - val_loss: 17.6803 - val_mse: 721.8719\n",
      "Epoch 2790/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1804 - mse: 665.6415 - val_loss: 17.9671 - val_mse: 704.6589\n",
      "Epoch 2791/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.9479 - mse: 718.3906 - val_loss: 17.9392 - val_mse: 690.8421\n",
      "Epoch 2792/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3031 - mse: 676.0715 - val_loss: 17.6917 - val_mse: 674.7853\n",
      "Epoch 2793/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 16.9395 - mse: 654.5947 - val_loss: 17.4893 - val_mse: 678.8545\n",
      "Epoch 2794/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 16.9973 - mse: 658.6571 - val_loss: 17.6895 - val_mse: 712.9092\n",
      "Epoch 2795/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6383 - mse: 687.4183 - val_loss: 17.8295 - val_mse: 720.9250\n",
      "Epoch 2796/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1479 - mse: 665.4561 - val_loss: 18.2878 - val_mse: 771.8692\n",
      "Epoch 2797/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7107 - mse: 698.3635 - val_loss: 17.6237 - val_mse: 715.4613\n",
      "Epoch 2798/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4508 - mse: 688.4352 - val_loss: 18.8091 - val_mse: 821.4105\n",
      "Epoch 2799/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.8309 - mse: 704.5900 - val_loss: 17.8518 - val_mse: 752.9108\n",
      "Epoch 2800/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.2743 - mse: 674.3088 - val_loss: 18.6871 - val_mse: 818.5048\n",
      "Epoch 2801/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.2727 - mse: 675.9282 - val_loss: 18.5358 - val_mse: 804.0643\n",
      "Epoch 2802/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4198 - mse: 689.0229 - val_loss: 18.5010 - val_mse: 770.5519\n",
      "Epoch 2803/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6439 - mse: 691.5551 - val_loss: 18.2082 - val_mse: 767.2299\n",
      "Epoch 2804/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4843 - mse: 692.3057 - val_loss: 18.2956 - val_mse: 694.4854\n",
      "Epoch 2805/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3323 - mse: 676.4797 - val_loss: 17.3882 - val_mse: 678.4227\n",
      "Epoch 2806/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3117 - mse: 678.6462 - val_loss: 17.8040 - val_mse: 749.6541\n",
      "Epoch 2807/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5045 - mse: 677.4370 - val_loss: 17.8784 - val_mse: 715.0390\n",
      "Epoch 2808/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5407 - mse: 684.7766 - val_loss: 17.3306 - val_mse: 693.7894\n",
      "Epoch 2809/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3680 - mse: 685.9141 - val_loss: 17.5666 - val_mse: 726.3873\n",
      "Epoch 2810/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2782 - mse: 672.1080 - val_loss: 18.3610 - val_mse: 802.9393\n",
      "Epoch 2811/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5038 - mse: 684.4813 - val_loss: 18.3382 - val_mse: 774.5467\n",
      "Epoch 2812/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5737 - mse: 689.6129 - val_loss: 18.3684 - val_mse: 795.2817\n",
      "Epoch 2813/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2868 - mse: 677.4282 - val_loss: 17.6126 - val_mse: 713.1996\n",
      "Epoch 2814/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0951 - mse: 663.9512 - val_loss: 17.5988 - val_mse: 693.1569\n",
      "Epoch 2815/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1865 - mse: 670.5001 - val_loss: 17.4355 - val_mse: 684.8216\n",
      "Epoch 2816/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7712 - mse: 706.4927 - val_loss: 18.6293 - val_mse: 808.6719\n",
      "Epoch 2817/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4111 - mse: 685.4778 - val_loss: 18.0093 - val_mse: 748.7095\n",
      "Epoch 2818/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2778 - mse: 670.9508 - val_loss: 18.6078 - val_mse: 768.2975\n",
      "Epoch 2819/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4320 - mse: 679.8193 - val_loss: 18.1577 - val_mse: 769.2892\n",
      "Epoch 2820/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5515 - mse: 767.1931 - val_loss: 18.3505 - val_mse: 725.6949\n",
      "Epoch 2821/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3002 - mse: 671.1876 - val_loss: 17.5662 - val_mse: 701.7734\n",
      "Epoch 2822/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9875 - mse: 654.5965 - val_loss: 17.5581 - val_mse: 688.9129\n",
      "Epoch 2823/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9244 - mse: 711.2109 - val_loss: 18.0128 - val_mse: 693.3563\n",
      "Epoch 2824/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6397 - mse: 746.7009 - val_loss: 18.0524 - val_mse: 784.2097\n",
      "Epoch 2825/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4769 - mse: 685.9980 - val_loss: 17.7161 - val_mse: 732.7292\n",
      "Epoch 2826/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0137 - mse: 662.2092 - val_loss: 17.4465 - val_mse: 687.4584\n",
      "Epoch 2827/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4321 - mse: 678.1616 - val_loss: 17.5760 - val_mse: 683.2194\n",
      "Epoch 2828/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.2262 - mse: 672.5877 - val_loss: 18.1081 - val_mse: 749.3793\n",
      "Epoch 2829/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2324 - mse: 733.3096 - val_loss: 18.7127 - val_mse: 734.4124\n",
      "Epoch 2830/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4324 - mse: 734.6069 - val_loss: 18.9814 - val_mse: 727.1810\n",
      "Epoch 2831/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7168 - mse: 701.9224 - val_loss: 18.2631 - val_mse: 772.9266\n",
      "Epoch 2832/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7091 - mse: 687.0081 - val_loss: 18.4119 - val_mse: 786.5867\n",
      "Epoch 2833/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1618 - mse: 674.8411 - val_loss: 17.8932 - val_mse: 734.3934\n",
      "Epoch 2834/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5729 - mse: 699.4346 - val_loss: 18.0206 - val_mse: 682.7599\n",
      "Epoch 2835/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9062 - mse: 652.8384 - val_loss: 17.9815 - val_mse: 691.4618\n",
      "Epoch 2836/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7878 - mse: 709.3580 - val_loss: 18.6094 - val_mse: 793.4199\n",
      "Epoch 2837/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.7509 - mse: 763.3184 - val_loss: 18.8983 - val_mse: 731.2138\n",
      "Epoch 2838/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6391 - mse: 693.6777 - val_loss: 17.7162 - val_mse: 729.4575\n",
      "Epoch 2839/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7113 - mse: 692.5024 - val_loss: 19.8981 - val_mse: 914.7355\n",
      "Epoch 2840/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7639 - mse: 714.3748 - val_loss: 17.6962 - val_mse: 735.4660\n",
      "Epoch 2841/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2332 - mse: 668.2977 - val_loss: 17.3976 - val_mse: 681.5911\n",
      "Epoch 2842/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1638 - mse: 668.5555 - val_loss: 17.8233 - val_mse: 669.8627\n",
      "Epoch 2843/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1395 - mse: 663.0773 - val_loss: 17.6057 - val_mse: 694.5790\n",
      "Epoch 2844/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1008 - mse: 662.4571 - val_loss: 17.9639 - val_mse: 697.3300\n",
      "Epoch 2845/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4954 - mse: 680.2459 - val_loss: 17.9791 - val_mse: 716.4539\n",
      "Epoch 2846/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2698 - mse: 683.7625 - val_loss: 17.8572 - val_mse: 705.8866\n",
      "Epoch 2847/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4234 - mse: 676.6518 - val_loss: 19.1767 - val_mse: 858.8267\n",
      "Epoch 2848/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7602 - mse: 706.0617 - val_loss: 17.9627 - val_mse: 754.7761\n",
      "Epoch 2849/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6135 - mse: 689.5009 - val_loss: 17.6208 - val_mse: 720.3109\n",
      "Epoch 2850/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3386 - mse: 675.9899 - val_loss: 17.8074 - val_mse: 744.9890\n",
      "Epoch 2851/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2648 - mse: 679.0945 - val_loss: 20.2342 - val_mse: 756.7321\n",
      "Epoch 2852/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9760 - mse: 723.1918 - val_loss: 18.9373 - val_mse: 699.8647\n",
      "Epoch 2853/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9969 - mse: 655.5101 - val_loss: 17.8905 - val_mse: 698.4938\n",
      "Epoch 2854/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4884 - mse: 682.6351 - val_loss: 18.9484 - val_mse: 834.9519\n",
      "Epoch 2855/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5248 - mse: 696.0731 - val_loss: 17.7675 - val_mse: 734.1065\n",
      "Epoch 2856/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9266 - mse: 706.9560 - val_loss: 18.0057 - val_mse: 728.8154\n",
      "Epoch 2857/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3519 - mse: 680.8181 - val_loss: 17.4183 - val_mse: 679.6929\n",
      "Epoch 2858/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4930 - mse: 689.3828 - val_loss: 17.6861 - val_mse: 721.5769\n",
      "Epoch 2859/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1702 - mse: 670.5004 - val_loss: 17.7373 - val_mse: 720.0268\n",
      "Epoch 2860/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1508 - mse: 667.5510 - val_loss: 17.4013 - val_mse: 676.4163\n",
      "Epoch 2861/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8022 - mse: 708.4599 - val_loss: 18.0273 - val_mse: 742.8289\n",
      "Epoch 2862/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5979 - mse: 703.3416 - val_loss: 18.4984 - val_mse: 687.2001\n",
      "Epoch 2863/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2394 - mse: 718.5359 - val_loss: 17.6362 - val_mse: 732.7935\n",
      "Epoch 2864/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3222 - mse: 685.7930 - val_loss: 18.1606 - val_mse: 775.5148\n",
      "Epoch 2865/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0203 - mse: 662.9355 - val_loss: 17.7267 - val_mse: 723.4559\n",
      "Epoch 2866/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1063 - mse: 663.6804 - val_loss: 17.7736 - val_mse: 666.7302\n",
      "Epoch 2867/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5662 - mse: 682.3310 - val_loss: 17.6444 - val_mse: 721.8062\n",
      "Epoch 2868/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3050 - mse: 676.1824 - val_loss: 18.3441 - val_mse: 777.9247\n",
      "Epoch 2869/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0502 - mse: 666.8121 - val_loss: 17.6870 - val_mse: 732.7148\n",
      "Epoch 2870/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7498 - mse: 691.0031 - val_loss: 17.7120 - val_mse: 720.6433\n",
      "Epoch 2871/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3831 - mse: 685.7518 - val_loss: 17.7140 - val_mse: 728.8316\n",
      "Epoch 2872/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.0948 - mse: 667.0069 - val_loss: 18.3498 - val_mse: 782.2846\n",
      "Epoch 2873/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5970 - mse: 699.5549 - val_loss: 19.0196 - val_mse: 863.1598\n",
      "Epoch 2874/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0514 - mse: 717.8982 - val_loss: 18.8046 - val_mse: 845.4142\n",
      "Epoch 2875/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2665 - mse: 730.4812 - val_loss: 18.1847 - val_mse: 682.3969\n",
      "Epoch 2876/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9737 - mse: 654.3569 - val_loss: 17.6794 - val_mse: 672.7333\n",
      "Epoch 2877/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1729 - mse: 668.6671 - val_loss: 17.6827 - val_mse: 687.7110\n",
      "Epoch 2878/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1486 - mse: 669.7584 - val_loss: 17.5970 - val_mse: 676.2001\n",
      "Epoch 2879/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4168 - mse: 684.2296 - val_loss: 18.6254 - val_mse: 717.6031\n",
      "Epoch 2880/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7850 - mse: 712.7394 - val_loss: 18.2924 - val_mse: 710.5654\n",
      "Epoch 2881/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7055 - mse: 703.5815 - val_loss: 18.2831 - val_mse: 727.7338\n",
      "Epoch 2882/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8570 - mse: 697.7812 - val_loss: 18.2393 - val_mse: 743.4157\n",
      "Epoch 2883/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5944 - mse: 702.4009 - val_loss: 17.4281 - val_mse: 686.0331\n",
      "Epoch 2884/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6707 - mse: 700.9426 - val_loss: 18.0463 - val_mse: 772.5517\n",
      "Epoch 2885/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8036 - mse: 692.8290 - val_loss: 17.9813 - val_mse: 754.9479\n",
      "Epoch 2886/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2352 - mse: 670.0134 - val_loss: 18.4089 - val_mse: 712.7035\n",
      "Epoch 2887/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4066 - mse: 750.5080 - val_loss: 19.2070 - val_mse: 807.6584\n",
      "Epoch 2888/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.7176 - mse: 743.9335 - val_loss: 18.0609 - val_mse: 741.3358\n",
      "Epoch 2889/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5254 - mse: 693.4452 - val_loss: 17.9365 - val_mse: 740.5786\n",
      "Epoch 2890/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3188 - mse: 676.1299 - val_loss: 17.5061 - val_mse: 697.2422\n",
      "Epoch 2891/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2543 - mse: 676.8434 - val_loss: 18.1042 - val_mse: 684.1194\n",
      "Epoch 2892/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8449 - mse: 698.4349 - val_loss: 17.5166 - val_mse: 699.4479\n",
      "Epoch 2893/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0686 - mse: 659.2786 - val_loss: 17.7365 - val_mse: 709.7993\n",
      "Epoch 2894/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0234 - mse: 720.1258 - val_loss: 19.6143 - val_mse: 731.1560\n",
      "Epoch 2895/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4101 - mse: 683.3323 - val_loss: 18.1203 - val_mse: 711.5898\n",
      "Epoch 2896/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5029 - mse: 693.8196 - val_loss: 17.7290 - val_mse: 708.5819\n",
      "Epoch 2897/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0641 - mse: 661.9237 - val_loss: 18.3393 - val_mse: 678.7437\n",
      "Epoch 2898/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1551 - mse: 667.6292 - val_loss: 17.8123 - val_mse: 724.1990\n",
      "Epoch 2899/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9942 - mse: 652.7911 - val_loss: 18.1644 - val_mse: 738.1824\n",
      "Epoch 2900/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1837 - mse: 672.5815 - val_loss: 17.7760 - val_mse: 680.2670\n",
      "Epoch 2901/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9030 - mse: 653.4496 - val_loss: 18.5010 - val_mse: 755.6300\n",
      "Epoch 2902/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.8157 - mse: 702.8137 - val_loss: 18.0013 - val_mse: 708.8053\n",
      "Epoch 2903/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0772 - mse: 662.1289 - val_loss: 17.6923 - val_mse: 722.5058\n",
      "Epoch 2904/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7092 - mse: 695.7135 - val_loss: 19.4613 - val_mse: 839.3171\n",
      "Epoch 2905/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7884 - mse: 712.3953 - val_loss: 17.5628 - val_mse: 704.1771\n",
      "Epoch 2906/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5636 - mse: 686.4222 - val_loss: 17.6937 - val_mse: 692.4416\n",
      "Epoch 2907/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1323 - mse: 662.9731 - val_loss: 18.9338 - val_mse: 714.2094\n",
      "Epoch 2908/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3735 - mse: 680.0251 - val_loss: 17.5101 - val_mse: 692.0378\n",
      "Epoch 2909/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0482 - mse: 661.5004 - val_loss: 17.5075 - val_mse: 701.4480\n",
      "Epoch 2910/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2180 - mse: 675.8551 - val_loss: 17.8179 - val_mse: 686.0146\n",
      "Epoch 2911/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0689 - mse: 655.1598 - val_loss: 17.6846 - val_mse: 702.6458\n",
      "Epoch 2912/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4977 - mse: 690.7293 - val_loss: 20.0096 - val_mse: 830.2444\n",
      "Epoch 2913/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.4636 - mse: 729.3458 - val_loss: 18.1588 - val_mse: 757.1213\n",
      "Epoch 2914/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5008 - mse: 688.1675 - val_loss: 17.5366 - val_mse: 689.7299\n",
      "Epoch 2915/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4328 - mse: 678.1680 - val_loss: 19.0396 - val_mse: 833.5229\n",
      "Epoch 2916/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7010 - mse: 706.8420 - val_loss: 17.4442 - val_mse: 685.0747\n",
      "Epoch 2917/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3701 - mse: 669.4326 - val_loss: 17.8250 - val_mse: 754.9111\n",
      "Epoch 2918/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8061 - mse: 653.6588 - val_loss: 17.4974 - val_mse: 686.7094\n",
      "Epoch 2919/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1969 - mse: 667.2614 - val_loss: 17.5971 - val_mse: 683.0503\n",
      "Epoch 2920/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1994 - mse: 677.8541 - val_loss: 17.5128 - val_mse: 724.2250\n",
      "Epoch 2921/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0536 - mse: 667.3595 - val_loss: 17.6171 - val_mse: 727.4276\n",
      "Epoch 2922/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1244 - mse: 656.1663 - val_loss: 17.4889 - val_mse: 691.6796\n",
      "Epoch 2923/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3095 - mse: 676.9913 - val_loss: 17.5316 - val_mse: 697.4857\n",
      "Epoch 2924/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8440 - mse: 701.2896 - val_loss: 17.8898 - val_mse: 770.0456\n",
      "Epoch 2925/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4594 - mse: 686.6130 - val_loss: 18.1104 - val_mse: 668.3136\n",
      "Epoch 2926/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0063 - mse: 656.2596 - val_loss: 17.6234 - val_mse: 711.3502\n",
      "Epoch 2927/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0055 - mse: 663.0113 - val_loss: 19.4190 - val_mse: 805.9437\n",
      "Epoch 2928/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8596 - mse: 707.6007 - val_loss: 18.6695 - val_mse: 717.1218\n",
      "Epoch 2929/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5669 - mse: 762.6599 - val_loss: 18.0799 - val_mse: 699.6738\n",
      "Epoch 2930/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1970 - mse: 665.2767 - val_loss: 18.0961 - val_mse: 682.2786\n",
      "Epoch 2931/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4724 - mse: 697.3694 - val_loss: 18.0989 - val_mse: 759.4459\n",
      "Epoch 2932/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.1679 - mse: 728.3052 - val_loss: 17.5415 - val_mse: 706.2423\n",
      "Epoch 2933/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0401 - mse: 666.1259 - val_loss: 18.2284 - val_mse: 717.9554\n",
      "Epoch 2934/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3272 - mse: 680.6727 - val_loss: 17.5716 - val_mse: 688.8343\n",
      "Epoch 2935/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7527 - mse: 644.4796 - val_loss: 17.6570 - val_mse: 670.5179\n",
      "Epoch 2936/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0169 - mse: 654.6733 - val_loss: 17.8162 - val_mse: 700.5806\n",
      "Epoch 2937/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1549 - mse: 670.5579 - val_loss: 17.8130 - val_mse: 678.1506\n",
      "Epoch 2938/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9663 - mse: 720.4156 - val_loss: 18.2038 - val_mse: 692.2013\n",
      "Epoch 2939/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8949 - mse: 716.2376 - val_loss: 17.8945 - val_mse: 741.6223\n",
      "Epoch 2940/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2379 - mse: 670.2480 - val_loss: 18.8497 - val_mse: 711.0925\n",
      "Epoch 2941/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8163 - mse: 697.8869 - val_loss: 17.8734 - val_mse: 694.2029\n",
      "Epoch 2942/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4035 - mse: 692.2275 - val_loss: 19.8635 - val_mse: 876.8169\n",
      "Epoch 2943/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2841 - mse: 672.0515 - val_loss: 17.7565 - val_mse: 703.3311\n",
      "Epoch 2944/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6510 - mse: 686.5999 - val_loss: 18.6229 - val_mse: 779.0277\n",
      "Epoch 2945/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5835 - mse: 692.9224 - val_loss: 17.5923 - val_mse: 688.5678\n",
      "Epoch 2946/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2952 - mse: 672.3022 - val_loss: 18.1448 - val_mse: 772.1976\n",
      "Epoch 2947/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9781 - mse: 662.3931 - val_loss: 18.1251 - val_mse: 730.1718\n",
      "Epoch 2948/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0582 - mse: 655.9219 - val_loss: 18.0543 - val_mse: 720.7567\n",
      "Epoch 2949/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1019 - mse: 665.1888 - val_loss: 17.4944 - val_mse: 715.4736\n",
      "Epoch 2950/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9090 - mse: 652.2849 - val_loss: 17.6619 - val_mse: 694.2289\n",
      "Epoch 2951/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.1875 - mse: 725.7917 - val_loss: 18.3505 - val_mse: 695.4431\n",
      "Epoch 2952/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1837 - mse: 672.0182 - val_loss: 17.9886 - val_mse: 710.9385\n",
      "Epoch 2953/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0319 - mse: 726.9994 - val_loss: 20.6798 - val_mse: 967.4805\n",
      "Epoch 2954/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.4663 - mse: 757.2574 - val_loss: 17.6241 - val_mse: 716.3206\n",
      "Epoch 2955/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1925 - mse: 669.0747 - val_loss: 18.1069 - val_mse: 690.1471\n",
      "Epoch 2956/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1708 - mse: 668.9933 - val_loss: 17.4904 - val_mse: 699.5208\n",
      "Epoch 2957/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9917 - mse: 655.5502 - val_loss: 17.5561 - val_mse: 680.3491\n",
      "Epoch 2958/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9114 - mse: 653.2921 - val_loss: 17.5586 - val_mse: 687.3470\n",
      "Epoch 2959/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2081 - mse: 672.0851 - val_loss: 17.4500 - val_mse: 688.7177\n",
      "Epoch 2960/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2755 - mse: 673.3437 - val_loss: 18.0653 - val_mse: 725.6675\n",
      "Epoch 2961/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9377 - mse: 706.5083 - val_loss: 17.6993 - val_mse: 734.3771\n",
      "Epoch 2962/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6866 - mse: 699.3405 - val_loss: 17.9816 - val_mse: 734.4536\n",
      "Epoch 2963/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3065 - mse: 752.6570 - val_loss: 17.5112 - val_mse: 716.9167\n",
      "Epoch 2964/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0540 - mse: 666.1473 - val_loss: 17.5161 - val_mse: 707.3873\n",
      "Epoch 2965/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7193 - mse: 648.2562 - val_loss: 17.5026 - val_mse: 671.4426\n",
      "Epoch 2966/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9174 - mse: 651.4170 - val_loss: 17.5547 - val_mse: 675.9706\n",
      "Epoch 2967/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9257 - mse: 652.8502 - val_loss: 17.6585 - val_mse: 691.7104\n",
      "Epoch 2968/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2407 - mse: 674.4369 - val_loss: 18.2017 - val_mse: 731.3311\n",
      "Epoch 2969/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0868 - mse: 660.7861 - val_loss: 18.3892 - val_mse: 692.7625\n",
      "Epoch 2970/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0851 - mse: 659.2026 - val_loss: 18.0933 - val_mse: 757.2848\n",
      "Epoch 2971/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.6739 - mse: 697.7302 - val_loss: 18.6156 - val_mse: 826.0641\n",
      "Epoch 2972/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.2694 - mse: 665.1628 - val_loss: 17.5071 - val_mse: 702.0844\n",
      "Epoch 2973/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2087 - mse: 675.1130 - val_loss: 17.7844 - val_mse: 736.4560\n",
      "Epoch 2974/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9316 - mse: 651.4182 - val_loss: 17.5325 - val_mse: 688.0356\n",
      "Epoch 2975/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2827 - mse: 671.1923 - val_loss: 18.4689 - val_mse: 704.2256\n",
      "Epoch 2976/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.2500 - mse: 667.3815 - val_loss: 17.7707 - val_mse: 693.3958\n",
      "Epoch 2977/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.5527 - mse: 690.7901 - val_loss: 19.0313 - val_mse: 739.7840\n",
      "Epoch 2978/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.5413 - mse: 738.3173 - val_loss: 17.6834 - val_mse: 716.2667\n",
      "Epoch 2979/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2351 - mse: 680.8234 - val_loss: 17.9522 - val_mse: 742.6155\n",
      "Epoch 2980/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1548 - mse: 675.0490 - val_loss: 17.4935 - val_mse: 695.7915\n",
      "Epoch 2981/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8331 - mse: 644.8382 - val_loss: 17.7254 - val_mse: 683.1896\n",
      "Epoch 2982/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3898 - mse: 687.9855 - val_loss: 17.8648 - val_mse: 699.3642\n",
      "Epoch 2983/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2943 - mse: 677.3976 - val_loss: 18.1358 - val_mse: 707.5893\n",
      "Epoch 2984/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5259 - mse: 684.4467 - val_loss: 17.8941 - val_mse: 748.8943\n",
      "Epoch 2985/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2660 - mse: 675.5011 - val_loss: 17.5325 - val_mse: 708.5295\n",
      "Epoch 2986/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4894 - mse: 687.8004 - val_loss: 17.4052 - val_mse: 688.5724\n",
      "Epoch 2987/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1827 - mse: 670.3558 - val_loss: 17.6555 - val_mse: 680.9921\n",
      "Epoch 2988/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1776 - mse: 672.8345 - val_loss: 18.0244 - val_mse: 661.4445\n",
      "Epoch 2989/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5986 - mse: 691.2250 - val_loss: 18.3911 - val_mse: 760.5087\n",
      "Epoch 2990/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4704 - mse: 676.1794 - val_loss: 18.7571 - val_mse: 825.6371\n",
      "Epoch 2991/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8209 - mse: 706.7473 - val_loss: 17.6140 - val_mse: 694.0732\n",
      "Epoch 2992/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1555 - mse: 667.2128 - val_loss: 17.4518 - val_mse: 699.2148\n",
      "Epoch 2993/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.8080 - mse: 650.3138 - val_loss: 18.0674 - val_mse: 701.9018\n",
      "Epoch 2994/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2848 - mse: 681.0974 - val_loss: 18.3650 - val_mse: 707.4262\n",
      "Epoch 2995/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9038 - mse: 651.6420 - val_loss: 17.6626 - val_mse: 724.8030\n",
      "Epoch 2996/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1590 - mse: 666.1783 - val_loss: 17.9521 - val_mse: 693.8512\n",
      "Epoch 2997/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1739 - mse: 663.9053 - val_loss: 17.5710 - val_mse: 727.7850\n",
      "Epoch 2998/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8781 - mse: 723.6009 - val_loss: 18.4421 - val_mse: 802.3138\n",
      "Epoch 2999/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4023 - mse: 685.0845 - val_loss: 18.7519 - val_mse: 832.7484\n",
      "Epoch 3000/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4640 - mse: 686.4639 - val_loss: 17.7009 - val_mse: 749.1019\n",
      "Epoch 3001/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1682 - mse: 669.4304 - val_loss: 17.5142 - val_mse: 698.3990\n",
      "Epoch 3002/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0353 - mse: 660.3459 - val_loss: 17.5941 - val_mse: 709.2642\n",
      "Epoch 3003/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6308 - mse: 688.9796 - val_loss: 17.8928 - val_mse: 752.1354\n",
      "Epoch 3004/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9923 - mse: 721.9894 - val_loss: 20.2384 - val_mse: 950.0188\n",
      "Epoch 3005/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9127 - mse: 715.8134 - val_loss: 17.7873 - val_mse: 695.6866\n",
      "Epoch 3006/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3193 - mse: 676.0663 - val_loss: 17.4599 - val_mse: 689.8689\n",
      "Epoch 3007/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7913 - mse: 649.2253 - val_loss: 17.6317 - val_mse: 686.3268\n",
      "Epoch 3008/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0497 - mse: 654.3219 - val_loss: 18.1404 - val_mse: 747.3092\n",
      "Epoch 3009/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5134 - mse: 699.8118 - val_loss: 17.4295 - val_mse: 713.1819\n",
      "Epoch 3010/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3706 - mse: 671.7511 - val_loss: 18.0948 - val_mse: 779.5471\n",
      "Epoch 3011/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3044 - mse: 677.3600 - val_loss: 18.4975 - val_mse: 737.1028\n",
      "Epoch 3012/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5088 - mse: 692.0184 - val_loss: 17.7406 - val_mse: 687.0530\n",
      "Epoch 3013/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4488 - mse: 693.9472 - val_loss: 18.0098 - val_mse: 700.2200\n",
      "Epoch 3014/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3177 - mse: 672.7737 - val_loss: 18.3141 - val_mse: 690.2357\n",
      "Epoch 3015/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1257 - mse: 664.6749 - val_loss: 17.7902 - val_mse: 672.7487\n",
      "Epoch 3016/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2435 - mse: 664.0738 - val_loss: 18.8670 - val_mse: 715.2884\n",
      "Epoch 3017/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3303 - mse: 667.1779 - val_loss: 17.4659 - val_mse: 701.1821\n",
      "Epoch 3018/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3494 - mse: 671.0497 - val_loss: 17.8420 - val_mse: 699.1655\n",
      "Epoch 3019/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5829 - mse: 695.6113 - val_loss: 18.2045 - val_mse: 785.7473\n",
      "Epoch 3020/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.1190 - mse: 723.0811 - val_loss: 18.4781 - val_mse: 740.0390\n",
      "Epoch 3021/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7716 - mse: 706.5922 - val_loss: 19.0700 - val_mse: 733.8025\n",
      "Epoch 3022/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5067 - mse: 743.7808 - val_loss: 18.0649 - val_mse: 696.9844\n",
      "Epoch 3023/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6809 - mse: 698.2826 - val_loss: 18.2501 - val_mse: 796.6990\n",
      "Epoch 3024/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4393 - mse: 682.5620 - val_loss: 17.7347 - val_mse: 709.9374\n",
      "Epoch 3025/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1354 - mse: 675.0528 - val_loss: 17.8747 - val_mse: 686.4366\n",
      "Epoch 3026/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2569 - mse: 673.4449 - val_loss: 18.1588 - val_mse: 694.7181\n",
      "Epoch 3027/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5812 - mse: 685.3342 - val_loss: 19.0359 - val_mse: 800.8127\n",
      "Epoch 3028/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0396 - mse: 729.1879 - val_loss: 17.6749 - val_mse: 731.4488\n",
      "Epoch 3029/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8494 - mse: 699.6884 - val_loss: 18.7424 - val_mse: 826.1709\n",
      "Epoch 3030/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3545 - mse: 695.4074 - val_loss: 18.1135 - val_mse: 692.4305\n",
      "Epoch 3031/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3249 - mse: 679.9798 - val_loss: 17.7611 - val_mse: 688.0580\n",
      "Epoch 3032/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6970 - mse: 699.7771 - val_loss: 17.5891 - val_mse: 658.8539\n",
      "Epoch 3033/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1644 - mse: 665.6561 - val_loss: 19.9302 - val_mse: 874.6444\n",
      "Epoch 3034/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.1124 - mse: 725.9376 - val_loss: 18.2602 - val_mse: 698.8464\n",
      "Epoch 3035/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6288 - mse: 704.0315 - val_loss: 18.4587 - val_mse: 702.2079\n",
      "Epoch 3036/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5345 - mse: 677.9730 - val_loss: 17.6558 - val_mse: 677.4803\n",
      "Epoch 3037/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5341 - mse: 693.8520 - val_loss: 18.5618 - val_mse: 800.0524\n",
      "Epoch 3038/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4337 - mse: 692.9055 - val_loss: 19.1463 - val_mse: 827.1813\n",
      "Epoch 3039/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4636 - mse: 685.2745 - val_loss: 17.7061 - val_mse: 718.0134\n",
      "Epoch 3040/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2208 - mse: 667.8679 - val_loss: 17.8500 - val_mse: 694.4148\n",
      "Epoch 3041/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0696 - mse: 668.7135 - val_loss: 17.8843 - val_mse: 731.0243\n",
      "Epoch 3042/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8611 - mse: 712.7889 - val_loss: 17.6369 - val_mse: 707.5194\n",
      "Epoch 3043/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2498 - mse: 675.6342 - val_loss: 17.8113 - val_mse: 735.6903\n",
      "Epoch 3044/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9863 - mse: 658.4905 - val_loss: 17.9355 - val_mse: 689.7238\n",
      "Epoch 3045/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0241 - mse: 710.5860 - val_loss: 18.3908 - val_mse: 798.8781\n",
      "Epoch 3046/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5781 - mse: 685.1848 - val_loss: 18.3374 - val_mse: 766.3297\n",
      "Epoch 3047/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6243 - mse: 695.1920 - val_loss: 17.4774 - val_mse: 703.5887\n",
      "Epoch 3048/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4427 - mse: 679.2712 - val_loss: 18.9360 - val_mse: 818.3765\n",
      "Epoch 3049/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1797 - mse: 675.2535 - val_loss: 17.6125 - val_mse: 669.8174\n",
      "Epoch 3050/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3747 - mse: 666.6946 - val_loss: 18.2065 - val_mse: 696.7382\n",
      "Epoch 3051/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8876 - mse: 656.3167 - val_loss: 17.5574 - val_mse: 727.7190\n",
      "Epoch 3052/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8083 - mse: 651.9649 - val_loss: 17.6011 - val_mse: 691.3956\n",
      "Epoch 3053/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5446 - mse: 681.1842 - val_loss: 17.9217 - val_mse: 709.2175\n",
      "Epoch 3054/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0257 - mse: 660.7895 - val_loss: 17.9044 - val_mse: 725.1443\n",
      "Epoch 3055/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1890 - mse: 661.9356 - val_loss: 17.5812 - val_mse: 724.3270\n",
      "Epoch 3056/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3014 - mse: 673.5257 - val_loss: 18.1142 - val_mse: 682.0430\n",
      "Epoch 3057/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.7480 - mse: 696.4080 - val_loss: 18.5362 - val_mse: 694.4700\n",
      "Epoch 3058/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0821 - mse: 659.7302 - val_loss: 17.4330 - val_mse: 700.7095\n",
      "Epoch 3059/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.8741 - mse: 650.3105 - val_loss: 17.8342 - val_mse: 692.9114\n",
      "Epoch 3060/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.3130 - mse: 741.3241 - val_loss: 18.6598 - val_mse: 752.5777\n",
      "Epoch 3061/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.5064 - mse: 814.8386 - val_loss: 19.6819 - val_mse: 914.6644\n",
      "Epoch 3062/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9712 - mse: 725.6399 - val_loss: 17.7437 - val_mse: 672.8722\n",
      "Epoch 3063/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1840 - mse: 666.4374 - val_loss: 18.0419 - val_mse: 682.5325\n",
      "Epoch 3064/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7521 - mse: 703.0663 - val_loss: 17.5371 - val_mse: 693.2823\n",
      "Epoch 3065/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1336 - mse: 669.4370 - val_loss: 18.5637 - val_mse: 800.5222\n",
      "Epoch 3066/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1969 - mse: 676.0043 - val_loss: 17.7236 - val_mse: 724.3716\n",
      "Epoch 3067/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9320 - mse: 649.8842 - val_loss: 18.0921 - val_mse: 783.8751\n",
      "Epoch 3068/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1362 - mse: 662.0270 - val_loss: 17.4574 - val_mse: 690.4587\n",
      "Epoch 3069/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0429 - mse: 658.7863 - val_loss: 17.6890 - val_mse: 710.4304\n",
      "Epoch 3070/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2965 - mse: 679.7511 - val_loss: 17.7757 - val_mse: 751.7934\n",
      "Epoch 3071/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6319 - mse: 696.5239 - val_loss: 17.9641 - val_mse: 751.4363\n",
      "Epoch 3072/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0578 - mse: 659.3502 - val_loss: 17.4956 - val_mse: 703.0317\n",
      "Epoch 3073/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8219 - mse: 647.0912 - val_loss: 17.5501 - val_mse: 709.0502\n",
      "Epoch 3074/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2456 - mse: 672.7794 - val_loss: 17.6572 - val_mse: 674.8480\n",
      "Epoch 3075/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5809 - mse: 688.3361 - val_loss: 19.0271 - val_mse: 836.9625\n",
      "Epoch 3076/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8669 - mse: 699.3416 - val_loss: 18.5296 - val_mse: 798.9011\n",
      "Epoch 3077/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1960 - mse: 679.0685 - val_loss: 17.5890 - val_mse: 707.2688\n",
      "Epoch 3078/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9293 - mse: 701.8776 - val_loss: 17.9344 - val_mse: 753.5389\n",
      "Epoch 3079/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2500 - mse: 672.2982 - val_loss: 17.8683 - val_mse: 699.2261\n",
      "Epoch 3080/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2898 - mse: 683.9720 - val_loss: 17.4982 - val_mse: 717.5587\n",
      "Epoch 3081/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8272 - mse: 656.6586 - val_loss: 17.6209 - val_mse: 673.5751\n",
      "Epoch 3082/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7054 - mse: 641.9706 - val_loss: 17.4353 - val_mse: 701.1339\n",
      "Epoch 3083/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0082 - mse: 657.0671 - val_loss: 18.6786 - val_mse: 763.8198\n",
      "Epoch 3084/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5239 - mse: 693.8779 - val_loss: 17.3909 - val_mse: 696.6060\n",
      "Epoch 3085/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8835 - mse: 652.5078 - val_loss: 17.4491 - val_mse: 710.3960\n",
      "Epoch 3086/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2409 - mse: 755.1421 - val_loss: 19.6878 - val_mse: 797.3441\n",
      "Epoch 3087/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9869 - mse: 719.6834 - val_loss: 17.5276 - val_mse: 673.9871\n",
      "Epoch 3088/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1722 - mse: 672.3297 - val_loss: 17.3864 - val_mse: 685.5903\n",
      "Epoch 3089/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8407 - mse: 643.6959 - val_loss: 17.6066 - val_mse: 667.0004\n",
      "Epoch 3090/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9922 - mse: 646.5257 - val_loss: 17.7986 - val_mse: 709.2364\n",
      "Epoch 3091/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9353 - mse: 654.9588 - val_loss: 17.8365 - val_mse: 746.1010\n",
      "Epoch 3092/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0413 - mse: 656.9777 - val_loss: 17.5800 - val_mse: 721.4837\n",
      "Epoch 3093/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0841 - mse: 668.0968 - val_loss: 17.9522 - val_mse: 705.0079\n",
      "Epoch 3094/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3680 - mse: 680.7697 - val_loss: 17.7152 - val_mse: 750.1056\n",
      "Epoch 3095/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.5140 - mse: 686.8553 - val_loss: 17.7295 - val_mse: 699.7540\n",
      "Epoch 3096/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0407 - mse: 661.1227 - val_loss: 17.6961 - val_mse: 702.3986\n",
      "Epoch 3097/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9465 - mse: 656.0219 - val_loss: 17.8879 - val_mse: 740.3122\n",
      "Epoch 3098/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2567 - mse: 672.6746 - val_loss: 18.6067 - val_mse: 784.2573\n",
      "Epoch 3099/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1830 - mse: 672.1830 - val_loss: 17.5810 - val_mse: 692.4931\n",
      "Epoch 3100/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1951 - mse: 666.6915 - val_loss: 17.5215 - val_mse: 668.1453\n",
      "Epoch 3101/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0501 - mse: 722.1018 - val_loss: 19.1042 - val_mse: 787.0648\n",
      "Epoch 3102/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.8535 - mse: 705.7810 - val_loss: 18.4287 - val_mse: 725.3192\n",
      "Epoch 3103/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.6982 - mse: 691.1402 - val_loss: 18.2162 - val_mse: 792.0178\n",
      "Epoch 3104/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2936 - mse: 672.3734 - val_loss: 18.1429 - val_mse: 781.4227\n",
      "Epoch 3105/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5246 - mse: 691.7674 - val_loss: 17.3233 - val_mse: 681.7798\n",
      "Epoch 3106/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4533 - mse: 699.8743 - val_loss: 18.2439 - val_mse: 723.9550\n",
      "Epoch 3107/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.9667 - mse: 782.0052 - val_loss: 18.8101 - val_mse: 813.4750\n",
      "Epoch 3108/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.8554 - mse: 776.9841 - val_loss: 18.7159 - val_mse: 821.6151\n",
      "Epoch 3109/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7389 - mse: 765.5369 - val_loss: 18.8466 - val_mse: 770.4033\n",
      "Epoch 3110/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.1679 - mse: 734.7319 - val_loss: 18.3571 - val_mse: 791.1180\n",
      "Epoch 3111/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8991 - mse: 700.5383 - val_loss: 18.4324 - val_mse: 805.0967\n",
      "Epoch 3112/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6829 - mse: 707.1763 - val_loss: 17.4321 - val_mse: 699.4495\n",
      "Epoch 3113/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4740 - mse: 685.4111 - val_loss: 17.7564 - val_mse: 688.2020\n",
      "Epoch 3114/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3434 - mse: 684.6351 - val_loss: 17.6781 - val_mse: 669.5682\n",
      "Epoch 3115/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3575 - mse: 684.0286 - val_loss: 17.9767 - val_mse: 704.6587\n",
      "Epoch 3116/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3685 - mse: 684.8023 - val_loss: 18.2874 - val_mse: 739.9971\n",
      "Epoch 3117/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4696 - mse: 687.2117 - val_loss: 18.2491 - val_mse: 679.0878\n",
      "Epoch 3118/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.0600 - mse: 656.7444 - val_loss: 18.6410 - val_mse: 814.5677\n",
      "Epoch 3119/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.8097 - mse: 779.9816 - val_loss: 19.3061 - val_mse: 755.5094\n",
      "Epoch 3120/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1466 - mse: 724.0575 - val_loss: 17.6077 - val_mse: 709.6146\n",
      "Epoch 3121/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5461 - mse: 701.4991 - val_loss: 18.1808 - val_mse: 725.1791\n",
      "Epoch 3122/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6731 - mse: 690.0078 - val_loss: 18.7808 - val_mse: 813.6292\n",
      "Epoch 3123/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2959 - mse: 678.6564 - val_loss: 17.4969 - val_mse: 714.0836\n",
      "Epoch 3124/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0891 - mse: 671.4791 - val_loss: 18.0942 - val_mse: 732.6193\n",
      "Epoch 3125/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.8825 - mse: 650.5839 - val_loss: 17.7842 - val_mse: 698.8606\n",
      "Epoch 3126/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2545 - mse: 666.2734 - val_loss: 17.9665 - val_mse: 684.3531\n",
      "Epoch 3127/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3293 - mse: 680.0113 - val_loss: 17.6581 - val_mse: 702.4194\n",
      "Epoch 3128/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9853 - mse: 658.9232 - val_loss: 17.9483 - val_mse: 681.8828\n",
      "Epoch 3129/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.3764 - mse: 743.9672 - val_loss: 18.5794 - val_mse: 788.3186\n",
      "Epoch 3130/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6076 - mse: 694.4048 - val_loss: 17.9977 - val_mse: 735.2953\n",
      "Epoch 3131/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4943 - mse: 695.3828 - val_loss: 18.9192 - val_mse: 698.2886\n",
      "Epoch 3132/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3266 - mse: 681.2050 - val_loss: 17.6470 - val_mse: 673.4516\n",
      "Epoch 3133/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3956 - mse: 678.8596 - val_loss: 17.6389 - val_mse: 714.3489\n",
      "Epoch 3134/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1019 - mse: 672.4827 - val_loss: 17.7488 - val_mse: 687.1553\n",
      "Epoch 3135/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0436 - mse: 658.9541 - val_loss: 17.8904 - val_mse: 731.9327\n",
      "Epoch 3136/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2579 - mse: 680.3800 - val_loss: 18.4069 - val_mse: 778.5669\n",
      "Epoch 3137/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8796 - mse: 708.8662 - val_loss: 17.5172 - val_mse: 696.0200\n",
      "Epoch 3138/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8795 - mse: 712.8462 - val_loss: 19.3482 - val_mse: 866.9197\n",
      "Epoch 3139/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0149 - mse: 726.1954 - val_loss: 17.5492 - val_mse: 693.5220\n",
      "Epoch 3140/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3968 - mse: 686.4236 - val_loss: 17.5835 - val_mse: 720.7876\n",
      "Epoch 3141/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9621 - mse: 659.2689 - val_loss: 17.4889 - val_mse: 680.2825\n",
      "Epoch 3142/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6771 - mse: 702.1384 - val_loss: 17.8587 - val_mse: 665.4106\n",
      "Epoch 3143/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2120 - mse: 665.7589 - val_loss: 17.3792 - val_mse: 700.8936\n",
      "Epoch 3144/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7858 - mse: 642.2338 - val_loss: 17.7108 - val_mse: 682.5862\n",
      "Epoch 3145/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0272 - mse: 657.4053 - val_loss: 18.0415 - val_mse: 692.2704\n",
      "Epoch 3146/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6171 - mse: 700.7781 - val_loss: 18.3331 - val_mse: 697.7610\n",
      "Epoch 3147/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1272 - mse: 662.2117 - val_loss: 17.6106 - val_mse: 737.0442\n",
      "Epoch 3148/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8373 - mse: 648.7062 - val_loss: 17.3235 - val_mse: 696.3857\n",
      "Epoch 3149/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7247 - mse: 690.9628 - val_loss: 18.8608 - val_mse: 805.8057\n",
      "Epoch 3150/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4745 - mse: 685.3563 - val_loss: 17.6019 - val_mse: 700.9374\n",
      "Epoch 3151/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1516 - mse: 670.3787 - val_loss: 18.0175 - val_mse: 768.6894\n",
      "Epoch 3152/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6971 - mse: 700.0494 - val_loss: 18.2434 - val_mse: 734.2028\n",
      "Epoch 3153/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.3300 - mse: 681.6398 - val_loss: 17.3449 - val_mse: 688.0831\n",
      "Epoch 3154/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2359 - mse: 676.8650 - val_loss: 19.1760 - val_mse: 843.2683\n",
      "Epoch 3155/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0622 - mse: 725.2260 - val_loss: 18.6399 - val_mse: 768.5892\n",
      "Epoch 3156/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4998 - mse: 691.4662 - val_loss: 17.4331 - val_mse: 706.4045\n",
      "Epoch 3157/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8572 - mse: 648.5432 - val_loss: 18.0986 - val_mse: 700.7448\n",
      "Epoch 3158/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0691 - mse: 667.7956 - val_loss: 18.5631 - val_mse: 791.8004\n",
      "Epoch 3159/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3586 - mse: 680.8016 - val_loss: 17.6491 - val_mse: 710.0667\n",
      "Epoch 3160/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5320 - mse: 693.5571 - val_loss: 17.8313 - val_mse: 733.5958\n",
      "Epoch 3161/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.9113 - mse: 714.1741 - val_loss: 18.0529 - val_mse: 711.2571\n",
      "Epoch 3162/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5945 - mse: 683.0138 - val_loss: 17.8784 - val_mse: 676.9103\n",
      "Epoch 3163/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7017 - mse: 703.0149 - val_loss: 18.2461 - val_mse: 695.5455\n",
      "Epoch 3164/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2172 - mse: 672.1762 - val_loss: 17.8837 - val_mse: 697.2527\n",
      "Epoch 3165/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1576 - mse: 668.4819 - val_loss: 18.6865 - val_mse: 822.9042\n",
      "Epoch 3166/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6994 - mse: 701.3514 - val_loss: 18.3293 - val_mse: 786.3761\n",
      "Epoch 3167/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7619 - mse: 707.5051 - val_loss: 17.7477 - val_mse: 696.1353\n",
      "Epoch 3168/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1066 - mse: 668.0423 - val_loss: 17.7919 - val_mse: 675.2183\n",
      "Epoch 3169/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4550 - mse: 679.7351 - val_loss: 17.4789 - val_mse: 684.7953\n",
      "Epoch 3170/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9804 - mse: 656.8513 - val_loss: 17.4440 - val_mse: 692.4945\n",
      "Epoch 3171/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9587 - mse: 653.8622 - val_loss: 17.5030 - val_mse: 694.7859\n",
      "Epoch 3172/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0387 - mse: 660.2745 - val_loss: 17.5162 - val_mse: 701.2755\n",
      "Epoch 3173/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1941 - mse: 679.9046 - val_loss: 20.9952 - val_mse: 993.7564\n",
      "Epoch 3174/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.5809 - mse: 749.5828 - val_loss: 18.2429 - val_mse: 698.0159\n",
      "Epoch 3175/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4221 - mse: 682.3701 - val_loss: 17.4394 - val_mse: 708.4416\n",
      "Epoch 3176/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5703 - mse: 686.3917 - val_loss: 19.7078 - val_mse: 892.4002\n",
      "Epoch 3177/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0939 - mse: 739.7015 - val_loss: 18.4156 - val_mse: 730.5703\n",
      "Epoch 3178/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.4204 - mse: 737.0096 - val_loss: 18.6712 - val_mse: 816.7743\n",
      "Epoch 3179/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5400 - mse: 691.3978 - val_loss: 18.9843 - val_mse: 843.1109\n",
      "Epoch 3180/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8788 - mse: 705.2003 - val_loss: 20.0859 - val_mse: 938.9971\n",
      "Epoch 3181/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.6793 - mse: 761.6703 - val_loss: 18.9435 - val_mse: 835.4281\n",
      "Epoch 3182/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4358 - mse: 678.1226 - val_loss: 17.4520 - val_mse: 698.3533\n",
      "Epoch 3183/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0527 - mse: 663.5148 - val_loss: 17.8595 - val_mse: 695.1276\n",
      "Epoch 3184/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8871 - mse: 652.6301 - val_loss: 17.7736 - val_mse: 673.2139\n",
      "Epoch 3185/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3538 - mse: 684.2194 - val_loss: 18.3613 - val_mse: 744.8333\n",
      "Epoch 3186/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2444 - mse: 739.8894 - val_loss: 18.0497 - val_mse: 765.2507\n",
      "Epoch 3187/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6880 - mse: 698.3420 - val_loss: 17.8820 - val_mse: 720.7641\n",
      "Epoch 3188/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.9954 - mse: 718.4086 - val_loss: 19.3938 - val_mse: 869.6895\n",
      "Epoch 3189/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.5277 - mse: 768.8215 - val_loss: 18.2390 - val_mse: 785.4327\n",
      "Epoch 3190/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6875 - mse: 701.6664 - val_loss: 17.7043 - val_mse: 699.2648\n",
      "Epoch 3191/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2077 - mse: 678.3156 - val_loss: 18.7598 - val_mse: 704.6032\n",
      "Epoch 3192/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1860 - mse: 672.0024 - val_loss: 18.3631 - val_mse: 739.4280\n",
      "Epoch 3193/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3858 - mse: 682.3788 - val_loss: 17.6369 - val_mse: 700.5830\n",
      "Epoch 3194/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4411 - mse: 689.3337 - val_loss: 17.5590 - val_mse: 687.7393\n",
      "Epoch 3195/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1530 - mse: 665.7524 - val_loss: 17.5321 - val_mse: 689.5914\n",
      "Epoch 3196/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1501 - mse: 669.7568 - val_loss: 17.9178 - val_mse: 696.4877\n",
      "Epoch 3197/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4083 - mse: 683.5408 - val_loss: 18.6123 - val_mse: 734.0638\n",
      "Epoch 3198/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9676 - mse: 710.2070 - val_loss: 17.9597 - val_mse: 772.4044\n",
      "Epoch 3199/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3461 - mse: 678.8398 - val_loss: 18.2729 - val_mse: 742.2240\n",
      "Epoch 3200/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3226 - mse: 674.3873 - val_loss: 18.5064 - val_mse: 708.3521\n",
      "Epoch 3201/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.6280 - mse: 699.8864 - val_loss: 17.6540 - val_mse: 694.1960\n",
      "Epoch 3202/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3313 - mse: 678.3362 - val_loss: 18.0917 - val_mse: 668.4865\n",
      "Epoch 3203/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.9144 - mse: 714.8438 - val_loss: 18.5630 - val_mse: 727.0754\n",
      "Epoch 3204/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4873 - mse: 677.3405 - val_loss: 17.8436 - val_mse: 735.5509\n",
      "Epoch 3205/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5408 - mse: 686.4812 - val_loss: 17.6460 - val_mse: 718.6635\n",
      "Epoch 3206/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.3601 - mse: 737.3113 - val_loss: 18.6269 - val_mse: 779.3600\n",
      "Epoch 3207/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5116 - mse: 698.7971 - val_loss: 17.8302 - val_mse: 723.9001\n",
      "Epoch 3208/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0594 - mse: 720.4656 - val_loss: 17.6256 - val_mse: 701.1807\n",
      "Epoch 3209/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3512 - mse: 674.8928 - val_loss: 17.8917 - val_mse: 713.3859\n",
      "Epoch 3210/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9650 - mse: 655.7214 - val_loss: 17.3940 - val_mse: 685.0365\n",
      "Epoch 3211/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8122 - mse: 644.4294 - val_loss: 17.5095 - val_mse: 702.9537\n",
      "Epoch 3212/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0823 - mse: 656.7532 - val_loss: 18.1303 - val_mse: 774.9750\n",
      "Epoch 3213/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4431 - mse: 690.7028 - val_loss: 17.7945 - val_mse: 721.4286\n",
      "Epoch 3214/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2385 - mse: 666.7448 - val_loss: 17.8505 - val_mse: 698.1846\n",
      "Epoch 3215/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3473 - mse: 684.2605 - val_loss: 17.6400 - val_mse: 701.2005\n",
      "Epoch 3216/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4732 - mse: 698.8358 - val_loss: 17.7689 - val_mse: 698.7856\n",
      "Epoch 3217/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2834 - mse: 663.4702 - val_loss: 17.5989 - val_mse: 729.3881\n",
      "Epoch 3218/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9956 - mse: 665.6452 - val_loss: 17.7033 - val_mse: 687.7211\n",
      "Epoch 3219/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1770 - mse: 670.8461 - val_loss: 17.7905 - val_mse: 705.4877\n",
      "Epoch 3220/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9191 - mse: 654.2902 - val_loss: 17.6847 - val_mse: 734.1520\n",
      "Epoch 3221/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0957 - mse: 662.9511 - val_loss: 17.6510 - val_mse: 712.5110\n",
      "Epoch 3222/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4713 - mse: 691.8955 - val_loss: 17.6015 - val_mse: 712.6095\n",
      "Epoch 3223/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1496 - mse: 666.7615 - val_loss: 17.7103 - val_mse: 680.1669\n",
      "Epoch 3224/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.8367 - mse: 648.3397 - val_loss: 17.8425 - val_mse: 715.9238\n",
      "Epoch 3225/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4807 - mse: 683.2336 - val_loss: 18.6346 - val_mse: 761.9277\n",
      "Epoch 3226/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2157 - mse: 670.7579 - val_loss: 17.6105 - val_mse: 725.1688\n",
      "Epoch 3227/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9535 - mse: 657.0616 - val_loss: 18.3909 - val_mse: 732.0081\n",
      "Epoch 3228/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9571 - mse: 664.0071 - val_loss: 18.0848 - val_mse: 770.6743\n",
      "Epoch 3229/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.0909 - mse: 661.3046 - val_loss: 17.8064 - val_mse: 709.4522\n",
      "Epoch 3230/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3263 - mse: 678.0909 - val_loss: 18.8115 - val_mse: 818.2356\n",
      "Epoch 3231/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1535 - mse: 800.1521 - val_loss: 19.6494 - val_mse: 846.6656\n",
      "Epoch 3232/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8174 - mse: 698.6747 - val_loss: 17.4497 - val_mse: 676.9676\n",
      "Epoch 3233/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1646 - mse: 672.3163 - val_loss: 17.4411 - val_mse: 689.3564\n",
      "Epoch 3234/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1117 - mse: 663.2990 - val_loss: 17.5258 - val_mse: 717.1617\n",
      "Epoch 3235/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8080 - mse: 709.9351 - val_loss: 19.0468 - val_mse: 744.8171\n",
      "Epoch 3236/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.0698 - mse: 715.1605 - val_loss: 18.4495 - val_mse: 691.5086\n",
      "Epoch 3237/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4973 - mse: 689.0297 - val_loss: 17.8529 - val_mse: 672.9977\n",
      "Epoch 3238/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9997 - mse: 658.7135 - val_loss: 17.6128 - val_mse: 692.5276\n",
      "Epoch 3239/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.8875 - mse: 648.7476 - val_loss: 18.2368 - val_mse: 788.8243\n",
      "Epoch 3240/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1150 - mse: 664.3089 - val_loss: 17.5398 - val_mse: 726.2723\n",
      "Epoch 3241/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3873 - mse: 684.4946 - val_loss: 17.7290 - val_mse: 724.2769\n",
      "Epoch 3242/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0385 - mse: 718.1380 - val_loss: 18.2904 - val_mse: 760.5552\n",
      "Epoch 3243/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1923 - mse: 666.7969 - val_loss: 18.1541 - val_mse: 682.2499\n",
      "Epoch 3244/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5398 - mse: 688.0002 - val_loss: 18.2849 - val_mse: 710.6946\n",
      "Epoch 3245/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3880 - mse: 680.2250 - val_loss: 17.9268 - val_mse: 753.0983\n",
      "Epoch 3246/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.5898 - mse: 699.7198 - val_loss: 17.9706 - val_mse: 749.7408\n",
      "Epoch 3247/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.4037 - mse: 737.7634 - val_loss: 19.2497 - val_mse: 741.5218\n",
      "Epoch 3248/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.2662 - mse: 729.0054 - val_loss: 17.6655 - val_mse: 722.0588\n",
      "Epoch 3249/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2741 - mse: 675.9857 - val_loss: 17.3699 - val_mse: 686.7035\n",
      "Epoch 3250/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9599 - mse: 656.9326 - val_loss: 17.2765 - val_mse: 700.0075\n",
      "Epoch 3251/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3313 - mse: 686.1279 - val_loss: 18.5615 - val_mse: 785.5165\n",
      "Epoch 3252/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.6833 - mse: 700.8523 - val_loss: 18.9858 - val_mse: 724.6301\n",
      "Epoch 3253/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1541 - mse: 675.7505 - val_loss: 17.5356 - val_mse: 706.6163\n",
      "Epoch 3254/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3657 - mse: 675.0833 - val_loss: 17.4942 - val_mse: 717.5527\n",
      "Epoch 3255/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2618 - mse: 681.9969 - val_loss: 18.4489 - val_mse: 790.4968\n",
      "Epoch 3256/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2913 - mse: 677.4948 - val_loss: 18.8100 - val_mse: 695.6456\n",
      "Epoch 3257/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4100 - mse: 678.8918 - val_loss: 17.5947 - val_mse: 667.3549\n",
      "Epoch 3258/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1595 - mse: 677.2040 - val_loss: 17.6983 - val_mse: 663.6873\n",
      "Epoch 3259/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0889 - mse: 660.2304 - val_loss: 17.5413 - val_mse: 668.2693\n",
      "Epoch 3260/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0361 - mse: 663.0835 - val_loss: 18.0253 - val_mse: 695.4927\n",
      "Epoch 3261/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.0074 - mse: 721.5292 - val_loss: 17.5500 - val_mse: 704.6356\n",
      "Epoch 3262/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4223 - mse: 688.7734 - val_loss: 18.2392 - val_mse: 775.8492\n",
      "Epoch 3263/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1018 - mse: 666.1163 - val_loss: 18.0558 - val_mse: 714.4329\n",
      "Epoch 3264/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9987 - mse: 653.4857 - val_loss: 18.4357 - val_mse: 745.8675\n",
      "Epoch 3265/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6494 - mse: 701.2042 - val_loss: 18.5683 - val_mse: 797.0800\n",
      "Epoch 3266/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8790 - mse: 703.2938 - val_loss: 17.5916 - val_mse: 678.8438\n",
      "Epoch 3267/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1878 - mse: 669.1989 - val_loss: 17.5765 - val_mse: 686.3365\n",
      "Epoch 3268/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9436 - mse: 654.3746 - val_loss: 17.7484 - val_mse: 724.4589\n",
      "Epoch 3269/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9997 - mse: 664.2795 - val_loss: 17.8054 - val_mse: 672.3008\n",
      "Epoch 3270/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8845 - mse: 647.0335 - val_loss: 18.0535 - val_mse: 756.8287\n",
      "Epoch 3271/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.2802 - mse: 676.5567 - val_loss: 18.2457 - val_mse: 774.9217\n",
      "Epoch 3272/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0193 - mse: 661.1698 - val_loss: 17.7188 - val_mse: 709.4242\n",
      "Epoch 3273/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8687 - mse: 652.3077 - val_loss: 17.2388 - val_mse: 691.8515\n",
      "Epoch 3274/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3229 - mse: 677.7871 - val_loss: 18.2166 - val_mse: 676.2299\n",
      "Epoch 3275/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2283 - mse: 673.1344 - val_loss: 18.1776 - val_mse: 694.2341\n",
      "Epoch 3276/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1001 - mse: 666.5999 - val_loss: 18.2604 - val_mse: 705.9064\n",
      "Epoch 3277/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1497 - mse: 664.4158 - val_loss: 17.4278 - val_mse: 674.0670\n",
      "Epoch 3278/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8368 - mse: 651.6394 - val_loss: 18.4075 - val_mse: 707.5067\n",
      "Epoch 3279/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9058 - mse: 704.6531 - val_loss: 17.7984 - val_mse: 741.0109\n",
      "Epoch 3280/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.6293 - mse: 700.4335 - val_loss: 18.2775 - val_mse: 782.2211\n",
      "Epoch 3281/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1030 - mse: 666.1254 - val_loss: 17.8581 - val_mse: 720.5586\n",
      "Epoch 3282/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.8299 - mse: 710.0386 - val_loss: 18.9805 - val_mse: 805.4483\n",
      "Epoch 3283/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.8527 - mse: 684.9967 - val_loss: 17.7332 - val_mse: 720.0299\n",
      "Epoch 3284/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.0897 - mse: 665.5281 - val_loss: 17.5849 - val_mse: 679.1917\n",
      "Epoch 3285/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9476 - mse: 654.4017 - val_loss: 17.5046 - val_mse: 703.7392\n",
      "Epoch 3286/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0571 - mse: 660.1899 - val_loss: 18.0190 - val_mse: 774.0215\n",
      "Epoch 3287/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4322 - mse: 674.6437 - val_loss: 19.5975 - val_mse: 868.0710\n",
      "Epoch 3288/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.1381 - mse: 784.3674 - val_loss: 18.7983 - val_mse: 841.6902\n",
      "Epoch 3289/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 18.1356 - mse: 727.5585 - val_loss: 19.1391 - val_mse: 755.9669\n",
      "Epoch 3290/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9451 - mse: 658.3505 - val_loss: 17.6867 - val_mse: 722.8484\n",
      "Epoch 3291/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7193 - mse: 723.7494 - val_loss: 19.4599 - val_mse: 733.0316\n",
      "Epoch 3292/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2962 - mse: 714.3707 - val_loss: 18.3621 - val_mse: 709.8226\n",
      "Epoch 3293/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5731 - mse: 693.0804 - val_loss: 18.0332 - val_mse: 729.4999\n",
      "Epoch 3294/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3113 - mse: 687.5283 - val_loss: 18.6026 - val_mse: 719.9364\n",
      "Epoch 3295/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2989 - mse: 676.9325 - val_loss: 19.3784 - val_mse: 759.8489\n",
      "Epoch 3296/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3163 - mse: 681.3835 - val_loss: 17.2430 - val_mse: 682.9550\n",
      "Epoch 3297/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0581 - mse: 656.0261 - val_loss: 17.4662 - val_mse: 726.6779\n",
      "Epoch 3298/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4939 - mse: 681.1501 - val_loss: 17.5184 - val_mse: 694.9128\n",
      "Epoch 3299/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0538 - mse: 668.3635 - val_loss: 17.8982 - val_mse: 748.6448\n",
      "Epoch 3300/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2981 - mse: 685.3818 - val_loss: 17.5875 - val_mse: 702.7221\n",
      "Epoch 3301/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6129 - mse: 696.4321 - val_loss: 19.4517 - val_mse: 880.4979\n",
      "Epoch 3302/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4788 - mse: 699.6633 - val_loss: 17.8169 - val_mse: 693.7593\n",
      "Epoch 3303/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 18.7388 - mse: 772.1246 - val_loss: 18.7211 - val_mse: 717.6028\n",
      "Epoch 3304/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1789 - mse: 677.1058 - val_loss: 17.5400 - val_mse: 679.8649\n",
      "Epoch 3305/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6349 - mse: 701.4808 - val_loss: 17.4927 - val_mse: 689.2940\n",
      "Epoch 3306/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5542 - mse: 696.6621 - val_loss: 18.4385 - val_mse: 748.0724\n",
      "Epoch 3307/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.5375 - mse: 722.9026 - val_loss: 18.5281 - val_mse: 753.2431\n",
      "Epoch 3308/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6401 - mse: 699.4826 - val_loss: 17.5807 - val_mse: 707.9243\n",
      "Epoch 3309/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4835 - mse: 689.5438 - val_loss: 18.0326 - val_mse: 694.0043\n",
      "Epoch 3310/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1892 - mse: 668.1617 - val_loss: 17.8221 - val_mse: 686.1917\n",
      "Epoch 3311/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.8920 - mse: 726.8969 - val_loss: 18.5179 - val_mse: 735.0855\n",
      "Epoch 3312/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7556 - mse: 690.6231 - val_loss: 17.5061 - val_mse: 709.0176\n",
      "Epoch 3313/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2029 - mse: 664.7307 - val_loss: 17.7020 - val_mse: 714.2179\n",
      "Epoch 3314/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9352 - mse: 642.8764 - val_loss: 17.4566 - val_mse: 683.2136\n",
      "Epoch 3315/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7563 - mse: 649.5337 - val_loss: 17.8109 - val_mse: 717.5838\n",
      "Epoch 3316/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4005 - mse: 680.1625 - val_loss: 18.0557 - val_mse: 685.6634\n",
      "Epoch 3317/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8042 - mse: 649.0793 - val_loss: 17.4938 - val_mse: 668.2153\n",
      "Epoch 3318/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8523 - mse: 652.4802 - val_loss: 18.2435 - val_mse: 745.6546\n",
      "Epoch 3319/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.1700 - mse: 728.0799 - val_loss: 18.1607 - val_mse: 697.5243\n",
      "Epoch 3320/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9749 - mse: 654.1379 - val_loss: 17.6998 - val_mse: 685.0571\n",
      "Epoch 3321/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1817 - mse: 667.1147 - val_loss: 17.6811 - val_mse: 729.3343\n",
      "Epoch 3322/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1459 - mse: 680.2112 - val_loss: 18.6218 - val_mse: 769.0093\n",
      "Epoch 3323/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 18.4006 - mse: 750.0826 - val_loss: 17.7854 - val_mse: 745.3263\n",
      "Epoch 3324/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8722 - mse: 708.3925 - val_loss: 18.3091 - val_mse: 723.0566\n",
      "Epoch 3325/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5774 - mse: 698.1949 - val_loss: 18.2427 - val_mse: 780.7787\n",
      "Epoch 3326/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.5082 - mse: 689.8096 - val_loss: 18.1405 - val_mse: 751.9767\n",
      "Epoch 3327/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4351 - mse: 680.7043 - val_loss: 17.8921 - val_mse: 707.4579\n",
      "Epoch 3328/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2747 - mse: 683.1838 - val_loss: 17.4831 - val_mse: 659.2789\n",
      "Epoch 3329/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9240 - mse: 653.6208 - val_loss: 17.7008 - val_mse: 700.5606\n",
      "Epoch 3330/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.3149 - mse: 670.1504 - val_loss: 18.0385 - val_mse: 766.5016\n",
      "Epoch 3331/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.4282 - mse: 677.0137 - val_loss: 17.6806 - val_mse: 706.9567\n",
      "Epoch 3332/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9606 - mse: 657.7513 - val_loss: 18.2515 - val_mse: 750.5698\n",
      "Epoch 3333/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1451 - mse: 671.7280 - val_loss: 18.0464 - val_mse: 759.4235\n",
      "Epoch 3334/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4443 - mse: 692.8671 - val_loss: 17.5012 - val_mse: 683.5168\n",
      "Epoch 3335/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8904 - mse: 704.2794 - val_loss: 18.6473 - val_mse: 708.2319\n",
      "Epoch 3336/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1366 - mse: 668.8118 - val_loss: 17.5291 - val_mse: 705.2139\n",
      "Epoch 3337/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1404 - mse: 669.9743 - val_loss: 17.8419 - val_mse: 730.8943\n",
      "Epoch 3338/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0614 - mse: 667.4254 - val_loss: 17.6016 - val_mse: 673.2900\n",
      "Epoch 3339/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1516 - mse: 672.5778 - val_loss: 18.0156 - val_mse: 718.9395\n",
      "Epoch 3340/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6873 - mse: 704.3573 - val_loss: 17.5222 - val_mse: 709.7203\n",
      "Epoch 3341/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8786 - mse: 653.2372 - val_loss: 17.6402 - val_mse: 671.3543\n",
      "Epoch 3342/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0330 - mse: 660.1503 - val_loss: 17.6479 - val_mse: 676.5564\n",
      "Epoch 3343/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7512 - mse: 643.7608 - val_loss: 17.6231 - val_mse: 661.4017\n",
      "Epoch 3344/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.8763 - mse: 645.5380 - val_loss: 18.7160 - val_mse: 814.0442\n",
      "Epoch 3345/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3695 - mse: 690.8290 - val_loss: 18.9965 - val_mse: 829.2727\n",
      "Epoch 3346/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3976 - mse: 677.9440 - val_loss: 18.6399 - val_mse: 824.4346\n",
      "Epoch 3347/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2373 - mse: 678.1328 - val_loss: 18.8572 - val_mse: 776.2658\n",
      "Epoch 3348/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1283 - mse: 678.8521 - val_loss: 17.7509 - val_mse: 705.7101\n",
      "Epoch 3349/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1186 - mse: 663.4384 - val_loss: 17.3755 - val_mse: 683.2813\n",
      "Epoch 3350/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1252 - mse: 677.0253 - val_loss: 17.7278 - val_mse: 686.3294\n",
      "Epoch 3351/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0907 - mse: 671.9931 - val_loss: 17.9537 - val_mse: 695.3362\n",
      "Epoch 3352/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0060 - mse: 713.7861 - val_loss: 17.5984 - val_mse: 714.2798\n",
      "Epoch 3353/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7452 - mse: 708.5760 - val_loss: 18.0022 - val_mse: 701.7408\n",
      "Epoch 3354/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.8790 - mse: 708.7380 - val_loss: 17.5556 - val_mse: 705.3558\n",
      "Epoch 3355/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9521 - mse: 658.2697 - val_loss: 18.4701 - val_mse: 750.0458\n",
      "Epoch 3356/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.5682 - mse: 751.8270 - val_loss: 18.5521 - val_mse: 801.6274\n",
      "Epoch 3357/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.5723 - mse: 754.9739 - val_loss: 18.0142 - val_mse: 706.0070\n",
      "Epoch 3358/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5518 - mse: 695.9530 - val_loss: 18.8428 - val_mse: 709.0035\n",
      "Epoch 3359/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6848 - mse: 698.3988 - val_loss: 17.5752 - val_mse: 712.5389\n",
      "Epoch 3360/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0726 - mse: 664.5970 - val_loss: 17.9067 - val_mse: 696.6980\n",
      "Epoch 3361/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2154 - mse: 667.6448 - val_loss: 17.8892 - val_mse: 752.8030\n",
      "Epoch 3362/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0736 - mse: 668.0974 - val_loss: 17.6262 - val_mse: 670.0080\n",
      "Epoch 3363/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3810 - mse: 687.1410 - val_loss: 17.6052 - val_mse: 682.2551\n",
      "Epoch 3364/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9584 - mse: 654.6184 - val_loss: 18.4064 - val_mse: 793.4184\n",
      "Epoch 3365/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8785 - mse: 716.6663 - val_loss: 17.6113 - val_mse: 708.0719\n",
      "Epoch 3366/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8004 - mse: 685.7385 - val_loss: 18.4794 - val_mse: 808.4025\n",
      "Epoch 3367/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2862 - mse: 678.8960 - val_loss: 18.2519 - val_mse: 693.2245\n",
      "Epoch 3368/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8362 - mse: 651.5024 - val_loss: 17.8955 - val_mse: 682.4496\n",
      "Epoch 3369/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0936 - mse: 667.0530 - val_loss: 17.9152 - val_mse: 725.6564\n",
      "Epoch 3370/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2838 - mse: 674.0027 - val_loss: 17.7432 - val_mse: 726.4193\n",
      "Epoch 3371/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9717 - mse: 657.3110 - val_loss: 17.5648 - val_mse: 692.5003\n",
      "Epoch 3372/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4210 - mse: 679.5333 - val_loss: 19.1048 - val_mse: 842.1100\n",
      "Epoch 3373/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4310 - mse: 683.3702 - val_loss: 17.5002 - val_mse: 696.9409\n",
      "Epoch 3374/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2920 - mse: 675.0867 - val_loss: 17.4962 - val_mse: 676.6165\n",
      "Epoch 3375/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2367 - mse: 674.6905 - val_loss: 18.1138 - val_mse: 695.4206\n",
      "Epoch 3376/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6700 - mse: 690.3253 - val_loss: 18.1607 - val_mse: 785.1981\n",
      "Epoch 3377/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.1989 - mse: 669.0428 - val_loss: 17.7325 - val_mse: 738.2173\n",
      "Epoch 3378/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1982 - mse: 670.3858 - val_loss: 18.1783 - val_mse: 731.3506\n",
      "Epoch 3379/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2223 - mse: 671.0892 - val_loss: 17.6568 - val_mse: 686.2403\n",
      "Epoch 3380/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2448 - mse: 678.7650 - val_loss: 18.3080 - val_mse: 802.2806\n",
      "Epoch 3381/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1665 - mse: 680.8669 - val_loss: 18.3885 - val_mse: 710.3998\n",
      "Epoch 3382/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5780 - mse: 688.2850 - val_loss: 18.0693 - val_mse: 687.4340\n",
      "Epoch 3383/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.7458 - mse: 706.2132 - val_loss: 17.6329 - val_mse: 682.7599\n",
      "Epoch 3384/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3506 - mse: 676.6890 - val_loss: 18.4380 - val_mse: 776.3358\n",
      "Epoch 3385/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0448 - mse: 725.5184 - val_loss: 17.8951 - val_mse: 684.5987\n",
      "Epoch 3386/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.6300 - mse: 687.8274 - val_loss: 17.5831 - val_mse: 708.0082\n",
      "Epoch 3387/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4956 - mse: 681.0142 - val_loss: 17.6152 - val_mse: 685.2654\n",
      "Epoch 3388/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.3034 - mse: 676.6044 - val_loss: 18.7819 - val_mse: 776.6555\n",
      "Epoch 3389/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.0780 - mse: 726.7449 - val_loss: 20.4854 - val_mse: 912.7469\n",
      "Epoch 3390/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.9581 - mse: 769.7360 - val_loss: 18.7455 - val_mse: 734.2844\n",
      "Epoch 3391/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.6987 - mse: 702.9059 - val_loss: 19.0038 - val_mse: 837.3019\n",
      "Epoch 3392/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4485 - mse: 690.0420 - val_loss: 17.9414 - val_mse: 678.3144\n",
      "Epoch 3393/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.4514 - mse: 677.0121 - val_loss: 17.6257 - val_mse: 709.0250\n",
      "Epoch 3394/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1440 - mse: 674.0537 - val_loss: 17.5829 - val_mse: 684.1078\n",
      "Epoch 3395/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.3968 - mse: 680.7233 - val_loss: 19.4797 - val_mse: 861.7610\n",
      "Epoch 3396/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.4791 - mse: 680.7217 - val_loss: 17.7249 - val_mse: 667.9727\n",
      "Epoch 3397/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 16.8875 - mse: 649.5806 - val_loss: 17.4923 - val_mse: 714.0222\n",
      "Epoch 3398/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.1885 - mse: 669.1506 - val_loss: 18.1656 - val_mse: 752.6136\n",
      "Epoch 3399/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3212 - mse: 684.1182 - val_loss: 17.4604 - val_mse: 684.7755\n",
      "Epoch 3400/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.0834 - mse: 658.5557 - val_loss: 17.6667 - val_mse: 700.6604\n",
      "Epoch 3401/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.2893 - mse: 670.0244 - val_loss: 18.6458 - val_mse: 831.5896\n",
      "Epoch 3402/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 18.4676 - mse: 746.3021 - val_loss: 18.5868 - val_mse: 759.1142\n",
      "Epoch 3403/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.8084 - mse: 713.0248 - val_loss: 18.1028 - val_mse: 666.4581\n",
      "Epoch 3404/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4318 - mse: 676.5366 - val_loss: 17.6353 - val_mse: 674.6586\n",
      "Epoch 3405/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.0055 - mse: 657.4067 - val_loss: 17.4529 - val_mse: 698.8456\n",
      "Epoch 3406/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7979 - mse: 647.5240 - val_loss: 17.4104 - val_mse: 687.0783\n",
      "Epoch 3407/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.0486 - mse: 663.7585 - val_loss: 18.1383 - val_mse: 674.6602\n",
      "Epoch 3408/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.6719 - mse: 700.8578 - val_loss: 17.4206 - val_mse: 670.2234\n",
      "Epoch 3409/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.0420 - mse: 657.5763 - val_loss: 17.5300 - val_mse: 692.6999\n",
      "Epoch 3410/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.8783 - mse: 653.8032 - val_loss: 17.3943 - val_mse: 661.7584\n",
      "Epoch 3411/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.3720 - mse: 676.2827 - val_loss: 18.2934 - val_mse: 727.4968\n",
      "Epoch 3412/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.9986 - mse: 656.0037 - val_loss: 18.1096 - val_mse: 752.0437\n",
      "Epoch 3413/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.8368 - mse: 712.0031 - val_loss: 18.0174 - val_mse: 777.6053\n",
      "Epoch 3414/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.0370 - mse: 663.2161 - val_loss: 17.5920 - val_mse: 713.4214\n",
      "Epoch 3415/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.9324 - mse: 653.6897 - val_loss: 17.7465 - val_mse: 697.9438\n",
      "Epoch 3416/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.7850 - mse: 698.8146 - val_loss: 17.8466 - val_mse: 716.9029\n",
      "Epoch 3417/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.1043 - mse: 668.4252 - val_loss: 19.3720 - val_mse: 749.0961\n",
      "Epoch 3418/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 19.0762 - mse: 782.5916 - val_loss: 19.1283 - val_mse: 749.0150\n",
      "Epoch 3419/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.7416 - mse: 688.5545 - val_loss: 17.9330 - val_mse: 717.7653\n",
      "Epoch 3420/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9846 - mse: 656.5186 - val_loss: 17.8677 - val_mse: 686.6232\n",
      "Epoch 3421/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5294 - mse: 702.4595 - val_loss: 17.5244 - val_mse: 723.5548\n",
      "Epoch 3422/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0660 - mse: 663.1923 - val_loss: 17.9212 - val_mse: 747.0993\n",
      "Epoch 3423/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1842 - mse: 671.5520 - val_loss: 17.4854 - val_mse: 707.3918\n",
      "Epoch 3424/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.7726 - mse: 719.8505 - val_loss: 19.5186 - val_mse: 759.7424\n",
      "Epoch 3425/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4380 - mse: 684.4960 - val_loss: 17.5672 - val_mse: 735.8116\n",
      "Epoch 3426/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8808 - mse: 656.6129 - val_loss: 17.9934 - val_mse: 691.7128\n",
      "Epoch 3427/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0842 - mse: 662.4382 - val_loss: 17.9900 - val_mse: 727.3417\n",
      "Epoch 3428/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2136 - mse: 669.1273 - val_loss: 17.7926 - val_mse: 718.1422\n",
      "Epoch 3429/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7441 - mse: 711.1360 - val_loss: 17.5377 - val_mse: 695.9164\n",
      "Epoch 3430/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1624 - mse: 672.7658 - val_loss: 18.0928 - val_mse: 753.9165\n",
      "Epoch 3431/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9979 - mse: 717.8244 - val_loss: 18.8619 - val_mse: 729.0646\n",
      "Epoch 3432/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3452 - mse: 673.3582 - val_loss: 17.5358 - val_mse: 692.3160\n",
      "Epoch 3433/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.8761 - mse: 648.2660 - val_loss: 17.5201 - val_mse: 669.9765\n",
      "Epoch 3434/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0189 - mse: 657.9283 - val_loss: 18.2623 - val_mse: 689.0322\n",
      "Epoch 3435/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4107 - mse: 685.9097 - val_loss: 17.4397 - val_mse: 681.4500\n",
      "Epoch 3436/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1811 - mse: 669.4942 - val_loss: 19.7078 - val_mse: 921.1083\n",
      "Epoch 3437/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.9253 - mse: 709.7360 - val_loss: 18.1869 - val_mse: 767.6161\n",
      "Epoch 3438/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5790 - mse: 693.2178 - val_loss: 18.5241 - val_mse: 763.6769\n",
      "Epoch 3439/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2123 - mse: 664.3566 - val_loss: 18.0048 - val_mse: 756.6771\n",
      "Epoch 3440/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5697 - mse: 694.7103 - val_loss: 17.9636 - val_mse: 736.1528\n",
      "Epoch 3441/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1937 - mse: 669.4488 - val_loss: 17.9100 - val_mse: 746.4307\n",
      "Epoch 3442/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9551 - mse: 662.8185 - val_loss: 17.9554 - val_mse: 746.7729\n",
      "Epoch 3443/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3732 - mse: 686.7019 - val_loss: 18.6833 - val_mse: 766.9092\n",
      "Epoch 3444/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2563 - mse: 675.9924 - val_loss: 18.1065 - val_mse: 683.7838\n",
      "Epoch 3445/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1960 - mse: 670.6677 - val_loss: 17.7307 - val_mse: 685.0372\n",
      "Epoch 3446/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.6979 - mse: 692.4118 - val_loss: 18.2763 - val_mse: 720.6531\n",
      "Epoch 3447/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5243 - mse: 686.2601 - val_loss: 17.5913 - val_mse: 699.0942\n",
      "Epoch 3448/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9709 - mse: 652.9249 - val_loss: 17.4991 - val_mse: 702.3752\n",
      "Epoch 3449/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5402 - mse: 692.1267 - val_loss: 18.0216 - val_mse: 755.7269\n",
      "Epoch 3450/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.3586 - mse: 747.0486 - val_loss: 18.7579 - val_mse: 733.9950\n",
      "Epoch 3451/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8874 - mse: 707.9235 - val_loss: 17.8196 - val_mse: 682.2392\n",
      "Epoch 3452/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5611 - mse: 692.4755 - val_loss: 18.2291 - val_mse: 671.9563\n",
      "Epoch 3453/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5593 - mse: 678.3451 - val_loss: 17.8187 - val_mse: 732.5262\n",
      "Epoch 3454/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1944 - mse: 667.3033 - val_loss: 18.1029 - val_mse: 737.7366\n",
      "Epoch 3455/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.7614 - mse: 697.3166 - val_loss: 17.5896 - val_mse: 714.6602\n",
      "Epoch 3456/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5512 - mse: 691.3765 - val_loss: 17.8601 - val_mse: 675.7534\n",
      "Epoch 3457/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8701 - mse: 705.3792 - val_loss: 17.7441 - val_mse: 746.5276\n",
      "Epoch 3458/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2466 - mse: 673.2430 - val_loss: 17.5965 - val_mse: 703.9406\n",
      "Epoch 3459/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0549 - mse: 659.0303 - val_loss: 17.5272 - val_mse: 689.6783\n",
      "Epoch 3460/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0479 - mse: 664.8647 - val_loss: 17.8174 - val_mse: 718.0534\n",
      "Epoch 3461/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2253 - mse: 668.4669 - val_loss: 17.3223 - val_mse: 693.9897\n",
      "Epoch 3462/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9553 - mse: 651.2134 - val_loss: 17.6529 - val_mse: 692.9376\n",
      "Epoch 3463/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0370 - mse: 659.3550 - val_loss: 17.4411 - val_mse: 686.1821\n",
      "Epoch 3464/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7884 - mse: 640.7706 - val_loss: 17.4168 - val_mse: 687.8833\n",
      "Epoch 3465/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0314 - mse: 662.7067 - val_loss: 17.8108 - val_mse: 751.4708\n",
      "Epoch 3466/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9525 - mse: 725.5016 - val_loss: 17.8489 - val_mse: 702.0119\n",
      "Epoch 3467/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0899 - mse: 665.6837 - val_loss: 17.8559 - val_mse: 699.6849\n",
      "Epoch 3468/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3786 - mse: 685.6826 - val_loss: 18.0221 - val_mse: 732.1115\n",
      "Epoch 3469/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0538 - mse: 728.0068 - val_loss: 18.3333 - val_mse: 721.5771\n",
      "Epoch 3470/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9817 - mse: 661.5873 - val_loss: 17.5010 - val_mse: 676.4091\n",
      "Epoch 3471/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2234 - mse: 667.8397 - val_loss: 18.2252 - val_mse: 759.5004\n",
      "Epoch 3472/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7515 - mse: 718.8348 - val_loss: 17.8133 - val_mse: 752.2827\n",
      "Epoch 3473/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3782 - mse: 670.9089 - val_loss: 17.4229 - val_mse: 699.5424\n",
      "Epoch 3474/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9708 - mse: 663.3867 - val_loss: 18.2381 - val_mse: 689.9519\n",
      "Epoch 3475/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1764 - mse: 665.9051 - val_loss: 17.7377 - val_mse: 674.5621\n",
      "Epoch 3476/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9241 - mse: 656.8915 - val_loss: 17.5059 - val_mse: 720.2997\n",
      "Epoch 3477/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9760 - mse: 661.2074 - val_loss: 17.6208 - val_mse: 661.4769\n",
      "Epoch 3478/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9760 - mse: 659.7192 - val_loss: 17.8458 - val_mse: 744.3382\n",
      "Epoch 3479/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9236 - mse: 729.1594 - val_loss: 18.3117 - val_mse: 662.9693\n",
      "Epoch 3480/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6645 - mse: 697.7286 - val_loss: 18.9725 - val_mse: 825.0338\n",
      "Epoch 3481/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4432 - mse: 674.3689 - val_loss: 17.3948 - val_mse: 689.4152\n",
      "Epoch 3482/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2369 - mse: 675.2801 - val_loss: 17.5038 - val_mse: 686.2422\n",
      "Epoch 3483/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4404 - mse: 688.3286 - val_loss: 17.6220 - val_mse: 727.7483\n",
      "Epoch 3484/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5419 - mse: 688.9277 - val_loss: 18.9550 - val_mse: 829.5915\n",
      "Epoch 3485/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2006 - mse: 667.8966 - val_loss: 17.5363 - val_mse: 676.3632\n",
      "Epoch 3486/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.8935 - mse: 701.0359 - val_loss: 17.9410 - val_mse: 715.5029\n",
      "Epoch 3487/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2599 - mse: 669.4229 - val_loss: 18.1845 - val_mse: 772.5602\n",
      "Epoch 3488/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3878 - mse: 679.4431 - val_loss: 17.5739 - val_mse: 679.7979\n",
      "Epoch 3489/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.6258 - mse: 689.5400 - val_loss: 17.6289 - val_mse: 720.4542\n",
      "Epoch 3490/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.7305 - mse: 707.2172 - val_loss: 17.3952 - val_mse: 675.2541\n",
      "Epoch 3491/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.0329 - mse: 723.1900 - val_loss: 18.7819 - val_mse: 810.8621\n",
      "Epoch 3492/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5665 - mse: 694.8058 - val_loss: 17.5699 - val_mse: 699.0562\n",
      "Epoch 3493/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5514 - mse: 688.7952 - val_loss: 18.9601 - val_mse: 754.0400\n",
      "Epoch 3494/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7177 - mse: 703.7595 - val_loss: 17.4636 - val_mse: 677.9812\n",
      "Epoch 3495/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.0467 - mse: 717.5111 - val_loss: 18.2804 - val_mse: 695.2798\n",
      "Epoch 3496/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.4525 - mse: 743.1968 - val_loss: 19.1268 - val_mse: 755.2458\n",
      "Epoch 3497/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.4543 - mse: 749.9376 - val_loss: 17.9761 - val_mse: 767.0435\n",
      "Epoch 3498/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.6834 - mse: 697.6381 - val_loss: 18.6900 - val_mse: 833.0477\n",
      "Epoch 3499/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5963 - mse: 692.5828 - val_loss: 18.0910 - val_mse: 779.0218\n",
      "Epoch 3500/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3664 - mse: 685.2408 - val_loss: 17.4893 - val_mse: 696.4158\n",
      "Epoch 3501/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2973 - mse: 677.2388 - val_loss: 18.3957 - val_mse: 807.9004\n",
      "Epoch 3502/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.1307 - mse: 734.8640 - val_loss: 17.8400 - val_mse: 713.0224\n",
      "Epoch 3503/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3316 - mse: 667.7895 - val_loss: 17.7895 - val_mse: 717.4069\n",
      "Epoch 3504/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1376 - mse: 661.4197 - val_loss: 17.4606 - val_mse: 690.6165\n",
      "Epoch 3505/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2337 - mse: 661.6352 - val_loss: 17.7931 - val_mse: 742.5998\n",
      "Epoch 3506/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4621 - mse: 688.5279 - val_loss: 18.1826 - val_mse: 694.6252\n",
      "Epoch 3507/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.8791 - mse: 703.6154 - val_loss: 17.5185 - val_mse: 715.3420\n",
      "Epoch 3508/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9604 - mse: 664.5912 - val_loss: 18.5920 - val_mse: 690.3480\n",
      "Epoch 3509/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.2957 - mse: 682.9951 - val_loss: 17.9309 - val_mse: 740.4672\n",
      "Epoch 3510/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8893 - mse: 647.5045 - val_loss: 17.5149 - val_mse: 702.1784\n",
      "Epoch 3511/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3653 - mse: 673.3096 - val_loss: 17.8446 - val_mse: 740.5389\n",
      "Epoch 3512/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4530 - mse: 686.7607 - val_loss: 17.6539 - val_mse: 718.5670\n",
      "Epoch 3513/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 17.7605 - mse: 699.3040 - val_loss: 18.0524 - val_mse: 670.2151\n",
      "Epoch 3514/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0916 - mse: 665.6666 - val_loss: 17.6415 - val_mse: 695.9946\n",
      "Epoch 3515/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.1254 - mse: 664.7971 - val_loss: 18.1444 - val_mse: 772.8819\n",
      "Epoch 3516/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.0672 - mse: 662.5086 - val_loss: 17.5274 - val_mse: 692.0581\n",
      "Epoch 3517/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7859 - mse: 641.2929 - val_loss: 17.3377 - val_mse: 673.5131\n",
      "Epoch 3518/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 16.9126 - mse: 650.7003 - val_loss: 17.5471 - val_mse: 677.0019\n",
      "Epoch 3519/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8336 - mse: 650.1526 - val_loss: 17.6654 - val_mse: 681.2342\n",
      "Epoch 3520/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7260 - mse: 653.2692 - val_loss: 18.0492 - val_mse: 691.1097\n",
      "Epoch 3521/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0546 - mse: 728.4612 - val_loss: 19.8850 - val_mse: 896.9946\n",
      "Epoch 3522/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 19.2586 - mse: 805.9929 - val_loss: 19.0288 - val_mse: 819.0944\n",
      "Epoch 3523/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.0814 - mse: 790.0261 - val_loss: 20.0870 - val_mse: 930.8721\n",
      "Epoch 3524/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.8501 - mse: 781.3151 - val_loss: 18.5513 - val_mse: 793.2579\n",
      "Epoch 3525/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.5331 - mse: 752.5538 - val_loss: 19.7454 - val_mse: 789.0785\n",
      "Epoch 3526/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.9184 - mse: 779.9157 - val_loss: 18.5968 - val_mse: 790.2811\n",
      "Epoch 3527/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0562 - mse: 735.5798 - val_loss: 18.1334 - val_mse: 727.5194\n",
      "Epoch 3528/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3793 - mse: 681.1263 - val_loss: 17.9236 - val_mse: 696.1245\n",
      "Epoch 3529/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4601 - mse: 677.5035 - val_loss: 17.7453 - val_mse: 671.4846\n",
      "Epoch 3530/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4031 - mse: 676.8602 - val_loss: 17.8409 - val_mse: 718.9283\n",
      "Epoch 3531/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1743 - mse: 666.6245 - val_loss: 17.5627 - val_mse: 701.4550\n",
      "Epoch 3532/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.8536 - mse: 651.0101 - val_loss: 17.8947 - val_mse: 682.7902\n",
      "Epoch 3533/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0128 - mse: 658.1011 - val_loss: 18.4361 - val_mse: 805.0027\n",
      "Epoch 3534/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2589 - mse: 673.8643 - val_loss: 17.9314 - val_mse: 707.4761\n",
      "Epoch 3535/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0116 - mse: 720.0754 - val_loss: 18.3423 - val_mse: 732.5235\n",
      "Epoch 3536/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9111 - mse: 706.2111 - val_loss: 17.6945 - val_mse: 732.8421\n",
      "Epoch 3537/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6998 - mse: 701.5673 - val_loss: 18.5226 - val_mse: 759.2477\n",
      "Epoch 3538/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7442 - mse: 690.7726 - val_loss: 17.9118 - val_mse: 757.6705\n",
      "Epoch 3539/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4163 - mse: 688.7563 - val_loss: 18.2241 - val_mse: 782.2541\n",
      "Epoch 3540/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6617 - mse: 685.6534 - val_loss: 18.3150 - val_mse: 719.6033\n",
      "Epoch 3541/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5982 - mse: 696.4201 - val_loss: 17.7543 - val_mse: 724.4174\n",
      "Epoch 3542/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2420 - mse: 668.0961 - val_loss: 18.0325 - val_mse: 733.5145\n",
      "Epoch 3543/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7641 - mse: 707.3412 - val_loss: 18.2170 - val_mse: 795.2772\n",
      "Epoch 3544/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0429 - mse: 726.3763 - val_loss: 17.8785 - val_mse: 720.3663\n",
      "Epoch 3545/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2118 - mse: 664.5904 - val_loss: 17.2953 - val_mse: 688.8265\n",
      "Epoch 3546/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9824 - mse: 660.3801 - val_loss: 18.1417 - val_mse: 732.2053\n",
      "Epoch 3547/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4599 - mse: 682.6016 - val_loss: 18.0582 - val_mse: 694.6094\n",
      "Epoch 3548/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7490 - mse: 708.9770 - val_loss: 17.6558 - val_mse: 712.1635\n",
      "Epoch 3549/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1506 - mse: 719.7292 - val_loss: 17.8934 - val_mse: 669.9550\n",
      "Epoch 3550/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9882 - mse: 664.6253 - val_loss: 18.3103 - val_mse: 684.9474\n",
      "Epoch 3551/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0510 - mse: 659.5200 - val_loss: 17.7741 - val_mse: 726.7092\n",
      "Epoch 3552/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6998 - mse: 706.0635 - val_loss: 18.8746 - val_mse: 768.7490\n",
      "Epoch 3553/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3329 - mse: 675.7445 - val_loss: 17.4894 - val_mse: 721.0627\n",
      "Epoch 3554/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.3418 - mse: 735.0850 - val_loss: 17.8837 - val_mse: 725.9382\n",
      "Epoch 3555/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1373 - mse: 666.1203 - val_loss: 18.7615 - val_mse: 749.9592\n",
      "Epoch 3556/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5731 - mse: 687.9976 - val_loss: 17.3720 - val_mse: 692.2932\n",
      "Epoch 3557/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9719 - mse: 658.9329 - val_loss: 18.1991 - val_mse: 692.2834\n",
      "Epoch 3558/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3046 - mse: 668.7784 - val_loss: 18.3147 - val_mse: 692.7489\n",
      "Epoch 3559/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1873 - mse: 666.2277 - val_loss: 17.7388 - val_mse: 720.6336\n",
      "Epoch 3560/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1163 - mse: 661.7593 - val_loss: 17.8728 - val_mse: 721.5239\n",
      "Epoch 3561/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3513 - mse: 672.4589 - val_loss: 17.6954 - val_mse: 725.0753\n",
      "Epoch 3562/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1747 - mse: 669.3611 - val_loss: 19.3361 - val_mse: 857.2271\n",
      "Epoch 3563/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3090 - mse: 677.8463 - val_loss: 17.6196 - val_mse: 699.0518\n",
      "Epoch 3564/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2701 - mse: 682.9566 - val_loss: 18.4659 - val_mse: 732.6942\n",
      "Epoch 3565/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1214 - mse: 666.4459 - val_loss: 18.6471 - val_mse: 784.8765\n",
      "Epoch 3566/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4279 - mse: 677.7062 - val_loss: 17.3431 - val_mse: 713.1678\n",
      "Epoch 3567/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0900 - mse: 669.0513 - val_loss: 17.8989 - val_mse: 726.5912\n",
      "Epoch 3568/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5922 - mse: 697.8195 - val_loss: 18.3481 - val_mse: 758.9577\n",
      "Epoch 3569/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7092 - mse: 693.9344 - val_loss: 19.3302 - val_mse: 804.9081\n",
      "Epoch 3570/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.3620 - mse: 741.2801 - val_loss: 18.0885 - val_mse: 694.9483\n",
      "Epoch 3571/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3201 - mse: 681.7220 - val_loss: 17.9922 - val_mse: 703.8171\n",
      "Epoch 3572/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0367 - mse: 658.3873 - val_loss: 17.5076 - val_mse: 712.6615\n",
      "Epoch 3573/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0419 - mse: 668.1765 - val_loss: 18.0650 - val_mse: 760.7735\n",
      "Epoch 3574/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.1844 - mse: 740.4883 - val_loss: 18.3982 - val_mse: 790.7337\n",
      "Epoch 3575/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6837 - mse: 700.9150 - val_loss: 17.4934 - val_mse: 722.3806\n",
      "Epoch 3576/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1256 - mse: 667.0607 - val_loss: 17.5058 - val_mse: 676.0695\n",
      "Epoch 3577/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9689 - mse: 657.2585 - val_loss: 18.0787 - val_mse: 700.4417\n",
      "Epoch 3578/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3857 - mse: 690.9850 - val_loss: 17.5257 - val_mse: 723.1987\n",
      "Epoch 3579/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5061 - mse: 688.7618 - val_loss: 18.2099 - val_mse: 773.1212\n",
      "Epoch 3580/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3324 - mse: 680.0370 - val_loss: 17.7088 - val_mse: 746.8039\n",
      "Epoch 3581/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3265 - mse: 679.3268 - val_loss: 18.6457 - val_mse: 799.2964\n",
      "Epoch 3582/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0606 - mse: 658.3674 - val_loss: 17.6309 - val_mse: 680.7412\n",
      "Epoch 3583/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8126 - mse: 641.9238 - val_loss: 17.6553 - val_mse: 748.0867\n",
      "Epoch 3584/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3799 - mse: 680.0378 - val_loss: 17.6932 - val_mse: 708.9053\n",
      "Epoch 3585/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9741 - mse: 657.1660 - val_loss: 17.8456 - val_mse: 728.4907\n",
      "Epoch 3586/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9687 - mse: 653.3657 - val_loss: 17.6676 - val_mse: 738.6314\n",
      "Epoch 3587/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2049 - mse: 669.4456 - val_loss: 17.7758 - val_mse: 741.3702\n",
      "Epoch 3588/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3657 - mse: 682.5829 - val_loss: 17.4550 - val_mse: 706.0345\n",
      "Epoch 3589/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5229 - mse: 688.0242 - val_loss: 19.9013 - val_mse: 890.4744\n",
      "Epoch 3590/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.2407 - mse: 792.8059 - val_loss: 19.0643 - val_mse: 830.0711\n",
      "Epoch 3591/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.8980 - mse: 780.5692 - val_loss: 18.1375 - val_mse: 761.3810\n",
      "Epoch 3592/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5478 - mse: 699.0325 - val_loss: 18.3955 - val_mse: 796.2648\n",
      "Epoch 3593/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8693 - mse: 709.9935 - val_loss: 17.9250 - val_mse: 714.6882\n",
      "Epoch 3594/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7736 - mse: 698.4905 - val_loss: 17.8466 - val_mse: 762.7272\n",
      "Epoch 3595/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8736 - mse: 649.9589 - val_loss: 17.5418 - val_mse: 714.6709\n",
      "Epoch 3596/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3914 - mse: 677.3350 - val_loss: 19.1267 - val_mse: 820.1212\n",
      "Epoch 3597/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.8639 - mse: 704.7754 - val_loss: 18.1318 - val_mse: 725.3754\n",
      "Epoch 3598/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2553 - mse: 672.7643 - val_loss: 17.5531 - val_mse: 665.2388\n",
      "Epoch 3599/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1989 - mse: 663.1270 - val_loss: 17.4376 - val_mse: 683.2954\n",
      "Epoch 3600/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2751 - mse: 677.1945 - val_loss: 18.4733 - val_mse: 800.0504\n",
      "Epoch 3601/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.5870 - mse: 689.9108 - val_loss: 18.7301 - val_mse: 723.5613\n",
      "Epoch 3602/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3595 - mse: 683.0495 - val_loss: 17.8700 - val_mse: 686.6719\n",
      "Epoch 3603/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0347 - mse: 658.7268 - val_loss: 18.1606 - val_mse: 772.1129\n",
      "Epoch 3604/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0529 - mse: 725.4093 - val_loss: 20.3827 - val_mse: 902.3644\n",
      "Epoch 3605/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.5299 - mse: 761.8606 - val_loss: 18.6121 - val_mse: 783.2762\n",
      "Epoch 3606/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.8495 - mse: 711.0445 - val_loss: 17.9195 - val_mse: 708.1309\n",
      "Epoch 3607/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.8423 - mse: 717.8119 - val_loss: 18.5226 - val_mse: 743.1868\n",
      "Epoch 3608/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.6027 - mse: 749.3664 - val_loss: 18.8955 - val_mse: 804.2164\n",
      "Epoch 3609/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.3839 - mse: 742.2159 - val_loss: 18.1357 - val_mse: 762.0863\n",
      "Epoch 3610/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3248 - mse: 679.5400 - val_loss: 18.2361 - val_mse: 711.5577\n",
      "Epoch 3611/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2841 - mse: 675.5103 - val_loss: 18.7755 - val_mse: 800.1637\n",
      "Epoch 3612/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6924 - mse: 697.7336 - val_loss: 17.6066 - val_mse: 696.8536\n",
      "Epoch 3613/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1896 - mse: 664.7801 - val_loss: 17.7779 - val_mse: 746.5845\n",
      "Epoch 3614/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0675 - mse: 661.3126 - val_loss: 17.3123 - val_mse: 689.0245\n",
      "Epoch 3615/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.3068 - mse: 670.2235 - val_loss: 19.0762 - val_mse: 714.3799\n",
      "Epoch 3616/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.1592 - mse: 729.4269 - val_loss: 17.3218 - val_mse: 708.6371\n",
      "Epoch 3617/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9621 - mse: 652.8954 - val_loss: 17.4982 - val_mse: 685.8160\n",
      "Epoch 3618/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.5127 - mse: 700.3685 - val_loss: 18.2276 - val_mse: 735.8079\n",
      "Epoch 3619/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 17.4978 - mse: 686.3589 - val_loss: 17.3152 - val_mse: 682.7638\n",
      "Epoch 3620/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8761 - mse: 657.4344 - val_loss: 17.5689 - val_mse: 712.7096\n",
      "Epoch 3621/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8888 - mse: 650.6473 - val_loss: 17.3318 - val_mse: 685.2825\n",
      "Epoch 3622/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1011 - mse: 661.9633 - val_loss: 18.6816 - val_mse: 818.4392\n",
      "Epoch 3623/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2724 - mse: 724.6096 - val_loss: 18.1303 - val_mse: 746.0450\n",
      "Epoch 3624/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.6584 - mse: 708.1005 - val_loss: 17.8991 - val_mse: 665.7375\n",
      "Epoch 3625/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4984 - mse: 681.9109 - val_loss: 18.0394 - val_mse: 767.2531\n",
      "Epoch 3626/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2660 - mse: 682.3399 - val_loss: 17.3241 - val_mse: 691.7817\n",
      "Epoch 3627/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9489 - mse: 724.3007 - val_loss: 19.1708 - val_mse: 721.2202\n",
      "Epoch 3628/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9452 - mse: 712.4054 - val_loss: 17.8268 - val_mse: 702.4933\n",
      "Epoch 3629/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1036 - mse: 663.0079 - val_loss: 18.2677 - val_mse: 721.9161\n",
      "Epoch 3630/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.5502 - mse: 683.3244 - val_loss: 18.7897 - val_mse: 835.6183\n",
      "Epoch 3631/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.6376 - mse: 696.9897 - val_loss: 17.4635 - val_mse: 701.2881\n",
      "Epoch 3632/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6246 - mse: 643.5505 - val_loss: 17.4066 - val_mse: 692.3138\n",
      "Epoch 3633/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8011 - mse: 653.2838 - val_loss: 17.7981 - val_mse: 748.0385\n",
      "Epoch 3634/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.1476 - mse: 821.7197 - val_loss: 19.4962 - val_mse: 827.6682\n",
      "Epoch 3635/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.4098 - mse: 799.7405 - val_loss: 18.2210 - val_mse: 758.7817\n",
      "Epoch 3636/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.9511 - mse: 709.0090 - val_loss: 18.0067 - val_mse: 715.5460\n",
      "Epoch 3637/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.3875 - mse: 684.1609 - val_loss: 17.5693 - val_mse: 684.8577\n",
      "Epoch 3638/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9615 - mse: 717.9319 - val_loss: 17.7714 - val_mse: 738.7728\n",
      "Epoch 3639/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1301 - mse: 666.6080 - val_loss: 17.6064 - val_mse: 695.6993\n",
      "Epoch 3640/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5161 - mse: 686.9664 - val_loss: 17.4623 - val_mse: 691.7059\n",
      "Epoch 3641/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2237 - mse: 672.5435 - val_loss: 17.5775 - val_mse: 692.0548\n",
      "Epoch 3642/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 18.4116 - mse: 748.4644 - val_loss: 19.1311 - val_mse: 799.0179\n",
      "Epoch 3643/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9650 - mse: 707.7202 - val_loss: 18.0471 - val_mse: 770.0469\n",
      "Epoch 3644/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.1122 - mse: 727.6497 - val_loss: 18.4070 - val_mse: 715.0925\n",
      "Epoch 3645/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.8802 - mse: 699.8555 - val_loss: 18.4713 - val_mse: 772.2627\n",
      "Epoch 3646/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2632 - mse: 668.5753 - val_loss: 17.6111 - val_mse: 710.1462\n",
      "Epoch 3647/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6853 - mse: 699.8878 - val_loss: 19.3580 - val_mse: 872.2744\n",
      "Epoch 3648/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0750 - mse: 700.1987 - val_loss: 18.0331 - val_mse: 765.9528\n",
      "Epoch 3649/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4114 - mse: 683.3214 - val_loss: 17.8035 - val_mse: 735.9438\n",
      "Epoch 3650/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.6850 - mse: 708.8174 - val_loss: 17.4729 - val_mse: 707.4912\n",
      "Epoch 3651/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2358 - mse: 672.3323 - val_loss: 17.4688 - val_mse: 696.8723\n",
      "Epoch 3652/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2905 - mse: 676.9104 - val_loss: 17.6933 - val_mse: 720.2280\n",
      "Epoch 3653/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4776 - mse: 690.8980 - val_loss: 18.1011 - val_mse: 690.1866\n",
      "Epoch 3654/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.8483 - mse: 705.5203 - val_loss: 18.1913 - val_mse: 744.8394\n",
      "Epoch 3655/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3696 - mse: 677.5452 - val_loss: 17.9155 - val_mse: 756.5000\n",
      "Epoch 3656/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2212 - mse: 663.5130 - val_loss: 17.6112 - val_mse: 727.0074\n",
      "Epoch 3657/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.1443 - mse: 733.7256 - val_loss: 18.3850 - val_mse: 748.7985\n",
      "Epoch 3658/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4262 - mse: 680.8040 - val_loss: 17.4378 - val_mse: 687.0372\n",
      "Epoch 3659/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2057 - mse: 670.9424 - val_loss: 17.5564 - val_mse: 673.5552\n",
      "Epoch 3660/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6885 - mse: 689.0173 - val_loss: 17.5096 - val_mse: 701.4414\n",
      "Epoch 3661/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2506 - mse: 667.6966 - val_loss: 17.7549 - val_mse: 679.0644\n",
      "Epoch 3662/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0140 - mse: 655.8511 - val_loss: 17.6054 - val_mse: 697.2446\n",
      "Epoch 3663/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0029 - mse: 651.2966 - val_loss: 17.4535 - val_mse: 702.8955\n",
      "Epoch 3664/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1104 - mse: 656.6561 - val_loss: 17.4466 - val_mse: 699.2473\n",
      "Epoch 3665/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2621 - mse: 679.4666 - val_loss: 17.4964 - val_mse: 682.8699\n",
      "Epoch 3666/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1368 - mse: 664.0569 - val_loss: 17.6920 - val_mse: 677.2354\n",
      "Epoch 3667/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3326 - mse: 679.1712 - val_loss: 17.7344 - val_mse: 714.0014\n",
      "Epoch 3668/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9009 - mse: 705.4249 - val_loss: 17.8201 - val_mse: 753.2317\n",
      "Epoch 3669/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4496 - mse: 681.0367 - val_loss: 17.5356 - val_mse: 689.5407\n",
      "Epoch 3670/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4589 - mse: 675.4173 - val_loss: 17.6040 - val_mse: 685.5225\n",
      "Epoch 3671/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2095 - mse: 670.1852 - val_loss: 17.5206 - val_mse: 696.6732\n",
      "Epoch 3672/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0680 - mse: 657.6349 - val_loss: 17.7487 - val_mse: 687.3015\n",
      "Epoch 3673/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1901 - mse: 664.6908 - val_loss: 17.7250 - val_mse: 712.2833\n",
      "Epoch 3674/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1237 - mse: 668.5001 - val_loss: 19.0335 - val_mse: 789.0024\n",
      "Epoch 3675/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.4691 - mse: 734.8053 - val_loss: 19.6153 - val_mse: 866.5554\n",
      "Epoch 3676/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9292 - mse: 709.7567 - val_loss: 17.8553 - val_mse: 707.7247\n",
      "Epoch 3677/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2828 - mse: 672.7723 - val_loss: 17.6288 - val_mse: 691.9823\n",
      "Epoch 3678/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0649 - mse: 665.0055 - val_loss: 17.7127 - val_mse: 698.9560\n",
      "Epoch 3679/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3834 - mse: 679.7457 - val_loss: 17.6935 - val_mse: 716.1526\n",
      "Epoch 3680/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2857 - mse: 667.3802 - val_loss: 18.5074 - val_mse: 728.1216\n",
      "Epoch 3681/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.7441 - mse: 696.6938 - val_loss: 17.5811 - val_mse: 678.1748\n",
      "Epoch 3682/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2080 - mse: 673.2281 - val_loss: 17.5749 - val_mse: 723.6050\n",
      "Epoch 3683/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.9940 - mse: 710.5128 - val_loss: 18.3490 - val_mse: 788.1259\n",
      "Epoch 3684/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0742 - mse: 661.1848 - val_loss: 17.3924 - val_mse: 681.0137\n",
      "Epoch 3685/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1984 - mse: 668.0730 - val_loss: 17.3139 - val_mse: 672.4274\n",
      "Epoch 3686/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0803 - mse: 656.7274 - val_loss: 18.4050 - val_mse: 676.2063\n",
      "Epoch 3687/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3970 - mse: 684.1451 - val_loss: 17.4905 - val_mse: 717.2870\n",
      "Epoch 3688/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0439 - mse: 657.0859 - val_loss: 17.7194 - val_mse: 702.0626\n",
      "Epoch 3689/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2796 - mse: 672.2995 - val_loss: 17.5755 - val_mse: 681.2388\n",
      "Epoch 3690/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9350 - mse: 656.0985 - val_loss: 17.9570 - val_mse: 741.5111\n",
      "Epoch 3691/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9127 - mse: 648.1703 - val_loss: 17.7002 - val_mse: 685.1319\n",
      "Epoch 3692/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.3818 - mse: 682.8723 - val_loss: 17.4402 - val_mse: 697.0994\n",
      "Epoch 3693/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.8915 - mse: 705.0323 - val_loss: 18.7457 - val_mse: 783.3455\n",
      "Epoch 3694/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7407 - mse: 709.4101 - val_loss: 17.9289 - val_mse: 747.2425\n",
      "Epoch 3695/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4561 - mse: 689.0342 - val_loss: 17.4094 - val_mse: 704.1082\n",
      "Epoch 3696/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2716 - mse: 674.1683 - val_loss: 17.6839 - val_mse: 740.0121\n",
      "Epoch 3697/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0363 - mse: 663.2426 - val_loss: 17.4989 - val_mse: 673.8254\n",
      "Epoch 3698/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3345 - mse: 683.1461 - val_loss: 18.7372 - val_mse: 720.4771\n",
      "Epoch 3699/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2391 - mse: 675.2003 - val_loss: 17.6254 - val_mse: 735.3042\n",
      "Epoch 3700/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4629 - mse: 686.1938 - val_loss: 18.9127 - val_mse: 840.1977\n",
      "Epoch 3701/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7739 - mse: 712.9034 - val_loss: 17.6797 - val_mse: 696.0294\n",
      "Epoch 3702/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9547 - mse: 653.2252 - val_loss: 17.5616 - val_mse: 681.3585\n",
      "Epoch 3703/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9078 - mse: 656.7979 - val_loss: 17.7541 - val_mse: 678.5566\n",
      "Epoch 3704/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1841 - mse: 668.3647 - val_loss: 17.6510 - val_mse: 681.1715\n",
      "Epoch 3705/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3958 - mse: 678.0013 - val_loss: 18.6369 - val_mse: 824.8368\n",
      "Epoch 3706/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9931 - mse: 661.4036 - val_loss: 17.3839 - val_mse: 705.6786\n",
      "Epoch 3707/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8820 - mse: 649.1426 - val_loss: 17.5110 - val_mse: 692.3712\n",
      "Epoch 3708/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0705 - mse: 662.9327 - val_loss: 17.5107 - val_mse: 695.7324\n",
      "Epoch 3709/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1297 - mse: 682.4637 - val_loss: 17.7227 - val_mse: 682.2690\n",
      "Epoch 3710/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.2507 - mse: 660.4338 - val_loss: 18.6939 - val_mse: 752.5153\n",
      "Epoch 3711/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3210 - mse: 680.0435 - val_loss: 17.6038 - val_mse: 699.9144\n",
      "Epoch 3712/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2208 - mse: 663.9932 - val_loss: 20.0613 - val_mse: 763.2751\n",
      "Epoch 3713/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.7568 - mse: 710.8022 - val_loss: 17.8563 - val_mse: 706.2800\n",
      "Epoch 3714/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1989 - mse: 662.9906 - val_loss: 17.3899 - val_mse: 718.3478\n",
      "Epoch 3715/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7956 - mse: 694.6948 - val_loss: 17.6685 - val_mse: 701.2918\n",
      "Epoch 3716/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.1509 - mse: 674.0195 - val_loss: 17.4577 - val_mse: 678.9865\n",
      "Epoch 3717/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.9064 - mse: 650.1649 - val_loss: 17.8112 - val_mse: 731.3662\n",
      "Epoch 3718/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5613 - mse: 683.0633 - val_loss: 17.8646 - val_mse: 739.1829\n",
      "Epoch 3719/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9928 - mse: 657.8759 - val_loss: 17.4070 - val_mse: 692.7153\n",
      "Epoch 3720/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 18.5570 - mse: 773.0449 - val_loss: 18.5992 - val_mse: 723.4291\n",
      "Epoch 3721/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 19.4587 - mse: 808.4012 - val_loss: 18.8839 - val_mse: 783.9028\n",
      "Epoch 3722/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 18.2602 - mse: 739.7288 - val_loss: 18.6672 - val_mse: 742.1844\n",
      "Epoch 3723/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4458 - mse: 678.6461 - val_loss: 17.7060 - val_mse: 674.6216\n",
      "Epoch 3724/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2958 - mse: 670.5848 - val_loss: 17.8647 - val_mse: 723.0930\n",
      "Epoch 3725/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.6106 - mse: 690.2325 - val_loss: 17.5622 - val_mse: 686.6202\n",
      "Epoch 3726/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2854 - mse: 684.4807 - val_loss: 17.4831 - val_mse: 670.9557\n",
      "Epoch 3727/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.4990 - mse: 689.4402 - val_loss: 17.9266 - val_mse: 684.1548\n",
      "Epoch 3728/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8817 - mse: 710.6867 - val_loss: 17.6912 - val_mse: 684.6324\n",
      "Epoch 3729/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3259 - mse: 683.6196 - val_loss: 18.9919 - val_mse: 814.3724\n",
      "Epoch 3730/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7733 - mse: 704.0730 - val_loss: 18.6694 - val_mse: 704.0183\n",
      "Epoch 3731/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4592 - mse: 693.2515 - val_loss: 17.6048 - val_mse: 695.1403\n",
      "Epoch 3732/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9777 - mse: 649.4229 - val_loss: 17.6164 - val_mse: 710.4183\n",
      "Epoch 3733/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0163 - mse: 661.4493 - val_loss: 17.7008 - val_mse: 693.1495\n",
      "Epoch 3734/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3943 - mse: 678.6308 - val_loss: 18.4255 - val_mse: 704.9504\n",
      "Epoch 3735/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3372 - mse: 686.0983 - val_loss: 18.0035 - val_mse: 700.6978\n",
      "Epoch 3736/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5084 - mse: 688.8154 - val_loss: 17.9346 - val_mse: 705.6232\n",
      "Epoch 3737/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1377 - mse: 661.9750 - val_loss: 17.5276 - val_mse: 663.4127\n",
      "Epoch 3738/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0083 - mse: 661.0728 - val_loss: 17.3996 - val_mse: 688.5508\n",
      "Epoch 3739/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8541 - mse: 641.2120 - val_loss: 17.6696 - val_mse: 730.6741\n",
      "Epoch 3740/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9174 - mse: 659.1801 - val_loss: 17.6238 - val_mse: 677.7814\n",
      "Epoch 3741/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9363 - mse: 647.7501 - val_loss: 17.8671 - val_mse: 733.0880\n",
      "Epoch 3742/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9910 - mse: 650.2958 - val_loss: 18.0266 - val_mse: 767.3307\n",
      "Epoch 3743/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8296 - mse: 657.2186 - val_loss: 17.7371 - val_mse: 697.0988\n",
      "Epoch 3744/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4268 - mse: 683.1104 - val_loss: 17.6507 - val_mse: 727.3414\n",
      "Epoch 3745/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.7014 - mse: 691.1066 - val_loss: 18.1545 - val_mse: 768.7790\n",
      "Epoch 3746/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0468 - mse: 666.2336 - val_loss: 18.5585 - val_mse: 797.2610\n",
      "Epoch 3747/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2967 - mse: 676.0059 - val_loss: 18.1835 - val_mse: 707.4896\n",
      "Epoch 3748/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1916 - mse: 668.9658 - val_loss: 17.5386 - val_mse: 716.4454\n",
      "Epoch 3749/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8427 - mse: 710.5638 - val_loss: 18.4342 - val_mse: 713.9661\n",
      "Epoch 3750/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0579 - mse: 663.6720 - val_loss: 17.8703 - val_mse: 681.1184\n",
      "Epoch 3751/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.6223 - mse: 688.4880 - val_loss: 17.6890 - val_mse: 669.2169\n",
      "Epoch 3752/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2995 - mse: 734.1948 - val_loss: 18.5799 - val_mse: 704.5395\n",
      "Epoch 3753/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.6419 - mse: 698.4830 - val_loss: 18.2433 - val_mse: 719.9293\n",
      "Epoch 3754/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.7296 - mse: 769.3762 - val_loss: 18.1423 - val_mse: 760.7691\n",
      "Epoch 3755/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3889 - mse: 676.0638 - val_loss: 17.4848 - val_mse: 696.6177\n",
      "Epoch 3756/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0118 - mse: 663.3312 - val_loss: 17.4719 - val_mse: 659.5345\n",
      "Epoch 3757/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1362 - mse: 667.0912 - val_loss: 17.6792 - val_mse: 688.5215\n",
      "Epoch 3758/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.8629 - mse: 713.9622 - val_loss: 18.3595 - val_mse: 716.9812\n",
      "Epoch 3759/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4301 - mse: 685.9754 - val_loss: 18.6858 - val_mse: 746.6912\n",
      "Epoch 3760/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 19.7686 - mse: 826.3295 - val_loss: 19.3451 - val_mse: 849.0677\n",
      "Epoch 3761/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 19.5884 - mse: 822.3137 - val_loss: 19.0105 - val_mse: 811.7364\n",
      "Epoch 3762/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.9495 - mse: 766.7264 - val_loss: 19.2651 - val_mse: 788.7841\n",
      "Epoch 3763/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.7909 - mse: 767.8226 - val_loss: 18.5091 - val_mse: 723.8246\n",
      "Epoch 3764/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.4320 - mse: 741.9054 - val_loss: 18.5750 - val_mse: 750.3085\n",
      "Epoch 3765/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.9347 - mse: 707.1887 - val_loss: 18.4294 - val_mse: 759.0632\n",
      "Epoch 3766/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5983 - mse: 679.8573 - val_loss: 19.5043 - val_mse: 876.0992\n",
      "Epoch 3767/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6883 - mse: 710.2667 - val_loss: 18.0476 - val_mse: 688.2960\n",
      "Epoch 3768/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.2262 - mse: 665.8207 - val_loss: 17.9418 - val_mse: 755.5410\n",
      "Epoch 3769/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6062 - mse: 690.1447 - val_loss: 17.7724 - val_mse: 741.1917\n",
      "Epoch 3770/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5490 - mse: 695.8622 - val_loss: 18.2558 - val_mse: 736.8811\n",
      "Epoch 3771/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0088 - mse: 715.3282 - val_loss: 17.9298 - val_mse: 741.0817\n",
      "Epoch 3772/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7898 - mse: 713.6355 - val_loss: 18.1604 - val_mse: 780.6413\n",
      "Epoch 3773/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3178 - mse: 673.8243 - val_loss: 17.9455 - val_mse: 669.7640\n",
      "Epoch 3774/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6767 - mse: 689.9559 - val_loss: 18.3499 - val_mse: 778.1017\n",
      "Epoch 3775/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3555 - mse: 676.4512 - val_loss: 17.7893 - val_mse: 698.5781\n",
      "Epoch 3776/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1524 - mse: 672.8329 - val_loss: 17.3709 - val_mse: 679.5735\n",
      "Epoch 3777/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2523 - mse: 672.4130 - val_loss: 17.8232 - val_mse: 729.8986\n",
      "Epoch 3778/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9979 - mse: 654.7744 - val_loss: 17.5413 - val_mse: 700.1745\n",
      "Epoch 3779/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.0527 - mse: 662.1157 - val_loss: 17.6993 - val_mse: 715.4616\n",
      "Epoch 3780/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.6646 - mse: 704.3804 - val_loss: 17.4573 - val_mse: 692.7350\n",
      "Epoch 3781/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9526 - mse: 653.4003 - val_loss: 18.9323 - val_mse: 780.3131\n",
      "Epoch 3782/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4982 - mse: 696.8488 - val_loss: 17.6656 - val_mse: 667.1014\n",
      "Epoch 3783/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0818 - mse: 717.3781 - val_loss: 19.7170 - val_mse: 887.0961\n",
      "Epoch 3784/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.6542 - mse: 689.9659 - val_loss: 17.5322 - val_mse: 682.5335\n",
      "Epoch 3785/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.4060 - mse: 684.8726 - val_loss: 17.4271 - val_mse: 679.7304\n",
      "Epoch 3786/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4479 - mse: 683.0733 - val_loss: 17.5001 - val_mse: 702.3570\n",
      "Epoch 3787/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2185 - mse: 681.4907 - val_loss: 18.4776 - val_mse: 680.6724\n",
      "Epoch 3788/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1783 - mse: 660.6304 - val_loss: 17.3404 - val_mse: 692.1194\n",
      "Epoch 3789/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1749 - mse: 666.7966 - val_loss: 18.0581 - val_mse: 774.5377\n",
      "Epoch 3790/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1165 - mse: 665.3118 - val_loss: 17.4869 - val_mse: 704.8134\n",
      "Epoch 3791/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0191 - mse: 652.3884 - val_loss: 18.0960 - val_mse: 742.8512\n",
      "Epoch 3792/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8886 - mse: 655.9929 - val_loss: 17.5894 - val_mse: 709.4203\n",
      "Epoch 3793/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9995 - mse: 658.4307 - val_loss: 17.9471 - val_mse: 668.5338\n",
      "Epoch 3794/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7047 - mse: 703.2949 - val_loss: 17.7181 - val_mse: 730.0674\n",
      "Epoch 3795/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3040 - mse: 664.5291 - val_loss: 17.4445 - val_mse: 708.4037\n",
      "Epoch 3796/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0853 - mse: 659.7966 - val_loss: 17.3623 - val_mse: 691.4940\n",
      "Epoch 3797/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 16.9171 - mse: 659.4180 - val_loss: 17.4045 - val_mse: 664.3445\n",
      "Epoch 3798/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8043 - mse: 648.3498 - val_loss: 17.5326 - val_mse: 669.9488\n",
      "Epoch 3799/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0370 - mse: 658.0388 - val_loss: 17.3299 - val_mse: 685.3284\n",
      "Epoch 3800/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0238 - mse: 667.1926 - val_loss: 17.8456 - val_mse: 713.4036\n",
      "Epoch 3801/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0167 - mse: 667.7634 - val_loss: 17.9546 - val_mse: 762.0942\n",
      "Epoch 3802/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8846 - mse: 648.1982 - val_loss: 17.3470 - val_mse: 674.5049\n",
      "Epoch 3803/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9800 - mse: 653.2216 - val_loss: 17.2810 - val_mse: 675.6092\n",
      "Epoch 3804/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8785 - mse: 654.1066 - val_loss: 18.6619 - val_mse: 827.0096\n",
      "Epoch 3805/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2007 - mse: 678.0459 - val_loss: 17.6270 - val_mse: 691.6349\n",
      "Epoch 3806/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7882 - mse: 698.2004 - val_loss: 21.4903 - val_mse: 1062.6273\n",
      "Epoch 3807/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 19.3355 - mse: 799.1432 - val_loss: 18.5674 - val_mse: 754.4333\n",
      "Epoch 3808/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.1115 - mse: 736.3709 - val_loss: 18.4552 - val_mse: 767.5641\n",
      "Epoch 3809/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.1747 - mse: 715.3632 - val_loss: 17.8496 - val_mse: 704.2670\n",
      "Epoch 3810/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4742 - mse: 681.6031 - val_loss: 18.6799 - val_mse: 826.8069\n",
      "Epoch 3811/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.0153 - mse: 721.5933 - val_loss: 18.1837 - val_mse: 786.2780\n",
      "Epoch 3812/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.4671 - mse: 683.6507 - val_loss: 17.6688 - val_mse: 721.7780\n",
      "Epoch 3813/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.6624 - mse: 699.4055 - val_loss: 18.6191 - val_mse: 790.6754\n",
      "Epoch 3814/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 19.5474 - mse: 812.7596 - val_loss: 18.7943 - val_mse: 778.1677\n",
      "Epoch 3815/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.7545 - mse: 768.5497 - val_loss: 18.3193 - val_mse: 740.0133\n",
      "Epoch 3816/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.0952 - mse: 729.2375 - val_loss: 18.6971 - val_mse: 776.0240\n",
      "Epoch 3817/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.7388 - mse: 763.7114 - val_loss: 18.3428 - val_mse: 729.6079\n",
      "Epoch 3818/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 18.4223 - mse: 753.5396 - val_loss: 18.5856 - val_mse: 781.5814\n",
      "Epoch 3819/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.9911 - mse: 699.7043 - val_loss: 17.7952 - val_mse: 713.8979\n",
      "Epoch 3820/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3615 - mse: 675.0721 - val_loss: 17.7756 - val_mse: 714.1269\n",
      "Epoch 3821/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4519 - mse: 675.2800 - val_loss: 17.6769 - val_mse: 714.2683\n",
      "Epoch 3822/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5863 - mse: 688.2598 - val_loss: 17.7127 - val_mse: 699.6690\n",
      "Epoch 3823/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3554 - mse: 676.4958 - val_loss: 17.9299 - val_mse: 749.1132\n",
      "Epoch 3824/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.8003 - mse: 703.1443 - val_loss: 19.1588 - val_mse: 847.8573\n",
      "Epoch 3825/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.8383 - mse: 714.2437 - val_loss: 17.8126 - val_mse: 737.5178\n",
      "Epoch 3826/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.0646 - mse: 660.8243 - val_loss: 17.7738 - val_mse: 698.7162\n",
      "Epoch 3827/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2826 - mse: 679.5125 - val_loss: 17.5574 - val_mse: 694.7929\n",
      "Epoch 3828/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7748 - mse: 721.1403 - val_loss: 17.3458 - val_mse: 669.4866\n",
      "Epoch 3829/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2344 - mse: 670.8016 - val_loss: 17.2825 - val_mse: 668.2352\n",
      "Epoch 3830/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5679 - mse: 695.0245 - val_loss: 17.6341 - val_mse: 676.8738\n",
      "Epoch 3831/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.9218 - mse: 650.8077 - val_loss: 17.8254 - val_mse: 737.5179\n",
      "Epoch 3832/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3407 - mse: 684.6923 - val_loss: 17.6818 - val_mse: 698.7548\n",
      "Epoch 3833/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0196 - mse: 652.5083 - val_loss: 17.5722 - val_mse: 713.7424\n",
      "Epoch 3834/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9952 - mse: 715.3882 - val_loss: 19.5949 - val_mse: 892.4787\n",
      "Epoch 3835/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4879 - mse: 692.5311 - val_loss: 17.6349 - val_mse: 690.1386\n",
      "Epoch 3836/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6877 - mse: 696.6911 - val_loss: 18.3770 - val_mse: 764.3709\n",
      "Epoch 3837/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5977 - mse: 681.5857 - val_loss: 17.8164 - val_mse: 733.2876\n",
      "Epoch 3838/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0067 - mse: 654.6403 - val_loss: 17.7362 - val_mse: 704.6193\n",
      "Epoch 3839/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5602 - mse: 697.4048 - val_loss: 17.7256 - val_mse: 743.0541\n",
      "Epoch 3840/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4737 - mse: 682.1012 - val_loss: 17.4008 - val_mse: 674.0969\n",
      "Epoch 3841/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2935 - mse: 674.3970 - val_loss: 18.3767 - val_mse: 793.3377\n",
      "Epoch 3842/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.6774 - mse: 690.3645 - val_loss: 18.3097 - val_mse: 741.5924\n",
      "Epoch 3843/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3257 - mse: 682.7663 - val_loss: 17.5049 - val_mse: 689.8748\n",
      "Epoch 3844/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1307 - mse: 667.2705 - val_loss: 17.5913 - val_mse: 717.6219\n",
      "Epoch 3845/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1251 - mse: 668.6353 - val_loss: 17.9164 - val_mse: 695.7823\n",
      "Epoch 3846/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9764 - mse: 652.3835 - val_loss: 18.1009 - val_mse: 696.0964\n",
      "Epoch 3847/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1259 - mse: 668.2035 - val_loss: 17.3109 - val_mse: 685.3168\n",
      "Epoch 3848/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1438 - mse: 660.8358 - val_loss: 18.0432 - val_mse: 741.7394\n",
      "Epoch 3849/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3392 - mse: 676.2000 - val_loss: 17.6817 - val_mse: 716.4697\n",
      "Epoch 3850/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2240 - mse: 666.2779 - val_loss: 18.0722 - val_mse: 768.2540\n",
      "Epoch 3851/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8461 - mse: 657.7398 - val_loss: 17.6291 - val_mse: 694.0555\n",
      "Epoch 3852/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4866 - mse: 678.8978 - val_loss: 17.4241 - val_mse: 703.2721\n",
      "Epoch 3853/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1859 - mse: 670.3824 - val_loss: 17.6011 - val_mse: 700.0587\n",
      "Epoch 3854/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2403 - mse: 681.3713 - val_loss: 17.5029 - val_mse: 706.2084\n",
      "Epoch 3855/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0194 - mse: 657.3778 - val_loss: 17.4819 - val_mse: 702.5748\n",
      "Epoch 3856/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8499 - mse: 715.6324 - val_loss: 17.7708 - val_mse: 706.1607\n",
      "Epoch 3857/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1995 - mse: 676.6453 - val_loss: 18.7959 - val_mse: 831.0496\n",
      "Epoch 3858/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0429 - mse: 666.0032 - val_loss: 17.1814 - val_mse: 667.4749\n",
      "Epoch 3859/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7527 - mse: 696.7447 - val_loss: 18.2647 - val_mse: 796.4463\n",
      "Epoch 3860/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1913 - mse: 676.0697 - val_loss: 17.8446 - val_mse: 703.6292\n",
      "Epoch 3861/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2156 - mse: 680.7388 - val_loss: 17.2733 - val_mse: 695.2588\n",
      "Epoch 3862/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1732 - mse: 668.3138 - val_loss: 17.7621 - val_mse: 723.6040\n",
      "Epoch 3863/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1307 - mse: 666.0391 - val_loss: 18.0772 - val_mse: 744.8922\n",
      "Epoch 3864/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0449 - mse: 657.9598 - val_loss: 17.8125 - val_mse: 689.7688\n",
      "Epoch 3865/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1169 - mse: 663.3603 - val_loss: 17.6690 - val_mse: 670.9454\n",
      "Epoch 3866/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2445 - mse: 661.7392 - val_loss: 20.1102 - val_mse: 910.5327\n",
      "Epoch 3867/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.4917 - mse: 824.1121 - val_loss: 19.6329 - val_mse: 758.6973\n",
      "Epoch 3868/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.9185 - mse: 703.9492 - val_loss: 17.5381 - val_mse: 694.5360\n",
      "Epoch 3869/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8463 - mse: 652.9198 - val_loss: 17.8797 - val_mse: 709.1288\n",
      "Epoch 3870/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9120 - mse: 659.3151 - val_loss: 18.1981 - val_mse: 684.4629\n",
      "Epoch 3871/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4151 - mse: 690.2755 - val_loss: 17.6561 - val_mse: 698.1247\n",
      "Epoch 3872/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.1664 - mse: 667.9545 - val_loss: 17.6010 - val_mse: 664.2768\n",
      "Epoch 3873/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3645 - mse: 687.2422 - val_loss: 17.9732 - val_mse: 730.8367\n",
      "Epoch 3874/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2111 - mse: 668.0081 - val_loss: 17.6003 - val_mse: 682.2732\n",
      "Epoch 3875/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0853 - mse: 661.4863 - val_loss: 17.3794 - val_mse: 692.7521\n",
      "Epoch 3876/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9915 - mse: 659.6594 - val_loss: 17.6521 - val_mse: 701.2464\n",
      "Epoch 3877/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0178 - mse: 664.5913 - val_loss: 17.2013 - val_mse: 678.2521\n",
      "Epoch 3878/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9912 - mse: 658.7112 - val_loss: 17.7997 - val_mse: 685.2715\n",
      "Epoch 3879/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9454 - mse: 652.4924 - val_loss: 17.2065 - val_mse: 698.6366\n",
      "Epoch 3880/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7931 - mse: 646.3156 - val_loss: 18.7344 - val_mse: 701.2328\n",
      "Epoch 3881/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 18.1479 - mse: 743.4921 - val_loss: 18.0609 - val_mse: 757.4746\n",
      "Epoch 3882/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0266 - mse: 654.0454 - val_loss: 17.2659 - val_mse: 689.0682\n",
      "Epoch 3883/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1136 - mse: 667.0948 - val_loss: 18.7065 - val_mse: 775.5607\n",
      "Epoch 3884/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.9379 - mse: 717.9824 - val_loss: 18.0726 - val_mse: 713.1846\n",
      "Epoch 3885/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4907 - mse: 693.6469 - val_loss: 17.6982 - val_mse: 701.3843\n",
      "Epoch 3886/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.2368 - mse: 745.8994 - val_loss: 18.0100 - val_mse: 701.0048\n",
      "Epoch 3887/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4038 - mse: 680.9075 - val_loss: 17.9692 - val_mse: 712.3350\n",
      "Epoch 3888/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0943 - mse: 662.6686 - val_loss: 17.8977 - val_mse: 724.4456\n",
      "Epoch 3889/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.2315 - mse: 669.4795 - val_loss: 18.5235 - val_mse: 684.1333\n",
      "Epoch 3890/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3535 - mse: 686.4886 - val_loss: 17.5352 - val_mse: 708.7484\n",
      "Epoch 3891/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.5377 - mse: 691.1278 - val_loss: 17.4171 - val_mse: 699.3575\n",
      "Epoch 3892/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8448 - mse: 653.2448 - val_loss: 17.5024 - val_mse: 675.9210\n",
      "Epoch 3893/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1599 - mse: 669.2715 - val_loss: 17.2226 - val_mse: 674.5726\n",
      "Epoch 3894/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8132 - mse: 649.4535 - val_loss: 17.3467 - val_mse: 671.8111\n",
      "Epoch 3895/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4598 - mse: 696.0092 - val_loss: 18.2257 - val_mse: 709.5115\n",
      "Epoch 3896/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7803 - mse: 652.9305 - val_loss: 17.6693 - val_mse: 678.8660\n",
      "Epoch 3897/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3297 - mse: 684.8593 - val_loss: 17.9262 - val_mse: 727.1472\n",
      "Epoch 3898/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1068 - mse: 664.6735 - val_loss: 17.4416 - val_mse: 664.4934\n",
      "Epoch 3899/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2946 - mse: 671.5079 - val_loss: 17.7201 - val_mse: 682.9080\n",
      "Epoch 3900/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9670 - mse: 652.9644 - val_loss: 17.4217 - val_mse: 683.7949\n",
      "Epoch 3901/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2371 - mse: 670.3708 - val_loss: 17.7432 - val_mse: 684.1119\n",
      "Epoch 3902/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2927 - mse: 679.3145 - val_loss: 18.8284 - val_mse: 756.1604\n",
      "Epoch 3903/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6663 - mse: 694.6520 - val_loss: 17.9136 - val_mse: 752.8594\n",
      "Epoch 3904/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2905 - mse: 673.9679 - val_loss: 17.4540 - val_mse: 692.7676\n",
      "Epoch 3905/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5012 - mse: 695.9415 - val_loss: 18.1152 - val_mse: 705.4733\n",
      "Epoch 3906/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.5121 - mse: 681.6977 - val_loss: 17.7060 - val_mse: 706.1107\n",
      "Epoch 3907/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7201 - mse: 708.8652 - val_loss: 18.8887 - val_mse: 786.5988\n",
      "Epoch 3908/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.1799 - mse: 801.5750 - val_loss: 18.5040 - val_mse: 755.0707\n",
      "Epoch 3909/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4289 - mse: 675.8522 - val_loss: 17.6569 - val_mse: 719.6707\n",
      "Epoch 3910/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9993 - mse: 658.0530 - val_loss: 17.5585 - val_mse: 672.4772\n",
      "Epoch 3911/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2392 - mse: 673.5989 - val_loss: 17.5189 - val_mse: 692.1097\n",
      "Epoch 3912/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2620 - mse: 681.6152 - val_loss: 19.4717 - val_mse: 873.5663\n",
      "Epoch 3913/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7874 - mse: 704.8051 - val_loss: 17.4676 - val_mse: 659.1048\n",
      "Epoch 3914/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1914 - mse: 670.1763 - val_loss: 17.3551 - val_mse: 680.0446\n",
      "Epoch 3915/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3133 - mse: 670.2876 - val_loss: 17.7612 - val_mse: 702.1523\n",
      "Epoch 3916/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2385 - mse: 680.5256 - val_loss: 17.4951 - val_mse: 684.7661\n",
      "Epoch 3917/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8499 - mse: 651.2324 - val_loss: 18.0380 - val_mse: 769.5530\n",
      "Epoch 3918/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0457 - mse: 661.5562 - val_loss: 17.2042 - val_mse: 684.1445\n",
      "Epoch 3919/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.6616 - mse: 639.3032 - val_loss: 17.6711 - val_mse: 666.8792\n",
      "Epoch 3920/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9721 - mse: 718.1141 - val_loss: 18.8076 - val_mse: 793.1377\n",
      "Epoch 3921/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1932 - mse: 667.8788 - val_loss: 17.3328 - val_mse: 703.7342\n",
      "Epoch 3922/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4578 - mse: 673.7365 - val_loss: 17.5313 - val_mse: 698.3233\n",
      "Epoch 3923/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1379 - mse: 664.8375 - val_loss: 17.9538 - val_mse: 757.3110\n",
      "Epoch 3924/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0218 - mse: 660.3478 - val_loss: 17.3595 - val_mse: 679.0571\n",
      "Epoch 3925/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9115 - mse: 656.3711 - val_loss: 19.8490 - val_mse: 759.1868\n",
      "Epoch 3926/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.3465 - mse: 721.9141 - val_loss: 18.5223 - val_mse: 788.5253\n",
      "Epoch 3927/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2167 - mse: 672.4266 - val_loss: 17.7015 - val_mse: 702.4811\n",
      "Epoch 3928/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1096 - mse: 663.5538 - val_loss: 18.1208 - val_mse: 761.6200\n",
      "Epoch 3929/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3994 - mse: 684.4900 - val_loss: 18.5575 - val_mse: 685.7544\n",
      "Epoch 3930/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.5340 - mse: 683.0483 - val_loss: 19.7004 - val_mse: 872.7327\n",
      "Epoch 3931/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1207 - mse: 668.0474 - val_loss: 17.3729 - val_mse: 704.8986\n",
      "Epoch 3932/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1457 - mse: 659.8325 - val_loss: 18.2370 - val_mse: 762.2591\n",
      "Epoch 3933/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4254 - mse: 678.9373 - val_loss: 17.3918 - val_mse: 696.9354\n",
      "Epoch 3934/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8553 - mse: 650.5692 - val_loss: 17.8449 - val_mse: 758.8745\n",
      "Epoch 3935/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.5981 - mse: 697.2698 - val_loss: 17.7467 - val_mse: 724.3130\n",
      "Epoch 3936/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9074 - mse: 655.5562 - val_loss: 17.4125 - val_mse: 668.3544\n",
      "Epoch 3937/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9031 - mse: 653.4849 - val_loss: 17.6611 - val_mse: 668.3984\n",
      "Epoch 3938/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.5315 - mse: 684.6273 - val_loss: 18.3207 - val_mse: 808.1660\n",
      "Epoch 3939/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.5692 - mse: 701.5082 - val_loss: 17.8395 - val_mse: 724.6004\n",
      "Epoch 3940/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.1171 - mse: 661.1433 - val_loss: 17.8527 - val_mse: 668.2518\n",
      "Epoch 3941/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8939 - mse: 649.4051 - val_loss: 17.8166 - val_mse: 732.6642\n",
      "Epoch 3942/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7276 - mse: 651.9644 - val_loss: 17.3924 - val_mse: 681.5960\n",
      "Epoch 3943/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.6616 - mse: 636.8434 - val_loss: 17.9056 - val_mse: 727.9498\n",
      "Epoch 3944/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.9240 - mse: 654.3428 - val_loss: 17.8229 - val_mse: 749.6799\n",
      "Epoch 3945/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6076 - mse: 687.9149 - val_loss: 18.6566 - val_mse: 781.2439\n",
      "Epoch 3946/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.5740 - mse: 694.7008 - val_loss: 18.4207 - val_mse: 777.4121\n",
      "Epoch 3947/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0821 - mse: 667.1711 - val_loss: 17.5896 - val_mse: 707.9528\n",
      "Epoch 3948/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0372 - mse: 663.7570 - val_loss: 17.4251 - val_mse: 710.1750\n",
      "Epoch 3949/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6344 - mse: 689.3879 - val_loss: 17.7985 - val_mse: 751.9613\n",
      "Epoch 3950/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6807 - mse: 701.7502 - val_loss: 18.1791 - val_mse: 702.2321\n",
      "Epoch 3951/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.9071 - mse: 655.3011 - val_loss: 17.6586 - val_mse: 691.6220\n",
      "Epoch 3952/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9351 - mse: 660.8557 - val_loss: 17.4697 - val_mse: 675.1823\n",
      "Epoch 3953/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9583 - mse: 655.0048 - val_loss: 17.1399 - val_mse: 681.7816\n",
      "Epoch 3954/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0236 - mse: 664.2019 - val_loss: 17.8927 - val_mse: 691.6454\n",
      "Epoch 3955/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0995 - mse: 666.0029 - val_loss: 17.4243 - val_mse: 694.9706\n",
      "Epoch 3956/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1389 - mse: 676.7101 - val_loss: 18.1740 - val_mse: 783.7729\n",
      "Epoch 3957/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0071 - mse: 657.0494 - val_loss: 17.2527 - val_mse: 683.8388\n",
      "Epoch 3958/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2389 - mse: 661.2329 - val_loss: 19.1742 - val_mse: 814.4500\n",
      "Epoch 3959/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3486 - mse: 686.3961 - val_loss: 17.6075 - val_mse: 709.1166\n",
      "Epoch 3960/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1180 - mse: 669.2277 - val_loss: 17.3970 - val_mse: 686.4004\n",
      "Epoch 3961/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0666 - mse: 663.3076 - val_loss: 17.2988 - val_mse: 699.2093\n",
      "Epoch 3962/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0847 - mse: 668.7397 - val_loss: 17.5950 - val_mse: 691.5389\n",
      "Epoch 3963/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 16.8957 - mse: 653.0086 - val_loss: 17.6771 - val_mse: 681.3091\n",
      "Epoch 3964/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2493 - mse: 674.5740 - val_loss: 17.5974 - val_mse: 718.2499\n",
      "Epoch 3965/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8636 - mse: 651.0672 - val_loss: 17.8066 - val_mse: 676.3408\n",
      "Epoch 3966/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3242 - mse: 673.7984 - val_loss: 17.6902 - val_mse: 689.7519\n",
      "Epoch 3967/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3631 - mse: 681.0649 - val_loss: 17.5062 - val_mse: 692.4227\n",
      "Epoch 3968/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3448 - mse: 681.9274 - val_loss: 17.4872 - val_mse: 708.6076\n",
      "Epoch 3969/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3117 - mse: 669.5090 - val_loss: 17.7468 - val_mse: 750.3848\n",
      "Epoch 3970/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.3840 - mse: 747.8238 - val_loss: 18.1274 - val_mse: 745.2359\n",
      "Epoch 3971/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5790 - mse: 688.5748 - val_loss: 17.4664 - val_mse: 686.3337\n",
      "Epoch 3972/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7725 - mse: 646.9426 - val_loss: 17.3625 - val_mse: 689.2020\n",
      "Epoch 3973/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1578 - mse: 668.2185 - val_loss: 17.8560 - val_mse: 701.7054\n",
      "Epoch 3974/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0614 - mse: 661.3769 - val_loss: 17.2492 - val_mse: 683.9815\n",
      "Epoch 3975/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8281 - mse: 651.1570 - val_loss: 17.7677 - val_mse: 668.5447\n",
      "Epoch 3976/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2027 - mse: 673.1285 - val_loss: 17.6921 - val_mse: 684.0610\n",
      "Epoch 3977/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8979 - mse: 705.2894 - val_loss: 17.8203 - val_mse: 731.7599\n",
      "Epoch 3978/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8709 - mse: 648.0309 - val_loss: 17.2743 - val_mse: 671.7517\n",
      "Epoch 3979/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3468 - mse: 676.2390 - val_loss: 17.5880 - val_mse: 687.0170\n",
      "Epoch 3980/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2285 - mse: 676.8985 - val_loss: 17.8101 - val_mse: 679.6577\n",
      "Epoch 3981/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.9175 - mse: 703.3752 - val_loss: 17.4962 - val_mse: 690.0020\n",
      "Epoch 3982/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9012 - mse: 719.4229 - val_loss: 20.2592 - val_mse: 934.4067\n",
      "Epoch 3983/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2320 - mse: 734.3802 - val_loss: 18.3981 - val_mse: 751.1721\n",
      "Epoch 3984/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2266 - mse: 676.0066 - val_loss: 17.6229 - val_mse: 723.4369\n",
      "Epoch 3985/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1133 - mse: 664.7390 - val_loss: 18.3387 - val_mse: 764.0146\n",
      "Epoch 3986/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2922 - mse: 683.6980 - val_loss: 17.4798 - val_mse: 689.8574\n",
      "Epoch 3987/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.7683 - mse: 703.2960 - val_loss: 17.3131 - val_mse: 678.3530\n",
      "Epoch 3988/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3265 - mse: 669.7510 - val_loss: 18.8313 - val_mse: 697.3089\n",
      "Epoch 3989/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.1497 - mse: 730.0098 - val_loss: 17.8271 - val_mse: 737.2505\n",
      "Epoch 3990/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4636 - mse: 694.2370 - val_loss: 18.3318 - val_mse: 716.7629\n",
      "Epoch 3991/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.0145 - mse: 656.8334 - val_loss: 17.3973 - val_mse: 708.5298\n",
      "Epoch 3992/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7807 - mse: 647.1807 - val_loss: 17.3021 - val_mse: 682.8467\n",
      "Epoch 3993/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7558 - mse: 648.2213 - val_loss: 18.4640 - val_mse: 684.5048\n",
      "Epoch 3994/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0864 - mse: 669.1546 - val_loss: 17.5533 - val_mse: 689.4291\n",
      "Epoch 3995/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.6421 - mse: 635.5336 - val_loss: 17.4462 - val_mse: 707.5073\n",
      "Epoch 3996/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 17.8390 - mse: 709.5988 - val_loss: 18.0606 - val_mse: 744.5878\n",
      "Epoch 3997/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0616 - mse: 657.7451 - val_loss: 17.5526 - val_mse: 674.3111\n",
      "Epoch 3998/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4442 - mse: 687.7016 - val_loss: 18.9212 - val_mse: 706.5522\n",
      "Epoch 3999/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.0195 - mse: 720.5526 - val_loss: 20.6844 - val_mse: 977.2436\n",
      "Epoch 4000/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 19.5932 - mse: 798.7213 - val_loss: 18.4475 - val_mse: 796.4081\n",
      "Epoch 4001/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0494 - mse: 711.7302 - val_loss: 17.7902 - val_mse: 750.4169\n",
      "Epoch 4002/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9628 - mse: 656.4808 - val_loss: 17.5912 - val_mse: 688.5051\n",
      "Epoch 4003/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2969 - mse: 665.9591 - val_loss: 18.7249 - val_mse: 843.2890\n",
      "Epoch 4004/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.8413 - mse: 704.4766 - val_loss: 17.6039 - val_mse: 729.0512\n",
      "Epoch 4005/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 19.0678 - mse: 792.3894 - val_loss: 19.2741 - val_mse: 770.3383\n",
      "Epoch 4006/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9048 - mse: 714.2327 - val_loss: 17.4511 - val_mse: 658.9866\n",
      "Epoch 4007/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7019 - mse: 705.9807 - val_loss: 18.2174 - val_mse: 742.3301\n",
      "Epoch 4008/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3056 - mse: 666.7908 - val_loss: 17.4940 - val_mse: 716.7383\n",
      "Epoch 4009/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.1855 - mse: 669.4534 - val_loss: 17.7292 - val_mse: 714.3000\n",
      "Epoch 4010/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9700 - mse: 655.9125 - val_loss: 17.6897 - val_mse: 703.1934\n",
      "Epoch 4011/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1493 - mse: 661.3128 - val_loss: 18.5735 - val_mse: 813.3680\n",
      "Epoch 4012/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1608 - mse: 668.9305 - val_loss: 17.5442 - val_mse: 704.4846\n",
      "Epoch 4013/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0323 - mse: 657.9268 - val_loss: 17.2285 - val_mse: 681.9942\n",
      "Epoch 4014/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0077 - mse: 658.5331 - val_loss: 17.7044 - val_mse: 736.1959\n",
      "Epoch 4015/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7262 - mse: 648.0027 - val_loss: 17.7791 - val_mse: 674.8686\n",
      "Epoch 4016/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8950 - mse: 658.0246 - val_loss: 17.8336 - val_mse: 685.6907\n",
      "Epoch 4017/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1142 - mse: 657.7972 - val_loss: 18.4916 - val_mse: 744.6320\n",
      "Epoch 4018/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1334 - mse: 672.9368 - val_loss: 17.5280 - val_mse: 699.7202\n",
      "Epoch 4019/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2218 - mse: 667.6279 - val_loss: 17.8359 - val_mse: 702.5217\n",
      "Epoch 4020/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6025 - mse: 701.0420 - val_loss: 18.4139 - val_mse: 723.2323\n",
      "Epoch 4021/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0932 - mse: 717.4760 - val_loss: 18.7463 - val_mse: 833.0052\n",
      "Epoch 4022/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1340 - mse: 664.8253 - val_loss: 17.2772 - val_mse: 670.1072\n",
      "Epoch 4023/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8739 - mse: 651.3559 - val_loss: 17.2539 - val_mse: 692.2504\n",
      "Epoch 4024/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9573 - mse: 652.7576 - val_loss: 17.6987 - val_mse: 690.8222\n",
      "Epoch 4025/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7613 - mse: 650.3433 - val_loss: 17.3529 - val_mse: 665.7817\n",
      "Epoch 4026/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5523 - mse: 686.8271 - val_loss: 19.8513 - val_mse: 908.9568\n",
      "Epoch 4027/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5806 - mse: 690.3672 - val_loss: 18.1421 - val_mse: 713.3831\n",
      "Epoch 4028/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3024 - mse: 676.4121 - val_loss: 18.5402 - val_mse: 786.2887\n",
      "Epoch 4029/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9890 - mse: 658.5721 - val_loss: 17.4127 - val_mse: 686.7482\n",
      "Epoch 4030/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2589 - mse: 678.8799 - val_loss: 17.3107 - val_mse: 673.3875\n",
      "Epoch 4031/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3106 - mse: 672.2630 - val_loss: 17.6774 - val_mse: 679.3291\n",
      "Epoch 4032/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4713 - mse: 682.0006 - val_loss: 17.5356 - val_mse: 725.0280\n",
      "Epoch 4033/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1154 - mse: 674.6154 - val_loss: 18.0621 - val_mse: 693.4200\n",
      "Epoch 4034/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5163 - mse: 697.0994 - val_loss: 17.8082 - val_mse: 683.4670\n",
      "Epoch 4035/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0255 - mse: 663.1495 - val_loss: 17.4720 - val_mse: 713.7723\n",
      "Epoch 4036/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0139 - mse: 664.0968 - val_loss: 17.5145 - val_mse: 699.6475\n",
      "Epoch 4037/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7513 - mse: 640.9714 - val_loss: 17.8519 - val_mse: 735.2744\n",
      "Epoch 4038/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.6554 - mse: 709.1665 - val_loss: 17.4213 - val_mse: 688.7580\n",
      "Epoch 4039/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5913 - mse: 689.7850 - val_loss: 17.3647 - val_mse: 688.9923\n",
      "Epoch 4040/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7752 - mse: 648.7300 - val_loss: 18.0738 - val_mse: 723.2916\n",
      "Epoch 4041/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8165 - mse: 652.5298 - val_loss: 17.3189 - val_mse: 667.4545\n",
      "Epoch 4042/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4130 - mse: 686.6736 - val_loss: 17.2717 - val_mse: 675.4315\n",
      "Epoch 4043/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.0701 - mse: 790.2347 - val_loss: 20.2459 - val_mse: 913.2513\n",
      "Epoch 4044/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2375 - mse: 736.8208 - val_loss: 17.8251 - val_mse: 688.4700\n",
      "Epoch 4045/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.3621 - mse: 670.4780 - val_loss: 17.7786 - val_mse: 756.3488\n",
      "Epoch 4046/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3745 - mse: 689.9039 - val_loss: 18.0057 - val_mse: 728.1620\n",
      "Epoch 4047/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5180 - mse: 695.3424 - val_loss: 17.8799 - val_mse: 665.2717\n",
      "Epoch 4048/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2019 - mse: 653.5211 - val_loss: 18.0719 - val_mse: 749.1718\n",
      "Epoch 4049/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3365 - mse: 680.8687 - val_loss: 17.5388 - val_mse: 682.9360\n",
      "Epoch 4050/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3203 - mse: 664.4915 - val_loss: 18.7591 - val_mse: 775.1468\n",
      "Epoch 4051/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.0294 - mse: 723.1685 - val_loss: 17.4060 - val_mse: 694.1547\n",
      "Epoch 4052/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0050 - mse: 656.0406 - val_loss: 17.7809 - val_mse: 679.8284\n",
      "Epoch 4053/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9354 - mse: 657.8114 - val_loss: 17.4266 - val_mse: 688.1658\n",
      "Epoch 4054/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8219 - mse: 651.1364 - val_loss: 17.9176 - val_mse: 695.5188\n",
      "Epoch 4055/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4508 - mse: 685.8539 - val_loss: 17.5292 - val_mse: 688.4934\n",
      "Epoch 4056/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4324 - mse: 684.0493 - val_loss: 17.2484 - val_mse: 679.2546\n",
      "Epoch 4057/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9714 - mse: 663.4991 - val_loss: 18.3773 - val_mse: 714.0422\n",
      "Epoch 4058/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9736 - mse: 663.1228 - val_loss: 17.5314 - val_mse: 666.8251\n",
      "Epoch 4059/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2401 - mse: 668.0034 - val_loss: 17.6104 - val_mse: 707.6251\n",
      "Epoch 4060/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3478 - mse: 672.2239 - val_loss: 17.8910 - val_mse: 741.0754\n",
      "Epoch 4061/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0603 - mse: 666.3145 - val_loss: 17.8777 - val_mse: 709.7519\n",
      "Epoch 4062/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.1633 - mse: 664.6916 - val_loss: 18.3454 - val_mse: 783.6053\n",
      "Epoch 4063/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8949 - mse: 660.6892 - val_loss: 17.6920 - val_mse: 676.7436\n",
      "Epoch 4064/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7414 - mse: 648.2972 - val_loss: 17.2207 - val_mse: 679.3118\n",
      "Epoch 4065/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1147 - mse: 660.3336 - val_loss: 17.5591 - val_mse: 707.8524\n",
      "Epoch 4066/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1806 - mse: 671.5861 - val_loss: 18.4169 - val_mse: 769.4831\n",
      "Epoch 4067/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0911 - mse: 662.8089 - val_loss: 17.4735 - val_mse: 672.9561\n",
      "Epoch 4068/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6123 - mse: 638.3238 - val_loss: 17.3611 - val_mse: 668.4410\n",
      "Epoch 4069/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.2691 - mse: 677.1475 - val_loss: 18.1598 - val_mse: 778.5975\n",
      "Epoch 4070/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.9482 - mse: 659.7961 - val_loss: 18.2393 - val_mse: 692.6222\n",
      "Epoch 4071/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.2109 - mse: 738.0389 - val_loss: 18.3768 - val_mse: 759.0822\n",
      "Epoch 4072/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.5936 - mse: 691.1599 - val_loss: 17.3946 - val_mse: 684.6591\n",
      "Epoch 4073/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.0983 - mse: 655.9100 - val_loss: 17.8904 - val_mse: 666.7068\n",
      "Epoch 4074/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2068 - mse: 674.6993 - val_loss: 17.6256 - val_mse: 713.3002\n",
      "Epoch 4075/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.2113 - mse: 737.1803 - val_loss: 17.9124 - val_mse: 718.7693\n",
      "Epoch 4076/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4505 - mse: 686.5497 - val_loss: 17.6834 - val_mse: 679.0239\n",
      "Epoch 4077/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 16.9598 - mse: 647.6985 - val_loss: 17.4427 - val_mse: 707.8022\n",
      "Epoch 4078/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7370 - mse: 651.1710 - val_loss: 18.1529 - val_mse: 688.1373\n",
      "Epoch 4079/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0953 - mse: 659.5629 - val_loss: 17.3465 - val_mse: 693.8054\n",
      "Epoch 4080/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0480 - mse: 671.4470 - val_loss: 20.0814 - val_mse: 907.7770\n",
      "Epoch 4081/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.4029 - mse: 684.7961 - val_loss: 18.0031 - val_mse: 716.1042\n",
      "Epoch 4082/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.0377 - mse: 666.5954 - val_loss: 17.4561 - val_mse: 706.0561\n",
      "Epoch 4083/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.2210 - mse: 668.3217 - val_loss: 17.6337 - val_mse: 707.6347\n",
      "Epoch 4084/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8188 - mse: 649.0129 - val_loss: 17.6453 - val_mse: 720.2258\n",
      "Epoch 4085/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 17.1913 - mse: 673.7736 - val_loss: 17.9819 - val_mse: 687.5031\n",
      "Epoch 4086/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8842 - mse: 651.2906 - val_loss: 17.8514 - val_mse: 735.6263\n",
      "Epoch 4087/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9910 - mse: 662.2855 - val_loss: 18.4357 - val_mse: 772.6159\n",
      "Epoch 4088/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0025 - mse: 659.5836 - val_loss: 17.8067 - val_mse: 705.7791\n",
      "Epoch 4089/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1331 - mse: 661.4816 - val_loss: 17.4510 - val_mse: 692.6274\n",
      "Epoch 4090/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8282 - mse: 650.3638 - val_loss: 17.8579 - val_mse: 719.1246\n",
      "Epoch 4091/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3387 - mse: 685.7372 - val_loss: 18.0204 - val_mse: 732.2672\n",
      "Epoch 4092/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2174 - mse: 675.1205 - val_loss: 17.6638 - val_mse: 677.0208\n",
      "Epoch 4093/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.9534 - mse: 657.5903 - val_loss: 17.3244 - val_mse: 674.7429\n",
      "Epoch 4094/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1950 - mse: 673.5795 - val_loss: 17.6815 - val_mse: 690.1854\n",
      "Epoch 4095/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2758 - mse: 682.5250 - val_loss: 18.4300 - val_mse: 728.6202\n",
      "Epoch 4096/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3663 - mse: 686.4799 - val_loss: 17.3581 - val_mse: 677.2240\n",
      "Epoch 4097/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1277 - mse: 664.8084 - val_loss: 17.5918 - val_mse: 706.7222\n",
      "Epoch 4098/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2743 - mse: 677.7465 - val_loss: 18.5018 - val_mse: 717.7111\n",
      "Epoch 4099/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.2035 - mse: 674.7645 - val_loss: 17.7544 - val_mse: 709.7491\n",
      "Epoch 4100/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2216 - mse: 659.0627 - val_loss: 17.8015 - val_mse: 739.6330\n",
      "Epoch 4101/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0494 - mse: 666.8656 - val_loss: 17.8070 - val_mse: 684.4717\n",
      "Epoch 4102/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0161 - mse: 654.2042 - val_loss: 18.0212 - val_mse: 728.2363\n",
      "Epoch 4103/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9927 - mse: 661.0981 - val_loss: 17.3983 - val_mse: 666.9865\n",
      "Epoch 4104/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.6792 - mse: 708.0480 - val_loss: 18.0600 - val_mse: 694.0675\n",
      "Epoch 4105/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.5597 - mse: 682.0308 - val_loss: 17.4886 - val_mse: 682.9817\n",
      "Epoch 4106/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3603 - mse: 690.5121 - val_loss: 17.3495 - val_mse: 697.0475\n",
      "Epoch 4107/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.0200 - mse: 664.9858 - val_loss: 19.7100 - val_mse: 847.0380\n",
      "Epoch 4108/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.1637 - mse: 805.1010 - val_loss: 19.5638 - val_mse: 740.5547\n",
      "Epoch 4109/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.8442 - mse: 695.8277 - val_loss: 17.6459 - val_mse: 706.2205\n",
      "Epoch 4110/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 16.8893 - mse: 652.6550 - val_loss: 17.4203 - val_mse: 681.9155\n",
      "Epoch 4111/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9491 - mse: 661.5310 - val_loss: 18.1818 - val_mse: 691.4886\n",
      "Epoch 4112/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4063 - mse: 680.6947 - val_loss: 18.0948 - val_mse: 763.7480\n",
      "Epoch 4113/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9210 - mse: 654.4257 - val_loss: 17.4396 - val_mse: 665.9208\n",
      "Epoch 4114/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8799 - mse: 659.3123 - val_loss: 17.1712 - val_mse: 652.7177\n",
      "Epoch 4115/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 17.1621 - mse: 672.0035 - val_loss: 17.8607 - val_mse: 723.6135\n",
      "Epoch 4116/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 16.7403 - mse: 650.9399 - val_loss: 17.1906 - val_mse: 686.9423\n",
      "Epoch 4117/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8983 - mse: 658.4397 - val_loss: 17.3640 - val_mse: 683.5955\n",
      "Epoch 4118/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.7608 - mse: 650.8602 - val_loss: 17.3732 - val_mse: 668.9216\n",
      "Epoch 4119/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.9545 - mse: 715.5322 - val_loss: 19.1369 - val_mse: 818.2531\n",
      "Epoch 4120/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.4546 - mse: 682.8057 - val_loss: 17.8387 - val_mse: 677.4185\n",
      "Epoch 4121/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1236 - mse: 670.6333 - val_loss: 19.6140 - val_mse: 885.5189\n",
      "Epoch 4122/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3126 - mse: 685.3802 - val_loss: 17.3070 - val_mse: 673.0654\n",
      "Epoch 4123/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9554 - mse: 656.2090 - val_loss: 17.5019 - val_mse: 710.0123\n",
      "Epoch 4124/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.9924 - mse: 770.4218 - val_loss: 20.2927 - val_mse: 768.2858\n",
      "Epoch 4125/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.1500 - mse: 797.0239 - val_loss: 18.5397 - val_mse: 769.1967\n",
      "Epoch 4126/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2571 - mse: 739.6008 - val_loss: 19.3985 - val_mse: 857.7076\n",
      "Epoch 4127/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0212 - mse: 718.1737 - val_loss: 20.1312 - val_mse: 742.7282\n",
      "Epoch 4128/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.9891 - mse: 777.1749 - val_loss: 18.1197 - val_mse: 734.4926\n",
      "Epoch 4129/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0099 - mse: 706.7383 - val_loss: 17.5969 - val_mse: 710.9955\n",
      "Epoch 4130/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4767 - mse: 673.3333 - val_loss: 17.8442 - val_mse: 737.0476\n",
      "Epoch 4131/5000\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 17.0306 - mse: 664.4975 - val_loss: 17.4648 - val_mse: 675.4175\n",
      "Epoch 4132/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 16.7650 - mse: 645.2404 - val_loss: 17.9335 - val_mse: 677.9260\n",
      "Epoch 4133/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8693 - mse: 648.3658 - val_loss: 17.4713 - val_mse: 692.3180\n",
      "Epoch 4134/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0743 - mse: 670.5928 - val_loss: 18.4775 - val_mse: 766.9611\n",
      "Epoch 4135/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0624 - mse: 665.0190 - val_loss: 17.5499 - val_mse: 687.9640\n",
      "Epoch 4136/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0767 - mse: 667.7758 - val_loss: 17.3479 - val_mse: 680.2951\n",
      "Epoch 4137/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1925 - mse: 668.7419 - val_loss: 18.0233 - val_mse: 778.2733\n",
      "Epoch 4138/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4845 - mse: 686.0877 - val_loss: 17.6765 - val_mse: 740.5915\n",
      "Epoch 4139/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7058 - mse: 647.9503 - val_loss: 17.3467 - val_mse: 662.5995\n",
      "Epoch 4140/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0061 - mse: 659.3466 - val_loss: 17.6539 - val_mse: 687.1255\n",
      "Epoch 4141/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4703 - mse: 690.1563 - val_loss: 17.4868 - val_mse: 694.6812\n",
      "Epoch 4142/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6657 - mse: 644.6646 - val_loss: 17.4868 - val_mse: 673.7736\n",
      "Epoch 4143/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0655 - mse: 665.4126 - val_loss: 17.4592 - val_mse: 660.0952\n",
      "Epoch 4144/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7536 - mse: 650.2875 - val_loss: 17.9784 - val_mse: 767.5212\n",
      "Epoch 4145/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7759 - mse: 644.5023 - val_loss: 18.2737 - val_mse: 780.0096\n",
      "Epoch 4146/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9820 - mse: 665.5867 - val_loss: 17.8969 - val_mse: 678.5440\n",
      "Epoch 4147/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2601 - mse: 750.9336 - val_loss: 18.7469 - val_mse: 691.6303\n",
      "Epoch 4148/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0747 - mse: 665.4908 - val_loss: 17.3175 - val_mse: 660.1100\n",
      "Epoch 4149/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1423 - mse: 668.4091 - val_loss: 18.0747 - val_mse: 690.5842\n",
      "Epoch 4150/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9462 - mse: 656.6425 - val_loss: 17.8219 - val_mse: 735.3906\n",
      "Epoch 4151/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8162 - mse: 653.4353 - val_loss: 17.6940 - val_mse: 733.5688\n",
      "Epoch 4152/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6223 - mse: 643.4310 - val_loss: 17.3015 - val_mse: 703.0287\n",
      "Epoch 4153/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0649 - mse: 658.4077 - val_loss: 18.3479 - val_mse: 753.2069\n",
      "Epoch 4154/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4786 - mse: 699.6027 - val_loss: 18.5158 - val_mse: 746.6820\n",
      "Epoch 4155/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6923 - mse: 701.9717 - val_loss: 18.1107 - val_mse: 673.8566\n",
      "Epoch 4156/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4341 - mse: 689.6191 - val_loss: 18.1016 - val_mse: 689.3705\n",
      "Epoch 4157/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5339 - mse: 694.8892 - val_loss: 20.6391 - val_mse: 967.0154\n",
      "Epoch 4158/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.0580 - mse: 734.1276 - val_loss: 17.8709 - val_mse: 682.5473\n",
      "Epoch 4159/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0584 - mse: 657.5018 - val_loss: 17.3814 - val_mse: 669.3241\n",
      "Epoch 4160/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7284 - mse: 638.0471 - val_loss: 17.3713 - val_mse: 712.7605\n",
      "Epoch 4161/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7004 - mse: 643.4478 - val_loss: 17.3830 - val_mse: 676.9349\n",
      "Epoch 4162/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.4860 - mse: 629.1552 - val_loss: 17.3009 - val_mse: 696.6122\n",
      "Epoch 4163/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0152 - mse: 724.7511 - val_loss: 19.9043 - val_mse: 890.8554\n",
      "Epoch 4164/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4012 - mse: 690.6400 - val_loss: 17.9882 - val_mse: 683.9652\n",
      "Epoch 4165/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9922 - mse: 658.2502 - val_loss: 18.2699 - val_mse: 720.7118\n",
      "Epoch 4166/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2002 - mse: 672.1346 - val_loss: 18.4735 - val_mse: 687.0930\n",
      "Epoch 4167/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3004 - mse: 668.9706 - val_loss: 17.7422 - val_mse: 662.6762\n",
      "Epoch 4168/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0666 - mse: 663.1834 - val_loss: 17.4316 - val_mse: 669.8329\n",
      "Epoch 4169/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9045 - mse: 648.3011 - val_loss: 18.5642 - val_mse: 797.5739\n",
      "Epoch 4170/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0931 - mse: 668.6941 - val_loss: 17.8263 - val_mse: 693.5419\n",
      "Epoch 4171/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4506 - mse: 683.4722 - val_loss: 18.7777 - val_mse: 704.5140\n",
      "Epoch 4172/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5231 - mse: 690.9008 - val_loss: 18.5348 - val_mse: 699.6855\n",
      "Epoch 4173/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1907 - mse: 668.9997 - val_loss: 18.0553 - val_mse: 739.3137\n",
      "Epoch 4174/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9747 - mse: 660.2996 - val_loss: 17.7393 - val_mse: 682.6526\n",
      "Epoch 4175/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7677 - mse: 651.4249 - val_loss: 17.3801 - val_mse: 698.9413\n",
      "Epoch 4176/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2056 - mse: 667.6454 - val_loss: 18.5301 - val_mse: 691.3578\n",
      "Epoch 4177/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2213 - mse: 671.8578 - val_loss: 17.4511 - val_mse: 662.6904\n",
      "Epoch 4178/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3808 - mse: 684.3451 - val_loss: 18.0301 - val_mse: 723.9731\n",
      "Epoch 4179/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.6239 - mse: 703.8149 - val_loss: 18.0125 - val_mse: 735.8641\n",
      "Epoch 4180/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.0366 - mse: 657.6913 - val_loss: 17.4250 - val_mse: 672.3544\n",
      "Epoch 4181/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0780 - mse: 665.0034 - val_loss: 17.9943 - val_mse: 740.2797\n",
      "Epoch 4182/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.7025 - mse: 694.2059 - val_loss: 17.7182 - val_mse: 732.4910\n",
      "Epoch 4183/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.0651 - mse: 735.3526 - val_loss: 18.9408 - val_mse: 717.0262\n",
      "Epoch 4184/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.3656 - mse: 685.7153 - val_loss: 18.3314 - val_mse: 787.1946\n",
      "Epoch 4185/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9462 - mse: 651.3845 - val_loss: 18.2936 - val_mse: 735.3436\n",
      "Epoch 4186/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1067 - mse: 664.2308 - val_loss: 18.0165 - val_mse: 687.0448\n",
      "Epoch 4187/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9842 - mse: 658.8721 - val_loss: 17.4404 - val_mse: 675.9552\n",
      "Epoch 4188/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.7627 - mse: 700.3971 - val_loss: 18.9907 - val_mse: 860.9984\n",
      "Epoch 4189/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2137 - mse: 688.2034 - val_loss: 18.6577 - val_mse: 751.7118\n",
      "Epoch 4190/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5330 - mse: 682.6241 - val_loss: 17.4236 - val_mse: 698.3016\n",
      "Epoch 4191/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1925 - mse: 675.6480 - val_loss: 17.3689 - val_mse: 682.3701\n",
      "Epoch 4192/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9247 - mse: 655.0328 - val_loss: 18.2872 - val_mse: 702.8143\n",
      "Epoch 4193/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0521 - mse: 663.2709 - val_loss: 17.9538 - val_mse: 683.6187\n",
      "Epoch 4194/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1749 - mse: 663.0193 - val_loss: 17.3630 - val_mse: 701.2131\n",
      "Epoch 4195/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7447 - mse: 647.3844 - val_loss: 17.6609 - val_mse: 672.7584\n",
      "Epoch 4196/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0017 - mse: 665.3314 - val_loss: 17.2449 - val_mse: 661.4109\n",
      "Epoch 4197/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7500 - mse: 647.0667 - val_loss: 17.4971 - val_mse: 664.9832\n",
      "Epoch 4198/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7982 - mse: 646.0512 - val_loss: 17.2506 - val_mse: 690.6359\n",
      "Epoch 4199/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4872 - mse: 691.9991 - val_loss: 18.0930 - val_mse: 763.3997\n",
      "Epoch 4200/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1140 - mse: 673.0648 - val_loss: 17.6733 - val_mse: 653.3460\n",
      "Epoch 4201/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7999 - mse: 652.4957 - val_loss: 17.1843 - val_mse: 658.6549\n",
      "Epoch 4202/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 18.0157 - mse: 722.1132 - val_loss: 18.7142 - val_mse: 735.6439\n",
      "Epoch 4203/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.9313 - mse: 713.1510 - val_loss: 18.4890 - val_mse: 723.4516\n",
      "Epoch 4204/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4927 - mse: 684.4005 - val_loss: 17.4867 - val_mse: 674.9426\n",
      "Epoch 4205/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7908 - mse: 653.4500 - val_loss: 17.2213 - val_mse: 669.2187\n",
      "Epoch 4206/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9671 - mse: 661.9568 - val_loss: 17.4264 - val_mse: 681.4871\n",
      "Epoch 4207/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3434 - mse: 677.7139 - val_loss: 17.4266 - val_mse: 708.4909\n",
      "Epoch 4208/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1546 - mse: 674.2410 - val_loss: 17.5162 - val_mse: 708.9813\n",
      "Epoch 4209/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8523 - mse: 653.2288 - val_loss: 17.3588 - val_mse: 704.7828\n",
      "Epoch 4210/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1332 - mse: 669.6055 - val_loss: 18.8086 - val_mse: 756.0417\n",
      "Epoch 4211/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1119 - mse: 680.8120 - val_loss: 17.6956 - val_mse: 717.5255\n",
      "Epoch 4212/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.7831 - mse: 649.8027 - val_loss: 17.2538 - val_mse: 675.5001\n",
      "Epoch 4213/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0451 - mse: 664.6623 - val_loss: 17.9030 - val_mse: 670.6804\n",
      "Epoch 4214/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4473 - mse: 687.0035 - val_loss: 18.1949 - val_mse: 731.8990\n",
      "Epoch 4215/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3927 - mse: 689.6113 - val_loss: 17.9276 - val_mse: 692.0475\n",
      "Epoch 4216/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2104 - mse: 674.5607 - val_loss: 17.5832 - val_mse: 704.3893\n",
      "Epoch 4217/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9063 - mse: 657.4085 - val_loss: 17.8757 - val_mse: 699.6238\n",
      "Epoch 4218/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9130 - mse: 653.1578 - val_loss: 17.1717 - val_mse: 681.4318\n",
      "Epoch 4219/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7936 - mse: 645.1603 - val_loss: 17.2160 - val_mse: 675.4538\n",
      "Epoch 4220/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9341 - mse: 658.8892 - val_loss: 17.2717 - val_mse: 685.3124\n",
      "Epoch 4221/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.6403 - mse: 644.3746 - val_loss: 17.1853 - val_mse: 672.5223\n",
      "Epoch 4222/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.5839 - mse: 632.3971 - val_loss: 17.0281 - val_mse: 659.4833\n",
      "Epoch 4223/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6885 - mse: 645.3863 - val_loss: 18.4213 - val_mse: 692.6481\n",
      "Epoch 4224/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8051 - mse: 649.3677 - val_loss: 17.0236 - val_mse: 655.6725\n",
      "Epoch 4225/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8354 - mse: 650.2992 - val_loss: 17.6000 - val_mse: 695.7004\n",
      "Epoch 4226/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5147 - mse: 692.7585 - val_loss: 17.6197 - val_mse: 654.6899\n",
      "Epoch 4227/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9787 - mse: 671.0396 - val_loss: 18.3686 - val_mse: 728.5927\n",
      "Epoch 4228/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1043 - mse: 660.1711 - val_loss: 17.9425 - val_mse: 673.2090\n",
      "Epoch 4229/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7803 - mse: 652.6794 - val_loss: 17.4421 - val_mse: 709.6562\n",
      "Epoch 4230/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9164 - mse: 664.1235 - val_loss: 17.9456 - val_mse: 748.2702\n",
      "Epoch 4231/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.5775 - mse: 630.7993 - val_loss: 17.2400 - val_mse: 683.1978\n",
      "Epoch 4232/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0889 - mse: 672.0787 - val_loss: 17.4043 - val_mse: 689.7793\n",
      "Epoch 4233/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0704 - mse: 667.0040 - val_loss: 17.6791 - val_mse: 731.9261\n",
      "Epoch 4234/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5458 - mse: 704.8755 - val_loss: 18.7254 - val_mse: 818.5352\n",
      "Epoch 4235/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3797 - mse: 679.8206 - val_loss: 18.2549 - val_mse: 680.7886\n",
      "Epoch 4236/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3095 - mse: 688.6357 - val_loss: 17.4352 - val_mse: 666.9277\n",
      "Epoch 4237/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.1877 - mse: 668.9214 - val_loss: 17.6788 - val_mse: 696.5457\n",
      "Epoch 4238/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4954 - mse: 750.0076 - val_loss: 19.0288 - val_mse: 804.3114\n",
      "Epoch 4239/5000\n",
      "36/36 [==============================] - 5s 137ms/step - loss: 17.2152 - mse: 684.0154 - val_loss: 17.2573 - val_mse: 673.8651\n",
      "Epoch 4240/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0501 - mse: 670.8729 - val_loss: 17.6740 - val_mse: 660.5737\n",
      "Epoch 4241/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.0715 - mse: 671.8303 - val_loss: 17.8593 - val_mse: 725.8916\n",
      "Epoch 4242/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3676 - mse: 691.0733 - val_loss: 17.2126 - val_mse: 690.8973\n",
      "Epoch 4243/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1008 - mse: 660.5166 - val_loss: 18.1892 - val_mse: 771.0333\n",
      "Epoch 4244/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7633 - mse: 712.2661 - val_loss: 18.7607 - val_mse: 723.7846\n",
      "Epoch 4245/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.0679 - mse: 719.5009 - val_loss: 17.4767 - val_mse: 716.9099\n",
      "Epoch 4246/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4669 - mse: 684.5052 - val_loss: 17.9663 - val_mse: 690.4399\n",
      "Epoch 4247/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 16.7927 - mse: 650.0002 - val_loss: 17.4972 - val_mse: 656.8871\n",
      "Epoch 4248/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1341 - mse: 669.4111 - val_loss: 18.0917 - val_mse: 659.7513\n",
      "Epoch 4249/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2984 - mse: 679.1603 - val_loss: 18.2550 - val_mse: 676.0138\n",
      "Epoch 4250/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2126 - mse: 673.0146 - val_loss: 17.5678 - val_mse: 723.5950\n",
      "Epoch 4251/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1934 - mse: 665.2084 - val_loss: 18.1882 - val_mse: 779.0956\n",
      "Epoch 4252/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.1277 - mse: 677.0411 - val_loss: 17.4240 - val_mse: 691.2963\n",
      "Epoch 4253/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1066 - mse: 662.7130 - val_loss: 17.8623 - val_mse: 735.3206\n",
      "Epoch 4254/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3748 - mse: 678.5859 - val_loss: 17.6783 - val_mse: 666.2751\n",
      "Epoch 4255/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7569 - mse: 701.9230 - val_loss: 17.4412 - val_mse: 706.8995\n",
      "Epoch 4256/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9401 - mse: 659.1214 - val_loss: 17.2476 - val_mse: 671.1993\n",
      "Epoch 4257/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7792 - mse: 636.5964 - val_loss: 17.4254 - val_mse: 681.0516\n",
      "Epoch 4258/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6247 - mse: 703.3032 - val_loss: 18.6414 - val_mse: 689.6801\n",
      "Epoch 4259/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7739 - mse: 644.5425 - val_loss: 17.1277 - val_mse: 642.3564\n",
      "Epoch 4260/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.8254 - mse: 651.2490 - val_loss: 17.6108 - val_mse: 705.4826\n",
      "Epoch 4261/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7377 - mse: 645.4610 - val_loss: 17.2284 - val_mse: 661.8623\n",
      "Epoch 4262/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.5867 - mse: 627.6951 - val_loss: 17.4622 - val_mse: 659.6252\n",
      "Epoch 4263/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.4453 - mse: 636.9030 - val_loss: 18.0125 - val_mse: 676.1314\n",
      "Epoch 4264/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0283 - mse: 658.4449 - val_loss: 17.4089 - val_mse: 676.8403\n",
      "Epoch 4265/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9273 - mse: 659.7334 - val_loss: 17.4470 - val_mse: 670.5024\n",
      "Epoch 4266/5000\n",
      "36/36 [==============================] - 461s 13s/step - loss: 17.0859 - mse: 666.0309 - val_loss: 18.7587 - val_mse: 720.5547\n",
      "Epoch 4267/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 17.2690 - mse: 674.1099 - val_loss: 18.4534 - val_mse: 713.7633\n",
      "Epoch 4268/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 18.1011 - mse: 726.3000 - val_loss: 17.7412 - val_mse: 719.6122\n",
      "Epoch 4269/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8313 - mse: 653.2079 - val_loss: 17.4718 - val_mse: 692.3127\n",
      "Epoch 4270/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 17.0339 - mse: 665.0486 - val_loss: 17.2394 - val_mse: 659.5138\n",
      "Epoch 4271/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.5086 - mse: 638.2178 - val_loss: 17.9395 - val_mse: 685.2307\n",
      "Epoch 4272/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4118 - mse: 674.3867 - val_loss: 17.7034 - val_mse: 741.1264\n",
      "Epoch 4273/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8114 - mse: 650.8290 - val_loss: 17.2539 - val_mse: 646.2726\n",
      "Epoch 4274/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7940 - mse: 651.2417 - val_loss: 17.2941 - val_mse: 674.3495\n",
      "Epoch 4275/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6340 - mse: 641.4774 - val_loss: 17.2972 - val_mse: 635.6616\n",
      "Epoch 4276/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.9017 - mse: 648.4993 - val_loss: 17.7432 - val_mse: 707.1774\n",
      "Epoch 4277/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9075 - mse: 656.1176 - val_loss: 17.4793 - val_mse: 672.0118\n",
      "Epoch 4278/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1242 - mse: 667.0890 - val_loss: 18.3544 - val_mse: 744.6107\n",
      "Epoch 4279/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8176 - mse: 647.7386 - val_loss: 17.1907 - val_mse: 632.3034\n",
      "Epoch 4280/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5735 - mse: 691.4389 - val_loss: 17.9442 - val_mse: 692.8553\n",
      "Epoch 4281/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4382 - mse: 689.9938 - val_loss: 17.2148 - val_mse: 649.5180\n",
      "Epoch 4282/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8410 - mse: 640.2980 - val_loss: 17.9002 - val_mse: 665.3525\n",
      "Epoch 4283/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1973 - mse: 674.7291 - val_loss: 17.6022 - val_mse: 677.4584\n",
      "Epoch 4284/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1445 - mse: 677.2787 - val_loss: 17.1950 - val_mse: 676.5647\n",
      "Epoch 4285/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9864 - mse: 657.0912 - val_loss: 17.5167 - val_mse: 690.2689\n",
      "Epoch 4286/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.8902 - mse: 655.8311 - val_loss: 19.6732 - val_mse: 737.3254\n",
      "Epoch 4287/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2466 - mse: 668.4147 - val_loss: 17.4662 - val_mse: 658.0740\n",
      "Epoch 4288/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6642 - mse: 636.4140 - val_loss: 18.5366 - val_mse: 781.0643\n",
      "Epoch 4289/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.5626 - mse: 646.2651 - val_loss: 17.1854 - val_mse: 657.9473\n",
      "Epoch 4290/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3121 - mse: 677.8784 - val_loss: 17.2660 - val_mse: 686.1201\n",
      "Epoch 4291/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2834 - mse: 688.3888 - val_loss: 17.4283 - val_mse: 662.9573\n",
      "Epoch 4292/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6395 - mse: 632.3875 - val_loss: 17.2562 - val_mse: 662.4052\n",
      "Epoch 4293/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6243 - mse: 641.2783 - val_loss: 17.3901 - val_mse: 691.7659\n",
      "Epoch 4294/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.8192 - mse: 658.3880 - val_loss: 17.3713 - val_mse: 669.3874\n",
      "Epoch 4295/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6088 - mse: 638.3989 - val_loss: 17.3020 - val_mse: 682.8118\n",
      "Epoch 4296/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 16.5898 - mse: 645.6849 - val_loss: 18.2338 - val_mse: 695.4022\n",
      "Epoch 4297/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2625 - mse: 671.5780 - val_loss: 17.9750 - val_mse: 722.1993\n",
      "Epoch 4298/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1891 - mse: 673.0892 - val_loss: 17.3170 - val_mse: 672.3713\n",
      "Epoch 4299/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.8363 - mse: 658.4590 - val_loss: 17.4857 - val_mse: 701.4019\n",
      "Epoch 4300/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4656 - mse: 691.2042 - val_loss: 17.7005 - val_mse: 721.1629\n",
      "Epoch 4301/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6093 - mse: 638.6866 - val_loss: 17.5058 - val_mse: 706.6545\n",
      "Epoch 4302/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4751 - mse: 684.5038 - val_loss: 18.2951 - val_mse: 780.6661\n",
      "Epoch 4303/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.8711 - mse: 656.5414 - val_loss: 17.6227 - val_mse: 674.3099\n",
      "Epoch 4304/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.4541 - mse: 630.9704 - val_loss: 18.6906 - val_mse: 714.2757\n",
      "Epoch 4305/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7237 - mse: 653.9524 - val_loss: 17.9212 - val_mse: 668.1720\n",
      "Epoch 4306/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9666 - mse: 654.2621 - val_loss: 17.8404 - val_mse: 758.8829\n",
      "Epoch 4307/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.8210 - mse: 657.7466 - val_loss: 17.4850 - val_mse: 671.2367\n",
      "Epoch 4308/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7921 - mse: 711.3449 - val_loss: 17.2126 - val_mse: 679.9238\n",
      "Epoch 4309/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 16.9711 - mse: 657.6266 - val_loss: 17.3196 - val_mse: 681.9803\n",
      "Epoch 4310/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7568 - mse: 645.8137 - val_loss: 17.1636 - val_mse: 653.6100\n",
      "Epoch 4311/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.4742 - mse: 630.8130 - val_loss: 17.1654 - val_mse: 655.9319\n",
      "Epoch 4312/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3825 - mse: 678.6794 - val_loss: 17.9783 - val_mse: 695.1907\n",
      "Epoch 4313/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0936 - mse: 672.3533 - val_loss: 17.9693 - val_mse: 754.2138\n",
      "Epoch 4314/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7671 - mse: 645.0839 - val_loss: 17.1099 - val_mse: 653.8749\n",
      "Epoch 4315/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.3637 - mse: 622.6246 - val_loss: 17.1066 - val_mse: 663.1862\n",
      "Epoch 4316/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0216 - mse: 659.4612 - val_loss: 17.1941 - val_mse: 679.6010\n",
      "Epoch 4317/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0539 - mse: 669.7006 - val_loss: 17.3692 - val_mse: 709.7466\n",
      "Epoch 4318/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.5308 - mse: 639.0748 - val_loss: 17.1085 - val_mse: 653.3417\n",
      "Epoch 4319/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.3882 - mse: 625.6208 - val_loss: 17.1061 - val_mse: 666.9955\n",
      "Epoch 4320/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.4951 - mse: 632.3406 - val_loss: 18.2078 - val_mse: 748.1854\n",
      "Epoch 4321/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3395 - mse: 679.7606 - val_loss: 17.8924 - val_mse: 690.2581\n",
      "Epoch 4322/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1924 - mse: 672.3914 - val_loss: 18.2693 - val_mse: 767.6192\n",
      "Epoch 4323/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0664 - mse: 671.1050 - val_loss: 17.2177 - val_mse: 666.3856\n",
      "Epoch 4324/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0896 - mse: 668.7292 - val_loss: 17.4049 - val_mse: 669.7496\n",
      "Epoch 4325/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4182 - mse: 689.4902 - val_loss: 18.3484 - val_mse: 743.8046\n",
      "Epoch 4326/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.8970 - mse: 647.9030 - val_loss: 17.1293 - val_mse: 655.7621\n",
      "Epoch 4327/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.5884 - mse: 637.1642 - val_loss: 17.2466 - val_mse: 667.6753\n",
      "Epoch 4328/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6351 - mse: 638.0564 - val_loss: 17.8320 - val_mse: 718.2647\n",
      "Epoch 4329/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8491 - mse: 707.1063 - val_loss: 17.9528 - val_mse: 664.6976\n",
      "Epoch 4330/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6751 - mse: 696.0446 - val_loss: 19.7694 - val_mse: 741.2097\n",
      "Epoch 4331/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.2990 - mse: 797.1537 - val_loss: 18.1540 - val_mse: 668.4887\n",
      "Epoch 4332/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5895 - mse: 697.5597 - val_loss: 18.1991 - val_mse: 739.8711\n",
      "Epoch 4333/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1987 - mse: 668.7255 - val_loss: 17.7786 - val_mse: 677.6118\n",
      "Epoch 4334/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9773 - mse: 661.4434 - val_loss: 18.2627 - val_mse: 683.1902\n",
      "Epoch 4335/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0025 - mse: 662.4488 - val_loss: 17.2230 - val_mse: 662.9948\n",
      "Epoch 4336/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 16.5292 - mse: 640.5135 - val_loss: 17.6606 - val_mse: 648.4470\n",
      "Epoch 4337/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.3339 - mse: 626.5905 - val_loss: 18.0976 - val_mse: 662.7273\n",
      "Epoch 4338/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0071 - mse: 701.6345 - val_loss: 17.4844 - val_mse: 728.5966\n",
      "Epoch 4339/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8751 - mse: 658.2562 - val_loss: 17.9536 - val_mse: 649.9175\n",
      "Epoch 4340/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7383 - mse: 648.2947 - val_loss: 17.7174 - val_mse: 634.7178\n",
      "Epoch 4341/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6999 - mse: 632.8054 - val_loss: 17.1752 - val_mse: 676.8606\n",
      "Epoch 4342/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9448 - mse: 664.0142 - val_loss: 19.7464 - val_mse: 900.4371\n",
      "Epoch 4343/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6261 - mse: 698.0152 - val_loss: 18.1566 - val_mse: 680.3657\n",
      "Epoch 4344/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.8971 - mse: 652.6467 - val_loss: 17.7407 - val_mse: 668.0858\n",
      "Epoch 4345/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0458 - mse: 655.5071 - val_loss: 19.1162 - val_mse: 739.8073\n",
      "Epoch 4346/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8558 - mse: 655.2702 - val_loss: 17.4770 - val_mse: 656.3103\n",
      "Epoch 4347/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6187 - mse: 643.9666 - val_loss: 17.5086 - val_mse: 666.8566\n",
      "Epoch 4348/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7561 - mse: 634.4413 - val_loss: 17.2233 - val_mse: 648.4286\n",
      "Epoch 4349/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.5859 - mse: 637.2961 - val_loss: 17.5883 - val_mse: 654.3094\n",
      "Epoch 4350/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1374 - mse: 669.2346 - val_loss: 18.9264 - val_mse: 799.3267\n",
      "Epoch 4351/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4323 - mse: 683.8603 - val_loss: 17.2303 - val_mse: 680.7752\n",
      "Epoch 4352/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9039 - mse: 652.0308 - val_loss: 18.4459 - val_mse: 687.3429\n",
      "Epoch 4353/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.8990 - mse: 655.6368 - val_loss: 18.0158 - val_mse: 672.4026\n",
      "Epoch 4354/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5328 - mse: 695.6990 - val_loss: 17.0330 - val_mse: 668.7962\n",
      "Epoch 4355/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 16.4696 - mse: 626.5645 - val_loss: 17.0298 - val_mse: 652.6121\n",
      "Epoch 4356/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6011 - mse: 637.8514 - val_loss: 18.1972 - val_mse: 753.6837\n",
      "Epoch 4357/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 16.5390 - mse: 633.0412 - val_loss: 17.4765 - val_mse: 713.3487\n",
      "Epoch 4358/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9408 - mse: 658.7332 - val_loss: 17.4200 - val_mse: 686.1639\n",
      "Epoch 4359/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6313 - mse: 704.4913 - val_loss: 17.6305 - val_mse: 681.0613\n",
      "Epoch 4360/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.4313 - mse: 682.3232 - val_loss: 19.0385 - val_mse: 796.5662\n",
      "Epoch 4361/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.2445 - mse: 748.6171 - val_loss: 17.7615 - val_mse: 746.9371\n",
      "Epoch 4362/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.0594 - mse: 666.2505 - val_loss: 18.3891 - val_mse: 783.8585\n",
      "Epoch 4363/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1559 - mse: 663.3724 - val_loss: 17.6119 - val_mse: 695.1880\n",
      "Epoch 4364/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4059 - mse: 692.7256 - val_loss: 18.0089 - val_mse: 679.5861\n",
      "Epoch 4365/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0685 - mse: 725.9613 - val_loss: 17.5520 - val_mse: 676.1478\n",
      "Epoch 4366/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7866 - mse: 652.5934 - val_loss: 17.4612 - val_mse: 666.0734\n",
      "Epoch 4367/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9549 - mse: 652.6274 - val_loss: 17.5988 - val_mse: 723.7256\n",
      "Epoch 4368/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.5707 - mse: 637.7568 - val_loss: 17.0983 - val_mse: 651.5170\n",
      "Epoch 4369/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.0948 - mse: 657.6590 - val_loss: 17.2090 - val_mse: 679.8691\n",
      "Epoch 4370/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7754 - mse: 645.0705 - val_loss: 17.6011 - val_mse: 669.2139\n",
      "Epoch 4371/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 16.8834 - mse: 651.6296 - val_loss: 17.2090 - val_mse: 662.0361\n",
      "Epoch 4372/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.5119 - mse: 635.8577 - val_loss: 17.8195 - val_mse: 708.1338\n",
      "Epoch 4373/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6919 - mse: 645.2211 - val_loss: 17.1475 - val_mse: 666.3923\n",
      "Epoch 4374/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0167 - mse: 657.3873 - val_loss: 17.5758 - val_mse: 682.8693\n",
      "Epoch 4375/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7346 - mse: 645.9004 - val_loss: 17.3840 - val_mse: 685.7739\n",
      "Epoch 4376/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7242 - mse: 650.3796 - val_loss: 17.6161 - val_mse: 677.1969\n",
      "Epoch 4377/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.4713 - mse: 629.2637 - val_loss: 17.3481 - val_mse: 653.1630\n",
      "Epoch 4378/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2538 - mse: 736.4555 - val_loss: 19.8622 - val_mse: 899.7129\n",
      "Epoch 4379/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7103 - mse: 695.9820 - val_loss: 17.7514 - val_mse: 668.1157\n",
      "Epoch 4380/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6789 - mse: 639.5626 - val_loss: 17.2403 - val_mse: 697.9722\n",
      "Epoch 4381/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7019 - mse: 640.2197 - val_loss: 17.1783 - val_mse: 662.5121\n",
      "Epoch 4382/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9067 - mse: 654.2080 - val_loss: 18.7862 - val_mse: 813.2064\n",
      "Epoch 4383/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.8636 - mse: 647.2001 - val_loss: 17.8028 - val_mse: 725.8732\n",
      "Epoch 4384/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.8286 - mse: 645.0687 - val_loss: 18.0377 - val_mse: 721.1390\n",
      "Epoch 4385/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0587 - mse: 662.1994 - val_loss: 17.5922 - val_mse: 673.6385\n",
      "Epoch 4386/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0264 - mse: 667.6987 - val_loss: 18.3064 - val_mse: 683.7806\n",
      "Epoch 4387/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6088 - mse: 640.6514 - val_loss: 17.0135 - val_mse: 660.4094\n",
      "Epoch 4388/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1611 - mse: 663.3434 - val_loss: 19.0506 - val_mse: 827.8166\n",
      "Epoch 4389/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7502 - mse: 760.1362 - val_loss: 19.8256 - val_mse: 806.3310\n",
      "Epoch 4390/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 18.7120 - mse: 753.2271 - val_loss: 19.1664 - val_mse: 721.0392\n",
      "Epoch 4391/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1550 - mse: 668.5911 - val_loss: 17.1307 - val_mse: 658.3954\n",
      "Epoch 4392/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6622 - mse: 647.0544 - val_loss: 17.4179 - val_mse: 660.6045\n",
      "Epoch 4393/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.4892 - mse: 629.8513 - val_loss: 17.4247 - val_mse: 696.2200\n",
      "Epoch 4394/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7022 - mse: 639.8690 - val_loss: 17.7958 - val_mse: 654.4684\n",
      "Epoch 4395/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.4753 - mse: 632.3600 - val_loss: 17.3572 - val_mse: 687.1743\n",
      "Epoch 4396/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6219 - mse: 641.7540 - val_loss: 17.1369 - val_mse: 665.4739\n",
      "Epoch 4397/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6179 - mse: 642.3158 - val_loss: 17.2634 - val_mse: 671.8658\n",
      "Epoch 4398/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.4581 - mse: 635.5254 - val_loss: 17.9990 - val_mse: 698.8605\n",
      "Epoch 4399/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7403 - mse: 644.5601 - val_loss: 17.4938 - val_mse: 681.6354\n",
      "Epoch 4400/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 16.6503 - mse: 645.1118 - val_loss: 17.2383 - val_mse: 666.1960\n",
      "Epoch 4401/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7701 - mse: 649.6376 - val_loss: 17.1475 - val_mse: 659.2876\n",
      "Epoch 4402/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6977 - mse: 636.8202 - val_loss: 19.5906 - val_mse: 808.1605\n",
      "Epoch 4403/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2937 - mse: 737.1159 - val_loss: 18.0177 - val_mse: 702.1132\n",
      "Epoch 4404/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3201 - mse: 669.6511 - val_loss: 18.1492 - val_mse: 768.4095\n",
      "Epoch 4405/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7211 - mse: 642.1108 - val_loss: 17.4953 - val_mse: 703.8483\n",
      "Epoch 4406/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7578 - mse: 647.9065 - val_loss: 17.4801 - val_mse: 708.2769\n",
      "Epoch 4407/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6647 - mse: 643.9486 - val_loss: 17.2763 - val_mse: 664.8064\n",
      "Epoch 4408/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.5420 - mse: 633.2726 - val_loss: 18.0596 - val_mse: 762.7871\n",
      "Epoch 4409/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7330 - mse: 652.8687 - val_loss: 18.5455 - val_mse: 792.6801\n",
      "Epoch 4410/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0591 - mse: 661.8215 - val_loss: 17.3510 - val_mse: 655.7965\n",
      "Epoch 4411/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8297 - mse: 647.6132 - val_loss: 17.3983 - val_mse: 691.5620\n",
      "Epoch 4412/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8487 - mse: 709.4279 - val_loss: 20.5263 - val_mse: 834.0400\n",
      "Epoch 4413/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.4042 - mse: 813.1245 - val_loss: 18.8937 - val_mse: 795.2589\n",
      "Epoch 4414/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.8499 - mse: 766.6788 - val_loss: 18.8702 - val_mse: 832.5557\n",
      "Epoch 4415/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.3979 - mse: 745.4418 - val_loss: 19.5819 - val_mse: 909.7838\n",
      "Epoch 4416/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 19.4385 - mse: 800.5497 - val_loss: 19.2252 - val_mse: 836.4771\n",
      "Epoch 4417/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5584 - mse: 768.4296 - val_loss: 17.9401 - val_mse: 693.4888\n",
      "Epoch 4418/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6159 - mse: 697.8585 - val_loss: 17.8512 - val_mse: 724.8748\n",
      "Epoch 4419/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.2244 - mse: 726.3995 - val_loss: 18.0419 - val_mse: 767.9352\n",
      "Epoch 4420/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3496 - mse: 684.0007 - val_loss: 17.6743 - val_mse: 691.5413\n",
      "Epoch 4421/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6787 - mse: 679.1135 - val_loss: 18.7298 - val_mse: 814.3448\n",
      "Epoch 4422/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4872 - mse: 696.0327 - val_loss: 17.9165 - val_mse: 705.1764\n",
      "Epoch 4423/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6042 - mse: 687.0319 - val_loss: 18.1494 - val_mse: 774.2097\n",
      "Epoch 4424/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2162 - mse: 669.0370 - val_loss: 17.9574 - val_mse: 758.0835\n",
      "Epoch 4425/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5776 - mse: 700.9169 - val_loss: 18.1685 - val_mse: 667.4087\n",
      "Epoch 4426/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1569 - mse: 671.8811 - val_loss: 18.0987 - val_mse: 693.5526\n",
      "Epoch 4427/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9628 - mse: 657.8652 - val_loss: 17.7512 - val_mse: 714.2129\n",
      "Epoch 4428/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1180 - mse: 659.5303 - val_loss: 17.5932 - val_mse: 664.8916\n",
      "Epoch 4429/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9073 - mse: 711.3253 - val_loss: 17.6270 - val_mse: 710.5303\n",
      "Epoch 4430/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1404 - mse: 673.5785 - val_loss: 18.3685 - val_mse: 763.9777\n",
      "Epoch 4431/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9091 - mse: 651.1293 - val_loss: 17.1367 - val_mse: 669.6803\n",
      "Epoch 4432/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7226 - mse: 638.7278 - val_loss: 17.2157 - val_mse: 678.0844\n",
      "Epoch 4433/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2645 - mse: 675.6647 - val_loss: 17.2122 - val_mse: 671.0547\n",
      "Epoch 4434/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.8569 - mse: 650.7320 - val_loss: 17.6345 - val_mse: 689.1970\n",
      "Epoch 4435/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.6758 - mse: 644.6732 - val_loss: 17.2235 - val_mse: 654.1121\n",
      "Epoch 4436/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7400 - mse: 639.8649 - val_loss: 18.1494 - val_mse: 776.2391\n",
      "Epoch 4437/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7114 - mse: 696.4890 - val_loss: 17.1906 - val_mse: 676.6066\n",
      "Epoch 4438/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9368 - mse: 654.7242 - val_loss: 17.2038 - val_mse: 676.2237\n",
      "Epoch 4439/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 16.8891 - mse: 652.2617 - val_loss: 17.9519 - val_mse: 691.7884\n",
      "Epoch 4440/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6728 - mse: 646.9088 - val_loss: 17.2687 - val_mse: 658.8554\n",
      "Epoch 4441/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.0912 - mse: 658.7031 - val_loss: 17.3362 - val_mse: 661.2170\n",
      "Epoch 4442/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.3458 - mse: 686.0066 - val_loss: 17.4342 - val_mse: 665.7081\n",
      "Epoch 4443/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6590 - mse: 646.0623 - val_loss: 17.5258 - val_mse: 656.0668\n",
      "Epoch 4444/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.8394 - mse: 649.1321 - val_loss: 17.1833 - val_mse: 693.0275\n",
      "Epoch 4445/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7442 - mse: 642.1757 - val_loss: 17.3595 - val_mse: 664.6970\n",
      "Epoch 4446/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3253 - mse: 681.3964 - val_loss: 17.4706 - val_mse: 682.6868\n",
      "Epoch 4447/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 16.4352 - mse: 631.2910 - val_loss: 18.1033 - val_mse: 675.8636\n",
      "Epoch 4448/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7143 - mse: 647.7551 - val_loss: 17.2270 - val_mse: 665.3622\n",
      "Epoch 4449/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4445 - mse: 685.6703 - val_loss: 17.5879 - val_mse: 690.0099\n",
      "Epoch 4450/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6354 - mse: 640.0200 - val_loss: 17.5407 - val_mse: 692.4667\n",
      "Epoch 4451/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0159 - mse: 655.6522 - val_loss: 17.7373 - val_mse: 678.4270\n",
      "Epoch 4452/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 16.8308 - mse: 655.1062 - val_loss: 18.0392 - val_mse: 744.8846\n",
      "Epoch 4453/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8736 - mse: 710.0871 - val_loss: 17.7277 - val_mse: 689.2191\n",
      "Epoch 4454/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2769 - mse: 680.6359 - val_loss: 18.1301 - val_mse: 683.7733\n",
      "Epoch 4455/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4053 - mse: 676.8057 - val_loss: 18.5716 - val_mse: 703.0308\n",
      "Epoch 4456/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9183 - mse: 655.9301 - val_loss: 17.3683 - val_mse: 700.8081\n",
      "Epoch 4457/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7635 - mse: 642.5245 - val_loss: 18.3066 - val_mse: 696.4296\n",
      "Epoch 4458/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5609 - mse: 710.9407 - val_loss: 19.7213 - val_mse: 794.5798\n",
      "Epoch 4459/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3940 - mse: 729.3624 - val_loss: 17.9854 - val_mse: 750.0757\n",
      "Epoch 4460/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9735 - mse: 767.8431 - val_loss: 19.5807 - val_mse: 843.9133\n",
      "Epoch 4461/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.5237 - mse: 746.1266 - val_loss: 18.1326 - val_mse: 748.7556\n",
      "Epoch 4462/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 17.7690 - mse: 710.1888 - val_loss: 17.9923 - val_mse: 705.5660\n",
      "Epoch 4463/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1199 - mse: 668.6578 - val_loss: 17.5092 - val_mse: 660.7868\n",
      "Epoch 4464/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0221 - mse: 657.0912 - val_loss: 17.2490 - val_mse: 669.2170\n",
      "Epoch 4465/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 16.8052 - mse: 643.4927 - val_loss: 18.7727 - val_mse: 798.2308\n",
      "Epoch 4466/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0148 - mse: 655.3275 - val_loss: 17.5543 - val_mse: 688.6157\n",
      "Epoch 4467/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9902 - mse: 661.2755 - val_loss: 17.1448 - val_mse: 652.9421\n",
      "Epoch 4468/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2137 - mse: 665.9386 - val_loss: 18.1749 - val_mse: 759.9683\n",
      "Epoch 4469/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7928 - mse: 651.3390 - val_loss: 18.0035 - val_mse: 751.8642\n",
      "Epoch 4470/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6466 - mse: 646.3840 - val_loss: 17.6239 - val_mse: 682.7889\n",
      "Epoch 4471/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9764 - mse: 665.6542 - val_loss: 17.3319 - val_mse: 640.6710\n",
      "Epoch 4472/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3374 - mse: 675.7426 - val_loss: 18.4347 - val_mse: 815.0364\n",
      "Epoch 4473/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3741 - mse: 684.1071 - val_loss: 17.2725 - val_mse: 666.0086\n",
      "Epoch 4474/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6902 - mse: 646.0865 - val_loss: 17.1102 - val_mse: 664.0942\n",
      "Epoch 4475/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6837 - mse: 641.8621 - val_loss: 18.4194 - val_mse: 795.0735\n",
      "Epoch 4476/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8961 - mse: 658.5084 - val_loss: 17.2868 - val_mse: 688.7723\n",
      "Epoch 4477/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 16.5767 - mse: 639.7610 - val_loss: 18.1274 - val_mse: 712.4645\n",
      "Epoch 4478/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1059 - mse: 668.4371 - val_loss: 17.3122 - val_mse: 696.8563\n",
      "Epoch 4479/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1756 - mse: 665.6686 - val_loss: 18.8482 - val_mse: 764.7411\n",
      "Epoch 4480/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1951 - mse: 674.3036 - val_loss: 17.7240 - val_mse: 667.7531\n",
      "Epoch 4481/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7081 - mse: 649.3875 - val_loss: 16.9792 - val_mse: 669.3968\n",
      "Epoch 4482/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.5181 - mse: 631.1993 - val_loss: 17.2778 - val_mse: 692.5335\n",
      "Epoch 4483/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8132 - mse: 659.3838 - val_loss: 17.7728 - val_mse: 718.7527\n",
      "Epoch 4484/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0000 - mse: 657.7331 - val_loss: 17.8549 - val_mse: 685.5490\n",
      "Epoch 4485/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9424 - mse: 657.2140 - val_loss: 17.8045 - val_mse: 709.7282\n",
      "Epoch 4486/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4232 - mse: 690.4229 - val_loss: 18.0293 - val_mse: 686.4877\n",
      "Epoch 4487/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7920 - mse: 652.2881 - val_loss: 17.6083 - val_mse: 713.3521\n",
      "Epoch 4488/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6845 - mse: 641.4062 - val_loss: 17.5209 - val_mse: 684.1064\n",
      "Epoch 4489/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6598 - mse: 652.4750 - val_loss: 18.0481 - val_mse: 746.9819\n",
      "Epoch 4490/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.5729 - mse: 641.1868 - val_loss: 17.3174 - val_mse: 682.9035\n",
      "Epoch 4491/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7569 - mse: 643.2996 - val_loss: 17.0692 - val_mse: 651.5226\n",
      "Epoch 4492/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.4817 - mse: 627.7380 - val_loss: 16.9390 - val_mse: 665.2499\n",
      "Epoch 4493/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.4337 - mse: 631.8033 - val_loss: 17.9844 - val_mse: 661.2763\n",
      "Epoch 4494/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 16.6482 - mse: 647.0654 - val_loss: 17.6871 - val_mse: 665.0983\n",
      "Epoch 4495/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6716 - mse: 646.2972 - val_loss: 17.0416 - val_mse: 644.0151\n",
      "Epoch 4496/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6950 - mse: 647.8958 - val_loss: 18.4294 - val_mse: 684.7160\n",
      "Epoch 4497/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7041 - mse: 637.1066 - val_loss: 17.1517 - val_mse: 683.8577\n",
      "Epoch 4498/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7295 - mse: 648.2344 - val_loss: 18.0844 - val_mse: 709.4459\n",
      "Epoch 4499/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.4307 - mse: 627.4711 - val_loss: 17.0915 - val_mse: 666.5833\n",
      "Epoch 4500/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7123 - mse: 648.4432 - val_loss: 17.6282 - val_mse: 679.2289\n",
      "Epoch 4501/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2894 - mse: 684.6481 - val_loss: 19.8355 - val_mse: 782.4334\n",
      "Epoch 4502/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4274 - mse: 690.6805 - val_loss: 17.4954 - val_mse: 676.3883\n",
      "Epoch 4503/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2570 - mse: 679.9188 - val_loss: 17.9068 - val_mse: 757.8973\n",
      "Epoch 4504/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1413 - mse: 675.0393 - val_loss: 17.2070 - val_mse: 684.2758\n",
      "Epoch 4505/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.5177 - mse: 630.3369 - val_loss: 17.1498 - val_mse: 677.4573\n",
      "Epoch 4506/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7599 - mse: 650.9448 - val_loss: 18.2933 - val_mse: 699.5862\n",
      "Epoch 4507/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1005 - mse: 664.6405 - val_loss: 18.3114 - val_mse: 676.3502\n",
      "Epoch 4508/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5196 - mse: 683.9324 - val_loss: 18.5309 - val_mse: 791.2434\n",
      "Epoch 4509/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2021 - mse: 687.4746 - val_loss: 18.0609 - val_mse: 681.0545\n",
      "Epoch 4510/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.5100 - mse: 634.4343 - val_loss: 17.2938 - val_mse: 671.1893\n",
      "Epoch 4511/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.5104 - mse: 637.6234 - val_loss: 17.5898 - val_mse: 703.8413\n",
      "Epoch 4512/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8081 - mse: 660.6400 - val_loss: 17.2796 - val_mse: 688.6298\n",
      "Epoch 4513/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0032 - mse: 654.8234 - val_loss: 17.3115 - val_mse: 669.4006\n",
      "Epoch 4514/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0326 - mse: 673.4080 - val_loss: 18.5462 - val_mse: 706.2074\n",
      "Epoch 4515/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5417 - mse: 691.4741 - val_loss: 17.8243 - val_mse: 685.2504\n",
      "Epoch 4516/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.5971 - mse: 636.5322 - val_loss: 17.3822 - val_mse: 667.9565\n",
      "Epoch 4517/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.6775 - mse: 638.2480 - val_loss: 17.9632 - val_mse: 763.1481\n",
      "Epoch 4518/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.4300 - mse: 634.1418 - val_loss: 17.2597 - val_mse: 666.0360\n",
      "Epoch 4519/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.5966 - mse: 635.5132 - val_loss: 17.6834 - val_mse: 751.5281\n",
      "Epoch 4520/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.5736 - mse: 640.4910 - val_loss: 18.3445 - val_mse: 751.7202\n",
      "Epoch 4521/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5118 - mse: 684.5730 - val_loss: 17.3383 - val_mse: 665.3903\n",
      "Epoch 4522/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7866 - mse: 693.7488 - val_loss: 18.4765 - val_mse: 805.1329\n",
      "Epoch 4523/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.3690 - mse: 804.5163 - val_loss: 19.5420 - val_mse: 821.6348\n",
      "Epoch 4524/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19.1178 - mse: 792.8412 - val_loss: 18.7807 - val_mse: 810.0569\n",
      "Epoch 4525/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.4193 - mse: 750.7162 - val_loss: 17.9828 - val_mse: 718.6385\n",
      "Epoch 4526/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0755 - mse: 722.2327 - val_loss: 17.9096 - val_mse: 674.1180\n",
      "Epoch 4527/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6530 - mse: 697.2457 - val_loss: 17.4590 - val_mse: 690.2060\n",
      "Epoch 4528/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6271 - mse: 639.5471 - val_loss: 17.2515 - val_mse: 668.0888\n",
      "Epoch 4529/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6615 - mse: 644.3882 - val_loss: 17.8935 - val_mse: 668.4963\n",
      "Epoch 4530/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6805 - mse: 681.6661 - val_loss: 17.7971 - val_mse: 717.3875\n",
      "Epoch 4531/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.8234 - mse: 652.1043 - val_loss: 18.0052 - val_mse: 736.3808\n",
      "Epoch 4532/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4570 - mse: 678.6500 - val_loss: 18.2920 - val_mse: 684.2650\n",
      "Epoch 4533/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.8014 - mse: 634.8090 - val_loss: 18.3840 - val_mse: 793.2387\n",
      "Epoch 4534/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6480 - mse: 699.2696 - val_loss: 17.5451 - val_mse: 727.6902\n",
      "Epoch 4535/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5918 - mse: 689.6910 - val_loss: 17.7076 - val_mse: 720.6024\n",
      "Epoch 4536/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4021 - mse: 678.2485 - val_loss: 18.2544 - val_mse: 718.4769\n",
      "Epoch 4537/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0401 - mse: 658.5289 - val_loss: 18.1215 - val_mse: 672.9501\n",
      "Epoch 4538/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9353 - mse: 713.6868 - val_loss: 17.4126 - val_mse: 692.2498\n",
      "Epoch 4539/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9719 - mse: 660.6697 - val_loss: 17.5538 - val_mse: 656.3134\n",
      "Epoch 4540/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6230 - mse: 634.3959 - val_loss: 17.9029 - val_mse: 661.6558\n",
      "Epoch 4541/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.4969 - mse: 801.2732 - val_loss: 18.5359 - val_mse: 753.6161\n",
      "Epoch 4542/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1473 - mse: 733.8607 - val_loss: 17.8752 - val_mse: 674.1033\n",
      "Epoch 4543/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1204 - mse: 670.8575 - val_loss: 17.4260 - val_mse: 686.0466\n",
      "Epoch 4544/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6094 - mse: 640.6684 - val_loss: 17.1487 - val_mse: 658.8172\n",
      "Epoch 4545/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6028 - mse: 637.2328 - val_loss: 18.1726 - val_mse: 787.0522\n",
      "Epoch 4546/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6576 - mse: 649.5742 - val_loss: 17.1713 - val_mse: 677.4825\n",
      "Epoch 4547/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7317 - mse: 647.3549 - val_loss: 17.0460 - val_mse: 666.5760\n",
      "Epoch 4548/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6114 - mse: 687.3388 - val_loss: 19.1821 - val_mse: 782.2208\n",
      "Epoch 4549/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3271 - mse: 678.0165 - val_loss: 17.4459 - val_mse: 696.2141\n",
      "Epoch 4550/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.8213 - mse: 658.3241 - val_loss: 17.5590 - val_mse: 725.9207\n",
      "Epoch 4551/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.4917 - mse: 631.1246 - val_loss: 17.1944 - val_mse: 690.9383\n",
      "Epoch 4552/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8768 - mse: 657.9801 - val_loss: 17.0528 - val_mse: 668.8011\n",
      "Epoch 4553/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7912 - mse: 653.0277 - val_loss: 17.3610 - val_mse: 670.1478\n",
      "Epoch 4554/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1463 - mse: 669.3099 - val_loss: 17.3050 - val_mse: 692.1725\n",
      "Epoch 4555/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6636 - mse: 641.3132 - val_loss: 20.1310 - val_mse: 932.6661\n",
      "Epoch 4556/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8329 - mse: 707.9357 - val_loss: 17.5508 - val_mse: 661.1810\n",
      "Epoch 4557/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.4397 - mse: 627.7374 - val_loss: 17.5691 - val_mse: 701.9120\n",
      "Epoch 4558/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.3181 - mse: 628.1836 - val_loss: 17.3693 - val_mse: 639.5430\n",
      "Epoch 4559/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9017 - mse: 649.8069 - val_loss: 17.3427 - val_mse: 656.2249\n",
      "Epoch 4560/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7069 - mse: 642.6511 - val_loss: 17.4654 - val_mse: 693.4341\n",
      "Epoch 4561/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.1894 - mse: 729.6452 - val_loss: 20.7737 - val_mse: 934.8911\n",
      "Epoch 4562/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.9013 - mse: 764.6634 - val_loss: 18.5303 - val_mse: 759.3609\n",
      "Epoch 4563/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.4565 - mse: 743.6513 - val_loss: 18.6779 - val_mse: 761.1479\n",
      "Epoch 4564/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.3435 - mse: 742.0688 - val_loss: 18.2991 - val_mse: 727.1239\n",
      "Epoch 4565/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1148 - mse: 724.9263 - val_loss: 18.4310 - val_mse: 722.1755\n",
      "Epoch 4566/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.8813 - mse: 698.0683 - val_loss: 18.0188 - val_mse: 740.7239\n",
      "Epoch 4567/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.6480 - mse: 684.4501 - val_loss: 18.1689 - val_mse: 771.8812\n",
      "Epoch 4568/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.8386 - mse: 705.5878 - val_loss: 18.3056 - val_mse: 723.2794\n",
      "Epoch 4569/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.0164 - mse: 718.9351 - val_loss: 18.7778 - val_mse: 716.6625\n",
      "Epoch 4570/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5754 - mse: 702.1603 - val_loss: 17.4452 - val_mse: 692.0571\n",
      "Epoch 4571/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1954 - mse: 664.3697 - val_loss: 17.6478 - val_mse: 726.9673\n",
      "Epoch 4572/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2934 - mse: 684.7988 - val_loss: 17.8459 - val_mse: 722.5518\n",
      "Epoch 4573/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4476 - mse: 691.4985 - val_loss: 18.0991 - val_mse: 710.0206\n",
      "Epoch 4574/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0971 - mse: 671.3167 - val_loss: 19.0380 - val_mse: 796.5548\n",
      "Epoch 4575/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7300 - mse: 715.7507 - val_loss: 17.8394 - val_mse: 677.2792\n",
      "Epoch 4576/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3121 - mse: 665.1496 - val_loss: 17.7122 - val_mse: 729.8480\n",
      "Epoch 4577/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1668 - mse: 671.3450 - val_loss: 18.1230 - val_mse: 676.1502\n",
      "Epoch 4578/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7219 - mse: 699.9710 - val_loss: 18.4964 - val_mse: 717.9453\n",
      "Epoch 4579/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.1316 - mse: 718.2834 - val_loss: 19.2311 - val_mse: 833.6696\n",
      "Epoch 4580/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.7409 - mse: 753.9016 - val_loss: 18.9206 - val_mse: 808.5242\n",
      "Epoch 4581/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5971 - mse: 700.4798 - val_loss: 17.3293 - val_mse: 689.4180\n",
      "Epoch 4582/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.1447 - mse: 672.2753 - val_loss: 17.3777 - val_mse: 697.8641\n",
      "Epoch 4583/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4366 - mse: 683.0046 - val_loss: 17.7204 - val_mse: 707.5650\n",
      "Epoch 4584/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4734 - mse: 692.3545 - val_loss: 19.0867 - val_mse: 838.6006\n",
      "Epoch 4585/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4731 - mse: 672.9537 - val_loss: 17.8479 - val_mse: 692.9753\n",
      "Epoch 4586/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0765 - mse: 668.5878 - val_loss: 17.6497 - val_mse: 673.8237\n",
      "Epoch 4587/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8459 - mse: 652.7502 - val_loss: 17.4718 - val_mse: 669.4678\n",
      "Epoch 4588/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7491 - mse: 641.9683 - val_loss: 17.6719 - val_mse: 674.7880\n",
      "Epoch 4589/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2545 - mse: 682.0182 - val_loss: 18.1015 - val_mse: 694.8196\n",
      "Epoch 4590/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5684 - mse: 698.4297 - val_loss: 17.7440 - val_mse: 691.8156\n",
      "Epoch 4591/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7285 - mse: 643.7122 - val_loss: 17.8696 - val_mse: 730.9481\n",
      "Epoch 4592/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9706 - mse: 659.4519 - val_loss: 17.3836 - val_mse: 650.7620\n",
      "Epoch 4593/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7926 - mse: 651.6233 - val_loss: 17.3919 - val_mse: 679.9688\n",
      "Epoch 4594/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9456 - mse: 659.0936 - val_loss: 17.5614 - val_mse: 660.3321\n",
      "Epoch 4595/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2913 - mse: 668.7675 - val_loss: 17.6163 - val_mse: 702.6697\n",
      "Epoch 4596/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.3165 - mse: 680.7137 - val_loss: 18.5436 - val_mse: 767.0385\n",
      "Epoch 4597/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0984 - mse: 657.1848 - val_loss: 17.7532 - val_mse: 681.3376\n",
      "Epoch 4598/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.5232 - mse: 631.2105 - val_loss: 17.4428 - val_mse: 687.2437\n",
      "Epoch 4599/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.3929 - mse: 633.1405 - val_loss: 17.5229 - val_mse: 681.4904\n",
      "Epoch 4600/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9032 - mse: 650.8487 - val_loss: 17.6856 - val_mse: 672.4914\n",
      "Epoch 4601/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8116 - mse: 721.3668 - val_loss: 19.7672 - val_mse: 917.8761\n",
      "Epoch 4602/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6385 - mse: 716.0502 - val_loss: 17.5856 - val_mse: 682.1342\n",
      "Epoch 4603/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0331 - mse: 653.2883 - val_loss: 18.5977 - val_mse: 785.1619\n",
      "Epoch 4604/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.0426 - mse: 654.2413 - val_loss: 17.5496 - val_mse: 726.7672\n",
      "Epoch 4605/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7627 - mse: 649.5712 - val_loss: 17.2789 - val_mse: 653.4656\n",
      "Epoch 4606/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7724 - mse: 635.4692 - val_loss: 17.2908 - val_mse: 663.8685\n",
      "Epoch 4607/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6344 - mse: 640.8208 - val_loss: 17.6863 - val_mse: 691.8869\n",
      "Epoch 4608/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0368 - mse: 667.6271 - val_loss: 17.4811 - val_mse: 659.5303\n",
      "Epoch 4609/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7418 - mse: 643.5076 - val_loss: 17.1376 - val_mse: 680.6787\n",
      "Epoch 4610/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7243 - mse: 645.7050 - val_loss: 17.2638 - val_mse: 653.6122\n",
      "Epoch 4611/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.5392 - mse: 629.8185 - val_loss: 17.8564 - val_mse: 689.8036\n",
      "Epoch 4612/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0415 - mse: 668.8511 - val_loss: 17.6999 - val_mse: 681.2432\n",
      "Epoch 4613/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8938 - mse: 655.5314 - val_loss: 19.9969 - val_mse: 894.4011\n",
      "Epoch 4614/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0166 - mse: 729.1207 - val_loss: 17.2542 - val_mse: 677.8207\n",
      "Epoch 4615/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8931 - mse: 655.6553 - val_loss: 17.1492 - val_mse: 657.6717\n",
      "Epoch 4616/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7809 - mse: 710.9224 - val_loss: 17.9028 - val_mse: 749.2338\n",
      "Epoch 4617/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2733 - mse: 680.4197 - val_loss: 17.2318 - val_mse: 669.8766\n",
      "Epoch 4618/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6958 - mse: 641.6539 - val_loss: 18.4356 - val_mse: 692.7324\n",
      "Epoch 4619/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7616 - mse: 643.3587 - val_loss: 17.4968 - val_mse: 711.0726\n",
      "Epoch 4620/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5799 - mse: 690.8578 - val_loss: 17.6861 - val_mse: 720.9604\n",
      "Epoch 4621/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8077 - mse: 645.0032 - val_loss: 17.8604 - val_mse: 726.6118\n",
      "Epoch 4622/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.5498 - mse: 628.2925 - val_loss: 17.0785 - val_mse: 667.7006\n",
      "Epoch 4623/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6576 - mse: 643.4660 - val_loss: 17.9888 - val_mse: 700.4388\n",
      "Epoch 4624/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7946 - mse: 653.6216 - val_loss: 18.7634 - val_mse: 805.9915\n",
      "Epoch 4625/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2300 - mse: 675.4177 - val_loss: 17.6301 - val_mse: 655.7513\n",
      "Epoch 4626/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4006 - mse: 690.1888 - val_loss: 17.7272 - val_mse: 728.2056\n",
      "Epoch 4627/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4457 - mse: 688.5355 - val_loss: 17.5518 - val_mse: 721.2650\n",
      "Epoch 4628/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0375 - mse: 669.3710 - val_loss: 17.8579 - val_mse: 751.2304\n",
      "Epoch 4629/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5330 - mse: 692.6499 - val_loss: 17.4332 - val_mse: 680.8987\n",
      "Epoch 4630/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0688 - mse: 660.5409 - val_loss: 18.0336 - val_mse: 704.6088\n",
      "Epoch 4631/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.6920 - mse: 690.0580 - val_loss: 19.6103 - val_mse: 840.0266\n",
      "Epoch 4632/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6565 - mse: 709.1747 - val_loss: 17.7133 - val_mse: 711.8834\n",
      "Epoch 4633/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9832 - mse: 668.9830 - val_loss: 17.4365 - val_mse: 653.9849\n",
      "Epoch 4634/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.4898 - mse: 633.6688 - val_loss: 17.0546 - val_mse: 647.6863\n",
      "Epoch 4635/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.7801 - mse: 646.0283 - val_loss: 17.6011 - val_mse: 636.1428\n",
      "Epoch 4636/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6148 - mse: 644.1450 - val_loss: 17.5088 - val_mse: 651.8802\n",
      "Epoch 4637/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1741 - mse: 678.9265 - val_loss: 17.0994 - val_mse: 649.0289\n",
      "Epoch 4638/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.5524 - mse: 633.1967 - val_loss: 17.2892 - val_mse: 652.5675\n",
      "Epoch 4639/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9507 - mse: 651.2626 - val_loss: 17.1207 - val_mse: 668.5532\n",
      "Epoch 4640/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7317 - mse: 647.6132 - val_loss: 17.3280 - val_mse: 662.6307\n",
      "Epoch 4641/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7648 - mse: 649.2581 - val_loss: 17.1331 - val_mse: 655.7728\n",
      "Epoch 4642/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.5623 - mse: 641.2362 - val_loss: 17.6825 - val_mse: 656.6244\n",
      "Epoch 4643/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.3359 - mse: 743.7831 - val_loss: 17.7700 - val_mse: 687.7499\n",
      "Epoch 4644/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1196 - mse: 671.5922 - val_loss: 17.2635 - val_mse: 671.5038\n",
      "Epoch 4645/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.5337 - mse: 638.0198 - val_loss: 17.4312 - val_mse: 650.3245\n",
      "Epoch 4646/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7098 - mse: 652.3754 - val_loss: 17.1422 - val_mse: 673.3599\n",
      "Epoch 4647/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8863 - mse: 659.7855 - val_loss: 17.4213 - val_mse: 657.8171\n",
      "Epoch 4648/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9106 - mse: 658.6331 - val_loss: 18.0451 - val_mse: 684.7672\n",
      "Epoch 4649/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7066 - mse: 655.7480 - val_loss: 19.1458 - val_mse: 804.4948\n",
      "Epoch 4650/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3133 - mse: 681.6927 - val_loss: 17.9721 - val_mse: 741.9638\n",
      "Epoch 4651/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2502 - mse: 673.6710 - val_loss: 17.4169 - val_mse: 696.4536\n",
      "Epoch 4652/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.3805 - mse: 628.0500 - val_loss: 17.7731 - val_mse: 665.2260\n",
      "Epoch 4653/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6217 - mse: 642.1706 - val_loss: 17.8393 - val_mse: 721.9293\n",
      "Epoch 4654/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5993 - mse: 707.2540 - val_loss: 17.7985 - val_mse: 707.9019\n",
      "Epoch 4655/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3715 - mse: 685.0284 - val_loss: 17.3077 - val_mse: 679.4742\n",
      "Epoch 4656/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.3026 - mse: 682.1223 - val_loss: 17.4664 - val_mse: 660.4787\n",
      "Epoch 4657/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6075 - mse: 637.1738 - val_loss: 17.3272 - val_mse: 665.9294\n",
      "Epoch 4658/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.5374 - mse: 638.0789 - val_loss: 17.1820 - val_mse: 693.0675\n",
      "Epoch 4659/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7295 - mse: 656.5560 - val_loss: 17.7021 - val_mse: 664.5697\n",
      "Epoch 4660/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7070 - mse: 638.9727 - val_loss: 17.5394 - val_mse: 677.0682\n",
      "Epoch 4661/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8086 - mse: 649.6528 - val_loss: 17.1067 - val_mse: 658.9548\n",
      "Epoch 4662/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3020 - mse: 683.0152 - val_loss: 17.6373 - val_mse: 682.8858\n",
      "Epoch 4663/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.5003 - mse: 641.7250 - val_loss: 18.1317 - val_mse: 725.2629\n",
      "Epoch 4664/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0063 - mse: 657.2166 - val_loss: 18.3763 - val_mse: 759.2310\n",
      "Epoch 4665/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7993 - mse: 649.8976 - val_loss: 17.6359 - val_mse: 683.9296\n",
      "Epoch 4666/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8675 - mse: 655.2107 - val_loss: 17.4380 - val_mse: 676.8828\n",
      "Epoch 4667/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.4876 - mse: 637.4899 - val_loss: 18.7668 - val_mse: 766.0419\n",
      "Epoch 4668/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1248 - mse: 675.4164 - val_loss: 17.4017 - val_mse: 708.8458\n",
      "Epoch 4669/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.5053 - mse: 640.5963 - val_loss: 17.7468 - val_mse: 702.6445\n",
      "Epoch 4670/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.5758 - mse: 637.6641 - val_loss: 17.6416 - val_mse: 724.9919\n",
      "Epoch 4671/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.2930 - mse: 628.6600 - val_loss: 17.3755 - val_mse: 675.1071\n",
      "Epoch 4672/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7948 - mse: 648.4632 - val_loss: 17.7803 - val_mse: 680.8250\n",
      "Epoch 4673/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7773 - mse: 718.3566 - val_loss: 18.9271 - val_mse: 807.3533\n",
      "Epoch 4674/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.0993 - mse: 733.5233 - val_loss: 17.5822 - val_mse: 703.9437\n",
      "Epoch 4675/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9238 - mse: 658.8092 - val_loss: 17.8791 - val_mse: 685.5347\n",
      "Epoch 4676/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6947 - mse: 644.8206 - val_loss: 17.4360 - val_mse: 681.1797\n",
      "Epoch 4677/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.4951 - mse: 633.9418 - val_loss: 17.1520 - val_mse: 682.9545\n",
      "Epoch 4678/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.5089 - mse: 636.1097 - val_loss: 17.4967 - val_mse: 691.4070\n",
      "Epoch 4679/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3551 - mse: 688.1383 - val_loss: 18.7841 - val_mse: 804.2220\n",
      "Epoch 4680/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.9821 - mse: 715.2653 - val_loss: 18.2343 - val_mse: 778.7841\n",
      "Epoch 4681/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3052 - mse: 673.5308 - val_loss: 17.5000 - val_mse: 709.9133\n",
      "Epoch 4682/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6731 - mse: 650.7203 - val_loss: 18.0296 - val_mse: 659.9404\n",
      "Epoch 4683/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.1984 - mse: 742.6996 - val_loss: 19.5676 - val_mse: 723.9630\n",
      "Epoch 4684/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0971 - mse: 672.8388 - val_loss: 17.2851 - val_mse: 672.8300\n",
      "Epoch 4685/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.5791 - mse: 629.8796 - val_loss: 17.0660 - val_mse: 658.7726\n",
      "Epoch 4686/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8898 - mse: 660.0420 - val_loss: 17.7290 - val_mse: 706.6653\n",
      "Epoch 4687/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2731 - mse: 727.9835 - val_loss: 17.8628 - val_mse: 742.1536\n",
      "Epoch 4688/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7323 - mse: 698.3694 - val_loss: 17.7827 - val_mse: 741.5223\n",
      "Epoch 4689/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6234 - mse: 639.1082 - val_loss: 17.5103 - val_mse: 707.9155\n",
      "Epoch 4690/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6080 - mse: 642.6849 - val_loss: 17.1795 - val_mse: 692.6575\n",
      "Epoch 4691/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7438 - mse: 648.4218 - val_loss: 19.2283 - val_mse: 827.0106\n",
      "Epoch 4692/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5808 - mse: 689.4843 - val_loss: 17.6232 - val_mse: 695.3376\n",
      "Epoch 4693/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8637 - mse: 667.0166 - val_loss: 18.1538 - val_mse: 678.2427\n",
      "Epoch 4694/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.5256 - mse: 627.7618 - val_loss: 16.9119 - val_mse: 659.9351\n",
      "Epoch 4695/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.3887 - mse: 628.0880 - val_loss: 17.7269 - val_mse: 730.6231\n",
      "Epoch 4696/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.4381 - mse: 623.7166 - val_loss: 17.1364 - val_mse: 687.8976\n",
      "Epoch 4697/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.2876 - mse: 617.8788 - val_loss: 17.1711 - val_mse: 672.8118\n",
      "Epoch 4698/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.4767 - mse: 637.1523 - val_loss: 17.7265 - val_mse: 671.0750\n",
      "Epoch 4699/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0920 - mse: 673.4719 - val_loss: 17.3908 - val_mse: 698.2538\n",
      "Epoch 4700/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7501 - mse: 652.4609 - val_loss: 17.6841 - val_mse: 732.2206\n",
      "Epoch 4701/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9740 - mse: 660.6102 - val_loss: 17.8121 - val_mse: 688.7139\n",
      "Epoch 4702/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.6015 - mse: 642.7476 - val_loss: 17.1842 - val_mse: 647.8181\n",
      "Epoch 4703/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0608 - mse: 655.0303 - val_loss: 18.4527 - val_mse: 802.9927\n",
      "Epoch 4704/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 17.1400 - mse: 672.3708 - val_loss: 17.6232 - val_mse: 714.5654\n",
      "Epoch 4705/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7838 - mse: 648.2086 - val_loss: 17.4679 - val_mse: 674.4077\n",
      "Epoch 4706/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7580 - mse: 650.7169 - val_loss: 17.5053 - val_mse: 650.7855\n",
      "Epoch 4707/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.8650 - mse: 725.3990 - val_loss: 19.5045 - val_mse: 722.4930\n",
      "Epoch 4708/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2879 - mse: 679.6289 - val_loss: 17.2225 - val_mse: 659.5963\n",
      "Epoch 4709/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6050 - mse: 633.3379 - val_loss: 17.6729 - val_mse: 733.9847\n",
      "Epoch 4710/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.5081 - mse: 635.5468 - val_loss: 17.0351 - val_mse: 659.1567\n",
      "Epoch 4711/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.4559 - mse: 631.1670 - val_loss: 17.8936 - val_mse: 695.9111\n",
      "Epoch 4712/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2939 - mse: 678.1972 - val_loss: 17.6997 - val_mse: 732.3420\n",
      "Epoch 4713/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7015 - mse: 647.3474 - val_loss: 17.2665 - val_mse: 681.4769\n",
      "Epoch 4714/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.5582 - mse: 640.3366 - val_loss: 17.3589 - val_mse: 646.8734\n",
      "Epoch 4715/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.4151 - mse: 624.8347 - val_loss: 16.9992 - val_mse: 681.9496\n",
      "Epoch 4716/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6208 - mse: 643.8344 - val_loss: 18.1171 - val_mse: 762.7104\n",
      "Epoch 4717/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8805 - mse: 659.8079 - val_loss: 17.1371 - val_mse: 660.1791\n",
      "Epoch 4718/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.6404 - mse: 700.7496 - val_loss: 18.1519 - val_mse: 732.6938\n",
      "Epoch 4719/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.9848 - mse: 659.1227 - val_loss: 17.2788 - val_mse: 696.3735\n",
      "Epoch 4720/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1986 - mse: 667.9632 - val_loss: 17.5340 - val_mse: 667.4401\n",
      "Epoch 4721/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.2474 - mse: 682.8922 - val_loss: 17.4909 - val_mse: 688.3345\n",
      "Epoch 4722/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.5276 - mse: 630.2811 - val_loss: 17.5942 - val_mse: 730.8562\n",
      "Epoch 4723/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.9272 - mse: 659.8626 - val_loss: 17.3857 - val_mse: 693.7264\n",
      "Epoch 4724/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4456 - mse: 677.2918 - val_loss: 17.5689 - val_mse: 721.1391\n",
      "Epoch 4725/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 16.8048 - mse: 650.1758 - val_loss: 17.6929 - val_mse: 714.0296\n",
      "Epoch 4726/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 16.6339 - mse: 641.0875 - val_loss: 17.5409 - val_mse: 692.7677\n",
      "Epoch 4727/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0794 - mse: 655.1911 - val_loss: 17.7475 - val_mse: 736.8728\n",
      "Epoch 4728/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.6571 - mse: 640.8927 - val_loss: 17.1924 - val_mse: 686.4106\n",
      "Epoch 4729/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7887 - mse: 657.6700 - val_loss: 17.3939 - val_mse: 684.0428\n",
      "Epoch 4730/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 17.1342 - mse: 661.5442 - val_loss: 17.7724 - val_mse: 673.9525\n",
      "Epoch 4731/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.9569 - mse: 663.6248 - val_loss: 17.2748 - val_mse: 661.6184\n",
      "Epoch 4732/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7762 - mse: 641.7115 - val_loss: 17.3381 - val_mse: 691.2957\n",
      "Epoch 4733/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 16.6455 - mse: 645.6746 - val_loss: 17.8252 - val_mse: 669.6389\n",
      "Epoch 4734/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.9962 - mse: 669.2916 - val_loss: 17.2141 - val_mse: 663.8472\n",
      "Epoch 4735/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.5686 - mse: 643.2167 - val_loss: 17.2436 - val_mse: 662.1260\n",
      "Epoch 4736/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.3932 - mse: 624.3402 - val_loss: 18.1009 - val_mse: 751.8586\n",
      "Epoch 4737/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7939 - mse: 650.7548 - val_loss: 17.2086 - val_mse: 658.8596\n",
      "Epoch 4738/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 16.5540 - mse: 635.9817 - val_loss: 17.3373 - val_mse: 681.7174\n",
      "Epoch 4739/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 16.6255 - mse: 649.2258 - val_loss: 17.6668 - val_mse: 726.7185\n",
      "Epoch 4740/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.8555 - mse: 660.8121 - val_loss: 17.1209 - val_mse: 699.9435\n",
      "Epoch 4741/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 16.4558 - mse: 633.1263 - val_loss: 17.3813 - val_mse: 689.4572\n",
      "Epoch 4742/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.5353 - mse: 643.1392 - val_loss: 17.5327 - val_mse: 677.0801\n",
      "Epoch 4743/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 16.6455 - mse: 641.5829 - val_loss: 17.9280 - val_mse: 725.2123\n",
      "Epoch 4744/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7178 - mse: 640.7751 - val_loss: 17.1856 - val_mse: 639.0337\n",
      "Epoch 4745/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.3544 - mse: 631.0972 - val_loss: 17.4811 - val_mse: 665.0427\n",
      "Epoch 4746/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8615 - mse: 647.5901 - val_loss: 17.2320 - val_mse: 668.7958\n",
      "Epoch 4747/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8480 - mse: 656.3626 - val_loss: 17.2316 - val_mse: 673.3365\n",
      "Epoch 4748/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7993 - mse: 653.7997 - val_loss: 17.2897 - val_mse: 665.2379\n",
      "Epoch 4749/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.5164 - mse: 631.6034 - val_loss: 17.2413 - val_mse: 675.3622\n",
      "Epoch 4750/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.0230 - mse: 667.0126 - val_loss: 18.2922 - val_mse: 735.9227\n",
      "Epoch 4751/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.5152 - mse: 633.7877 - val_loss: 18.2416 - val_mse: 733.2367\n",
      "Epoch 4752/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1816 - mse: 671.7874 - val_loss: 18.2598 - val_mse: 775.3042\n",
      "Epoch 4753/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.5992 - mse: 703.2715 - val_loss: 19.2178 - val_mse: 763.7150\n",
      "Epoch 4754/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19.4521 - mse: 815.0666 - val_loss: 18.6574 - val_mse: 771.1204\n",
      "Epoch 4755/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 18.8808 - mse: 793.6903 - val_loss: 19.5309 - val_mse: 725.8463\n",
      "Epoch 4756/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.5523 - mse: 736.0411 - val_loss: 18.8199 - val_mse: 753.9675\n",
      "Epoch 4757/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.3714 - mse: 743.6055 - val_loss: 18.4115 - val_mse: 750.9979\n",
      "Epoch 4758/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.1689 - mse: 709.7764 - val_loss: 18.1668 - val_mse: 727.8430\n",
      "Epoch 4759/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.7408 - mse: 690.7250 - val_loss: 18.2995 - val_mse: 721.8859\n",
      "Epoch 4760/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8291 - mse: 702.0402 - val_loss: 17.9793 - val_mse: 718.7906\n",
      "Epoch 4761/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.0165 - mse: 705.4865 - val_loss: 17.9798 - val_mse: 705.3064\n",
      "Epoch 4762/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.9495 - mse: 700.0568 - val_loss: 18.7945 - val_mse: 792.5881\n",
      "Epoch 4763/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.0057 - mse: 710.0395 - val_loss: 18.2586 - val_mse: 783.4725\n",
      "Epoch 4764/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4569 - mse: 682.3787 - val_loss: 18.1522 - val_mse: 672.0344\n",
      "Epoch 4765/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.7903 - mse: 698.4984 - val_loss: 18.9129 - val_mse: 811.5219\n",
      "Epoch 4766/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.1648 - mse: 721.1480 - val_loss: 18.0680 - val_mse: 729.0108\n",
      "Epoch 4767/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7776 - mse: 697.4055 - val_loss: 18.0194 - val_mse: 704.4669\n",
      "Epoch 4768/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4999 - mse: 674.8923 - val_loss: 18.0738 - val_mse: 686.2228\n",
      "Epoch 4769/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.7118 - mse: 695.9899 - val_loss: 17.7048 - val_mse: 677.1331\n",
      "Epoch 4770/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5163 - mse: 678.0679 - val_loss: 17.7301 - val_mse: 707.5662\n",
      "Epoch 4771/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3339 - mse: 673.9933 - val_loss: 17.8096 - val_mse: 720.6288\n",
      "Epoch 4772/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4784 - mse: 688.7107 - val_loss: 18.2836 - val_mse: 706.6965\n",
      "Epoch 4773/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.3145 - mse: 674.1664 - val_loss: 17.5061 - val_mse: 695.8928\n",
      "Epoch 4774/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0434 - mse: 651.3901 - val_loss: 17.8440 - val_mse: 697.3519\n",
      "Epoch 4775/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.7576 - mse: 696.1299 - val_loss: 18.0688 - val_mse: 764.1968\n",
      "Epoch 4776/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2215 - mse: 667.1896 - val_loss: 17.4526 - val_mse: 688.7999\n",
      "Epoch 4777/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9118 - mse: 653.3881 - val_loss: 17.7339 - val_mse: 702.7145\n",
      "Epoch 4778/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.2743 - mse: 674.3918 - val_loss: 17.7319 - val_mse: 729.8627\n",
      "Epoch 4779/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8462 - mse: 647.7012 - val_loss: 17.8693 - val_mse: 726.7849\n",
      "Epoch 4780/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0921 - mse: 663.7892 - val_loss: 17.8274 - val_mse: 699.1915\n",
      "Epoch 4781/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2126 - mse: 669.7335 - val_loss: 17.4323 - val_mse: 672.1984\n",
      "Epoch 4782/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9272 - mse: 653.6058 - val_loss: 17.6470 - val_mse: 690.3295\n",
      "Epoch 4783/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9686 - mse: 649.7790 - val_loss: 17.5569 - val_mse: 678.9589\n",
      "Epoch 4784/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.5379 - mse: 694.9414 - val_loss: 17.7472 - val_mse: 679.6761\n",
      "Epoch 4785/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 18.6139 - mse: 752.1606 - val_loss: 19.2320 - val_mse: 885.7069\n",
      "Epoch 4786/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.4604 - mse: 686.1915 - val_loss: 17.3582 - val_mse: 690.5399\n",
      "Epoch 4787/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4429 - mse: 690.3337 - val_loss: 18.4041 - val_mse: 721.6538\n",
      "Epoch 4788/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.4624 - mse: 688.8032 - val_loss: 18.4777 - val_mse: 735.1393\n",
      "Epoch 4789/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.3766 - mse: 686.6887 - val_loss: 19.5560 - val_mse: 749.3795\n",
      "Epoch 4790/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.1419 - mse: 721.5599 - val_loss: 17.6322 - val_mse: 709.6328\n",
      "Epoch 4791/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.5317 - mse: 702.7995 - val_loss: 18.2936 - val_mse: 666.6339\n",
      "Epoch 4792/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1618 - mse: 666.0767 - val_loss: 17.6234 - val_mse: 660.7589\n",
      "Epoch 4793/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.6392 - mse: 647.2130 - val_loss: 17.2781 - val_mse: 657.8142\n",
      "Epoch 4794/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7224 - mse: 643.6624 - val_loss: 17.6730 - val_mse: 746.9648\n",
      "Epoch 4795/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.6000 - mse: 639.5580 - val_loss: 17.5072 - val_mse: 669.5786\n",
      "Epoch 4796/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7073 - mse: 641.7590 - val_loss: 17.2749 - val_mse: 683.5111\n",
      "Epoch 4797/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8234 - mse: 703.4292 - val_loss: 17.9856 - val_mse: 698.5103\n",
      "Epoch 4798/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8165 - mse: 712.4258 - val_loss: 17.9817 - val_mse: 753.6534\n",
      "Epoch 4799/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1192 - mse: 667.7658 - val_loss: 17.8803 - val_mse: 714.4617\n",
      "Epoch 4800/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8987 - mse: 656.6354 - val_loss: 17.1580 - val_mse: 686.4219\n",
      "Epoch 4801/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.6852 - mse: 650.9703 - val_loss: 17.3724 - val_mse: 683.2888\n",
      "Epoch 4802/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.4739 - mse: 638.4487 - val_loss: 17.1747 - val_mse: 678.3776\n",
      "Epoch 4803/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.6802 - mse: 645.5777 - val_loss: 17.2997 - val_mse: 660.1924\n",
      "Epoch 4804/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.2703 - mse: 728.4954 - val_loss: 20.4582 - val_mse: 757.3148\n",
      "Epoch 4805/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.2801 - mse: 752.0151 - val_loss: 18.2365 - val_mse: 680.8214\n",
      "Epoch 4806/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.7996 - mse: 701.2586 - val_loss: 18.1892 - val_mse: 762.9985\n",
      "Epoch 4807/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8755 - mse: 717.2499 - val_loss: 17.6238 - val_mse: 680.5773\n",
      "Epoch 4808/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0587 - mse: 664.5418 - val_loss: 17.4990 - val_mse: 663.7943\n",
      "Epoch 4809/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6483 - mse: 637.0686 - val_loss: 17.7046 - val_mse: 666.0280\n",
      "Epoch 4810/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7739 - mse: 652.6755 - val_loss: 17.4418 - val_mse: 693.9941\n",
      "Epoch 4811/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8475 - mse: 646.7239 - val_loss: 17.3049 - val_mse: 681.5148\n",
      "Epoch 4812/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.1369 - mse: 669.8300 - val_loss: 18.0931 - val_mse: 731.5696\n",
      "Epoch 4813/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.9768 - mse: 713.6042 - val_loss: 18.3692 - val_mse: 736.5190\n",
      "Epoch 4814/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.1707 - mse: 729.8552 - val_loss: 18.6551 - val_mse: 796.8846\n",
      "Epoch 4815/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.0445 - mse: 726.9410 - val_loss: 17.7498 - val_mse: 733.3645\n",
      "Epoch 4816/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.5955 - mse: 697.5139 - val_loss: 20.2193 - val_mse: 915.0994\n",
      "Epoch 4817/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.4013 - mse: 687.7033 - val_loss: 17.2924 - val_mse: 690.8191\n",
      "Epoch 4818/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.7077 - mse: 707.8444 - val_loss: 17.4838 - val_mse: 680.6060\n",
      "Epoch 4819/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8938 - mse: 653.9514 - val_loss: 17.5187 - val_mse: 694.4352\n",
      "Epoch 4820/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 16.7793 - mse: 655.6850 - val_loss: 17.2794 - val_mse: 657.6689\n",
      "Epoch 4821/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7910 - mse: 644.1608 - val_loss: 17.0089 - val_mse: 667.4961\n",
      "Epoch 4822/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.6208 - mse: 703.3536 - val_loss: 18.1147 - val_mse: 683.1484\n",
      "Epoch 4823/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 17.0913 - mse: 662.7545 - val_loss: 17.3476 - val_mse: 672.3375\n",
      "Epoch 4824/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.1949 - mse: 665.3988 - val_loss: 17.6170 - val_mse: 659.1897\n",
      "Epoch 4825/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.8479 - mse: 651.9838 - val_loss: 17.9255 - val_mse: 699.7309\n",
      "Epoch 4826/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.7476 - mse: 642.4777 - val_loss: 17.5567 - val_mse: 724.7637\n",
      "Epoch 4827/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 16.3564 - mse: 625.6897 - val_loss: 17.1879 - val_mse: 670.2430\n",
      "Epoch 4828/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 16.7884 - mse: 646.9929 - val_loss: 17.8912 - val_mse: 744.9786\n",
      "Epoch 4829/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.5910 - mse: 639.0014 - val_loss: 18.1254 - val_mse: 701.9868\n",
      "Epoch 4830/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.2127 - mse: 670.1328 - val_loss: 17.2672 - val_mse: 667.4131\n",
      "Epoch 4831/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.7523 - mse: 642.0143 - val_loss: 17.3721 - val_mse: 677.4067\n",
      "Epoch 4832/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7280 - mse: 645.2195 - val_loss: 17.5283 - val_mse: 659.4270\n",
      "Epoch 4833/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.6806 - mse: 644.8144 - val_loss: 17.1224 - val_mse: 671.0638\n",
      "Epoch 4834/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.4002 - mse: 624.8096 - val_loss: 17.3346 - val_mse: 671.0756\n",
      "Epoch 4835/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.9920 - mse: 716.2241 - val_loss: 17.7430 - val_mse: 727.6665\n",
      "Epoch 4836/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6638 - mse: 646.1830 - val_loss: 17.4027 - val_mse: 661.6510\n",
      "Epoch 4837/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 16.8151 - mse: 656.6387 - val_loss: 17.4927 - val_mse: 721.0718\n",
      "Epoch 4838/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.4377 - mse: 689.1641 - val_loss: 19.8517 - val_mse: 838.0601\n",
      "Epoch 4839/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.6680 - mse: 692.9972 - val_loss: 17.4162 - val_mse: 655.5422\n",
      "Epoch 4840/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.6733 - mse: 652.3699 - val_loss: 17.4871 - val_mse: 709.4148\n",
      "Epoch 4841/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.2297 - mse: 674.1053 - val_loss: 17.8345 - val_mse: 717.9803\n",
      "Epoch 4842/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7885 - mse: 648.4042 - val_loss: 19.0054 - val_mse: 797.6635\n",
      "Epoch 4843/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7906 - mse: 641.6573 - val_loss: 17.1875 - val_mse: 666.1731\n",
      "Epoch 4844/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0664 - mse: 656.2229 - val_loss: 17.3491 - val_mse: 693.3306\n",
      "Epoch 4845/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.4809 - mse: 695.6928 - val_loss: 17.5960 - val_mse: 703.6097\n",
      "Epoch 4846/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7120 - mse: 645.0588 - val_loss: 17.6364 - val_mse: 694.5087\n",
      "Epoch 4847/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.7903 - mse: 652.5089 - val_loss: 17.5211 - val_mse: 679.4608\n",
      "Epoch 4848/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0151 - mse: 661.9242 - val_loss: 17.8129 - val_mse: 751.1049\n",
      "Epoch 4849/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.5611 - mse: 646.6254 - val_loss: 17.1698 - val_mse: 661.5820\n",
      "Epoch 4850/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.5043 - mse: 634.4072 - val_loss: 17.2458 - val_mse: 656.0844\n",
      "Epoch 4851/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.5858 - mse: 636.0309 - val_loss: 17.4432 - val_mse: 675.4055\n",
      "Epoch 4852/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.4774 - mse: 635.9003 - val_loss: 17.2105 - val_mse: 675.3338\n",
      "Epoch 4853/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6809 - mse: 641.8118 - val_loss: 17.5697 - val_mse: 685.7460\n",
      "Epoch 4854/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8278 - mse: 649.7710 - val_loss: 17.6325 - val_mse: 673.7494\n",
      "Epoch 4855/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.7074 - mse: 706.5191 - val_loss: 18.1864 - val_mse: 693.1735\n",
      "Epoch 4856/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6164 - mse: 695.7817 - val_loss: 17.3574 - val_mse: 658.6729\n",
      "Epoch 4857/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.8518 - mse: 649.6201 - val_loss: 17.2217 - val_mse: 663.2835\n",
      "Epoch 4858/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.5587 - mse: 646.4260 - val_loss: 16.9442 - val_mse: 652.7989\n",
      "Epoch 4859/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.2969 - mse: 621.1708 - val_loss: 17.4188 - val_mse: 653.3066\n",
      "Epoch 4860/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.4206 - mse: 641.0275 - val_loss: 18.6819 - val_mse: 695.7182\n",
      "Epoch 4861/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8370 - mse: 694.5537 - val_loss: 17.3905 - val_mse: 656.5301\n",
      "Epoch 4862/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 16.8485 - mse: 653.6873 - val_loss: 17.9210 - val_mse: 652.9528\n",
      "Epoch 4863/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8791 - mse: 647.8875 - val_loss: 17.6904 - val_mse: 693.1478\n",
      "Epoch 4864/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 16.5231 - mse: 631.1945 - val_loss: 17.5051 - val_mse: 713.8731\n",
      "Epoch 4865/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.4047 - mse: 623.6993 - val_loss: 17.2982 - val_mse: 686.0070\n",
      "Epoch 4866/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1830 - mse: 676.6824 - val_loss: 17.1020 - val_mse: 669.5706\n",
      "Epoch 4867/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.3493 - mse: 632.8162 - val_loss: 17.0948 - val_mse: 668.8625\n",
      "Epoch 4868/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.3700 - mse: 628.3730 - val_loss: 17.0359 - val_mse: 670.9688\n",
      "Epoch 4869/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.2802 - mse: 622.2797 - val_loss: 18.2272 - val_mse: 689.7975\n",
      "Epoch 4870/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6545 - mse: 648.2072 - val_loss: 18.0622 - val_mse: 670.3278\n",
      "Epoch 4871/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 18.3189 - mse: 730.5304 - val_loss: 19.8230 - val_mse: 904.7179\n",
      "Epoch 4872/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.7051 - mse: 790.3021 - val_loss: 20.1060 - val_mse: 931.3425\n",
      "Epoch 4873/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8396 - mse: 713.1579 - val_loss: 17.4805 - val_mse: 666.5154\n",
      "Epoch 4874/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.6094 - mse: 628.7083 - val_loss: 17.5404 - val_mse: 668.9088\n",
      "Epoch 4875/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0815 - mse: 668.3611 - val_loss: 17.7526 - val_mse: 720.1932\n",
      "Epoch 4876/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1565 - mse: 669.4208 - val_loss: 17.5169 - val_mse: 675.2934\n",
      "Epoch 4877/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8628 - mse: 649.0792 - val_loss: 17.0591 - val_mse: 644.5610\n",
      "Epoch 4878/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7535 - mse: 652.8239 - val_loss: 19.4695 - val_mse: 835.6109\n",
      "Epoch 4879/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.1200 - mse: 672.7322 - val_loss: 17.3429 - val_mse: 663.0348\n",
      "Epoch 4880/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8188 - mse: 653.6424 - val_loss: 17.5002 - val_mse: 684.7414\n",
      "Epoch 4881/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9619 - mse: 665.4512 - val_loss: 17.2174 - val_mse: 688.8677\n",
      "Epoch 4882/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0483 - mse: 656.8029 - val_loss: 18.0659 - val_mse: 728.0637\n",
      "Epoch 4883/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6850 - mse: 645.1433 - val_loss: 16.9189 - val_mse: 651.9688\n",
      "Epoch 4884/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9965 - mse: 654.4827 - val_loss: 18.7670 - val_mse: 811.4133\n",
      "Epoch 4885/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.7034 - mse: 710.3864 - val_loss: 17.8527 - val_mse: 755.2993\n",
      "Epoch 4886/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7983 - mse: 651.6000 - val_loss: 19.6600 - val_mse: 886.3660\n",
      "Epoch 4887/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0138 - mse: 667.6099 - val_loss: 17.3265 - val_mse: 667.4868\n",
      "Epoch 4888/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.7366 - mse: 704.5930 - val_loss: 17.8862 - val_mse: 741.8261\n",
      "Epoch 4889/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0941 - mse: 671.4095 - val_loss: 18.1484 - val_mse: 750.5588\n",
      "Epoch 4890/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6158 - mse: 638.4785 - val_loss: 18.0475 - val_mse: 753.9760\n",
      "Epoch 4891/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.5610 - mse: 633.7673 - val_loss: 16.9660 - val_mse: 680.0643\n",
      "Epoch 4892/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.6772 - mse: 647.1866 - val_loss: 17.2988 - val_mse: 652.3320\n",
      "Epoch 4893/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.1817 - mse: 619.6517 - val_loss: 17.0477 - val_mse: 681.1298\n",
      "Epoch 4894/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.4530 - mse: 634.7049 - val_loss: 17.0943 - val_mse: 668.9058\n",
      "Epoch 4895/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.4204 - mse: 630.4267 - val_loss: 18.5719 - val_mse: 755.4785\n",
      "Epoch 4896/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9832 - mse: 661.9399 - val_loss: 16.9085 - val_mse: 659.6537\n",
      "Epoch 4897/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.5578 - mse: 635.5018 - val_loss: 17.5986 - val_mse: 653.1505\n",
      "Epoch 4898/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9525 - mse: 657.1490 - val_loss: 17.5258 - val_mse: 696.3500\n",
      "Epoch 4899/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.5912 - mse: 646.1983 - val_loss: 17.6681 - val_mse: 688.6971\n",
      "Epoch 4900/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8670 - mse: 661.8416 - val_loss: 17.5717 - val_mse: 705.1828\n",
      "Epoch 4901/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.6327 - mse: 644.0776 - val_loss: 17.1513 - val_mse: 689.3099\n",
      "Epoch 4902/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9325 - mse: 666.7449 - val_loss: 17.3210 - val_mse: 684.5193\n",
      "Epoch 4903/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.4957 - mse: 694.0479 - val_loss: 16.9711 - val_mse: 646.2159\n",
      "Epoch 4904/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.5269 - mse: 639.1365 - val_loss: 17.1837 - val_mse: 671.7778\n",
      "Epoch 4905/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0413 - mse: 667.1438 - val_loss: 18.7727 - val_mse: 724.4588\n",
      "Epoch 4906/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.2930 - mse: 681.5244 - val_loss: 17.4308 - val_mse: 658.0471\n",
      "Epoch 4907/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0081 - mse: 664.8092 - val_loss: 17.5882 - val_mse: 660.5975\n",
      "Epoch 4908/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8586 - mse: 652.3952 - val_loss: 17.1201 - val_mse: 681.6522\n",
      "Epoch 4909/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7132 - mse: 646.7604 - val_loss: 17.1002 - val_mse: 675.8428\n",
      "Epoch 4910/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.5894 - mse: 636.7980 - val_loss: 17.7870 - val_mse: 715.0023\n",
      "Epoch 4911/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 17.0851 - mse: 664.2850 - val_loss: 17.5579 - val_mse: 675.1714\n",
      "Epoch 4912/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8585 - mse: 661.1097 - val_loss: 17.0488 - val_mse: 656.7147\n",
      "Epoch 4913/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.2615 - mse: 625.5699 - val_loss: 17.2346 - val_mse: 650.7434\n",
      "Epoch 4914/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7554 - mse: 650.7263 - val_loss: 17.1826 - val_mse: 665.9040\n",
      "Epoch 4915/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.9666 - mse: 662.0567 - val_loss: 17.4370 - val_mse: 682.1032\n",
      "Epoch 4916/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7636 - mse: 650.0446 - val_loss: 17.9864 - val_mse: 726.9137\n",
      "Epoch 4917/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1625 - mse: 667.1083 - val_loss: 17.1346 - val_mse: 668.2897\n",
      "Epoch 4918/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0135 - mse: 660.8995 - val_loss: 17.5469 - val_mse: 707.5944\n",
      "Epoch 4919/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9454 - mse: 656.8680 - val_loss: 17.4060 - val_mse: 672.3417\n",
      "Epoch 4920/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0463 - mse: 667.9580 - val_loss: 17.3881 - val_mse: 670.2474\n",
      "Epoch 4921/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.5024 - mse: 625.5050 - val_loss: 17.4754 - val_mse: 697.3339\n",
      "Epoch 4922/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0820 - mse: 659.8745 - val_loss: 18.0163 - val_mse: 749.0139\n",
      "Epoch 4923/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.2239 - mse: 673.4875 - val_loss: 17.8582 - val_mse: 736.9912\n",
      "Epoch 4924/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 16.8865 - mse: 663.6916 - val_loss: 17.3456 - val_mse: 690.5933\n",
      "Epoch 4925/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.3791 - mse: 629.5171 - val_loss: 17.2666 - val_mse: 645.5803\n",
      "Epoch 4926/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.4285 - mse: 630.8630 - val_loss: 17.4512 - val_mse: 702.0001\n",
      "Epoch 4927/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.8975 - mse: 659.8176 - val_loss: 17.6191 - val_mse: 697.1567\n",
      "Epoch 4928/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8982 - mse: 657.7267 - val_loss: 16.9432 - val_mse: 663.0948\n",
      "Epoch 4929/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 16.3704 - mse: 629.0176 - val_loss: 17.3552 - val_mse: 658.8557\n",
      "Epoch 4930/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.3597 - mse: 632.7437 - val_loss: 17.2949 - val_mse: 680.0762\n",
      "Epoch 4931/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.6767 - mse: 647.2044 - val_loss: 17.1667 - val_mse: 656.2933\n",
      "Epoch 4932/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.0576 - mse: 665.0823 - val_loss: 18.6691 - val_mse: 739.5618\n",
      "Epoch 4933/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 16.6809 - mse: 645.3639 - val_loss: 17.4514 - val_mse: 654.8759\n",
      "Epoch 4934/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8044 - mse: 650.9128 - val_loss: 19.0411 - val_mse: 699.0737\n",
      "Epoch 4935/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 18.0879 - mse: 722.0170 - val_loss: 19.1557 - val_mse: 840.3448\n",
      "Epoch 4936/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.8830 - mse: 650.6657 - val_loss: 17.7176 - val_mse: 669.1853\n",
      "Epoch 4937/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.4115 - mse: 621.6270 - val_loss: 17.1498 - val_mse: 685.0118\n",
      "Epoch 4938/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.2017 - mse: 619.8334 - val_loss: 18.2491 - val_mse: 725.2866\n",
      "Epoch 4939/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9850 - mse: 663.7511 - val_loss: 17.3808 - val_mse: 668.8171\n",
      "Epoch 4940/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.3256 - mse: 617.6954 - val_loss: 17.5995 - val_mse: 695.3736\n",
      "Epoch 4941/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1081 - mse: 663.3155 - val_loss: 17.7461 - val_mse: 663.1381\n",
      "Epoch 4942/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9130 - mse: 655.8388 - val_loss: 18.2031 - val_mse: 765.4926\n",
      "Epoch 4943/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.5597 - mse: 642.1492 - val_loss: 17.6012 - val_mse: 723.8085\n",
      "Epoch 4944/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.9894 - mse: 729.7759 - val_loss: 18.0759 - val_mse: 705.1304\n",
      "Epoch 4945/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7560 - mse: 650.0364 - val_loss: 17.1098 - val_mse: 654.4453\n",
      "Epoch 4946/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.4458 - mse: 636.7830 - val_loss: 17.1469 - val_mse: 647.0627\n",
      "Epoch 4947/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7172 - mse: 647.3560 - val_loss: 18.0035 - val_mse: 671.5162\n",
      "Epoch 4948/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.4633 - mse: 689.9487 - val_loss: 18.8300 - val_mse: 776.8989\n",
      "Epoch 4949/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1335 - mse: 660.5259 - val_loss: 17.5256 - val_mse: 716.1030\n",
      "Epoch 4950/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.2850 - mse: 618.9042 - val_loss: 16.9289 - val_mse: 654.5417\n",
      "Epoch 4951/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.2054 - mse: 615.4758 - val_loss: 16.9678 - val_mse: 649.5527\n",
      "Epoch 4952/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.9501 - mse: 667.7521 - val_loss: 17.8040 - val_mse: 684.5889\n",
      "Epoch 4953/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.4394 - mse: 747.6817 - val_loss: 17.5472 - val_mse: 665.6003\n",
      "Epoch 4954/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.4917 - mse: 636.5771 - val_loss: 17.0763 - val_mse: 668.6771\n",
      "Epoch 4955/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6067 - mse: 633.1013 - val_loss: 17.0424 - val_mse: 656.3027\n",
      "Epoch 4956/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.5489 - mse: 682.6779 - val_loss: 18.0954 - val_mse: 689.6929\n",
      "Epoch 4957/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.6939 - mse: 652.9465 - val_loss: 17.2959 - val_mse: 647.8866\n",
      "Epoch 4958/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.0404 - mse: 660.9163 - val_loss: 17.3442 - val_mse: 655.4618\n",
      "Epoch 4959/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.2785 - mse: 622.8465 - val_loss: 17.3805 - val_mse: 707.7516\n",
      "Epoch 4960/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.3904 - mse: 635.0063 - val_loss: 17.4317 - val_mse: 704.4429\n",
      "Epoch 4961/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.9345 - mse: 654.6066 - val_loss: 18.6352 - val_mse: 693.6548\n",
      "Epoch 4962/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.9576 - mse: 796.1223 - val_loss: 19.8175 - val_mse: 850.1294\n",
      "Epoch 4963/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.8908 - mse: 711.5311 - val_loss: 17.9432 - val_mse: 707.0928\n",
      "Epoch 4964/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17.0888 - mse: 666.1523 - val_loss: 17.4442 - val_mse: 655.4612\n",
      "Epoch 4965/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.4821 - mse: 632.6254 - val_loss: 16.8491 - val_mse: 652.2573\n",
      "Epoch 4966/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.5504 - mse: 633.3042 - val_loss: 17.8114 - val_mse: 692.0661\n",
      "Epoch 4967/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.3851 - mse: 628.7898 - val_loss: 17.3558 - val_mse: 695.2191\n",
      "Epoch 4968/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6818 - mse: 686.3625 - val_loss: 17.5500 - val_mse: 697.7083\n",
      "Epoch 4969/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.5098 - mse: 691.6210 - val_loss: 17.7702 - val_mse: 689.3863\n",
      "Epoch 4970/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 16.4687 - mse: 646.3478 - val_loss: 17.0815 - val_mse: 662.3092\n",
      "Epoch 4971/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.1569 - mse: 619.9808 - val_loss: 16.9684 - val_mse: 661.0164\n",
      "Epoch 4972/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8888 - mse: 653.3357 - val_loss: 17.6666 - val_mse: 686.8575\n",
      "Epoch 4973/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.7907 - mse: 655.3241 - val_loss: 17.4327 - val_mse: 698.4456\n",
      "Epoch 4974/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.6334 - mse: 640.1945 - val_loss: 18.4601 - val_mse: 770.9421\n",
      "Epoch 4975/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.0247 - mse: 658.5658 - val_loss: 18.1868 - val_mse: 767.7921\n",
      "Epoch 4976/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7605 - mse: 650.1392 - val_loss: 17.2534 - val_mse: 637.1988\n",
      "Epoch 4977/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.2261 - mse: 672.7464 - val_loss: 18.0421 - val_mse: 762.4344\n",
      "Epoch 4978/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6952 - mse: 653.9424 - val_loss: 17.1159 - val_mse: 677.3837\n",
      "Epoch 4979/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.4056 - mse: 632.4072 - val_loss: 17.3072 - val_mse: 652.4725\n",
      "Epoch 4980/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.4220 - mse: 633.7122 - val_loss: 17.5211 - val_mse: 703.6296\n",
      "Epoch 4981/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.5304 - mse: 772.9625 - val_loss: 20.7954 - val_mse: 768.2653\n",
      "Epoch 4982/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.6009 - mse: 695.3538 - val_loss: 17.6093 - val_mse: 661.6992\n",
      "Epoch 4983/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.7432 - mse: 640.9495 - val_loss: 17.1017 - val_mse: 658.2815\n",
      "Epoch 4984/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.5805 - mse: 646.3350 - val_loss: 17.1656 - val_mse: 662.3263\n",
      "Epoch 4985/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 17.5649 - mse: 694.2756 - val_loss: 18.1323 - val_mse: 730.7110\n",
      "Epoch 4986/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.8295 - mse: 646.8449 - val_loss: 17.3900 - val_mse: 663.2844\n",
      "Epoch 4987/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.3133 - mse: 620.1064 - val_loss: 16.9694 - val_mse: 662.2501\n",
      "Epoch 4988/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18.1899 - mse: 720.1497 - val_loss: 18.3653 - val_mse: 756.5623\n",
      "Epoch 4989/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.8222 - mse: 719.9663 - val_loss: 17.3844 - val_mse: 656.3222\n",
      "Epoch 4990/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.4352 - mse: 628.8243 - val_loss: 17.4115 - val_mse: 700.5168\n",
      "Epoch 4991/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.9121 - mse: 725.5533 - val_loss: 17.5403 - val_mse: 650.7834\n",
      "Epoch 4992/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.6590 - mse: 633.0850 - val_loss: 18.1708 - val_mse: 676.9821\n",
      "Epoch 4993/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 17.1451 - mse: 661.5009 - val_loss: 17.7809 - val_mse: 736.0599\n",
      "Epoch 4994/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 17.1977 - mse: 677.3572 - val_loss: 17.4432 - val_mse: 667.3995\n",
      "Epoch 4995/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.9572 - mse: 659.5672 - val_loss: 17.2866 - val_mse: 686.6873\n",
      "Epoch 4996/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.4047 - mse: 624.2650 - val_loss: 17.4565 - val_mse: 708.4564\n",
      "Epoch 4997/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.5981 - mse: 636.1591 - val_loss: 16.9964 - val_mse: 654.3011\n",
      "Epoch 4998/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 16.2373 - mse: 622.1591 - val_loss: 17.0838 - val_mse: 667.3699\n",
      "Epoch 4999/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 16.3434 - mse: 619.7706 - val_loss: 17.3264 - val_mse: 669.6354\n",
      "Epoch 5000/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 16.3244 - mse: 623.6971 - val_loss: 17.2747 - val_mse: 672.5225\n"
     ]
    }
   ],
   "source": [
    "# more layers 5 hidden layers\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "      fivel_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu', input_dim = 42),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dense(1,kernel_initializer = 'uniform')\n",
    "    ])\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    fivel_model_history = model_compile_and_fit(X=X_train, \n",
    "                                            y=y_train,\n",
    "                                            model= fivel_model,\n",
    "                                            name='fivel_model',\n",
    "                                            optimizer='Adam', \n",
    "                                            max_epochs= EPOCHS )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e77cc5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 - 0s - loss: 18.3107 - mse: 777.2702 - 105ms/epoch - 2ms/step\n",
      "Model MSE: 777.2702026367188\n",
      "----------------------------------------\n",
      "RMSE: 27.879568542841607\n",
      "RMSE: 25.383008180540646\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    # plot MSE history \n",
    "    plot_metric(fivel_model_history)\n",
    "\n",
    "    # Evaluate the small model on test set using .evaluate\n",
    "    loss, mse = fivel_model.evaluate(X_test, y_test, verbose=2)\n",
    "    print(f'Model MSE: {mse}')\n",
    "    print('--------'*5)\n",
    "\n",
    "# Predict values for test set\n",
    "y_pred = fivel_model.predict(X_test)\n",
    "y_pred_train = fivel_model.predict(X_train)\n",
    "\n",
    "\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "test_results['fivel model'] =  [rmse_train, rmse_test]\n",
    "\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c2313bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fivel model</th>\n",
       "      <td>25.383008</td>\n",
       "      <td>27.879569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             RMSE Train  RMSE Test\n",
       "fivel model   25.383008  27.879569"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test_results, index=['RMSE Train', 'RMSE Test']).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbde3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 layers lr\n",
    "# more layers 5 hidden layers\n",
    "optimizer = tf.keras.optimizers.SGD(\n",
    "    learning_rate=0.01,\n",
    "    momentum=0.9,\n",
    "    nesterov=False,\n",
    "    name='SGD',\n",
    ")\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "      fivel_sgd_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu', input_dim = 42),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dense(1,kernel_initializer = 'uniform')\n",
    "    ])\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    fivel_sgd_model_history = model_compile_and_fit(X=X_train, \n",
    "                                            y=y_train,\n",
    "                                            model= fivel_sgd_model,\n",
    "                                            name='fivel_sgd_model',\n",
    "                                            optimizer=optimizer, \n",
    "                                            max_epochs= EPOCHS )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ceab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    # plot MSE history \n",
    "    plot_metric(fivel_sgd_model_history)\n",
    "\n",
    "    # Evaluate the small model on test set using .evaluate\n",
    "    loss, mse = fivel_sgd_model.evaluate(X_test, y_test, verbose=2)\n",
    "    print(f'Model MSE: {mse}')\n",
    "    print('--------'*5)\n",
    "\n",
    "# Predict values for test set\n",
    "y_pred = fivel_sgd_model.predict(X_test)\n",
    "y_pred_train = fivel_sgd_model.predict(X_train)\n",
    "\n",
    "\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "test_results['fivel_sgd_ model'] =  [rmse_train, rmse_test]\n",
    "\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05d65f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 5 layers lr\n",
    "# more layers 5 hidden layers and lr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c60504",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_results, index=['RMSE Train', 'RMSE Test']).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0fb4b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "36/36 [==============================] - 1s 12ms/step - loss: 745.2253 - mse: 16795320.0000 - val_loss: 21.7676 - val_mse: 1045.5120\n",
      "Epoch 2/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 22.4244 - mse: 1021.3669 - val_loss: 23.6618 - val_mse: 952.3500\n",
      "Epoch 3/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.8878 - mse: 973.1691 - val_loss: 21.3969 - val_mse: 900.0944\n",
      "Epoch 4/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 22.0962 - mse: 993.6052 - val_loss: 21.3065 - val_mse: 1022.1365\n",
      "Epoch 5/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 22.1094 - mse: 988.4109 - val_loss: 23.2055 - val_mse: 1193.1005\n",
      "Epoch 6/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 22.3637 - mse: 1009.7434 - val_loss: 20.8871 - val_mse: 986.8712\n",
      "Epoch 7/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.9590 - mse: 992.1125 - val_loss: 21.9589 - val_mse: 1101.6747\n",
      "Epoch 8/5000\n",
      "10/36 [=======>......................] - ETA: 0s - loss: 20.1639 - mse: 898.9421"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/valentina/ds/airquality/06_DNN_Assignment.ipynb Cell 57'\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valentina/ds/airquality/06_DNN_Assignment.ipynb#ch0000056?line=12'>13</a>\u001b[0m       fivel_01_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mSequential([\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valentina/ds/airquality/06_DNN_Assignment.ipynb#ch0000056?line=13'>14</a>\u001b[0m             tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m512\u001b[39m,kernel_initializer \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m'\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, input_dim \u001b[39m=\u001b[39m \u001b[39m42\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valentina/ds/airquality/06_DNN_Assignment.ipynb#ch0000056?line=14'>15</a>\u001b[0m             tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m512\u001b[39m,kernel_initializer \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m'\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valentina/ds/airquality/06_DNN_Assignment.ipynb#ch0000056?line=19'>20</a>\u001b[0m             tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m1\u001b[39m,kernel_initializer \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valentina/ds/airquality/06_DNN_Assignment.ipynb#ch0000056?line=20'>21</a>\u001b[0m     ])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valentina/ds/airquality/06_DNN_Assignment.ipynb#ch0000056?line=22'>23</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39m/cpu:0\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/valentina/ds/airquality/06_DNN_Assignment.ipynb#ch0000056?line=23'>24</a>\u001b[0m     fivel_01_model_history \u001b[39m=\u001b[39m model_compile_and_fit(X\u001b[39m=\u001b[39;49mX_train, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valentina/ds/airquality/06_DNN_Assignment.ipynb#ch0000056?line=24'>25</a>\u001b[0m                                             y\u001b[39m=\u001b[39;49my_train,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valentina/ds/airquality/06_DNN_Assignment.ipynb#ch0000056?line=25'>26</a>\u001b[0m                                             model\u001b[39m=\u001b[39;49m fivel_01_model,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valentina/ds/airquality/06_DNN_Assignment.ipynb#ch0000056?line=26'>27</a>\u001b[0m                                             name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mfivel_01_model\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valentina/ds/airquality/06_DNN_Assignment.ipynb#ch0000056?line=27'>28</a>\u001b[0m                                             optimizer\u001b[39m=\u001b[39;49moptimizer, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valentina/ds/airquality/06_DNN_Assignment.ipynb#ch0000056?line=28'>29</a>\u001b[0m                                             max_epochs\u001b[39m=\u001b[39;49m EPOCHS )\n",
      "\u001b[1;32m/Users/valentina/ds/airquality/06_DNN_Assignment.ipynb Cell 21'\u001b[0m in \u001b[0;36mmodel_compile_and_fit\u001b[0;34m(X, y, model, name, optimizer, max_epochs)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/valentina/ds/airquality/06_DNN_Assignment.ipynb#ch0000020?line=5'>6</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39moptimizer,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/valentina/ds/airquality/06_DNN_Assignment.ipynb#ch0000020?line=6'>7</a>\u001b[0m             metrics\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m# [tf.keras.metrics.RootMeanSquaredError()]\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/valentina/ds/airquality/06_DNN_Assignment.ipynb#ch0000020?line=7'>8</a>\u001b[0m             loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/valentina/ds/airquality/06_DNN_Assignment.ipynb#ch0000020?line=8'>9</a>\u001b[0m \u001b[39m# model.fit\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/valentina/ds/airquality/06_DNN_Assignment.ipynb#ch0000020?line=9'>10</a>\u001b[0m training_history[name] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valentina/ds/airquality/06_DNN_Assignment.ipynb#ch0000020?line=10'>11</a>\u001b[0m                     y,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valentina/ds/airquality/06_DNN_Assignment.ipynb#ch0000020?line=11'>12</a>\u001b[0m                     validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valentina/ds/airquality/06_DNN_Assignment.ipynb#ch0000020?line=12'>13</a>\u001b[0m                     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valentina/ds/airquality/06_DNN_Assignment.ipynb#ch0000020?line=13'>14</a>\u001b[0m                     steps_per_epoch\u001b[39m=\u001b[39;49mSTEPS_PER_EPOCH,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valentina/ds/airquality/06_DNN_Assignment.ipynb#ch0000020?line=14'>15</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49mEPOCHS, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valentina/ds/airquality/06_DNN_Assignment.ipynb#ch0000020?line=15'>16</a>\u001b[0m                     callbacks\u001b[39m=\u001b[39;49mget_callbacks(name))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valentina/ds/airquality/06_DNN_Assignment.ipynb#ch0000020?line=16'>17</a>\u001b[0m \u001b[39m# return results\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valentina/ds/airquality/06_DNN_Assignment.ipynb#ch0000020?line=17'>18</a>\u001b[0m \u001b[39mreturn\u001b[39;00m training_history[name]\n",
      "File \u001b[0;32m~/ds/airquality/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/ds/airquality/.venv/lib/python3.9/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/keras/engine/training.py?line=1376'>1377</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/keras/engine/training.py?line=1377'>1378</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/keras/engine/training.py?line=1378'>1379</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/keras/engine/training.py?line=1379'>1380</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/keras/engine/training.py?line=1380'>1381</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/keras/engine/training.py?line=1381'>1382</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/keras/engine/training.py?line=1382'>1383</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/keras/engine/training.py?line=1383'>1384</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/keras/engine/training.py?line=1384'>1385</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/keras/engine/training.py?line=1385'>1386</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=943'>944</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=944'>945</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=945'>946</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=946'>947</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=947'>948</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=948'>949</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=949'>950</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2952'>2953</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2953'>2954</a>\u001b[0m   (graph_function,\n\u001b[1;32m   <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2954'>2955</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2955'>2956</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2956'>2957</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1848'>1849</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1849'>1850</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1850'>1851</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1851'>1852</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1852'>1853</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1853'>1854</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1854'>1855</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m     args,\n\u001b[1;32m   <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m     possible_gradient_type,\n\u001b[1;32m   <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     executing_eagerly)\n\u001b[1;32m   <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=506'>507</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=507'>508</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=510'>511</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=511'>512</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='file:///Users/valentina/ds/airquality/.venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 5 layers lr\n",
    "# more layers 5 hidden layers\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.01,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False,\n",
    "    name='Adam',\n",
    ")\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "      fivel_01_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu', input_dim = 42),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dense(1,kernel_initializer = 'uniform')\n",
    "    ])\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    fivel_01_model_history = model_compile_and_fit(X=X_train, \n",
    "                                            y=y_train,\n",
    "                                            model= fivel_01_model,\n",
    "                                            name='fivel_01_model',\n",
    "                                            optimizer=optimizer, \n",
    "                                            max_epochs= EPOCHS )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62fa045",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    # plot MSE history \n",
    "    plot_metric(fivel_01_model_history)\n",
    "\n",
    "    # Evaluate the small model on test set using .evaluate\n",
    "    loss, mse = fivel_01_model.evaluate(X_test, y_test, verbose=2)\n",
    "    print(f'Model MSE: {mse}')\n",
    "    print('--------'*5)\n",
    "\n",
    "# Predict values for test set\n",
    "y_pred = fivel_01_model.predict(X_test)\n",
    "y_pred_train = fivel_01_model.predict(X_train)\n",
    "\n",
    "\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "test_results['fivel_01_ model'] =  [rmse_train, rmse_test]\n",
    "\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0d2901",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_results, index=['RMSE Train', 'RMSE Test']).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f94e0388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "36/36 [==============================] - 1s 13ms/step - loss: 26.2180 - mse: 1368.8135 - val_loss: 24.7057 - val_mse: 1292.6630\n",
      "Epoch 2/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 22.7129 - mse: 1033.3579 - val_loss: 25.0722 - val_mse: 1321.0341\n",
      "Epoch 3/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 23.2637 - mse: 1061.0315 - val_loss: 25.3196 - val_mse: 1340.0277\n",
      "Epoch 4/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 23.0137 - mse: 1044.8799 - val_loss: 29.6531 - val_mse: 1662.6570\n",
      "Epoch 5/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 23.0767 - mse: 1070.0306 - val_loss: 26.0258 - val_mse: 1393.8110\n",
      "Epoch 6/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 22.7911 - mse: 1038.0272 - val_loss: 26.0377 - val_mse: 1395.6182\n",
      "Epoch 7/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 23.0786 - mse: 1068.6195 - val_loss: 20.9213 - val_mse: 952.6938\n",
      "Epoch 8/5000\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 22.8260 - mse: 1043.3610 - val_loss: 22.6931 - val_mse: 1145.8113\n",
      "Epoch 9/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 22.2773 - mse: 1007.1502 - val_loss: 21.7198 - val_mse: 1064.0389\n",
      "Epoch 10/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 22.8054 - mse: 1035.0249 - val_loss: 24.5697 - val_mse: 1292.4274\n",
      "Epoch 11/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 23.3646 - mse: 1082.9637 - val_loss: 20.9805 - val_mse: 894.0052\n",
      "Epoch 12/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 22.8513 - mse: 1044.5610 - val_loss: 21.6687 - val_mse: 1067.9247\n",
      "Epoch 13/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 22.8345 - mse: 1034.0507 - val_loss: 20.5605 - val_mse: 920.5704\n",
      "Epoch 14/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 22.2840 - mse: 1004.6844 - val_loss: 20.5033 - val_mse: 930.0254\n",
      "Epoch 15/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.9284 - mse: 998.1897 - val_loss: 20.4061 - val_mse: 927.0396\n",
      "Epoch 16/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 22.2176 - mse: 1005.4858 - val_loss: 21.5149 - val_mse: 1070.0471\n",
      "Epoch 17/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 22.2096 - mse: 1000.5287 - val_loss: 27.7220 - val_mse: 1523.1100\n",
      "Epoch 18/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 23.9307 - mse: 1119.1011 - val_loss: 22.4220 - val_mse: 879.8121\n",
      "Epoch 19/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 22.9563 - mse: 1066.2859 - val_loss: 21.1910 - val_mse: 1038.8167\n",
      "Epoch 20/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 22.2569 - mse: 1011.7959 - val_loss: 21.8193 - val_mse: 1096.8555\n",
      "Epoch 21/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 22.5792 - mse: 1030.3759 - val_loss: 22.0690 - val_mse: 1117.1553\n",
      "Epoch 22/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 22.3862 - mse: 1012.3072 - val_loss: 20.2940 - val_mse: 908.2999\n",
      "Epoch 23/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.7211 - mse: 973.3084 - val_loss: 22.1168 - val_mse: 1121.5114\n",
      "Epoch 24/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 22.1068 - mse: 1003.8443 - val_loss: 24.7307 - val_mse: 1311.1428\n",
      "Epoch 25/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 22.0918 - mse: 990.9971 - val_loss: 20.2570 - val_mse: 914.9250\n",
      "Epoch 26/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 22.1411 - mse: 1001.7988 - val_loss: 20.7395 - val_mse: 856.6340\n",
      "Epoch 27/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 22.3948 - mse: 1008.5953 - val_loss: 27.7770 - val_mse: 1520.1885\n",
      "Epoch 28/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 22.4523 - mse: 1031.9922 - val_loss: 21.0367 - val_mse: 1027.8783\n",
      "Epoch 29/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 22.1467 - mse: 1015.9626 - val_loss: 23.4399 - val_mse: 1219.0125\n",
      "Epoch 30/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.8268 - mse: 969.2988 - val_loss: 20.3489 - val_mse: 883.0450\n",
      "Epoch 31/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 22.0180 - mse: 977.8666 - val_loss: 20.2471 - val_mse: 903.3328\n",
      "Epoch 32/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.9285 - mse: 978.4658 - val_loss: 22.8264 - val_mse: 1173.9022\n",
      "Epoch 33/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.8756 - mse: 985.0261 - val_loss: 21.1900 - val_mse: 1034.9055\n",
      "Epoch 34/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.5716 - mse: 955.6060 - val_loss: 20.8737 - val_mse: 1003.7671\n",
      "Epoch 35/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.9600 - mse: 988.5052 - val_loss: 21.7555 - val_mse: 854.9185\n",
      "Epoch 36/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 22.1391 - mse: 994.2412 - val_loss: 20.3110 - val_mse: 941.3654\n",
      "Epoch 37/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 22.2269 - mse: 997.2899 - val_loss: 21.0890 - val_mse: 1032.3345\n",
      "Epoch 38/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.6642 - mse: 966.2136 - val_loss: 22.9595 - val_mse: 1183.9872\n",
      "Epoch 39/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 22.0725 - mse: 998.1552 - val_loss: 21.1137 - val_mse: 847.7460\n",
      "Epoch 40/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 22.2801 - mse: 987.2172 - val_loss: 20.4125 - val_mse: 952.9055\n",
      "Epoch 41/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.6201 - mse: 965.0751 - val_loss: 20.2300 - val_mse: 927.4996\n",
      "Epoch 42/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.4339 - mse: 955.1108 - val_loss: 20.3310 - val_mse: 943.4615\n",
      "Epoch 43/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.9152 - mse: 985.9299 - val_loss: 23.3518 - val_mse: 1209.9279\n",
      "Epoch 44/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.6590 - mse: 968.0079 - val_loss: 22.3698 - val_mse: 1136.8135\n",
      "Epoch 45/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.8164 - mse: 985.1622 - val_loss: 20.2019 - val_mse: 888.6241\n",
      "Epoch 46/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.9556 - mse: 998.5759 - val_loss: 20.7112 - val_mse: 987.1503\n",
      "Epoch 47/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.6796 - mse: 963.8096 - val_loss: 21.0275 - val_mse: 1025.1826\n",
      "Epoch 48/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.7845 - mse: 975.3381 - val_loss: 24.4729 - val_mse: 1287.1744\n",
      "Epoch 49/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 22.0526 - mse: 997.5755 - val_loss: 20.4994 - val_mse: 970.7792\n",
      "Epoch 50/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 22.1045 - mse: 985.3954 - val_loss: 20.6499 - val_mse: 988.0407\n",
      "Epoch 51/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.9639 - mse: 980.5190 - val_loss: 21.0780 - val_mse: 1030.0685\n",
      "Epoch 52/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 22.1615 - mse: 1002.1609 - val_loss: 20.7078 - val_mse: 992.6578\n",
      "Epoch 53/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.8283 - mse: 979.0298 - val_loss: 21.3618 - val_mse: 1054.9426\n",
      "Epoch 54/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.9635 - mse: 976.8209 - val_loss: 20.3714 - val_mse: 864.7545\n",
      "Epoch 55/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 22.2554 - mse: 1002.7394 - val_loss: 20.1943 - val_mse: 895.8677\n",
      "Epoch 56/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.5726 - mse: 977.2235 - val_loss: 20.9926 - val_mse: 1017.1734\n",
      "Epoch 57/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.6331 - mse: 973.7055 - val_loss: 20.2576 - val_mse: 938.7275\n",
      "Epoch 58/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.8674 - mse: 966.1682 - val_loss: 22.6597 - val_mse: 1159.3394\n",
      "Epoch 59/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.8638 - mse: 981.3312 - val_loss: 20.6475 - val_mse: 988.4585\n",
      "Epoch 60/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.6081 - mse: 966.2051 - val_loss: 21.6307 - val_mse: 1077.9257\n",
      "Epoch 61/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.6133 - mse: 959.3115 - val_loss: 21.8898 - val_mse: 1098.5167\n",
      "Epoch 62/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.9899 - mse: 982.8431 - val_loss: 23.6299 - val_mse: 1229.1327\n",
      "Epoch 63/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.7530 - mse: 978.7323 - val_loss: 20.3109 - val_mse: 868.7327\n",
      "Epoch 64/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.5388 - mse: 951.6338 - val_loss: 21.8553 - val_mse: 1097.3163\n",
      "Epoch 65/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.6888 - mse: 971.0757 - val_loss: 20.8043 - val_mse: 1003.4503\n",
      "Epoch 66/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.5345 - mse: 950.7406 - val_loss: 20.6809 - val_mse: 990.8941\n",
      "Epoch 67/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.4771 - mse: 964.2770 - val_loss: 21.4676 - val_mse: 1065.1583\n",
      "Epoch 68/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.5543 - mse: 974.2722 - val_loss: 22.4406 - val_mse: 1140.3929\n",
      "Epoch 69/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3769 - mse: 944.9694 - val_loss: 21.7258 - val_mse: 1084.1927\n",
      "Epoch 70/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.5101 - mse: 971.7300 - val_loss: 22.2621 - val_mse: 1127.9586\n",
      "Epoch 71/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.4081 - mse: 947.1732 - val_loss: 24.2231 - val_mse: 1268.7096\n",
      "Epoch 72/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 22.2051 - mse: 1010.0150 - val_loss: 24.8593 - val_mse: 1312.2719\n",
      "Epoch 73/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.4469 - mse: 951.8126 - val_loss: 24.3142 - val_mse: 1274.7878\n",
      "Epoch 74/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.8043 - mse: 984.3810 - val_loss: 21.5892 - val_mse: 1074.9670\n",
      "Epoch 75/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.6779 - mse: 972.4428 - val_loss: 20.8285 - val_mse: 1004.6289\n",
      "Epoch 76/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.6679 - mse: 967.0574 - val_loss: 20.0974 - val_mse: 886.5671\n",
      "Epoch 77/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 22.0583 - mse: 994.0889 - val_loss: 23.8404 - val_mse: 1242.8701\n",
      "Epoch 78/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.8013 - mse: 974.5565 - val_loss: 20.6867 - val_mse: 992.5838\n",
      "Epoch 79/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.5897 - mse: 961.6684 - val_loss: 20.5257 - val_mse: 974.8515\n",
      "Epoch 80/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 22.2999 - mse: 1011.5388 - val_loss: 20.1397 - val_mse: 883.5128\n",
      "Epoch 81/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.7741 - mse: 959.6145 - val_loss: 22.7952 - val_mse: 1168.0421\n",
      "Epoch 82/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.9271 - mse: 991.3243 - val_loss: 21.5936 - val_mse: 1074.6133\n",
      "Epoch 83/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 22.1515 - mse: 1004.5595 - val_loss: 24.6348 - val_mse: 1296.8665\n",
      "Epoch 84/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2719 - mse: 956.0574 - val_loss: 20.7914 - val_mse: 1002.2638\n",
      "Epoch 85/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 22.1815 - mse: 1018.7105 - val_loss: 21.4842 - val_mse: 1065.6532\n",
      "Epoch 86/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.4838 - mse: 947.7938 - val_loss: 21.4774 - val_mse: 1064.1719\n",
      "Epoch 87/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.8513 - mse: 982.4282 - val_loss: 20.1499 - val_mse: 926.7531\n",
      "Epoch 88/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2803 - mse: 959.1635 - val_loss: 21.0902 - val_mse: 1029.8937\n",
      "Epoch 89/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.4901 - mse: 961.6946 - val_loss: 22.0177 - val_mse: 1109.5873\n",
      "Epoch 90/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3629 - mse: 958.5301 - val_loss: 20.7496 - val_mse: 998.9473\n",
      "Epoch 91/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.4243 - mse: 962.9553 - val_loss: 20.1958 - val_mse: 936.8406\n",
      "Epoch 92/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.8054 - mse: 965.2460 - val_loss: 21.5178 - val_mse: 1064.6927\n",
      "Epoch 93/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.6855 - mse: 983.5693 - val_loss: 20.5048 - val_mse: 974.5383\n",
      "Epoch 94/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.5506 - mse: 957.1173 - val_loss: 20.2386 - val_mse: 942.3510\n",
      "Epoch 95/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.4289 - mse: 949.2889 - val_loss: 21.0639 - val_mse: 1028.4586\n",
      "Epoch 96/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1611 - mse: 924.5143 - val_loss: 20.0965 - val_mse: 912.0931\n",
      "Epoch 97/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.4020 - mse: 945.1574 - val_loss: 20.0538 - val_mse: 900.8127\n",
      "Epoch 98/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.4180 - mse: 936.2913 - val_loss: 22.4010 - val_mse: 1137.7006\n",
      "Epoch 99/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.4821 - mse: 953.1678 - val_loss: 24.5549 - val_mse: 1285.4722\n",
      "Epoch 100/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.4527 - mse: 949.2702 - val_loss: 22.1375 - val_mse: 1116.1968\n",
      "Epoch 101/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.6335 - mse: 963.5286 - val_loss: 23.5837 - val_mse: 1220.2754\n",
      "Epoch 102/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0829 - mse: 932.9736 - val_loss: 21.1427 - val_mse: 1034.3217\n",
      "Epoch 103/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 22.3972 - mse: 1011.5897 - val_loss: 20.3144 - val_mse: 956.1148\n",
      "Epoch 104/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 22.1718 - mse: 993.9017 - val_loss: 21.2712 - val_mse: 1047.3224\n",
      "Epoch 105/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.5266 - mse: 974.2389 - val_loss: 20.5002 - val_mse: 974.5716\n",
      "Epoch 106/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.5563 - mse: 960.7394 - val_loss: 21.3822 - val_mse: 1055.9274\n",
      "Epoch 107/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.6951 - mse: 956.3143 - val_loss: 21.4259 - val_mse: 1060.1158\n",
      "Epoch 108/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.5693 - mse: 961.7062 - val_loss: 20.6102 - val_mse: 984.7429\n",
      "Epoch 109/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0503 - mse: 920.8905 - val_loss: 24.1942 - val_mse: 1261.4263\n",
      "Epoch 110/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.6951 - mse: 970.9249 - val_loss: 22.7444 - val_mse: 1160.6893\n",
      "Epoch 111/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3180 - mse: 926.1776 - val_loss: 21.4570 - val_mse: 1062.3257\n",
      "Epoch 112/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.4461 - mse: 952.4200 - val_loss: 26.4116 - val_mse: 1412.0919\n",
      "Epoch 113/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.4151 - mse: 957.5910 - val_loss: 20.3229 - val_mse: 956.0031\n",
      "Epoch 114/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.6804 - mse: 959.6039 - val_loss: 24.1250 - val_mse: 1259.9392\n",
      "Epoch 115/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.6088 - mse: 961.1841 - val_loss: 20.9325 - val_mse: 1016.5557\n",
      "Epoch 116/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.6687 - mse: 983.5701 - val_loss: 20.7201 - val_mse: 996.2169\n",
      "Epoch 117/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2052 - mse: 912.6339 - val_loss: 23.3650 - val_mse: 1205.3478\n",
      "Epoch 118/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.7258 - mse: 956.7325 - val_loss: 26.0633 - val_mse: 1390.5865\n",
      "Epoch 119/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2689 - mse: 952.6014 - val_loss: 22.0898 - val_mse: 1112.5011\n",
      "Epoch 120/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2186 - mse: 939.3650 - val_loss: 21.0747 - val_mse: 1026.9888\n",
      "Epoch 121/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2564 - mse: 944.4815 - val_loss: 23.7232 - val_mse: 1227.1597\n",
      "Epoch 122/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.6687 - mse: 972.0048 - val_loss: 24.4050 - val_mse: 1276.5663\n",
      "Epoch 123/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.4004 - mse: 945.9990 - val_loss: 22.6412 - val_mse: 1154.2979\n",
      "Epoch 124/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1850 - mse: 938.8268 - val_loss: 20.8430 - val_mse: 1007.6805\n",
      "Epoch 125/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.5325 - mse: 964.0084 - val_loss: 20.5260 - val_mse: 976.8939\n",
      "Epoch 126/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3960 - mse: 945.1734 - val_loss: 23.1201 - val_mse: 1184.4652\n",
      "Epoch 127/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.4342 - mse: 950.4005 - val_loss: 20.0743 - val_mse: 913.4479\n",
      "Epoch 128/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.3099 - mse: 942.4257 - val_loss: 20.1711 - val_mse: 936.7210\n",
      "Epoch 129/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.7487 - mse: 968.0688 - val_loss: 21.4127 - val_mse: 1059.6115\n",
      "Epoch 130/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.7085 - mse: 961.0316 - val_loss: 21.1199 - val_mse: 1032.2772\n",
      "Epoch 131/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0495 - mse: 938.4991 - val_loss: 22.9941 - val_mse: 1175.1899\n",
      "Epoch 132/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 22.1820 - mse: 978.1479 - val_loss: 25.8583 - val_mse: 1376.9623\n",
      "Epoch 133/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.6123 - mse: 944.6678 - val_loss: 27.0508 - val_mse: 1457.0981\n",
      "Epoch 134/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.6493 - mse: 960.2154 - val_loss: 22.0272 - val_mse: 1107.4615\n",
      "Epoch 135/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2164 - mse: 938.4672 - val_loss: 23.0938 - val_mse: 1184.1654\n",
      "Epoch 136/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0927 - mse: 932.0706 - val_loss: 22.9204 - val_mse: 1171.1735\n",
      "Epoch 137/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.4017 - mse: 961.7955 - val_loss: 21.0198 - val_mse: 1023.3762\n",
      "Epoch 138/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.1155 - mse: 932.9008 - val_loss: 20.7095 - val_mse: 994.1927\n",
      "Epoch 139/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0933 - mse: 928.5071 - val_loss: 19.9067 - val_mse: 867.6721\n",
      "Epoch 140/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.3651 - mse: 942.3118 - val_loss: 21.8070 - val_mse: 1088.8945\n",
      "Epoch 141/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 22.0610 - mse: 991.6842 - val_loss: 19.9757 - val_mse: 908.4042\n",
      "Epoch 142/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.9249 - mse: 975.9989 - val_loss: 24.5867 - val_mse: 1289.3118\n",
      "Epoch 143/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 21.4375 - mse: 948.9228 - val_loss: 23.7700 - val_mse: 1230.1923\n",
      "Epoch 144/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9298 - mse: 922.0054 - val_loss: 21.0810 - val_mse: 1026.5005\n",
      "Epoch 145/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1839 - mse: 927.0391 - val_loss: 21.3782 - val_mse: 1050.7839\n",
      "Epoch 146/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.6125 - mse: 962.8881 - val_loss: 23.9605 - val_mse: 1244.2605\n",
      "Epoch 147/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.6335 - mse: 952.7766 - val_loss: 26.4289 - val_mse: 1412.1818\n",
      "Epoch 148/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2937 - mse: 953.2184 - val_loss: 20.6437 - val_mse: 988.4021\n",
      "Epoch 149/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0681 - mse: 929.8538 - val_loss: 20.9046 - val_mse: 1013.4792\n",
      "Epoch 150/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0711 - mse: 928.5934 - val_loss: 22.9043 - val_mse: 1167.8256\n",
      "Epoch 151/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2669 - mse: 936.4203 - val_loss: 21.7632 - val_mse: 1086.1954\n",
      "Epoch 152/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.4376 - mse: 947.3947 - val_loss: 21.5902 - val_mse: 1070.8718\n",
      "Epoch 153/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.2612 - mse: 944.1418 - val_loss: 21.8404 - val_mse: 1090.9452\n",
      "Epoch 154/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3574 - mse: 947.0074 - val_loss: 20.3503 - val_mse: 959.3360\n",
      "Epoch 155/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.4538 - mse: 947.1815 - val_loss: 24.3970 - val_mse: 1273.6028\n",
      "Epoch 156/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2678 - mse: 941.7566 - val_loss: 24.8250 - val_mse: 1301.1752\n",
      "Epoch 157/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1617 - mse: 935.6680 - val_loss: 20.2900 - val_mse: 954.5787\n",
      "Epoch 158/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3506 - mse: 951.6947 - val_loss: 26.8146 - val_mse: 1436.1565\n",
      "Epoch 159/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.6257 - mse: 969.6820 - val_loss: 21.6725 - val_mse: 1078.7308\n",
      "Epoch 160/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.9188 - mse: 926.2120 - val_loss: 21.5205 - val_mse: 1064.9360\n",
      "Epoch 161/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.6850 - mse: 958.5443 - val_loss: 20.3983 - val_mse: 966.5062\n",
      "Epoch 162/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1340 - mse: 932.6432 - val_loss: 24.0074 - val_mse: 1246.1843\n",
      "Epoch 163/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2698 - mse: 956.5422 - val_loss: 23.7214 - val_mse: 1223.4907\n",
      "Epoch 164/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2342 - mse: 930.0386 - val_loss: 20.8981 - val_mse: 1013.9696\n",
      "Epoch 165/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.3399 - mse: 954.1602 - val_loss: 24.7427 - val_mse: 1293.1481\n",
      "Epoch 166/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2880 - mse: 941.2568 - val_loss: 20.4199 - val_mse: 967.9885\n",
      "Epoch 167/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0589 - mse: 929.7030 - val_loss: 20.1730 - val_mse: 941.7346\n",
      "Epoch 168/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1780 - mse: 935.6169 - val_loss: 20.8864 - val_mse: 1008.3989\n",
      "Epoch 169/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.9864 - mse: 920.1929 - val_loss: 23.7882 - val_mse: 1227.0029\n",
      "Epoch 170/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.8762 - mse: 975.4294 - val_loss: 27.9393 - val_mse: 1515.6863\n",
      "Epoch 171/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.9280 - mse: 986.7068 - val_loss: 20.6064 - val_mse: 986.3533\n",
      "Epoch 172/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1584 - mse: 938.6551 - val_loss: 22.8534 - val_mse: 1163.2578\n",
      "Epoch 173/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2965 - mse: 931.4246 - val_loss: 27.8538 - val_mse: 1510.7769\n",
      "Epoch 174/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2614 - mse: 947.7790 - val_loss: 20.8718 - val_mse: 1007.9952\n",
      "Epoch 175/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.4992 - mse: 960.8914 - val_loss: 22.5594 - val_mse: 1147.1409\n",
      "Epoch 176/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1697 - mse: 944.2356 - val_loss: 23.3016 - val_mse: 1198.1952\n",
      "Epoch 177/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2734 - mse: 947.3414 - val_loss: 20.7901 - val_mse: 1001.6881\n",
      "Epoch 178/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1754 - mse: 940.4397 - val_loss: 22.5555 - val_mse: 1142.7399\n",
      "Epoch 179/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0903 - mse: 926.5445 - val_loss: 20.5127 - val_mse: 973.5004\n",
      "Epoch 180/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0821 - mse: 918.9927 - val_loss: 23.9838 - val_mse: 1239.5156\n",
      "Epoch 181/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.8784 - mse: 917.5208 - val_loss: 21.5188 - val_mse: 1064.3346\n",
      "Epoch 182/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.9453 - mse: 920.6473 - val_loss: 20.0966 - val_mse: 930.9529\n",
      "Epoch 183/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.3297 - mse: 940.1368 - val_loss: 21.7487 - val_mse: 1076.6321\n",
      "Epoch 184/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2466 - mse: 941.9847 - val_loss: 21.6795 - val_mse: 1077.7432\n",
      "Epoch 185/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0894 - mse: 931.2947 - val_loss: 22.6055 - val_mse: 1143.1453\n",
      "Epoch 186/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1697 - mse: 939.2471 - val_loss: 22.1485 - val_mse: 1112.5690\n",
      "Epoch 187/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1606 - mse: 928.5329 - val_loss: 21.3261 - val_mse: 1051.1296\n",
      "Epoch 188/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2614 - mse: 938.6946 - val_loss: 23.4403 - val_mse: 1203.3848\n",
      "Epoch 189/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2387 - mse: 930.6855 - val_loss: 22.6387 - val_mse: 1146.7454\n",
      "Epoch 190/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9060 - mse: 921.0178 - val_loss: 20.2644 - val_mse: 955.2653\n",
      "Epoch 191/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0048 - mse: 924.0618 - val_loss: 20.0418 - val_mse: 928.9008\n",
      "Epoch 192/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2867 - mse: 930.6902 - val_loss: 23.6963 - val_mse: 1219.4417\n",
      "Epoch 193/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2769 - mse: 935.4714 - val_loss: 24.4372 - val_mse: 1272.4232\n",
      "Epoch 194/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.5185 - mse: 956.1315 - val_loss: 22.5799 - val_mse: 1142.8793\n",
      "Epoch 195/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.4120 - mse: 954.2419 - val_loss: 22.8538 - val_mse: 1162.7644\n",
      "Epoch 196/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1677 - mse: 937.9693 - val_loss: 24.1816 - val_mse: 1261.0360\n",
      "Epoch 197/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0833 - mse: 932.6545 - val_loss: 21.1569 - val_mse: 1033.4490\n",
      "Epoch 198/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.7511 - mse: 976.9536 - val_loss: 26.2196 - val_mse: 1387.4297\n",
      "Epoch 199/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.5140 - mse: 954.9756 - val_loss: 23.1430 - val_mse: 1185.3048\n",
      "Epoch 200/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.8444 - mse: 911.7827 - val_loss: 24.1940 - val_mse: 1259.0868\n",
      "Epoch 201/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.3592 - mse: 948.2719 - val_loss: 21.9152 - val_mse: 1095.0574\n",
      "Epoch 202/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1264 - mse: 919.5988 - val_loss: 24.3682 - val_mse: 1264.1208\n",
      "Epoch 203/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1602 - mse: 938.9224 - val_loss: 21.9658 - val_mse: 1098.9691\n",
      "Epoch 204/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2096 - mse: 936.2646 - val_loss: 20.7939 - val_mse: 1004.4498\n",
      "Epoch 205/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.7098 - mse: 983.6937 - val_loss: 23.9820 - val_mse: 1240.8566\n",
      "Epoch 206/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1547 - mse: 939.7271 - val_loss: 20.5604 - val_mse: 983.4028\n",
      "Epoch 207/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.4021 - mse: 943.1517 - val_loss: 21.7565 - val_mse: 1082.9171\n",
      "Epoch 208/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.4452 - mse: 962.6985 - val_loss: 23.1403 - val_mse: 1184.7626\n",
      "Epoch 209/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.5519 - mse: 960.4341 - val_loss: 23.1349 - val_mse: 1186.6901\n",
      "Epoch 210/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.9421 - mse: 917.2546 - val_loss: 23.1951 - val_mse: 1186.7555\n",
      "Epoch 211/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0329 - mse: 927.6682 - val_loss: 22.8194 - val_mse: 1156.3634\n",
      "Epoch 212/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9475 - mse: 913.8354 - val_loss: 25.9426 - val_mse: 1369.6182\n",
      "Epoch 213/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1869 - mse: 938.6490 - val_loss: 22.0922 - val_mse: 1108.3081\n",
      "Epoch 214/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.6478 - mse: 898.0635 - val_loss: 22.0074 - val_mse: 1099.8445\n",
      "Epoch 215/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.9213 - mse: 915.2610 - val_loss: 21.7412 - val_mse: 1084.0660\n",
      "Epoch 216/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.7430 - mse: 906.2419 - val_loss: 20.5882 - val_mse: 980.9015\n",
      "Epoch 217/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.5295 - mse: 967.9865 - val_loss: 21.4639 - val_mse: 1059.8855\n",
      "Epoch 218/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.8369 - mse: 989.1029 - val_loss: 21.5242 - val_mse: 1066.8314\n",
      "Epoch 219/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0845 - mse: 934.7156 - val_loss: 20.0290 - val_mse: 930.6669\n",
      "Epoch 220/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1198 - mse: 914.9408 - val_loss: 26.0208 - val_mse: 1376.3245\n",
      "Epoch 221/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.7893 - mse: 979.4429 - val_loss: 21.2885 - val_mse: 1049.8093\n",
      "Epoch 222/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9837 - mse: 914.5205 - val_loss: 24.7810 - val_mse: 1296.0431\n",
      "Epoch 223/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3689 - mse: 950.7559 - val_loss: 20.5363 - val_mse: 980.4962\n",
      "Epoch 224/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.3236 - mse: 944.7254 - val_loss: 23.2511 - val_mse: 1191.0385\n",
      "Epoch 225/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.8198 - mse: 904.3731 - val_loss: 22.4128 - val_mse: 1131.7151\n",
      "Epoch 226/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0966 - mse: 928.6130 - val_loss: 20.5920 - val_mse: 984.1837\n",
      "Epoch 227/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1497 - mse: 937.4039 - val_loss: 25.2575 - val_mse: 1323.4050\n",
      "Epoch 228/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1838 - mse: 923.0686 - val_loss: 24.8010 - val_mse: 1293.7593\n",
      "Epoch 229/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0814 - mse: 935.0165 - val_loss: 22.3091 - val_mse: 1123.2400\n",
      "Epoch 230/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2740 - mse: 928.2442 - val_loss: 27.9200 - val_mse: 1510.0422\n",
      "Epoch 231/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.4210 - mse: 967.7761 - val_loss: 20.0372 - val_mse: 932.3417\n",
      "Epoch 232/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1433 - mse: 930.5622 - val_loss: 20.1940 - val_mse: 949.8152\n",
      "Epoch 233/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.9021 - mse: 910.5928 - val_loss: 22.3857 - val_mse: 1129.0760\n",
      "Epoch 234/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1248 - mse: 931.7935 - val_loss: 23.5406 - val_mse: 1207.7197\n",
      "Epoch 235/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1014 - mse: 929.6350 - val_loss: 20.4004 - val_mse: 968.5161\n",
      "Epoch 236/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.7379 - mse: 921.9318 - val_loss: 20.1693 - val_mse: 947.5077\n",
      "Epoch 237/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0285 - mse: 923.2463 - val_loss: 24.5478 - val_mse: 1277.5255\n",
      "Epoch 238/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.7156 - mse: 965.0008 - val_loss: 20.8405 - val_mse: 1011.7881\n",
      "Epoch 239/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1794 - mse: 929.1248 - val_loss: 21.4225 - val_mse: 1059.7185\n",
      "Epoch 240/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.9405 - mse: 894.6090 - val_loss: 25.5827 - val_mse: 1347.8208\n",
      "Epoch 241/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.8492 - mse: 924.6553 - val_loss: 19.9228 - val_mse: 918.5604\n",
      "Epoch 242/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1537 - mse: 916.7331 - val_loss: 22.1215 - val_mse: 1109.7368\n",
      "Epoch 243/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0049 - mse: 911.5742 - val_loss: 22.8281 - val_mse: 1162.4552\n",
      "Epoch 244/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.7597 - mse: 909.3339 - val_loss: 22.2007 - val_mse: 1111.8904\n",
      "Epoch 245/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.6813 - mse: 901.6828 - val_loss: 24.4462 - val_mse: 1268.2848\n",
      "Epoch 246/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1802 - mse: 936.4742 - val_loss: 24.0389 - val_mse: 1237.3134\n",
      "Epoch 247/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.3101 - mse: 931.6310 - val_loss: 24.8712 - val_mse: 1300.7332\n",
      "Epoch 248/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9376 - mse: 925.5566 - val_loss: 20.3052 - val_mse: 959.2755\n",
      "Epoch 249/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9049 - mse: 916.2280 - val_loss: 19.8857 - val_mse: 918.0985\n",
      "Epoch 250/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0929 - mse: 926.2993 - val_loss: 22.0111 - val_mse: 1103.8048\n",
      "Epoch 251/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0991 - mse: 927.2028 - val_loss: 21.8578 - val_mse: 1086.0177\n",
      "Epoch 252/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.6892 - mse: 902.5204 - val_loss: 21.5937 - val_mse: 1060.9584\n",
      "Epoch 253/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1641 - mse: 925.5580 - val_loss: 23.9169 - val_mse: 1229.1864\n",
      "Epoch 254/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.8035 - mse: 909.2621 - val_loss: 21.8686 - val_mse: 1081.5358\n",
      "Epoch 255/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.9132 - mse: 915.4521 - val_loss: 23.5237 - val_mse: 1203.2528\n",
      "Epoch 256/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2344 - mse: 929.0117 - val_loss: 27.5184 - val_mse: 1478.4447\n",
      "Epoch 257/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0997 - mse: 938.8387 - val_loss: 21.5212 - val_mse: 1064.1158\n",
      "Epoch 258/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.5073 - mse: 953.4957 - val_loss: 22.0128 - val_mse: 1103.3489\n",
      "Epoch 259/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0301 - mse: 925.2811 - val_loss: 24.1290 - val_mse: 1249.7242\n",
      "Epoch 260/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.4569 - mse: 943.0358 - val_loss: 24.3480 - val_mse: 1261.4249\n",
      "Epoch 261/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1946 - mse: 947.1652 - val_loss: 21.5935 - val_mse: 1070.7935\n",
      "Epoch 262/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.6910 - mse: 899.6619 - val_loss: 21.7635 - val_mse: 1083.1763\n",
      "Epoch 263/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0822 - mse: 914.9710 - val_loss: 21.2668 - val_mse: 1044.9053\n",
      "Epoch 264/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.8114 - mse: 911.9186 - val_loss: 20.4568 - val_mse: 976.5212\n",
      "Epoch 265/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1600 - mse: 921.5759 - val_loss: 22.3057 - val_mse: 1120.7866\n",
      "Epoch 266/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.7117 - mse: 910.9263 - val_loss: 20.4292 - val_mse: 968.6279\n",
      "Epoch 267/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9581 - mse: 932.4767 - val_loss: 19.7324 - val_mse: 899.9946\n",
      "Epoch 268/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.3522 - mse: 957.0322 - val_loss: 21.1745 - val_mse: 1037.1194\n",
      "Epoch 269/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.8736 - mse: 918.1123 - val_loss: 21.8297 - val_mse: 1089.2976\n",
      "Epoch 270/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0140 - mse: 926.6110 - val_loss: 23.2256 - val_mse: 1188.4303\n",
      "Epoch 271/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.8310 - mse: 910.9478 - val_loss: 22.6358 - val_mse: 1143.6072\n",
      "Epoch 272/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.4320 - mse: 951.1327 - val_loss: 22.0382 - val_mse: 1103.3470\n",
      "Epoch 273/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9975 - mse: 922.0903 - val_loss: 21.9474 - val_mse: 1096.9178\n",
      "Epoch 274/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1046 - mse: 919.3560 - val_loss: 22.3245 - val_mse: 1120.6990\n",
      "Epoch 275/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1005 - mse: 936.9026 - val_loss: 19.5505 - val_mse: 852.8056\n",
      "Epoch 276/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1314 - mse: 937.7026 - val_loss: 20.4412 - val_mse: 975.6262\n",
      "Epoch 277/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.9605 - mse: 903.1410 - val_loss: 22.9717 - val_mse: 1170.4885\n",
      "Epoch 278/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.9452 - mse: 913.3566 - val_loss: 24.4842 - val_mse: 1266.5176\n",
      "Epoch 279/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1287 - mse: 920.5737 - val_loss: 21.4228 - val_mse: 1056.2311\n",
      "Epoch 280/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1322 - mse: 906.7260 - val_loss: 20.7043 - val_mse: 996.5791\n",
      "Epoch 281/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.4584 - mse: 954.7183 - val_loss: 22.8467 - val_mse: 1162.0671\n",
      "Epoch 282/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.6154 - mse: 957.5021 - val_loss: 24.4395 - val_mse: 1269.3732\n",
      "Epoch 283/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.8307 - mse: 916.4036 - val_loss: 20.3838 - val_mse: 965.3513\n",
      "Epoch 284/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.8178 - mse: 895.7727 - val_loss: 20.8332 - val_mse: 1009.0803\n",
      "Epoch 285/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0330 - mse: 921.7150 - val_loss: 25.9173 - val_mse: 1372.5254\n",
      "Epoch 286/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1162 - mse: 928.0873 - val_loss: 20.8057 - val_mse: 1009.9788\n",
      "Epoch 287/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.8173 - mse: 906.2734 - val_loss: 24.6505 - val_mse: 1274.2297\n",
      "Epoch 288/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9741 - mse: 914.2662 - val_loss: 21.9556 - val_mse: 1095.6626\n",
      "Epoch 289/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.7980 - mse: 899.9370 - val_loss: 19.5461 - val_mse: 875.1964\n",
      "Epoch 290/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.4241 - mse: 942.4311 - val_loss: 20.0841 - val_mse: 942.7177\n",
      "Epoch 291/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1970 - mse: 915.5305 - val_loss: 22.7319 - val_mse: 1152.4651\n",
      "Epoch 292/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9826 - mse: 926.6530 - val_loss: 24.7133 - val_mse: 1283.4476\n",
      "Epoch 293/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.8621 - mse: 914.4049 - val_loss: 21.2613 - val_mse: 1044.9561\n",
      "Epoch 294/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9503 - mse: 913.5689 - val_loss: 20.1014 - val_mse: 944.6381\n",
      "Epoch 295/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.3940 - mse: 953.4274 - val_loss: 22.9432 - val_mse: 1171.1653\n",
      "Epoch 296/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2587 - mse: 938.5770 - val_loss: 20.2151 - val_mse: 954.8572\n",
      "Epoch 297/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3529 - mse: 946.7849 - val_loss: 21.8807 - val_mse: 1094.2444\n",
      "Epoch 298/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.5420 - mse: 906.3905 - val_loss: 23.6591 - val_mse: 1209.5466\n",
      "Epoch 299/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.9468 - mse: 911.7122 - val_loss: 24.2983 - val_mse: 1254.6649\n",
      "Epoch 300/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2659 - mse: 925.9461 - val_loss: 21.6403 - val_mse: 1072.9056\n",
      "Epoch 301/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.8691 - mse: 892.7222 - val_loss: 26.9474 - val_mse: 1436.7032\n",
      "Epoch 302/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2456 - mse: 933.6382 - val_loss: 24.2196 - val_mse: 1256.2433\n",
      "Epoch 303/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2017 - mse: 931.5530 - val_loss: 22.7910 - val_mse: 1156.4012\n",
      "Epoch 304/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2281 - mse: 942.2244 - val_loss: 19.7365 - val_mse: 904.6024\n",
      "Epoch 305/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3571 - mse: 937.2836 - val_loss: 25.1831 - val_mse: 1318.0497\n",
      "Epoch 306/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.8920 - mse: 921.8273 - val_loss: 22.4457 - val_mse: 1132.6190\n",
      "Epoch 307/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.6226 - mse: 894.1957 - val_loss: 22.8005 - val_mse: 1156.2546\n",
      "Epoch 308/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.3052 - mse: 951.6761 - val_loss: 20.9865 - val_mse: 1025.6099\n",
      "Epoch 309/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.5335 - mse: 895.8549 - val_loss: 24.8225 - val_mse: 1292.3781\n",
      "Epoch 310/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.7814 - mse: 948.9980 - val_loss: 20.1003 - val_mse: 940.3010\n",
      "Epoch 311/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1458 - mse: 935.1671 - val_loss: 21.4047 - val_mse: 1056.9987\n",
      "Epoch 312/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.6969 - mse: 896.0687 - val_loss: 27.7523 - val_mse: 1497.3027\n",
      "Epoch 313/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1168 - mse: 937.5319 - val_loss: 22.7138 - val_mse: 1150.9019\n",
      "Epoch 314/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.4241 - mse: 900.0593 - val_loss: 25.0866 - val_mse: 1306.6055\n",
      "Epoch 315/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.6453 - mse: 969.6671 - val_loss: 23.9571 - val_mse: 1238.8398\n",
      "Epoch 316/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9624 - mse: 918.2560 - val_loss: 24.8359 - val_mse: 1295.0167\n",
      "Epoch 317/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9335 - mse: 908.2496 - val_loss: 23.5087 - val_mse: 1201.8903\n",
      "Epoch 318/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.7104 - mse: 903.9649 - val_loss: 22.2017 - val_mse: 1114.0613\n",
      "Epoch 319/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.8062 - mse: 897.3541 - val_loss: 21.0386 - val_mse: 1029.4265\n",
      "Epoch 320/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.8580 - mse: 904.4670 - val_loss: 23.5173 - val_mse: 1203.7980\n",
      "Epoch 321/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9304 - mse: 905.9518 - val_loss: 24.0184 - val_mse: 1237.0472\n",
      "Epoch 322/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.7690 - mse: 913.3570 - val_loss: 26.2146 - val_mse: 1385.1405\n",
      "Epoch 323/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.8334 - mse: 916.9675 - val_loss: 24.2964 - val_mse: 1251.6874\n",
      "Epoch 324/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9149 - mse: 915.4689 - val_loss: 24.2945 - val_mse: 1257.7201\n",
      "Epoch 325/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.8038 - mse: 899.8087 - val_loss: 23.6498 - val_mse: 1214.2469\n",
      "Epoch 326/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9398 - mse: 914.7137 - val_loss: 24.3579 - val_mse: 1262.5497\n",
      "Epoch 327/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.6634 - mse: 958.7151 - val_loss: 20.4787 - val_mse: 981.0001\n",
      "Epoch 328/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0547 - mse: 920.8568 - val_loss: 23.9452 - val_mse: 1236.5861\n",
      "Epoch 329/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.5130 - mse: 893.0845 - val_loss: 26.8267 - val_mse: 1429.4888\n",
      "Epoch 330/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.6636 - mse: 886.2554 - val_loss: 23.2868 - val_mse: 1187.3562\n",
      "Epoch 331/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.9281 - mse: 916.8473 - val_loss: 20.9379 - val_mse: 1021.8530\n",
      "Epoch 332/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9202 - mse: 910.4426 - val_loss: 23.2935 - val_mse: 1188.5090\n",
      "Epoch 333/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.5863 - mse: 898.6734 - val_loss: 26.1752 - val_mse: 1378.6439\n",
      "Epoch 334/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.8919 - mse: 916.5009 - val_loss: 24.2121 - val_mse: 1246.4695\n",
      "Epoch 335/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.8059 - mse: 900.6371 - val_loss: 22.6552 - val_mse: 1139.4353\n",
      "Epoch 336/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.9219 - mse: 911.6005 - val_loss: 24.7568 - val_mse: 1282.4156\n",
      "Epoch 337/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.8853 - mse: 917.2737 - val_loss: 23.8729 - val_mse: 1225.7721\n",
      "Epoch 338/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2015 - mse: 925.1504 - val_loss: 22.8941 - val_mse: 1165.5996\n",
      "Epoch 339/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1032 - mse: 926.6052 - val_loss: 24.0132 - val_mse: 1239.1653\n",
      "Epoch 340/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.4166 - mse: 954.0638 - val_loss: 21.7802 - val_mse: 1087.5701\n",
      "Epoch 341/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2247 - mse: 941.1473 - val_loss: 26.1443 - val_mse: 1385.2561\n",
      "Epoch 342/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.3905 - mse: 960.3819 - val_loss: 30.4837 - val_mse: 1688.7191\n",
      "Epoch 343/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9077 - mse: 910.0878 - val_loss: 25.2147 - val_mse: 1319.8420\n",
      "Epoch 344/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.8398 - mse: 911.7139 - val_loss: 24.5603 - val_mse: 1276.5209\n",
      "Epoch 345/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.7964 - mse: 906.6004 - val_loss: 28.8342 - val_mse: 1561.3624\n",
      "Epoch 346/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.2265 - mse: 940.8401 - val_loss: 22.8961 - val_mse: 1162.9393\n",
      "Epoch 347/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.6972 - mse: 910.5413 - val_loss: 24.6198 - val_mse: 1280.5317\n",
      "Epoch 348/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.7111 - mse: 901.2307 - val_loss: 26.6756 - val_mse: 1418.0608\n",
      "Epoch 349/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.8868 - mse: 909.6870 - val_loss: 24.8051 - val_mse: 1290.3783\n",
      "Epoch 350/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1583 - mse: 943.3248 - val_loss: 24.5050 - val_mse: 1273.9967\n",
      "Epoch 351/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1008 - mse: 921.1229 - val_loss: 28.9199 - val_mse: 1579.0415\n",
      "Epoch 352/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.6023 - mse: 907.6530 - val_loss: 21.8818 - val_mse: 1093.4694\n",
      "Epoch 353/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.8799 - mse: 913.7499 - val_loss: 24.8987 - val_mse: 1309.4165\n",
      "Epoch 354/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8234 - mse: 915.6583 - val_loss: 22.6884 - val_mse: 1149.1263\n",
      "Epoch 355/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.6614 - mse: 905.3141 - val_loss: 23.1786 - val_mse: 1194.7301\n",
      "Epoch 356/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0683 - mse: 921.5839 - val_loss: 23.5775 - val_mse: 1206.9373\n",
      "Epoch 357/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.6298 - mse: 896.8295 - val_loss: 24.4332 - val_mse: 1264.3579\n",
      "Epoch 358/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.4878 - mse: 899.2853 - val_loss: 25.6639 - val_mse: 1354.3020\n",
      "Epoch 359/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0092 - mse: 915.9637 - val_loss: 25.8278 - val_mse: 1362.7709\n",
      "Epoch 360/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.3658 - mse: 936.6821 - val_loss: 25.1275 - val_mse: 1320.0789\n",
      "Epoch 361/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0029 - mse: 932.9284 - val_loss: 25.0067 - val_mse: 1309.2457\n",
      "Epoch 362/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.7254 - mse: 916.4218 - val_loss: 22.8415 - val_mse: 1169.6553\n",
      "Epoch 363/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9959 - mse: 932.8040 - val_loss: 22.5417 - val_mse: 1142.1403\n",
      "Epoch 364/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0808 - mse: 934.4205 - val_loss: 24.4704 - val_mse: 1279.7306\n",
      "Epoch 365/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9243 - mse: 915.4814 - val_loss: 25.8120 - val_mse: 1369.9978\n",
      "Epoch 366/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.6229 - mse: 896.8593 - val_loss: 24.6877 - val_mse: 1287.0658\n",
      "Epoch 367/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.9969 - mse: 919.6508 - val_loss: 25.8061 - val_mse: 1367.8097\n",
      "Epoch 368/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0065 - mse: 928.2143 - val_loss: 28.1116 - val_mse: 1525.3561\n",
      "Epoch 369/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2641 - mse: 942.7145 - val_loss: 26.4217 - val_mse: 1412.5643\n",
      "Epoch 370/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.8330 - mse: 928.4719 - val_loss: 23.7765 - val_mse: 1233.3766\n",
      "Epoch 371/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0735 - mse: 928.7690 - val_loss: 27.5802 - val_mse: 1489.2643\n",
      "Epoch 372/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.8266 - mse: 920.8950 - val_loss: 26.0479 - val_mse: 1385.7943\n",
      "Epoch 373/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.8985 - mse: 920.4249 - val_loss: 23.4325 - val_mse: 1208.5013\n",
      "Epoch 374/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0578 - mse: 937.2814 - val_loss: 25.2697 - val_mse: 1333.8352\n",
      "Epoch 375/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.9020 - mse: 919.7725 - val_loss: 26.9479 - val_mse: 1445.0022\n",
      "Epoch 376/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0696 - mse: 926.3942 - val_loss: 23.8502 - val_mse: 1235.5791\n",
      "Epoch 377/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.8654 - mse: 919.7673 - val_loss: 26.0102 - val_mse: 1381.0068\n",
      "Epoch 378/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.6871 - mse: 901.8770 - val_loss: 24.6948 - val_mse: 1296.1577\n",
      "Epoch 379/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.8468 - mse: 908.9969 - val_loss: 23.3259 - val_mse: 1196.5778\n",
      "Epoch 380/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.8654 - mse: 917.6027 - val_loss: 21.4865 - val_mse: 1065.2993\n",
      "Epoch 381/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.9056 - mse: 916.3901 - val_loss: 24.8095 - val_mse: 1295.6428\n",
      "Epoch 382/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.7884 - mse: 900.9750 - val_loss: 28.0551 - val_mse: 1522.0834\n",
      "Epoch 383/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.8666 - mse: 912.2231 - val_loss: 25.6614 - val_mse: 1353.4006\n",
      "Epoch 384/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.5575 - mse: 892.3702 - val_loss: 24.3664 - val_mse: 1268.2274\n",
      "Epoch 385/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.6353 - mse: 911.2059 - val_loss: 26.1858 - val_mse: 1389.9528\n",
      "Epoch 386/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.5785 - mse: 898.8137 - val_loss: 24.3966 - val_mse: 1264.5463\n",
      "Epoch 387/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.7751 - mse: 898.8099 - val_loss: 28.6627 - val_mse: 1558.5359\n",
      "Epoch 388/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.7566 - mse: 899.4975 - val_loss: 24.4660 - val_mse: 1277.4470\n",
      "Epoch 389/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.5415 - mse: 902.6311 - val_loss: 24.8314 - val_mse: 1300.2703\n",
      "Epoch 390/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.6427 - mse: 902.4105 - val_loss: 25.3146 - val_mse: 1347.3994\n",
      "Epoch 391/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.7995 - mse: 913.1899 - val_loss: 19.8497 - val_mse: 916.7514\n",
      "Epoch 392/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.7727 - mse: 901.2488 - val_loss: 20.6702 - val_mse: 1002.1171\n",
      "Epoch 393/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.7100 - mse: 898.4846 - val_loss: 23.6766 - val_mse: 1222.7869\n",
      "Epoch 394/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.3030 - mse: 938.6091 - val_loss: 25.9230 - val_mse: 1375.0801\n",
      "Epoch 395/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.5341 - mse: 890.6832 - val_loss: 22.8345 - val_mse: 1163.9924\n",
      "Epoch 396/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.5844 - mse: 898.6822 - val_loss: 22.0526 - val_mse: 1108.8577\n",
      "Epoch 397/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1741 - mse: 932.1268 - val_loss: 24.6613 - val_mse: 1288.2316\n",
      "Epoch 398/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.7387 - mse: 908.1640 - val_loss: 24.9456 - val_mse: 1306.7329\n",
      "Epoch 399/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.8529 - mse: 927.6360 - val_loss: 22.5130 - val_mse: 1143.6208\n",
      "Epoch 400/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.4042 - mse: 885.9614 - val_loss: 22.0221 - val_mse: 1106.5099\n",
      "Epoch 401/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.2777 - mse: 874.7246 - val_loss: 23.6979 - val_mse: 1221.1010\n",
      "Epoch 402/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.5841 - mse: 907.6106 - val_loss: 23.1148 - val_mse: 1181.7819\n",
      "Epoch 403/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.2615 - mse: 875.2254 - val_loss: 22.1045 - val_mse: 1107.6635\n",
      "Epoch 404/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.4374 - mse: 883.8195 - val_loss: 22.4562 - val_mse: 1130.5576\n",
      "Epoch 405/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.3937 - mse: 882.1934 - val_loss: 21.4674 - val_mse: 1061.9581\n",
      "Epoch 406/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.6363 - mse: 894.5934 - val_loss: 24.4837 - val_mse: 1270.6932\n",
      "Epoch 407/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.3709 - mse: 895.9691 - val_loss: 21.9189 - val_mse: 1096.7046\n",
      "Epoch 408/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.3082 - mse: 876.5785 - val_loss: 22.1709 - val_mse: 1115.2960\n",
      "Epoch 409/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.4390 - mse: 904.7341 - val_loss: 19.9064 - val_mse: 927.7621\n",
      "Epoch 410/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.7234 - mse: 900.5599 - val_loss: 21.3181 - val_mse: 1054.0973\n",
      "Epoch 411/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.3904 - mse: 873.2990 - val_loss: 22.0018 - val_mse: 1105.4657\n",
      "Epoch 412/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.7374 - mse: 915.4258 - val_loss: 23.0322 - val_mse: 1175.3282\n",
      "Epoch 413/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.8314 - mse: 927.6820 - val_loss: 20.8176 - val_mse: 1013.2671\n",
      "Epoch 414/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.5647 - mse: 898.9513 - val_loss: 21.4531 - val_mse: 1061.6654\n",
      "Epoch 415/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.4023 - mse: 889.6683 - val_loss: 21.5571 - val_mse: 1071.5089\n",
      "Epoch 416/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.2942 - mse: 877.3619 - val_loss: 22.4634 - val_mse: 1138.6837\n",
      "Epoch 417/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.4723 - mse: 884.8530 - val_loss: 22.2305 - val_mse: 1118.4670\n",
      "Epoch 418/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.3987 - mse: 888.1108 - val_loss: 22.6202 - val_mse: 1149.6676\n",
      "Epoch 419/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.6095 - mse: 912.3107 - val_loss: 20.5155 - val_mse: 988.0085\n",
      "Epoch 420/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.6691 - mse: 917.3821 - val_loss: 20.7607 - val_mse: 1008.3931\n",
      "Epoch 421/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.9303 - mse: 919.0342 - val_loss: 22.3550 - val_mse: 1130.8098\n",
      "Epoch 422/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.4835 - mse: 891.8479 - val_loss: 24.5037 - val_mse: 1295.7534\n",
      "Epoch 423/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.8910 - mse: 917.5114 - val_loss: 21.5591 - val_mse: 1078.1951\n",
      "Epoch 424/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.6170 - mse: 906.9987 - val_loss: 21.2185 - val_mse: 1049.1991\n",
      "Epoch 425/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.8305 - mse: 919.5853 - val_loss: 20.6496 - val_mse: 998.6518\n",
      "Epoch 426/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.6677 - mse: 902.8608 - val_loss: 21.0061 - val_mse: 1031.2562\n",
      "Epoch 427/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9239 - mse: 924.5388 - val_loss: 19.8583 - val_mse: 919.4248\n",
      "Epoch 428/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.5622 - mse: 917.5172 - val_loss: 19.6961 - val_mse: 879.9919\n",
      "Epoch 429/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9963 - mse: 915.3770 - val_loss: 20.5625 - val_mse: 990.2473\n",
      "Epoch 430/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.4228 - mse: 893.1110 - val_loss: 19.7395 - val_mse: 893.9691\n",
      "Epoch 431/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.2774 - mse: 889.9816 - val_loss: 20.0886 - val_mse: 944.0536\n",
      "Epoch 432/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.5849 - mse: 890.7599 - val_loss: 22.4425 - val_mse: 1138.2426\n",
      "Epoch 433/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.6692 - mse: 901.9904 - val_loss: 21.4634 - val_mse: 1067.9299\n",
      "Epoch 434/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.5707 - mse: 894.3868 - val_loss: 19.6094 - val_mse: 887.9231\n",
      "Epoch 435/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.2766 - mse: 872.7566 - val_loss: 21.2488 - val_mse: 1051.0994\n",
      "Epoch 436/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.3248 - mse: 885.4059 - val_loss: 20.0087 - val_mse: 936.4568\n",
      "Epoch 437/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.4317 - mse: 895.2894 - val_loss: 20.3526 - val_mse: 972.8968\n",
      "Epoch 438/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.9895 - mse: 927.2855 - val_loss: 20.5791 - val_mse: 946.5233\n",
      "Epoch 439/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2014 - mse: 949.1263 - val_loss: 20.6261 - val_mse: 961.7059\n",
      "Epoch 440/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1956 - mse: 953.9576 - val_loss: 20.5996 - val_mse: 954.4028\n",
      "Epoch 441/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.2140 - mse: 952.3733 - val_loss: 20.5665 - val_mse: 939.5598\n",
      "Epoch 442/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2801 - mse: 953.1680 - val_loss: 20.6218 - val_mse: 909.0585\n",
      "Epoch 443/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2339 - mse: 953.4825 - val_loss: 20.5816 - val_mse: 947.6244\n",
      "Epoch 444/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.2155 - mse: 948.9791 - val_loss: 20.5904 - val_mse: 951.3717\n",
      "Epoch 445/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1003 - mse: 937.5847 - val_loss: 21.1074 - val_mse: 877.7538\n",
      "Epoch 446/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.2980 - mse: 950.2270 - val_loss: 20.6561 - val_mse: 967.8776\n",
      "Epoch 447/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.3197 - mse: 961.6158 - val_loss: 20.6003 - val_mse: 954.6369\n",
      "Epoch 448/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2468 - mse: 966.2014 - val_loss: 20.6992 - val_mse: 975.1655\n",
      "Epoch 449/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.2530 - mse: 957.0190 - val_loss: 20.7040 - val_mse: 975.9279\n",
      "Epoch 450/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2648 - mse: 951.4288 - val_loss: 20.5708 - val_mse: 922.7300\n",
      "Epoch 451/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.5251 - mse: 966.9044 - val_loss: 20.5610 - val_mse: 927.7355\n",
      "Epoch 452/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.3471 - mse: 956.2214 - val_loss: 20.5964 - val_mse: 914.5222\n",
      "Epoch 453/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.2074 - mse: 947.9773 - val_loss: 20.5742 - val_mse: 921.3310\n",
      "Epoch 454/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.1706 - mse: 944.3170 - val_loss: 21.0322 - val_mse: 1023.4852\n",
      "Epoch 455/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.2185 - mse: 946.7736 - val_loss: 20.6933 - val_mse: 974.2329\n",
      "Epoch 456/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.2177 - mse: 950.4362 - val_loss: 20.5877 - val_mse: 916.8358\n",
      "Epoch 457/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.3877 - mse: 952.3679 - val_loss: 21.3769 - val_mse: 1059.6183\n",
      "Epoch 458/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.3373 - mse: 959.4446 - val_loss: 20.6878 - val_mse: 899.6011\n",
      "Epoch 459/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.3265 - mse: 950.3752 - val_loss: 20.6617 - val_mse: 902.7021\n",
      "Epoch 460/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2348 - mse: 956.5140 - val_loss: 20.6465 - val_mse: 966.0052\n",
      "Epoch 461/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1922 - mse: 944.6628 - val_loss: 20.7162 - val_mse: 896.8052\n",
      "Epoch 462/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.2757 - mse: 949.4056 - val_loss: 20.6056 - val_mse: 912.3749\n",
      "Epoch 463/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2579 - mse: 942.2479 - val_loss: 20.7535 - val_mse: 983.6089\n",
      "Epoch 464/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.2378 - mse: 946.4773 - val_loss: 20.8974 - val_mse: 1005.2611\n",
      "Epoch 465/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.2134 - mse: 947.4697 - val_loss: 20.5632 - val_mse: 936.9543\n",
      "Epoch 466/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.2317 - mse: 944.8820 - val_loss: 20.7851 - val_mse: 988.5319\n",
      "Epoch 467/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1694 - mse: 940.5113 - val_loss: 21.1197 - val_mse: 1033.4236\n",
      "Epoch 468/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.5863 - mse: 962.4309 - val_loss: 20.6096 - val_mse: 957.3952\n",
      "Epoch 469/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.2363 - mse: 946.0255 - val_loss: 20.6090 - val_mse: 957.2302\n",
      "Epoch 470/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1954 - mse: 952.2914 - val_loss: 20.7791 - val_mse: 987.6241\n",
      "Epoch 471/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.2669 - mse: 968.1363 - val_loss: 20.6376 - val_mse: 964.1685\n",
      "Epoch 472/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2151 - mse: 947.0380 - val_loss: 20.5617 - val_mse: 927.0919\n",
      "Epoch 473/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1615 - mse: 936.0928 - val_loss: 20.5769 - val_mse: 945.5228\n",
      "Epoch 474/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.2601 - mse: 946.5881 - val_loss: 20.6686 - val_mse: 970.0629\n",
      "Epoch 475/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.2475 - mse: 963.6705 - val_loss: 20.5734 - val_mse: 921.6421\n",
      "Epoch 476/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2410 - mse: 945.0582 - val_loss: 20.5864 - val_mse: 917.1854\n",
      "Epoch 477/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.3181 - mse: 956.0969 - val_loss: 20.6659 - val_mse: 902.1493\n",
      "Epoch 478/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1901 - mse: 943.5599 - val_loss: 20.6530 - val_mse: 967.2925\n",
      "Epoch 479/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.1224 - mse: 945.6805 - val_loss: 20.7156 - val_mse: 896.8643\n",
      "Epoch 480/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.3158 - mse: 951.7335 - val_loss: 20.7506 - val_mse: 893.8481\n",
      "Epoch 481/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2429 - mse: 949.8451 - val_loss: 20.8812 - val_mse: 1002.8139\n",
      "Epoch 482/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1616 - mse: 935.3395 - val_loss: 21.1457 - val_mse: 1036.2291\n",
      "Epoch 483/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1837 - mse: 947.1719 - val_loss: 20.7734 - val_mse: 892.1354\n",
      "Epoch 484/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2756 - mse: 951.9075 - val_loss: 20.5690 - val_mse: 923.5108\n",
      "Epoch 485/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1668 - mse: 940.4973 - val_loss: 20.6172 - val_mse: 959.5643\n",
      "Epoch 486/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2645 - mse: 953.9241 - val_loss: 21.0131 - val_mse: 1021.0577\n",
      "Epoch 487/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.3312 - mse: 939.5551 - val_loss: 20.6981 - val_mse: 974.9952\n",
      "Epoch 488/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1911 - mse: 940.7982 - val_loss: 20.7394 - val_mse: 981.4254\n",
      "Epoch 489/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2512 - mse: 955.3823 - val_loss: 20.5711 - val_mse: 942.4368\n",
      "Epoch 490/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.3566 - mse: 955.9316 - val_loss: 20.9022 - val_mse: 1005.9675\n",
      "Epoch 491/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.3909 - mse: 955.8566 - val_loss: 20.5704 - val_mse: 922.8840\n",
      "Epoch 492/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2389 - mse: 957.2292 - val_loss: 20.6137 - val_mse: 910.6292\n",
      "Epoch 493/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.2618 - mse: 949.0577 - val_loss: 20.5885 - val_mse: 950.6644\n",
      "Epoch 494/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.4126 - mse: 949.1136 - val_loss: 21.0675 - val_mse: 1027.6594\n",
      "Epoch 495/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3829 - mse: 957.9658 - val_loss: 20.7937 - val_mse: 989.8396\n",
      "Epoch 496/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2148 - mse: 943.4433 - val_loss: 20.7176 - val_mse: 978.0338\n",
      "Epoch 497/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0491 - mse: 938.0845 - val_loss: 20.5641 - val_mse: 937.7011\n",
      "Epoch 498/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1249 - mse: 953.6954 - val_loss: 20.5670 - val_mse: 924.4028\n",
      "Epoch 499/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2995 - mse: 939.3832 - val_loss: 21.2918 - val_mse: 1051.2710\n",
      "Epoch 500/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2703 - mse: 961.9301 - val_loss: 20.5731 - val_mse: 921.7733\n",
      "Epoch 501/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.3103 - mse: 953.7834 - val_loss: 20.5712 - val_mse: 942.4967\n",
      "Epoch 502/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2322 - mse: 961.1462 - val_loss: 20.6215 - val_mse: 960.6445\n",
      "Epoch 503/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1601 - mse: 949.3458 - val_loss: 20.5713 - val_mse: 922.5100\n",
      "Epoch 504/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1241 - mse: 935.0208 - val_loss: 20.8494 - val_mse: 998.0963\n",
      "Epoch 505/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.3887 - mse: 960.5461 - val_loss: 21.3244 - val_mse: 1054.4586\n",
      "Epoch 506/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2868 - mse: 961.5780 - val_loss: 20.5648 - val_mse: 938.2347\n",
      "Epoch 507/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1872 - mse: 937.2469 - val_loss: 20.6041 - val_mse: 955.7593\n",
      "Epoch 508/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3954 - mse: 969.6538 - val_loss: 20.6320 - val_mse: 907.2217\n",
      "Epoch 509/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.3901 - mse: 962.3134 - val_loss: 20.6646 - val_mse: 969.3494\n",
      "Epoch 510/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3389 - mse: 945.3141 - val_loss: 21.6652 - val_mse: 1086.6272\n",
      "Epoch 511/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2446 - mse: 957.3587 - val_loss: 20.6020 - val_mse: 955.1369\n",
      "Epoch 512/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3284 - mse: 950.1711 - val_loss: 20.7046 - val_mse: 976.0153\n",
      "Epoch 513/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2822 - mse: 956.3381 - val_loss: 20.5993 - val_mse: 954.3294\n",
      "Epoch 514/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1048 - mse: 930.0802 - val_loss: 20.5832 - val_mse: 948.3563\n",
      "Epoch 515/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.5082 - mse: 972.8624 - val_loss: 20.5669 - val_mse: 924.4647\n",
      "Epoch 516/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2040 - mse: 949.0793 - val_loss: 20.8434 - val_mse: 997.2073\n",
      "Epoch 517/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2805 - mse: 961.4930 - val_loss: 20.5900 - val_mse: 916.2192\n",
      "Epoch 518/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2071 - mse: 934.2926 - val_loss: 20.5779 - val_mse: 919.9603\n",
      "Epoch 519/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1765 - mse: 950.4641 - val_loss: 20.5873 - val_mse: 916.9498\n",
      "Epoch 520/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2797 - mse: 952.7859 - val_loss: 20.5600 - val_mse: 929.6949\n",
      "Epoch 521/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2750 - mse: 955.8221 - val_loss: 20.5599 - val_mse: 931.1300\n",
      "Epoch 522/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2461 - mse: 942.7308 - val_loss: 21.3350 - val_mse: 1055.5033\n",
      "Epoch 523/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2798 - mse: 948.0800 - val_loss: 20.5730 - val_mse: 943.4875\n",
      "Epoch 524/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1687 - mse: 946.5839 - val_loss: 20.7013 - val_mse: 898.2321\n",
      "Epoch 525/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2160 - mse: 950.9968 - val_loss: 20.7135 - val_mse: 977.4042\n",
      "Epoch 526/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3603 - mse: 948.4658 - val_loss: 20.9769 - val_mse: 1016.3131\n",
      "Epoch 527/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2904 - mse: 957.2698 - val_loss: 20.6601 - val_mse: 968.5689\n",
      "Epoch 528/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1976 - mse: 955.0203 - val_loss: 20.6854 - val_mse: 972.9231\n",
      "Epoch 529/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2935 - mse: 948.8329 - val_loss: 20.6063 - val_mse: 912.2227\n",
      "Epoch 530/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0380 - mse: 933.9852 - val_loss: 20.7217 - val_mse: 978.6731\n",
      "Epoch 531/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2171 - mse: 949.2020 - val_loss: 20.5599 - val_mse: 930.8090\n",
      "Epoch 532/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1528 - mse: 943.6887 - val_loss: 20.9074 - val_mse: 1006.7122\n",
      "Epoch 533/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3383 - mse: 958.5731 - val_loss: 20.7219 - val_mse: 896.2915\n",
      "Epoch 534/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2811 - mse: 951.8082 - val_loss: 21.0358 - val_mse: 879.8368\n",
      "Epoch 535/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3511 - mse: 966.4073 - val_loss: 20.7068 - val_mse: 976.3630\n",
      "Epoch 536/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2104 - mse: 945.8151 - val_loss: 20.5738 - val_mse: 921.4976\n",
      "Epoch 537/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2605 - mse: 953.1323 - val_loss: 20.9972 - val_mse: 1018.9938\n",
      "Epoch 538/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3083 - mse: 953.0886 - val_loss: 20.5849 - val_mse: 917.5985\n",
      "Epoch 539/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2221 - mse: 940.9368 - val_loss: 20.7707 - val_mse: 986.2985\n",
      "Epoch 540/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1655 - mse: 948.0690 - val_loss: 20.5776 - val_mse: 945.8265\n",
      "Epoch 541/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2992 - mse: 950.1834 - val_loss: 20.7965 - val_mse: 990.2743\n",
      "Epoch 542/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.3668 - mse: 954.2575 - val_loss: 20.5751 - val_mse: 920.9807\n",
      "Epoch 543/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2942 - mse: 942.1736 - val_loss: 20.5738 - val_mse: 921.4981\n",
      "Epoch 544/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2596 - mse: 948.7387 - val_loss: 20.9472 - val_mse: 1012.2562\n",
      "Epoch 545/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2677 - mse: 946.6693 - val_loss: 20.7345 - val_mse: 980.6724\n",
      "Epoch 546/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2179 - mse: 947.4169 - val_loss: 20.7304 - val_mse: 980.0312\n",
      "Epoch 547/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3579 - mse: 951.7214 - val_loss: 20.9835 - val_mse: 1017.2004\n",
      "Epoch 548/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3096 - mse: 948.7990 - val_loss: 21.3606 - val_mse: 1058.0240\n",
      "Epoch 549/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.3388 - mse: 958.7861 - val_loss: 20.5739 - val_mse: 944.0045\n",
      "Epoch 550/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1355 - mse: 956.1396 - val_loss: 20.5604 - val_mse: 928.7609\n",
      "Epoch 551/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2652 - mse: 943.3073 - val_loss: 20.5868 - val_mse: 949.9885\n",
      "Epoch 552/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1520 - mse: 941.6795 - val_loss: 20.5660 - val_mse: 939.1540\n",
      "Epoch 553/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1760 - mse: 947.9019 - val_loss: 20.6380 - val_mse: 906.2217\n",
      "Epoch 554/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3283 - mse: 941.7742 - val_loss: 20.5634 - val_mse: 937.0792\n",
      "Epoch 555/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2569 - mse: 958.6248 - val_loss: 21.0846 - val_mse: 878.3781\n",
      "Epoch 556/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3182 - mse: 948.9109 - val_loss: 20.6642 - val_mse: 902.3636\n",
      "Epoch 557/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2984 - mse: 955.7151 - val_loss: 20.5610 - val_mse: 927.7406\n",
      "Epoch 558/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1559 - mse: 948.7349 - val_loss: 20.5887 - val_mse: 916.5777\n",
      "Epoch 559/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.3075 - mse: 955.2512 - val_loss: 20.5602 - val_mse: 929.0973\n",
      "Epoch 560/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0710 - mse: 944.0742 - val_loss: 20.8166 - val_mse: 993.2648\n",
      "Epoch 561/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1412 - mse: 943.7601 - val_loss: 20.6354 - val_mse: 906.6498\n",
      "Epoch 562/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2645 - mse: 955.0797 - val_loss: 20.6101 - val_mse: 911.4025\n",
      "Epoch 563/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2258 - mse: 944.0490 - val_loss: 20.7125 - val_mse: 897.1540\n",
      "Epoch 564/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.3157 - mse: 961.4086 - val_loss: 20.6058 - val_mse: 956.2916\n",
      "Epoch 565/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2545 - mse: 940.9746 - val_loss: 20.5879 - val_mse: 916.7819\n",
      "Epoch 566/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2264 - mse: 950.8464 - val_loss: 20.7051 - val_mse: 976.0903\n",
      "Epoch 567/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2943 - mse: 954.3259 - val_loss: 20.9121 - val_mse: 1007.3862\n",
      "Epoch 568/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2031 - mse: 938.8412 - val_loss: 20.5805 - val_mse: 919.0240\n",
      "Epoch 569/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1667 - mse: 948.7922 - val_loss: 20.5717 - val_mse: 942.7568\n",
      "Epoch 570/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2337 - mse: 945.9418 - val_loss: 20.6129 - val_mse: 910.7869\n",
      "Epoch 571/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1721 - mse: 948.5100 - val_loss: 20.6018 - val_mse: 913.2098\n",
      "Epoch 572/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.3275 - mse: 954.2966 - val_loss: 20.5736 - val_mse: 943.8171\n",
      "Epoch 573/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1863 - mse: 946.0142 - val_loss: 20.9820 - val_mse: 1017.0014\n",
      "Epoch 574/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.4567 - mse: 958.5361 - val_loss: 20.6838 - val_mse: 972.6559\n",
      "Epoch 575/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1851 - mse: 949.3597 - val_loss: 20.5851 - val_mse: 949.2418\n",
      "Epoch 576/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2475 - mse: 943.4850 - val_loss: 20.6697 - val_mse: 970.2625\n",
      "Epoch 577/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.3781 - mse: 948.3002 - val_loss: 21.2415 - val_mse: 1046.2041\n",
      "Epoch 578/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.2215 - mse: 949.0286 - val_loss: 20.9143 - val_mse: 1007.6932\n",
      "Epoch 579/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2356 - mse: 957.3710 - val_loss: 20.5644 - val_mse: 937.9097\n",
      "Epoch 580/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.3097 - mse: 952.3329 - val_loss: 20.6878 - val_mse: 899.6000\n",
      "Epoch 581/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1570 - mse: 946.3608 - val_loss: 20.8616 - val_mse: 999.8912\n",
      "Epoch 582/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1772 - mse: 949.0386 - val_loss: 20.5882 - val_mse: 950.5328\n",
      "Epoch 583/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1521 - mse: 937.7396 - val_loss: 20.6054 - val_mse: 912.4329\n",
      "Epoch 584/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.2225 - mse: 956.8732 - val_loss: 20.5810 - val_mse: 947.3466\n",
      "Epoch 585/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1139 - mse: 953.0620 - val_loss: 20.7001 - val_mse: 898.3553\n",
      "Epoch 586/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1632 - mse: 937.0646 - val_loss: 20.6317 - val_mse: 907.2817\n",
      "Epoch 587/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1501 - mse: 953.1607 - val_loss: 20.6128 - val_mse: 958.3218\n",
      "Epoch 588/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0991 - mse: 947.4023 - val_loss: 20.5601 - val_mse: 929.4436\n",
      "Epoch 589/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2849 - mse: 956.0720 - val_loss: 20.7124 - val_mse: 897.1655\n",
      "Epoch 590/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2279 - mse: 942.8950 - val_loss: 20.7028 - val_mse: 898.0831\n",
      "Epoch 591/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2765 - mse: 955.7094 - val_loss: 20.6338 - val_mse: 906.9127\n",
      "Epoch 592/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1880 - mse: 944.3123 - val_loss: 20.5615 - val_mse: 927.2141\n",
      "Epoch 593/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2456 - mse: 962.4493 - val_loss: 20.5694 - val_mse: 923.3598\n",
      "Epoch 594/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2788 - mse: 953.6634 - val_loss: 20.5723 - val_mse: 922.1003\n",
      "Epoch 595/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2032 - mse: 944.3391 - val_loss: 20.5873 - val_mse: 950.1737\n",
      "Epoch 596/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0850 - mse: 943.9101 - val_loss: 20.5757 - val_mse: 920.7690\n",
      "Epoch 597/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2590 - mse: 961.9858 - val_loss: 20.5603 - val_mse: 928.9523\n",
      "Epoch 598/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1208 - mse: 947.4754 - val_loss: 20.5651 - val_mse: 938.4448\n",
      "Epoch 599/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2656 - mse: 938.7178 - val_loss: 20.5689 - val_mse: 923.5610\n",
      "Epoch 600/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0381 - mse: 939.2722 - val_loss: 20.7176 - val_mse: 896.6750\n",
      "Epoch 601/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2622 - mse: 956.3141 - val_loss: 20.6288 - val_mse: 907.7850\n",
      "Epoch 602/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0914 - mse: 940.3900 - val_loss: 20.5896 - val_mse: 951.0648\n",
      "Epoch 603/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0958 - mse: 944.0779 - val_loss: 20.6941 - val_mse: 974.3600\n",
      "Epoch 604/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2289 - mse: 949.1165 - val_loss: 20.6483 - val_mse: 966.3604\n",
      "Epoch 605/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2044 - mse: 942.7419 - val_loss: 20.6307 - val_mse: 907.4463\n",
      "Epoch 606/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3935 - mse: 960.6866 - val_loss: 20.5649 - val_mse: 938.3232\n",
      "Epoch 607/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.4348 - mse: 971.2398 - val_loss: 20.9467 - val_mse: 882.9999\n",
      "Epoch 608/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.4062 - mse: 960.2999 - val_loss: 20.6012 - val_mse: 954.9116\n",
      "Epoch 609/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2261 - mse: 952.6677 - val_loss: 20.6013 - val_mse: 954.9413\n",
      "Epoch 610/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1434 - mse: 938.0081 - val_loss: 20.6341 - val_mse: 906.8607\n",
      "Epoch 611/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.3421 - mse: 957.2889 - val_loss: 20.5609 - val_mse: 933.9875\n",
      "Epoch 612/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1402 - mse: 941.7920 - val_loss: 20.5906 - val_mse: 951.4536\n",
      "Epoch 613/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1250 - mse: 937.5125 - val_loss: 20.7303 - val_mse: 980.0225\n",
      "Epoch 614/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1254 - mse: 934.9309 - val_loss: 20.6085 - val_mse: 911.7294\n",
      "Epoch 615/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2875 - mse: 958.8629 - val_loss: 20.6969 - val_mse: 974.8041\n",
      "Epoch 616/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2648 - mse: 942.4979 - val_loss: 20.8661 - val_mse: 1000.5693\n",
      "Epoch 617/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2189 - mse: 951.6509 - val_loss: 20.5864 - val_mse: 917.1892\n",
      "Epoch 618/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1754 - mse: 944.8806 - val_loss: 20.5774 - val_mse: 920.1358\n",
      "Epoch 619/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2615 - mse: 951.2893 - val_loss: 20.8799 - val_mse: 1002.6214\n",
      "Epoch 620/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1194 - mse: 945.9252 - val_loss: 20.7347 - val_mse: 980.6973\n",
      "Epoch 621/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.4021 - mse: 963.3083 - val_loss: 20.6052 - val_mse: 956.1129\n",
      "Epoch 622/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2325 - mse: 952.9996 - val_loss: 20.9658 - val_mse: 1014.8208\n",
      "Epoch 623/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2873 - mse: 945.9602 - val_loss: 20.5613 - val_mse: 934.8029\n",
      "Epoch 624/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2127 - mse: 949.9410 - val_loss: 20.6199 - val_mse: 909.4149\n",
      "Epoch 625/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1401 - mse: 945.4777 - val_loss: 20.5797 - val_mse: 919.3142\n",
      "Epoch 626/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1707 - mse: 948.1419 - val_loss: 20.6394 - val_mse: 964.5353\n",
      "Epoch 627/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2649 - mse: 954.6398 - val_loss: 20.7383 - val_mse: 981.2501\n",
      "Epoch 628/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0707 - mse: 942.3590 - val_loss: 20.5599 - val_mse: 930.3612\n",
      "Epoch 629/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1542 - mse: 951.0273 - val_loss: 20.5819 - val_mse: 918.5220\n",
      "Epoch 630/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2418 - mse: 951.8040 - val_loss: 20.5634 - val_mse: 937.1607\n",
      "Epoch 631/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1702 - mse: 940.2191 - val_loss: 20.5642 - val_mse: 925.6060\n",
      "Epoch 632/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2606 - mse: 949.8539 - val_loss: 20.5690 - val_mse: 923.4969\n",
      "Epoch 633/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2924 - mse: 939.5664 - val_loss: 20.6454 - val_mse: 905.0354\n",
      "Epoch 634/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0807 - mse: 941.8021 - val_loss: 20.9787 - val_mse: 1016.5626\n",
      "Epoch 635/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.3191 - mse: 964.8420 - val_loss: 20.6121 - val_mse: 958.1168\n",
      "Epoch 636/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.3036 - mse: 955.0559 - val_loss: 20.5690 - val_mse: 923.5056\n",
      "Epoch 637/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1666 - mse: 952.2737 - val_loss: 20.5989 - val_mse: 913.8542\n",
      "Epoch 638/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1964 - mse: 939.5738 - val_loss: 20.5878 - val_mse: 916.8071\n",
      "Epoch 639/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1476 - mse: 941.9579 - val_loss: 20.6719 - val_mse: 901.3972\n",
      "Epoch 640/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2441 - mse: 957.7089 - val_loss: 20.7311 - val_mse: 980.1462\n",
      "Epoch 641/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2409 - mse: 949.8044 - val_loss: 20.9730 - val_mse: 1015.7879\n",
      "Epoch 642/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2222 - mse: 955.9858 - val_loss: 20.6121 - val_mse: 958.1177\n",
      "Epoch 643/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0519 - mse: 940.8076 - val_loss: 21.0974 - val_mse: 1030.9801\n",
      "Epoch 644/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1800 - mse: 945.9303 - val_loss: 20.5663 - val_mse: 924.6537\n",
      "Epoch 645/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2101 - mse: 947.6790 - val_loss: 20.6149 - val_mse: 958.9423\n",
      "Epoch 646/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2123 - mse: 946.6108 - val_loss: 20.5618 - val_mse: 935.6702\n",
      "Epoch 647/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2375 - mse: 952.2427 - val_loss: 20.8822 - val_mse: 1002.9745\n",
      "Epoch 648/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2689 - mse: 940.1945 - val_loss: 20.6108 - val_mse: 957.7563\n",
      "Epoch 649/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2227 - mse: 949.2621 - val_loss: 20.6784 - val_mse: 971.7529\n",
      "Epoch 650/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1336 - mse: 949.9009 - val_loss: 20.5715 - val_mse: 942.6790\n",
      "Epoch 651/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1918 - mse: 949.5711 - val_loss: 20.6016 - val_mse: 913.2421\n",
      "Epoch 652/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.3419 - mse: 958.4925 - val_loss: 20.7634 - val_mse: 892.8550\n",
      "Epoch 653/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1209 - mse: 932.1868 - val_loss: 21.0764 - val_mse: 1028.6561\n",
      "Epoch 654/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2867 - mse: 956.7551 - val_loss: 20.9739 - val_mse: 881.9601\n",
      "Epoch 655/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2487 - mse: 951.7399 - val_loss: 20.5605 - val_mse: 933.1890\n",
      "Epoch 656/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1614 - mse: 941.9023 - val_loss: 20.5762 - val_mse: 945.1969\n",
      "Epoch 657/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.3337 - mse: 950.6085 - val_loss: 20.7172 - val_mse: 977.9894\n",
      "Epoch 658/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1045 - mse: 938.7792 - val_loss: 20.5857 - val_mse: 917.3672\n",
      "Epoch 659/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1668 - mse: 939.3922 - val_loss: 20.6118 - val_mse: 911.0140\n",
      "Epoch 660/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1628 - mse: 949.4771 - val_loss: 20.6680 - val_mse: 969.9721\n",
      "Epoch 661/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0531 - mse: 941.4595 - val_loss: 20.6224 - val_mse: 960.8764\n",
      "Epoch 662/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.3808 - mse: 961.0211 - val_loss: 21.0279 - val_mse: 1022.9509\n",
      "Epoch 663/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1564 - mse: 939.7911 - val_loss: 20.6685 - val_mse: 970.0515\n",
      "Epoch 664/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1926 - mse: 943.4681 - val_loss: 20.6220 - val_mse: 960.7820\n",
      "Epoch 665/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2051 - mse: 946.9702 - val_loss: 21.1647 - val_mse: 876.3680\n",
      "Epoch 666/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.2014 - mse: 937.8894 - val_loss: 20.5697 - val_mse: 923.1706\n",
      "Epoch 667/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.3339 - mse: 958.8863 - val_loss: 20.5784 - val_mse: 919.7653\n",
      "Epoch 668/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9648 - mse: 929.8444 - val_loss: 20.5601 - val_mse: 932.3279\n",
      "Epoch 669/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0962 - mse: 948.8243 - val_loss: 20.5616 - val_mse: 927.0800\n",
      "Epoch 670/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0619 - mse: 942.4689 - val_loss: 20.6584 - val_mse: 903.1492\n",
      "Epoch 671/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.2951 - mse: 961.0314 - val_loss: 20.5602 - val_mse: 929.0775\n",
      "Epoch 672/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2460 - mse: 950.3655 - val_loss: 20.6589 - val_mse: 903.0710\n",
      "Epoch 673/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2029 - mse: 934.8939 - val_loss: 20.6494 - val_mse: 966.5751\n",
      "Epoch 674/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2759 - mse: 955.2258 - val_loss: 20.5818 - val_mse: 947.7600\n",
      "Epoch 675/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1856 - mse: 933.7507 - val_loss: 20.5624 - val_mse: 936.3158\n",
      "Epoch 676/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.2832 - mse: 951.1528 - val_loss: 20.5802 - val_mse: 947.0400\n",
      "Epoch 677/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.3496 - mse: 961.6077 - val_loss: 20.6022 - val_mse: 913.1028\n",
      "Epoch 678/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1390 - mse: 943.5567 - val_loss: 20.6252 - val_mse: 961.5265\n",
      "Epoch 679/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2756 - mse: 945.5273 - val_loss: 20.7131 - val_mse: 897.0906\n",
      "Epoch 680/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2782 - mse: 955.4929 - val_loss: 20.6057 - val_mse: 912.3412\n",
      "Epoch 681/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1853 - mse: 942.9237 - val_loss: 20.5796 - val_mse: 946.7718\n",
      "Epoch 682/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2497 - mse: 948.6152 - val_loss: 20.6515 - val_mse: 966.9981\n",
      "Epoch 683/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3338 - mse: 949.2896 - val_loss: 21.1783 - val_mse: 1039.7062\n",
      "Epoch 684/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2455 - mse: 949.7583 - val_loss: 20.7831 - val_mse: 891.4490\n",
      "Epoch 685/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1904 - mse: 954.5526 - val_loss: 20.5619 - val_mse: 935.7781\n",
      "Epoch 686/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0329 - mse: 942.6281 - val_loss: 20.5914 - val_mse: 951.7468\n",
      "Epoch 687/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0416 - mse: 949.4614 - val_loss: 20.8346 - val_mse: 888.2753\n",
      "Epoch 688/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2667 - mse: 945.2670 - val_loss: 20.5830 - val_mse: 918.1812\n",
      "Epoch 689/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1527 - mse: 951.5007 - val_loss: 20.7025 - val_mse: 898.1003\n",
      "Epoch 690/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1914 - mse: 956.8953 - val_loss: 20.7367 - val_mse: 981.0099\n",
      "Epoch 691/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2076 - mse: 951.2529 - val_loss: 20.5987 - val_mse: 954.1398\n",
      "Epoch 692/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0881 - mse: 941.8153 - val_loss: 20.6730 - val_mse: 970.8295\n",
      "Epoch 693/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.2834 - mse: 951.9730 - val_loss: 20.6392 - val_mse: 906.0114\n",
      "Epoch 694/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0625 - mse: 947.8342 - val_loss: 20.5804 - val_mse: 919.0236\n",
      "Epoch 695/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1174 - mse: 939.7847 - val_loss: 20.7685 - val_mse: 985.9640\n",
      "Epoch 696/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1780 - mse: 940.2332 - val_loss: 20.5905 - val_mse: 951.4139\n",
      "Epoch 697/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1508 - mse: 952.9816 - val_loss: 20.7438 - val_mse: 894.3945\n",
      "Epoch 698/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.3231 - mse: 949.4506 - val_loss: 20.9347 - val_mse: 883.4856\n",
      "Epoch 699/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1779 - mse: 945.8879 - val_loss: 20.6083 - val_mse: 911.7666\n",
      "Epoch 700/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1679 - mse: 936.5184 - val_loss: 20.6091 - val_mse: 957.2735\n",
      "Epoch 701/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2406 - mse: 960.7738 - val_loss: 20.5812 - val_mse: 918.7486\n",
      "Epoch 702/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0765 - mse: 936.2723 - val_loss: 20.7468 - val_mse: 982.5663\n",
      "Epoch 703/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2307 - mse: 950.1210 - val_loss: 20.6025 - val_mse: 955.3215\n",
      "Epoch 704/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1636 - mse: 947.3944 - val_loss: 20.5717 - val_mse: 942.7896\n",
      "Epoch 705/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1680 - mse: 943.8970 - val_loss: 20.5850 - val_mse: 949.1915\n",
      "Epoch 706/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.2844 - mse: 960.6582 - val_loss: 20.5615 - val_mse: 927.1443\n",
      "Epoch 707/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1567 - mse: 942.3705 - val_loss: 20.5629 - val_mse: 936.7185\n",
      "Epoch 708/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0501 - mse: 940.7162 - val_loss: 20.5984 - val_mse: 954.0614\n",
      "Epoch 709/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0819 - mse: 936.7421 - val_loss: 20.5703 - val_mse: 941.9939\n",
      "Epoch 710/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1254 - mse: 954.4411 - val_loss: 20.5668 - val_mse: 939.7938\n",
      "Epoch 711/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2955 - mse: 945.8423 - val_loss: 20.5602 - val_mse: 928.8093\n",
      "Epoch 712/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1462 - mse: 941.6060 - val_loss: 20.5745 - val_mse: 921.1777\n",
      "Epoch 713/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1310 - mse: 952.5369 - val_loss: 20.5856 - val_mse: 917.3710\n",
      "Epoch 714/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.2004 - mse: 943.9082 - val_loss: 20.6211 - val_mse: 960.5623\n",
      "Epoch 715/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0176 - mse: 928.0455 - val_loss: 20.9655 - val_mse: 1014.7844\n",
      "Epoch 716/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1158 - mse: 938.2039 - val_loss: 20.5681 - val_mse: 940.7302\n",
      "Epoch 717/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0788 - mse: 949.7202 - val_loss: 20.6278 - val_mse: 962.1248\n",
      "Epoch 718/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1871 - mse: 942.9518 - val_loss: 20.5736 - val_mse: 943.9084\n",
      "Epoch 719/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2239 - mse: 946.0618 - val_loss: 20.6871 - val_mse: 899.6550\n",
      "Epoch 720/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1562 - mse: 934.2119 - val_loss: 20.5623 - val_mse: 936.1982\n",
      "Epoch 721/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1258 - mse: 940.2742 - val_loss: 20.7373 - val_mse: 981.1063\n",
      "Epoch 722/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3223 - mse: 950.9134 - val_loss: 20.8051 - val_mse: 991.5753\n",
      "Epoch 723/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1433 - mse: 950.0708 - val_loss: 20.7562 - val_mse: 893.3898\n",
      "Epoch 724/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1061 - mse: 932.4402 - val_loss: 20.5607 - val_mse: 927.9020\n",
      "Epoch 725/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0676 - mse: 935.5419 - val_loss: 20.6916 - val_mse: 973.9663\n",
      "Epoch 726/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.3568 - mse: 966.9397 - val_loss: 20.5744 - val_mse: 921.2217\n",
      "Epoch 727/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0785 - mse: 942.3207 - val_loss: 20.5607 - val_mse: 933.7853\n",
      "Epoch 728/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0969 - mse: 937.3796 - val_loss: 20.6407 - val_mse: 964.8234\n",
      "Epoch 729/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1297 - mse: 948.1281 - val_loss: 20.6130 - val_mse: 958.4133\n",
      "Epoch 730/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1778 - mse: 951.0474 - val_loss: 20.7582 - val_mse: 984.3566\n",
      "Epoch 731/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1994 - mse: 945.4464 - val_loss: 21.2456 - val_mse: 1046.6235\n",
      "Epoch 732/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2420 - mse: 955.8589 - val_loss: 20.6087 - val_mse: 911.6724\n",
      "Epoch 733/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1448 - mse: 947.1584 - val_loss: 20.5977 - val_mse: 914.1494\n",
      "Epoch 734/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1391 - mse: 946.1729 - val_loss: 20.6270 - val_mse: 961.9395\n",
      "Epoch 735/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1536 - mse: 942.0040 - val_loss: 20.6562 - val_mse: 903.4391\n",
      "Epoch 736/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2671 - mse: 960.2237 - val_loss: 20.5601 - val_mse: 929.1660\n",
      "Epoch 737/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2241 - mse: 937.1680 - val_loss: 20.6525 - val_mse: 967.2036\n",
      "Epoch 738/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2149 - mse: 957.4443 - val_loss: 20.6609 - val_mse: 902.7969\n",
      "Epoch 739/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2851 - mse: 948.2487 - val_loss: 20.7434 - val_mse: 982.0494\n",
      "Epoch 740/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2070 - mse: 944.2736 - val_loss: 20.7174 - val_mse: 978.0183\n",
      "Epoch 741/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1532 - mse: 955.5433 - val_loss: 20.6774 - val_mse: 900.7413\n",
      "Epoch 742/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1737 - mse: 942.2385 - val_loss: 20.6934 - val_mse: 974.2502\n",
      "Epoch 743/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2615 - mse: 952.6555 - val_loss: 20.5754 - val_mse: 944.8225\n",
      "Epoch 744/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1997 - mse: 945.5532 - val_loss: 20.5962 - val_mse: 953.3415\n",
      "Epoch 745/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.3037 - mse: 960.6955 - val_loss: 20.8459 - val_mse: 997.5873\n",
      "Epoch 746/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2974 - mse: 955.2733 - val_loss: 20.6248 - val_mse: 961.4290\n",
      "Epoch 747/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2955 - mse: 939.7737 - val_loss: 20.9901 - val_mse: 1018.0785\n",
      "Epoch 748/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3350 - mse: 972.2679 - val_loss: 20.6658 - val_mse: 969.5776\n",
      "Epoch 749/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1288 - mse: 948.1614 - val_loss: 20.5849 - val_mse: 917.5681\n",
      "Epoch 750/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2504 - mse: 937.3365 - val_loss: 20.6342 - val_mse: 963.4779\n",
      "Epoch 751/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2722 - mse: 952.2310 - val_loss: 20.5704 - val_mse: 942.0746\n",
      "Epoch 752/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1705 - mse: 946.1161 - val_loss: 20.5733 - val_mse: 943.6982\n",
      "Epoch 753/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1739 - mse: 947.8253 - val_loss: 20.5603 - val_mse: 928.7783\n",
      "Epoch 754/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1381 - mse: 953.9565 - val_loss: 20.6483 - val_mse: 904.5752\n",
      "Epoch 755/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0531 - mse: 937.6898 - val_loss: 20.6028 - val_mse: 955.3987\n",
      "Epoch 756/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1794 - mse: 938.7590 - val_loss: 20.9152 - val_mse: 1007.8301\n",
      "Epoch 757/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1748 - mse: 945.6836 - val_loss: 20.5631 - val_mse: 926.1608\n",
      "Epoch 758/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.8908 - mse: 938.3037 - val_loss: 20.5844 - val_mse: 948.9633\n",
      "Epoch 759/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1406 - mse: 943.4364 - val_loss: 20.5795 - val_mse: 919.3370\n",
      "Epoch 760/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1333 - mse: 941.2358 - val_loss: 20.7252 - val_mse: 979.2377\n",
      "Epoch 761/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1317 - mse: 947.1766 - val_loss: 20.5777 - val_mse: 919.9969\n",
      "Epoch 762/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0753 - mse: 937.2299 - val_loss: 20.5830 - val_mse: 948.3308\n",
      "Epoch 763/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1518 - mse: 933.7592 - val_loss: 20.6656 - val_mse: 902.1655\n",
      "Epoch 764/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1106 - mse: 955.5332 - val_loss: 20.6113 - val_mse: 911.1117\n",
      "Epoch 765/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1075 - mse: 941.8329 - val_loss: 20.5977 - val_mse: 914.1445\n",
      "Epoch 766/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1324 - mse: 938.9810 - val_loss: 20.5606 - val_mse: 933.4058\n",
      "Epoch 767/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1944 - mse: 954.3154 - val_loss: 20.5897 - val_mse: 916.2856\n",
      "Epoch 768/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1860 - mse: 938.6616 - val_loss: 20.6666 - val_mse: 969.7252\n",
      "Epoch 769/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1605 - mse: 938.5009 - val_loss: 20.6506 - val_mse: 966.8264\n",
      "Epoch 770/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3526 - mse: 966.7886 - val_loss: 20.7735 - val_mse: 892.1152\n",
      "Epoch 771/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2774 - mse: 954.9340 - val_loss: 20.5893 - val_mse: 916.3912\n",
      "Epoch 772/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0527 - mse: 926.1822 - val_loss: 20.5714 - val_mse: 942.6475\n",
      "Epoch 773/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3042 - mse: 957.3867 - val_loss: 21.0924 - val_mse: 1030.4180\n",
      "Epoch 774/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1637 - mse: 949.6762 - val_loss: 20.6013 - val_mse: 954.9556\n",
      "Epoch 775/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2772 - mse: 952.2911 - val_loss: 20.5598 - val_mse: 931.1877\n",
      "Epoch 776/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0572 - mse: 933.8447 - val_loss: 20.7207 - val_mse: 978.5275\n",
      "Epoch 777/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1781 - mse: 947.1517 - val_loss: 20.5705 - val_mse: 922.8110\n",
      "Epoch 778/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2303 - mse: 948.2018 - val_loss: 20.5650 - val_mse: 925.2329\n",
      "Epoch 779/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2353 - mse: 956.0378 - val_loss: 20.5838 - val_mse: 948.6649\n",
      "Epoch 780/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0790 - mse: 944.4870 - val_loss: 20.5603 - val_mse: 928.7342\n",
      "Epoch 781/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1691 - mse: 937.7448 - val_loss: 20.5853 - val_mse: 949.3221\n",
      "Epoch 782/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0540 - mse: 934.5008 - val_loss: 20.6003 - val_mse: 954.6544\n",
      "Epoch 783/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3809 - mse: 963.4079 - val_loss: 20.9348 - val_mse: 883.4847\n",
      "Epoch 784/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.3712 - mse: 969.7805 - val_loss: 20.6017 - val_mse: 955.0638\n",
      "Epoch 785/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1134 - mse: 941.1350 - val_loss: 20.7730 - val_mse: 892.1528\n",
      "Epoch 786/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1254 - mse: 943.1561 - val_loss: 20.5900 - val_mse: 951.2283\n",
      "Epoch 787/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2496 - mse: 957.4645 - val_loss: 20.9755 - val_mse: 1016.1325\n",
      "Epoch 788/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1993 - mse: 950.6232 - val_loss: 20.5679 - val_mse: 940.5634\n",
      "Epoch 789/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1388 - mse: 936.3232 - val_loss: 20.6705 - val_mse: 970.3995\n",
      "Epoch 790/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1965 - mse: 953.8291 - val_loss: 20.6051 - val_mse: 956.0709\n",
      "Epoch 791/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2208 - mse: 939.2308 - val_loss: 20.5625 - val_mse: 936.3193\n",
      "Epoch 792/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1316 - mse: 944.9103 - val_loss: 20.5845 - val_mse: 917.7073\n",
      "Epoch 793/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1067 - mse: 937.3195 - val_loss: 20.7329 - val_mse: 980.4178\n",
      "Epoch 794/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1191 - mse: 960.0322 - val_loss: 20.5774 - val_mse: 945.7606\n",
      "Epoch 795/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0876 - mse: 940.1494 - val_loss: 20.7084 - val_mse: 976.6210\n",
      "Epoch 796/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1215 - mse: 948.7813 - val_loss: 20.5619 - val_mse: 935.7227\n",
      "Epoch 797/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0830 - mse: 937.8887 - val_loss: 20.5836 - val_mse: 917.9846\n",
      "Epoch 798/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0196 - mse: 937.5931 - val_loss: 20.7055 - val_mse: 897.8145\n",
      "Epoch 799/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2407 - mse: 949.8796 - val_loss: 20.5750 - val_mse: 944.6147\n",
      "Epoch 800/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1602 - mse: 937.5978 - val_loss: 20.5746 - val_mse: 944.3831\n",
      "Epoch 801/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1346 - mse: 943.3306 - val_loss: 20.5902 - val_mse: 916.1412\n",
      "Epoch 802/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.4613 - mse: 973.5510 - val_loss: 20.5975 - val_mse: 953.7556\n",
      "Epoch 803/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2255 - mse: 937.1260 - val_loss: 20.7664 - val_mse: 985.6286\n",
      "Epoch 804/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9987 - mse: 938.5656 - val_loss: 20.5735 - val_mse: 943.7916\n",
      "Epoch 805/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2548 - mse: 956.4971 - val_loss: 20.5762 - val_mse: 945.1669\n",
      "Epoch 806/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2948 - mse: 956.8600 - val_loss: 20.6972 - val_mse: 974.8593\n",
      "Epoch 807/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.3218 - mse: 936.4403 - val_loss: 20.9725 - val_mse: 1015.7272\n",
      "Epoch 808/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1741 - mse: 950.5674 - val_loss: 20.5716 - val_mse: 922.3559\n",
      "Epoch 809/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.2416 - mse: 953.6780 - val_loss: 20.5789 - val_mse: 946.4629\n",
      "Epoch 810/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1284 - mse: 945.3820 - val_loss: 20.5635 - val_mse: 937.2391\n",
      "Epoch 811/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0641 - mse: 933.5891 - val_loss: 20.6255 - val_mse: 908.3683\n",
      "Epoch 812/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0478 - mse: 934.8323 - val_loss: 20.6107 - val_mse: 911.2583\n",
      "Epoch 813/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0913 - mse: 930.5207 - val_loss: 20.7092 - val_mse: 976.7500\n",
      "Epoch 814/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1540 - mse: 953.0864 - val_loss: 20.5598 - val_mse: 930.8716\n",
      "Epoch 815/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1308 - mse: 940.4213 - val_loss: 20.7247 - val_mse: 979.1562\n",
      "Epoch 816/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1326 - mse: 952.6987 - val_loss: 20.7758 - val_mse: 891.9583\n",
      "Epoch 817/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1518 - mse: 948.4620 - val_loss: 20.7236 - val_mse: 978.9762\n",
      "Epoch 818/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0169 - mse: 936.3114 - val_loss: 20.5612 - val_mse: 934.7593\n",
      "Epoch 819/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1020 - mse: 937.9775 - val_loss: 20.6268 - val_mse: 908.1325\n",
      "Epoch 820/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0572 - mse: 932.1504 - val_loss: 20.5612 - val_mse: 927.4246\n",
      "Epoch 821/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1405 - mse: 944.7761 - val_loss: 20.9211 - val_mse: 884.0714\n",
      "Epoch 822/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2698 - mse: 933.9222 - val_loss: 20.5688 - val_mse: 941.1293\n",
      "Epoch 823/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0933 - mse: 943.4460 - val_loss: 20.9426 - val_mse: 1011.6085\n",
      "Epoch 824/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0681 - mse: 930.1538 - val_loss: 20.5637 - val_mse: 937.4161\n",
      "Epoch 825/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2195 - mse: 955.9409 - val_loss: 20.8316 - val_mse: 995.4905\n",
      "Epoch 826/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2763 - mse: 945.6202 - val_loss: 20.6077 - val_mse: 911.9156\n",
      "Epoch 827/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1575 - mse: 948.2115 - val_loss: 20.6051 - val_mse: 956.0699\n",
      "Epoch 828/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1146 - mse: 939.0953 - val_loss: 20.5598 - val_mse: 931.4728\n",
      "Epoch 829/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1035 - mse: 937.6955 - val_loss: 20.5820 - val_mse: 947.8204\n",
      "Epoch 830/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2405 - mse: 936.0466 - val_loss: 20.5843 - val_mse: 917.7831\n",
      "Epoch 831/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2541 - mse: 949.2732 - val_loss: 20.5943 - val_mse: 915.0636\n",
      "Epoch 832/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0572 - mse: 933.1298 - val_loss: 20.7612 - val_mse: 984.8077\n",
      "Epoch 833/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0870 - mse: 943.3357 - val_loss: 20.9903 - val_mse: 1018.0983\n",
      "Epoch 834/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2519 - mse: 951.3598 - val_loss: 20.5778 - val_mse: 919.9827\n",
      "Epoch 835/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1462 - mse: 949.8823 - val_loss: 20.6145 - val_mse: 910.4501\n",
      "Epoch 836/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1533 - mse: 943.5049 - val_loss: 20.6118 - val_mse: 958.0413\n",
      "Epoch 837/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1079 - mse: 939.2235 - val_loss: 20.6355 - val_mse: 963.7385\n",
      "Epoch 838/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2515 - mse: 950.2863 - val_loss: 20.5763 - val_mse: 945.2485\n",
      "Epoch 839/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2362 - mse: 952.1461 - val_loss: 20.5942 - val_mse: 952.6929\n",
      "Epoch 840/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9885 - mse: 932.7139 - val_loss: 20.5729 - val_mse: 921.8286\n",
      "Epoch 841/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0867 - mse: 934.4227 - val_loss: 20.6141 - val_mse: 958.6938\n",
      "Epoch 842/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1202 - mse: 946.8329 - val_loss: 20.7199 - val_mse: 896.4652\n",
      "Epoch 843/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1195 - mse: 939.6393 - val_loss: 20.8052 - val_mse: 991.5875\n",
      "Epoch 844/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0539 - mse: 943.8770 - val_loss: 20.5966 - val_mse: 953.4700\n",
      "Epoch 845/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2176 - mse: 943.1755 - val_loss: 20.5996 - val_mse: 954.4337\n",
      "Epoch 846/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2151 - mse: 943.4810 - val_loss: 20.5902 - val_mse: 916.1604\n",
      "Epoch 847/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1187 - mse: 956.0246 - val_loss: 20.6057 - val_mse: 956.2556\n",
      "Epoch 848/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0945 - mse: 934.6506 - val_loss: 20.5771 - val_mse: 920.2242\n",
      "Epoch 849/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9339 - mse: 921.4454 - val_loss: 20.7555 - val_mse: 983.9254\n",
      "Epoch 850/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0223 - mse: 941.7657 - val_loss: 20.8137 - val_mse: 992.8422\n",
      "Epoch 851/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1938 - mse: 955.6283 - val_loss: 21.1709 - val_mse: 1038.9249\n",
      "Epoch 852/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3097 - mse: 956.4641 - val_loss: 20.6619 - val_mse: 902.6650\n",
      "Epoch 853/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1093 - mse: 948.5096 - val_loss: 20.5869 - val_mse: 950.0298\n",
      "Epoch 854/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1574 - mse: 941.4078 - val_loss: 20.5598 - val_mse: 931.5484\n",
      "Epoch 855/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0917 - mse: 949.6031 - val_loss: 21.0328 - val_mse: 879.9250\n",
      "Epoch 856/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2766 - mse: 949.3332 - val_loss: 20.5624 - val_mse: 936.3223\n",
      "Epoch 857/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1693 - mse: 955.9798 - val_loss: 20.7051 - val_mse: 976.1075\n",
      "Epoch 858/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2459 - mse: 953.5737 - val_loss: 20.5902 - val_mse: 951.3121\n",
      "Epoch 859/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1489 - mse: 944.1757 - val_loss: 20.5857 - val_mse: 949.5218\n",
      "Epoch 860/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0248 - mse: 947.0884 - val_loss: 20.5985 - val_mse: 913.9473\n",
      "Epoch 861/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1845 - mse: 941.6409 - val_loss: 20.6006 - val_mse: 913.4506\n",
      "Epoch 862/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1021 - mse: 949.3268 - val_loss: 20.7502 - val_mse: 893.8696\n",
      "Epoch 863/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0981 - mse: 941.9925 - val_loss: 20.6450 - val_mse: 965.7018\n",
      "Epoch 864/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1540 - mse: 946.0261 - val_loss: 20.5608 - val_mse: 933.9178\n",
      "Epoch 865/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1292 - mse: 952.2070 - val_loss: 20.6265 - val_mse: 961.8029\n",
      "Epoch 866/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1018 - mse: 938.3067 - val_loss: 20.6021 - val_mse: 955.1973\n",
      "Epoch 867/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1025 - mse: 936.5699 - val_loss: 20.6120 - val_mse: 910.9736\n",
      "Epoch 868/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0973 - mse: 943.5959 - val_loss: 20.6400 - val_mse: 964.6673\n",
      "Epoch 869/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0405 - mse: 947.3017 - val_loss: 20.5609 - val_mse: 933.9581\n",
      "Epoch 870/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0238 - mse: 936.9858 - val_loss: 20.5621 - val_mse: 935.9319\n",
      "Epoch 871/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1304 - mse: 940.5569 - val_loss: 20.6218 - val_mse: 960.7214\n",
      "Epoch 872/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1193 - mse: 941.1625 - val_loss: 20.5667 - val_mse: 924.4875\n",
      "Epoch 873/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.9953 - mse: 928.4108 - val_loss: 20.5636 - val_mse: 937.3188\n",
      "Epoch 874/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1507 - mse: 954.8514 - val_loss: 20.5814 - val_mse: 947.5616\n",
      "Epoch 875/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1754 - mse: 946.5626 - val_loss: 20.5615 - val_mse: 935.1407\n",
      "Epoch 876/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2062 - mse: 935.4948 - val_loss: 20.7575 - val_mse: 984.2385\n",
      "Epoch 877/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1906 - mse: 947.9460 - val_loss: 20.5599 - val_mse: 930.5649\n",
      "Epoch 878/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9771 - mse: 939.6517 - val_loss: 20.5814 - val_mse: 947.5769\n",
      "Epoch 879/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0317 - mse: 930.7529 - val_loss: 20.6185 - val_mse: 959.9073\n",
      "Epoch 880/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1320 - mse: 948.2285 - val_loss: 20.5708 - val_mse: 922.6959\n",
      "Epoch 881/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1572 - mse: 948.0743 - val_loss: 20.6337 - val_mse: 963.3508\n",
      "Epoch 882/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0500 - mse: 947.2704 - val_loss: 20.9507 - val_mse: 1012.7488\n",
      "Epoch 883/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1611 - mse: 942.8406 - val_loss: 20.5784 - val_mse: 946.2084\n",
      "Epoch 884/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0738 - mse: 954.6401 - val_loss: 20.5770 - val_mse: 920.2640\n",
      "Epoch 885/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1888 - mse: 948.7475 - val_loss: 20.5975 - val_mse: 953.7729\n",
      "Epoch 886/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1421 - mse: 937.9766 - val_loss: 20.5686 - val_mse: 923.6460\n",
      "Epoch 887/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2180 - mse: 952.8437 - val_loss: 20.6504 - val_mse: 904.2896\n",
      "Epoch 888/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.3349 - mse: 949.3642 - val_loss: 20.6789 - val_mse: 971.8365\n",
      "Epoch 889/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1636 - mse: 949.8344 - val_loss: 20.7152 - val_mse: 896.8877\n",
      "Epoch 890/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2757 - mse: 946.7972 - val_loss: 20.5640 - val_mse: 937.6320\n",
      "Epoch 891/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0810 - mse: 944.9683 - val_loss: 20.6199 - val_mse: 960.2858\n",
      "Epoch 892/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0872 - mse: 942.6450 - val_loss: 20.5687 - val_mse: 941.0472\n",
      "Epoch 893/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2436 - mse: 958.3357 - val_loss: 20.5630 - val_mse: 926.2448\n",
      "Epoch 894/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1579 - mse: 936.4038 - val_loss: 20.8650 - val_mse: 1000.4127\n",
      "Epoch 895/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2937 - mse: 960.6575 - val_loss: 20.5916 - val_mse: 915.7746\n",
      "Epoch 896/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0932 - mse: 948.2181 - val_loss: 20.6353 - val_mse: 963.6876\n",
      "Epoch 897/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0630 - mse: 947.0401 - val_loss: 20.6546 - val_mse: 967.6099\n",
      "Epoch 898/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1431 - mse: 935.7213 - val_loss: 20.5759 - val_mse: 920.6610\n",
      "Epoch 899/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0263 - mse: 940.1467 - val_loss: 20.5704 - val_mse: 942.0669\n",
      "Epoch 900/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1685 - mse: 950.0517 - val_loss: 20.5733 - val_mse: 921.6517\n",
      "Epoch 901/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1842 - mse: 935.4921 - val_loss: 20.8780 - val_mse: 1002.3500\n",
      "Epoch 902/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1863 - mse: 945.7598 - val_loss: 20.5712 - val_mse: 922.5131\n",
      "Epoch 903/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0158 - mse: 938.8303 - val_loss: 20.6294 - val_mse: 962.4675\n",
      "Epoch 904/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1223 - mse: 943.3034 - val_loss: 20.7143 - val_mse: 896.9750\n",
      "Epoch 905/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2772 - mse: 959.7980 - val_loss: 20.6804 - val_mse: 972.0904\n",
      "Epoch 906/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2460 - mse: 950.2401 - val_loss: 20.5809 - val_mse: 947.3281\n",
      "Epoch 907/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1308 - mse: 931.7291 - val_loss: 20.6236 - val_mse: 961.1594\n",
      "Epoch 908/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1045 - mse: 929.6423 - val_loss: 20.9837 - val_mse: 1017.2363\n",
      "Epoch 909/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2373 - mse: 962.5620 - val_loss: 20.6963 - val_mse: 898.7180\n",
      "Epoch 910/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0882 - mse: 929.1185 - val_loss: 20.6064 - val_mse: 956.4771\n",
      "Epoch 911/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2410 - mse: 949.2321 - val_loss: 20.5991 - val_mse: 954.2696\n",
      "Epoch 912/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1697 - mse: 941.3042 - val_loss: 20.5786 - val_mse: 946.3354\n",
      "Epoch 913/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2964 - mse: 964.9482 - val_loss: 20.5983 - val_mse: 914.0096\n",
      "Epoch 914/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.9725 - mse: 933.8500 - val_loss: 20.6046 - val_mse: 912.5794\n",
      "Epoch 915/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1237 - mse: 944.8677 - val_loss: 20.6521 - val_mse: 904.0386\n",
      "Epoch 916/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2650 - mse: 935.6749 - val_loss: 20.6130 - val_mse: 958.3898\n",
      "Epoch 917/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1960 - mse: 954.7905 - val_loss: 20.7372 - val_mse: 894.9462\n",
      "Epoch 918/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1555 - mse: 940.7799 - val_loss: 20.6451 - val_mse: 965.7223\n",
      "Epoch 919/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1662 - mse: 955.2406 - val_loss: 20.9888 - val_mse: 881.4167\n",
      "Epoch 920/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1943 - mse: 945.4558 - val_loss: 20.6548 - val_mse: 967.6389\n",
      "Epoch 921/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1166 - mse: 946.9301 - val_loss: 20.5755 - val_mse: 920.7982\n",
      "Epoch 922/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1227 - mse: 934.7667 - val_loss: 20.5613 - val_mse: 934.8440\n",
      "Epoch 923/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1456 - mse: 946.5799 - val_loss: 20.5605 - val_mse: 933.2480\n",
      "Epoch 924/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1123 - mse: 945.2235 - val_loss: 20.5961 - val_mse: 953.3085\n",
      "Epoch 925/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0652 - mse: 940.7736 - val_loss: 20.5934 - val_mse: 915.2842\n",
      "Epoch 926/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1202 - mse: 946.9313 - val_loss: 20.7930 - val_mse: 989.7421\n",
      "Epoch 927/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1942 - mse: 945.6630 - val_loss: 20.6061 - val_mse: 912.2361\n",
      "Epoch 928/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1964 - mse: 941.3876 - val_loss: 20.6411 - val_mse: 905.7098\n",
      "Epoch 929/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0488 - mse: 950.6371 - val_loss: 20.5599 - val_mse: 929.5458\n",
      "Epoch 930/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2559 - mse: 948.2300 - val_loss: 20.5618 - val_mse: 926.9366\n",
      "Epoch 931/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1937 - mse: 949.7642 - val_loss: 20.5878 - val_mse: 950.4083\n",
      "Epoch 932/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1970 - mse: 946.2944 - val_loss: 20.7846 - val_mse: 988.4643\n",
      "Epoch 933/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1493 - mse: 947.1148 - val_loss: 20.6173 - val_mse: 959.6119\n",
      "Epoch 934/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1638 - mse: 949.1131 - val_loss: 20.8032 - val_mse: 991.2928\n",
      "Epoch 935/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1156 - mse: 946.6698 - val_loss: 20.8759 - val_mse: 1002.0283\n",
      "Epoch 936/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0852 - mse: 948.2400 - val_loss: 20.6172 - val_mse: 959.5658\n",
      "Epoch 937/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0526 - mse: 940.6461 - val_loss: 20.5598 - val_mse: 931.0593\n",
      "Epoch 938/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1025 - mse: 952.8076 - val_loss: 20.6841 - val_mse: 972.7250\n",
      "Epoch 939/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1086 - mse: 935.9307 - val_loss: 20.6034 - val_mse: 955.5725\n",
      "Epoch 940/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0521 - mse: 945.8926 - val_loss: 20.6617 - val_mse: 968.8711\n",
      "Epoch 941/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1615 - mse: 946.9918 - val_loss: 20.5610 - val_mse: 927.6384\n",
      "Epoch 942/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.9463 - mse: 937.3214 - val_loss: 20.5662 - val_mse: 924.7042\n",
      "Epoch 943/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1905 - mse: 945.2740 - val_loss: 20.6456 - val_mse: 904.9850\n",
      "Epoch 944/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9390 - mse: 936.4434 - val_loss: 21.2247 - val_mse: 875.1578\n",
      "Epoch 945/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2168 - mse: 943.2730 - val_loss: 20.5737 - val_mse: 943.9077\n",
      "Epoch 946/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2465 - mse: 942.0308 - val_loss: 20.5925 - val_mse: 915.5185\n",
      "Epoch 947/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1921 - mse: 941.9091 - val_loss: 20.5801 - val_mse: 947.0066\n",
      "Epoch 948/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1248 - mse: 948.2871 - val_loss: 20.6333 - val_mse: 963.2894\n",
      "Epoch 949/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1431 - mse: 944.7105 - val_loss: 20.6893 - val_mse: 973.5902\n",
      "Epoch 950/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0758 - mse: 938.6302 - val_loss: 20.5998 - val_mse: 913.6523\n",
      "Epoch 951/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0924 - mse: 940.7114 - val_loss: 20.7416 - val_mse: 894.5748\n",
      "Epoch 952/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0967 - mse: 939.5179 - val_loss: 20.5898 - val_mse: 951.1883\n",
      "Epoch 953/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2054 - mse: 945.5827 - val_loss: 20.5691 - val_mse: 941.3083\n",
      "Epoch 954/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2352 - mse: 938.1833 - val_loss: 20.6744 - val_mse: 971.0767\n",
      "Epoch 955/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2579 - mse: 949.4812 - val_loss: 20.6056 - val_mse: 912.3644\n",
      "Epoch 956/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0553 - mse: 932.3121 - val_loss: 20.5895 - val_mse: 916.3271\n",
      "Epoch 957/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1180 - mse: 950.0347 - val_loss: 20.5613 - val_mse: 935.0071\n",
      "Epoch 958/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0833 - mse: 937.4117 - val_loss: 20.5863 - val_mse: 949.7952\n",
      "Epoch 959/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9978 - mse: 940.9868 - val_loss: 20.5815 - val_mse: 918.6402\n",
      "Epoch 960/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1864 - mse: 940.9071 - val_loss: 20.5605 - val_mse: 933.2062\n",
      "Epoch 961/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.9587 - mse: 931.8037 - val_loss: 20.5615 - val_mse: 935.2083\n",
      "Epoch 962/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1703 - mse: 946.9377 - val_loss: 20.6593 - val_mse: 968.4404\n",
      "Epoch 963/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.3866 - mse: 959.0240 - val_loss: 20.7453 - val_mse: 982.3356\n",
      "Epoch 964/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 20.9970 - mse: 936.5701 - val_loss: 20.5995 - val_mse: 954.4004\n",
      "Epoch 965/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0672 - mse: 952.5311 - val_loss: 20.5665 - val_mse: 924.5840\n",
      "Epoch 966/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1142 - mse: 941.8590 - val_loss: 20.5991 - val_mse: 954.2712\n",
      "Epoch 967/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1536 - mse: 948.2523 - val_loss: 20.5914 - val_mse: 915.8353\n",
      "Epoch 968/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2721 - mse: 951.1090 - val_loss: 20.6663 - val_mse: 969.6661\n",
      "Epoch 969/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0512 - mse: 935.7499 - val_loss: 20.6107 - val_mse: 957.7100\n",
      "Epoch 970/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1071 - mse: 939.4012 - val_loss: 20.5826 - val_mse: 948.1199\n",
      "Epoch 971/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0566 - mse: 938.5100 - val_loss: 20.6727 - val_mse: 970.7907\n",
      "Epoch 972/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0965 - mse: 934.9717 - val_loss: 20.5612 - val_mse: 934.7750\n",
      "Epoch 973/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1162 - mse: 945.8775 - val_loss: 20.8256 - val_mse: 994.6050\n",
      "Epoch 974/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1092 - mse: 956.8053 - val_loss: 20.7380 - val_mse: 894.8687\n",
      "Epoch 975/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2829 - mse: 949.0676 - val_loss: 20.5851 - val_mse: 949.2693\n",
      "Epoch 976/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.9649 - mse: 933.6100 - val_loss: 20.5888 - val_mse: 916.5160\n",
      "Epoch 977/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9628 - mse: 941.5916 - val_loss: 20.6027 - val_mse: 955.3762\n",
      "Epoch 978/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.9750 - mse: 935.5103 - val_loss: 20.5733 - val_mse: 921.6585\n",
      "Epoch 979/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0275 - mse: 933.9307 - val_loss: 20.6535 - val_mse: 967.3843\n",
      "Epoch 980/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1962 - mse: 943.4904 - val_loss: 20.6496 - val_mse: 904.3887\n",
      "Epoch 981/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1455 - mse: 946.2343 - val_loss: 20.6796 - val_mse: 971.9506\n",
      "Epoch 982/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1713 - mse: 948.9482 - val_loss: 20.6035 - val_mse: 955.6102\n",
      "Epoch 983/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1208 - mse: 937.6127 - val_loss: 20.8939 - val_mse: 1004.7375\n",
      "Epoch 984/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2640 - mse: 953.0921 - val_loss: 20.6656 - val_mse: 969.5362\n",
      "Epoch 985/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0807 - mse: 934.4987 - val_loss: 20.6765 - val_mse: 971.4297\n",
      "Epoch 986/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1525 - mse: 950.2248 - val_loss: 20.5709 - val_mse: 922.6431\n",
      "Epoch 987/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1671 - mse: 949.2394 - val_loss: 20.5914 - val_mse: 915.8276\n",
      "Epoch 988/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0510 - mse: 936.2581 - val_loss: 20.5638 - val_mse: 925.8233\n",
      "Epoch 989/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1694 - mse: 929.5961 - val_loss: 20.5943 - val_mse: 952.7346\n",
      "Epoch 990/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1502 - mse: 952.8696 - val_loss: 20.6571 - val_mse: 903.3294\n",
      "Epoch 991/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.3368 - mse: 951.4637 - val_loss: 20.5698 - val_mse: 923.1365\n",
      "Epoch 992/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2762 - mse: 956.9180 - val_loss: 20.5995 - val_mse: 954.3891\n",
      "Epoch 993/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2129 - mse: 947.1836 - val_loss: 20.5874 - val_mse: 916.8990\n",
      "Epoch 994/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0710 - mse: 944.7602 - val_loss: 20.5632 - val_mse: 937.0300\n",
      "Epoch 995/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1160 - mse: 943.5290 - val_loss: 20.5625 - val_mse: 936.3718\n",
      "Epoch 996/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1172 - mse: 937.8314 - val_loss: 20.5607 - val_mse: 927.9823\n",
      "Epoch 997/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1955 - mse: 944.3853 - val_loss: 20.5680 - val_mse: 940.6087\n",
      "Epoch 998/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0962 - mse: 940.8205 - val_loss: 20.5816 - val_mse: 918.5967\n",
      "Epoch 999/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2571 - mse: 948.7611 - val_loss: 20.6091 - val_mse: 957.2849\n",
      "Epoch 1000/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1385 - mse: 945.9266 - val_loss: 20.5839 - val_mse: 917.8732\n",
      "Epoch 1001/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1678 - mse: 945.7573 - val_loss: 20.5838 - val_mse: 948.6718\n",
      "Epoch 1002/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0468 - mse: 938.3631 - val_loss: 20.6249 - val_mse: 908.4496\n",
      "Epoch 1003/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1054 - mse: 943.5543 - val_loss: 20.9185 - val_mse: 1008.2915\n",
      "Epoch 1004/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1805 - mse: 938.7618 - val_loss: 20.6221 - val_mse: 908.9683\n",
      "Epoch 1005/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1319 - mse: 952.0547 - val_loss: 20.5623 - val_mse: 926.6218\n",
      "Epoch 1006/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.3003 - mse: 947.5261 - val_loss: 20.5616 - val_mse: 935.4307\n",
      "Epoch 1007/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1142 - mse: 943.5728 - val_loss: 20.6449 - val_mse: 905.0865\n",
      "Epoch 1008/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0500 - mse: 938.1160 - val_loss: 20.5604 - val_mse: 928.3154\n",
      "Epoch 1009/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1237 - mse: 931.6956 - val_loss: 20.5615 - val_mse: 927.0876\n",
      "Epoch 1010/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1810 - mse: 944.8975 - val_loss: 20.5658 - val_mse: 939.1124\n",
      "Epoch 1011/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1085 - mse: 941.0697 - val_loss: 20.6498 - val_mse: 966.6699\n",
      "Epoch 1012/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0907 - mse: 942.5380 - val_loss: 20.6017 - val_mse: 955.0831\n",
      "Epoch 1013/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1721 - mse: 946.4056 - val_loss: 20.6000 - val_mse: 954.5691\n",
      "Epoch 1014/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1588 - mse: 942.9631 - val_loss: 20.5618 - val_mse: 926.8826\n",
      "Epoch 1015/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1943 - mse: 938.1995 - val_loss: 20.6309 - val_mse: 962.7927\n",
      "Epoch 1016/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0971 - mse: 936.0469 - val_loss: 20.5598 - val_mse: 930.3829\n",
      "Epoch 1017/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0801 - mse: 944.2024 - val_loss: 20.6199 - val_mse: 960.2785\n",
      "Epoch 1018/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2394 - mse: 941.9344 - val_loss: 20.6162 - val_mse: 959.3248\n",
      "Epoch 1019/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2603 - mse: 958.3742 - val_loss: 20.5921 - val_mse: 952.0071\n",
      "Epoch 1020/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0169 - mse: 934.4240 - val_loss: 20.5611 - val_mse: 934.5696\n",
      "Epoch 1021/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1627 - mse: 939.8066 - val_loss: 20.5783 - val_mse: 946.1809\n",
      "Epoch 1022/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1957 - mse: 951.2844 - val_loss: 20.5898 - val_mse: 916.2361\n",
      "Epoch 1023/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1279 - mse: 938.1001 - val_loss: 20.5599 - val_mse: 929.4545\n",
      "Epoch 1024/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2788 - mse: 951.5703 - val_loss: 20.7271 - val_mse: 979.5215\n",
      "Epoch 1025/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1224 - mse: 942.4009 - val_loss: 20.8566 - val_mse: 999.1641\n",
      "Epoch 1026/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0372 - mse: 949.0018 - val_loss: 20.6488 - val_mse: 904.5108\n",
      "Epoch 1027/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2132 - mse: 943.1600 - val_loss: 20.6630 - val_mse: 969.0889\n",
      "Epoch 1028/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1741 - mse: 959.0833 - val_loss: 20.5675 - val_mse: 924.1478\n",
      "Epoch 1029/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0490 - mse: 941.2074 - val_loss: 20.6106 - val_mse: 911.2697\n",
      "Epoch 1030/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0528 - mse: 938.9910 - val_loss: 20.7959 - val_mse: 890.5696\n",
      "Epoch 1031/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1935 - mse: 934.3538 - val_loss: 20.5606 - val_mse: 928.0627\n",
      "Epoch 1032/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1628 - mse: 941.3612 - val_loss: 20.9294 - val_mse: 1009.7925\n",
      "Epoch 1033/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1998 - mse: 944.9230 - val_loss: 20.8227 - val_mse: 994.1671\n",
      "Epoch 1034/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1802 - mse: 946.5257 - val_loss: 20.5705 - val_mse: 942.1581\n",
      "Epoch 1035/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1934 - mse: 941.7176 - val_loss: 20.6750 - val_mse: 971.1760\n",
      "Epoch 1036/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1859 - mse: 961.0078 - val_loss: 21.1195 - val_mse: 1033.4043\n",
      "Epoch 1037/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2371 - mse: 950.3026 - val_loss: 20.5748 - val_mse: 944.5139\n",
      "Epoch 1038/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1402 - mse: 950.3807 - val_loss: 20.6731 - val_mse: 970.8495\n",
      "Epoch 1039/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.1636 - mse: 932.0202 - val_loss: 20.6668 - val_mse: 969.7568\n",
      "Epoch 1040/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1736 - mse: 958.3746 - val_loss: 20.5757 - val_mse: 920.7309\n",
      "Epoch 1041/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1199 - mse: 938.7711 - val_loss: 20.5598 - val_mse: 930.1823\n",
      "Epoch 1042/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2057 - mse: 947.1722 - val_loss: 20.7181 - val_mse: 978.1319\n",
      "Epoch 1043/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.2601 - mse: 944.9547 - val_loss: 20.5598 - val_mse: 931.5638\n",
      "Epoch 1044/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1397 - mse: 948.5980 - val_loss: 20.5625 - val_mse: 936.3638\n",
      "Epoch 1045/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0264 - mse: 928.5874 - val_loss: 20.5760 - val_mse: 945.0950\n",
      "Epoch 1046/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0465 - mse: 937.4973 - val_loss: 20.6551 - val_mse: 967.6929\n",
      "Epoch 1047/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0737 - mse: 951.1639 - val_loss: 20.5616 - val_mse: 935.3795\n",
      "Epoch 1048/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1441 - mse: 936.4324 - val_loss: 20.6942 - val_mse: 974.3873\n",
      "Epoch 1049/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0125 - mse: 938.5048 - val_loss: 20.5598 - val_mse: 930.9546\n",
      "Epoch 1050/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2347 - mse: 946.3404 - val_loss: 20.7956 - val_mse: 990.1315\n",
      "Epoch 1051/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1859 - mse: 944.2855 - val_loss: 20.5672 - val_mse: 940.1014\n",
      "Epoch 1052/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1622 - mse: 945.6060 - val_loss: 20.6183 - val_mse: 909.6937\n",
      "Epoch 1053/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0331 - mse: 946.4152 - val_loss: 20.5634 - val_mse: 926.0133\n",
      "Epoch 1054/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1659 - mse: 945.6004 - val_loss: 20.5683 - val_mse: 940.8435\n",
      "Epoch 1055/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0849 - mse: 934.2592 - val_loss: 20.7218 - val_mse: 978.7014\n",
      "Epoch 1056/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1378 - mse: 944.2211 - val_loss: 20.7321 - val_mse: 980.2940\n",
      "Epoch 1057/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1315 - mse: 948.0877 - val_loss: 20.8568 - val_mse: 999.1896\n",
      "Epoch 1058/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1408 - mse: 945.0925 - val_loss: 20.5894 - val_mse: 916.3765\n",
      "Epoch 1059/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1640 - mse: 949.8328 - val_loss: 20.5606 - val_mse: 933.4678\n",
      "Epoch 1060/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0264 - mse: 931.8616 - val_loss: 21.0596 - val_mse: 1026.7607\n",
      "Epoch 1061/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9600 - mse: 948.5081 - val_loss: 20.5598 - val_mse: 930.6136\n",
      "Epoch 1062/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1667 - mse: 948.9647 - val_loss: 20.6068 - val_mse: 912.0840\n",
      "Epoch 1063/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2805 - mse: 946.2945 - val_loss: 20.5682 - val_mse: 923.8164\n",
      "Epoch 1064/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1842 - mse: 943.5368 - val_loss: 20.7352 - val_mse: 980.7831\n",
      "Epoch 1065/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2642 - mse: 951.5759 - val_loss: 20.9339 - val_mse: 1010.4172\n",
      "Epoch 1066/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.2252 - mse: 947.2364 - val_loss: 21.1380 - val_mse: 1035.4124\n",
      "Epoch 1067/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1432 - mse: 943.4103 - val_loss: 20.5606 - val_mse: 928.0699\n",
      "Epoch 1068/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1296 - mse: 949.8610 - val_loss: 20.6284 - val_mse: 907.8123\n",
      "Epoch 1069/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1126 - mse: 944.4042 - val_loss: 20.7283 - val_mse: 979.7274\n",
      "Epoch 1070/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0454 - mse: 926.9921 - val_loss: 20.5709 - val_mse: 942.3674\n",
      "Epoch 1071/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0892 - mse: 953.8671 - val_loss: 20.6062 - val_mse: 912.2033\n",
      "Epoch 1072/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.1251 - mse: 929.1392 - val_loss: 20.8756 - val_mse: 1001.9912\n",
      "Epoch 1073/5000\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 21.0358 - mse: 926.8162 - val_loss: 20.5733 - val_mse: 921.6544\n",
      "Epoch 1074/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1451 - mse: 946.5776 - val_loss: 20.5608 - val_mse: 927.8945\n",
      "Epoch 1075/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1767 - mse: 959.1565 - val_loss: 20.6069 - val_mse: 956.6302\n",
      "Epoch 1076/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1174 - mse: 941.9314 - val_loss: 20.6303 - val_mse: 962.6565\n",
      "Epoch 1077/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0970 - mse: 945.3101 - val_loss: 20.5641 - val_mse: 937.7397\n",
      "Epoch 1078/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.3027 - mse: 951.2700 - val_loss: 20.5638 - val_mse: 937.5342\n",
      "Epoch 1079/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1000 - mse: 954.4422 - val_loss: 20.5760 - val_mse: 920.6127\n",
      "Epoch 1080/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1516 - mse: 936.2612 - val_loss: 20.5614 - val_mse: 935.1530\n",
      "Epoch 1081/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1767 - mse: 943.2460 - val_loss: 20.5613 - val_mse: 927.2742\n",
      "Epoch 1082/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1927 - mse: 951.0267 - val_loss: 20.5610 - val_mse: 927.6192\n",
      "Epoch 1083/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1032 - mse: 933.1360 - val_loss: 20.5757 - val_mse: 920.7106\n",
      "Epoch 1084/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0152 - mse: 929.2878 - val_loss: 20.5630 - val_mse: 936.8364\n",
      "Epoch 1085/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0819 - mse: 937.6619 - val_loss: 20.5733 - val_mse: 921.6329\n",
      "Epoch 1086/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.9190 - mse: 938.1960 - val_loss: 20.5984 - val_mse: 954.0650\n",
      "Epoch 1087/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1794 - mse: 954.7323 - val_loss: 20.5599 - val_mse: 929.6286\n",
      "Epoch 1088/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1573 - mse: 939.4525 - val_loss: 20.5629 - val_mse: 926.3135\n",
      "Epoch 1089/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0831 - mse: 946.3621 - val_loss: 20.5601 - val_mse: 929.1335\n",
      "Epoch 1090/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0749 - mse: 928.6700 - val_loss: 20.8873 - val_mse: 1003.7325\n",
      "Epoch 1091/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.2025 - mse: 953.4224 - val_loss: 20.5661 - val_mse: 939.2938\n",
      "Epoch 1092/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9681 - mse: 920.6300 - val_loss: 20.5674 - val_mse: 940.2415\n",
      "Epoch 1093/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2295 - mse: 942.8406 - val_loss: 20.5846 - val_mse: 917.6423\n",
      "Epoch 1094/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0501 - mse: 931.9586 - val_loss: 20.6324 - val_mse: 907.1351\n",
      "Epoch 1095/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1014 - mse: 937.4664 - val_loss: 20.5859 - val_mse: 949.6365\n",
      "Epoch 1096/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0841 - mse: 944.1590 - val_loss: 20.6239 - val_mse: 961.2209\n",
      "Epoch 1097/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1132 - mse: 941.9828 - val_loss: 20.5847 - val_mse: 949.0620\n",
      "Epoch 1098/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1462 - mse: 957.0138 - val_loss: 20.5807 - val_mse: 918.9321\n",
      "Epoch 1099/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1203 - mse: 935.7805 - val_loss: 20.6871 - val_mse: 899.6567\n",
      "Epoch 1100/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2834 - mse: 956.6292 - val_loss: 20.6144 - val_mse: 910.4568\n",
      "Epoch 1101/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1288 - mse: 939.5282 - val_loss: 20.7470 - val_mse: 894.1212\n",
      "Epoch 1102/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0667 - mse: 945.6814 - val_loss: 20.5849 - val_mse: 949.1924\n",
      "Epoch 1103/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1180 - mse: 947.9885 - val_loss: 20.6348 - val_mse: 963.6007\n",
      "Epoch 1104/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1067 - mse: 938.2328 - val_loss: 20.5598 - val_mse: 931.1167\n",
      "Epoch 1105/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1898 - mse: 941.5931 - val_loss: 20.7819 - val_mse: 988.0618\n",
      "Epoch 1106/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1318 - mse: 950.5639 - val_loss: 20.5939 - val_mse: 915.1552\n",
      "Epoch 1107/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0773 - mse: 940.7285 - val_loss: 20.5599 - val_mse: 929.8505\n",
      "Epoch 1108/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0795 - mse: 945.1479 - val_loss: 20.8239 - val_mse: 994.3446\n",
      "Epoch 1109/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.2826 - mse: 952.6838 - val_loss: 20.5610 - val_mse: 927.5609\n",
      "Epoch 1110/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1643 - mse: 947.5582 - val_loss: 20.6157 - val_mse: 959.1796\n",
      "Epoch 1111/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0251 - mse: 939.9788 - val_loss: 20.6687 - val_mse: 970.0910\n",
      "Epoch 1112/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1194 - mse: 954.7817 - val_loss: 20.5615 - val_mse: 927.1097\n",
      "Epoch 1113/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1396 - mse: 936.0006 - val_loss: 20.5614 - val_mse: 935.1772\n",
      "Epoch 1114/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0334 - mse: 932.4536 - val_loss: 20.5637 - val_mse: 937.4612\n",
      "Epoch 1115/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1359 - mse: 945.4430 - val_loss: 20.6458 - val_mse: 965.8789\n",
      "Epoch 1116/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0304 - mse: 938.4683 - val_loss: 20.6611 - val_mse: 968.7650\n",
      "Epoch 1117/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1557 - mse: 930.2506 - val_loss: 20.6714 - val_mse: 970.5571\n",
      "Epoch 1118/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.1560 - mse: 954.1105 - val_loss: 20.7425 - val_mse: 981.9137\n",
      "Epoch 1119/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1079 - mse: 943.9111 - val_loss: 20.6795 - val_mse: 971.9464\n",
      "Epoch 1120/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0869 - mse: 949.2012 - val_loss: 20.5782 - val_mse: 946.1533\n",
      "Epoch 1121/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.2144 - mse: 939.6823 - val_loss: 20.5652 - val_mse: 925.1473\n",
      "Epoch 1122/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0867 - mse: 945.7809 - val_loss: 20.5602 - val_mse: 928.8829\n",
      "Epoch 1123/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1063 - mse: 938.1340 - val_loss: 20.8239 - val_mse: 994.3458\n",
      "Epoch 1124/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1653 - mse: 943.4812 - val_loss: 20.5946 - val_mse: 914.9656\n",
      "Epoch 1125/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1645 - mse: 955.9172 - val_loss: 20.5673 - val_mse: 924.2081\n",
      "Epoch 1126/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0973 - mse: 939.0708 - val_loss: 20.5852 - val_mse: 949.3215\n",
      "Epoch 1127/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.1127 - mse: 941.7869 - val_loss: 20.5683 - val_mse: 940.8574\n",
      "Epoch 1128/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1921 - mse: 949.1326 - val_loss: 21.1028 - val_mse: 1031.5691\n",
      "Epoch 1129/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1250 - mse: 942.0877 - val_loss: 20.5754 - val_mse: 944.8138\n",
      "Epoch 1130/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0436 - mse: 934.2987 - val_loss: 20.5860 - val_mse: 949.6935\n",
      "Epoch 1131/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0945 - mse: 943.1243 - val_loss: 20.7845 - val_mse: 988.4506\n",
      "Epoch 1132/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1266 - mse: 944.6155 - val_loss: 20.5988 - val_mse: 913.8749\n",
      "Epoch 1133/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0988 - mse: 937.2905 - val_loss: 21.0414 - val_mse: 1024.6262\n",
      "Epoch 1134/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1631 - mse: 955.9745 - val_loss: 20.5642 - val_mse: 937.8542\n",
      "Epoch 1135/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.2401 - mse: 941.4513 - val_loss: 20.8692 - val_mse: 1001.0383\n",
      "Epoch 1136/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2050 - mse: 952.6978 - val_loss: 20.5878 - val_mse: 916.7701\n",
      "Epoch 1137/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0269 - mse: 932.3483 - val_loss: 20.5605 - val_mse: 928.2431\n",
      "Epoch 1138/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0061 - mse: 927.0968 - val_loss: 20.6663 - val_mse: 969.6672\n",
      "Epoch 1139/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1968 - mse: 955.4335 - val_loss: 20.5826 - val_mse: 948.1459\n",
      "Epoch 1140/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0023 - mse: 937.0679 - val_loss: 20.5631 - val_mse: 926.1526\n",
      "Epoch 1141/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0411 - mse: 930.8588 - val_loss: 20.9056 - val_mse: 1006.4658\n",
      "Epoch 1142/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0724 - mse: 941.9293 - val_loss: 20.5709 - val_mse: 942.3907\n",
      "Epoch 1143/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0719 - mse: 951.5812 - val_loss: 20.7146 - val_mse: 896.9335\n",
      "Epoch 1144/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.3456 - mse: 932.1842 - val_loss: 20.5604 - val_mse: 928.4493\n",
      "Epoch 1145/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0353 - mse: 940.2523 - val_loss: 20.5703 - val_mse: 942.0583\n",
      "Epoch 1146/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2630 - mse: 950.5989 - val_loss: 20.5698 - val_mse: 923.1064\n",
      "Epoch 1147/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0059 - mse: 928.9993 - val_loss: 20.7233 - val_mse: 978.9382\n",
      "Epoch 1148/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1006 - mse: 946.8272 - val_loss: 20.6416 - val_mse: 905.6284\n",
      "Epoch 1149/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1246 - mse: 943.8689 - val_loss: 20.5723 - val_mse: 943.1725\n",
      "Epoch 1150/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1061 - mse: 942.2181 - val_loss: 21.1050 - val_mse: 1031.8140\n",
      "Epoch 1151/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2044 - mse: 952.5037 - val_loss: 20.6859 - val_mse: 899.7809\n",
      "Epoch 1152/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.1183 - mse: 940.8486 - val_loss: 20.5665 - val_mse: 939.6325\n",
      "Epoch 1153/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1681 - mse: 947.0259 - val_loss: 20.5599 - val_mse: 929.9650\n",
      "Epoch 1154/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1364 - mse: 937.2706 - val_loss: 20.5698 - val_mse: 923.1304\n",
      "Epoch 1155/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1518 - mse: 948.5686 - val_loss: 20.6769 - val_mse: 971.5079\n",
      "Epoch 1156/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1115 - mse: 940.7535 - val_loss: 20.5687 - val_mse: 941.0823\n",
      "Epoch 1157/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1534 - mse: 943.9319 - val_loss: 20.7643 - val_mse: 985.3134\n",
      "Epoch 1158/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1532 - mse: 950.5248 - val_loss: 20.5862 - val_mse: 949.7738\n",
      "Epoch 1159/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1257 - mse: 930.9499 - val_loss: 20.9103 - val_mse: 1007.1431\n",
      "Epoch 1160/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0043 - mse: 946.4415 - val_loss: 20.8302 - val_mse: 995.2820\n",
      "Epoch 1161/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1763 - mse: 952.9565 - val_loss: 20.5982 - val_mse: 914.0058\n",
      "Epoch 1162/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.8886 - mse: 930.6196 - val_loss: 20.7436 - val_mse: 894.4000\n",
      "Epoch 1163/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0645 - mse: 935.7145 - val_loss: 20.6183 - val_mse: 909.6934\n",
      "Epoch 1164/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0605 - mse: 937.3971 - val_loss: 20.7201 - val_mse: 978.4425\n",
      "Epoch 1165/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.3066 - mse: 957.2878 - val_loss: 20.5627 - val_mse: 926.4366\n",
      "Epoch 1166/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0822 - mse: 943.7383 - val_loss: 20.5964 - val_mse: 914.5002\n",
      "Epoch 1167/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1908 - mse: 947.9123 - val_loss: 20.5614 - val_mse: 935.0642\n",
      "Epoch 1168/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0935 - mse: 937.2501 - val_loss: 20.6567 - val_mse: 967.9995\n",
      "Epoch 1169/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0497 - mse: 942.2571 - val_loss: 20.8274 - val_mse: 994.8672\n",
      "Epoch 1170/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0758 - mse: 945.5950 - val_loss: 20.6457 - val_mse: 965.8392\n",
      "Epoch 1171/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0328 - mse: 940.0262 - val_loss: 20.5640 - val_mse: 937.6677\n",
      "Epoch 1172/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0374 - mse: 939.1396 - val_loss: 20.6027 - val_mse: 955.3950\n",
      "Epoch 1173/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1139 - mse: 944.5551 - val_loss: 20.5606 - val_mse: 928.0785\n",
      "Epoch 1174/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0333 - mse: 933.1000 - val_loss: 20.5777 - val_mse: 919.9747\n",
      "Epoch 1175/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0780 - mse: 942.7260 - val_loss: 20.6593 - val_mse: 968.4413\n",
      "Epoch 1176/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0938 - mse: 948.2694 - val_loss: 20.7169 - val_mse: 977.9417\n",
      "Epoch 1177/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1014 - mse: 944.9708 - val_loss: 20.6040 - val_mse: 955.7626\n",
      "Epoch 1178/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1159 - mse: 943.9086 - val_loss: 20.5638 - val_mse: 925.8061\n",
      "Epoch 1179/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1140 - mse: 933.3348 - val_loss: 20.6148 - val_mse: 958.9190\n",
      "Epoch 1180/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2764 - mse: 960.2131 - val_loss: 20.6268 - val_mse: 908.1342\n",
      "Epoch 1181/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0729 - mse: 934.6302 - val_loss: 20.6404 - val_mse: 964.7556\n",
      "Epoch 1182/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0854 - mse: 955.9315 - val_loss: 20.6497 - val_mse: 904.3856\n",
      "Epoch 1183/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.9546 - mse: 934.5128 - val_loss: 20.6513 - val_mse: 966.9506\n",
      "Epoch 1184/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2492 - mse: 959.5043 - val_loss: 20.5693 - val_mse: 941.4294\n",
      "Epoch 1185/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0561 - mse: 943.0453 - val_loss: 20.5625 - val_mse: 926.5306\n",
      "Epoch 1186/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0776 - mse: 929.4854 - val_loss: 20.5622 - val_mse: 936.1168\n",
      "Epoch 1187/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1360 - mse: 943.1095 - val_loss: 20.6048 - val_mse: 956.0113\n",
      "Epoch 1188/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.9711 - mse: 940.3104 - val_loss: 20.6087 - val_mse: 957.1504\n",
      "Epoch 1189/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1818 - mse: 938.6306 - val_loss: 20.5779 - val_mse: 919.9020\n",
      "Epoch 1190/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0402 - mse: 940.1157 - val_loss: 20.5751 - val_mse: 944.6821\n",
      "Epoch 1191/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.2093 - mse: 944.2405 - val_loss: 20.5723 - val_mse: 922.0479\n",
      "Epoch 1192/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0574 - mse: 943.1749 - val_loss: 20.5650 - val_mse: 938.4381\n",
      "Epoch 1193/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1356 - mse: 941.2637 - val_loss: 20.6368 - val_mse: 906.4067\n",
      "Epoch 1194/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0922 - mse: 947.5178 - val_loss: 20.5599 - val_mse: 930.0974\n",
      "Epoch 1195/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.2077 - mse: 950.7305 - val_loss: 20.6522 - val_mse: 904.0150\n",
      "Epoch 1196/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0400 - mse: 937.1677 - val_loss: 20.5608 - val_mse: 933.8558\n",
      "Epoch 1197/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0497 - mse: 935.7709 - val_loss: 20.6072 - val_mse: 956.7296\n",
      "Epoch 1198/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1385 - mse: 943.6277 - val_loss: 20.5748 - val_mse: 921.0460\n",
      "Epoch 1199/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0450 - mse: 933.3234 - val_loss: 20.6124 - val_mse: 910.8790\n",
      "Epoch 1200/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1016 - mse: 936.2916 - val_loss: 20.7732 - val_mse: 892.1314\n",
      "Epoch 1201/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0810 - mse: 951.7838 - val_loss: 20.6372 - val_mse: 964.0931\n",
      "Epoch 1202/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1704 - mse: 949.8548 - val_loss: 20.5967 - val_mse: 914.4197\n",
      "Epoch 1203/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2015 - mse: 949.7820 - val_loss: 20.6053 - val_mse: 956.1391\n",
      "Epoch 1204/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1591 - mse: 943.8020 - val_loss: 20.5879 - val_mse: 916.7672\n",
      "Epoch 1205/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1516 - mse: 942.8030 - val_loss: 20.5905 - val_mse: 951.4420\n",
      "Epoch 1206/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0545 - mse: 930.6841 - val_loss: 20.5642 - val_mse: 925.6052\n",
      "Epoch 1207/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.2054 - mse: 948.3859 - val_loss: 21.0611 - val_mse: 879.0551\n",
      "Epoch 1208/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1102 - mse: 938.9941 - val_loss: 20.6191 - val_mse: 960.0771\n",
      "Epoch 1209/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.2403 - mse: 946.0793 - val_loss: 20.5712 - val_mse: 942.5156\n",
      "Epoch 1210/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1205 - mse: 942.4071 - val_loss: 20.6066 - val_mse: 912.1213\n",
      "Epoch 1211/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0752 - mse: 943.5410 - val_loss: 20.5806 - val_mse: 947.2319\n",
      "Epoch 1212/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1333 - mse: 954.0079 - val_loss: 20.5649 - val_mse: 925.2794\n",
      "Epoch 1213/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0326 - mse: 938.7518 - val_loss: 20.5691 - val_mse: 941.3059\n",
      "Epoch 1214/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0686 - mse: 932.1250 - val_loss: 20.6628 - val_mse: 969.0627\n",
      "Epoch 1215/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1297 - mse: 963.2529 - val_loss: 20.5660 - val_mse: 924.8016\n",
      "Epoch 1216/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0859 - mse: 931.4480 - val_loss: 20.5642 - val_mse: 937.8087\n",
      "Epoch 1217/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.4265 - mse: 965.7425 - val_loss: 21.0632 - val_mse: 1027.1687\n",
      "Epoch 1218/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1048 - mse: 955.4188 - val_loss: 20.5871 - val_mse: 916.9810\n",
      "Epoch 1219/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0527 - mse: 941.8633 - val_loss: 20.5693 - val_mse: 941.3942\n",
      "Epoch 1220/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9680 - mse: 943.5450 - val_loss: 20.5599 - val_mse: 930.6825\n",
      "Epoch 1221/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0342 - mse: 929.1212 - val_loss: 20.5986 - val_mse: 913.9305\n",
      "Epoch 1222/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.9812 - mse: 941.0671 - val_loss: 20.6098 - val_mse: 911.4361\n",
      "Epoch 1223/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1597 - mse: 938.1104 - val_loss: 20.6591 - val_mse: 903.0419\n",
      "Epoch 1224/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0081 - mse: 943.0510 - val_loss: 20.7549 - val_mse: 983.8391\n",
      "Epoch 1225/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0958 - mse: 944.2575 - val_loss: 20.5723 - val_mse: 943.1602\n",
      "Epoch 1226/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0889 - mse: 947.2638 - val_loss: 20.6325 - val_mse: 907.1259\n",
      "Epoch 1227/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1299 - mse: 941.0502 - val_loss: 20.5638 - val_mse: 937.5107\n",
      "Epoch 1228/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1150 - mse: 934.7921 - val_loss: 20.6793 - val_mse: 971.9058\n",
      "Epoch 1229/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.3177 - mse: 957.7698 - val_loss: 21.2016 - val_mse: 1042.1473\n",
      "Epoch 1230/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1318 - mse: 932.2006 - val_loss: 20.5994 - val_mse: 913.7379\n",
      "Epoch 1231/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1106 - mse: 946.2127 - val_loss: 20.7251 - val_mse: 979.2142\n",
      "Epoch 1232/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0869 - mse: 938.7043 - val_loss: 20.5683 - val_mse: 940.8522\n",
      "Epoch 1233/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0605 - mse: 937.0956 - val_loss: 20.6191 - val_mse: 960.0765\n",
      "Epoch 1234/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0406 - mse: 941.7846 - val_loss: 20.6252 - val_mse: 908.3975\n",
      "Epoch 1235/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0798 - mse: 941.9672 - val_loss: 20.6117 - val_mse: 958.0377\n",
      "Epoch 1236/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0140 - mse: 939.8635 - val_loss: 20.5861 - val_mse: 949.7136\n",
      "Epoch 1237/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0642 - mse: 933.4127 - val_loss: 20.6070 - val_mse: 912.0266\n",
      "Epoch 1238/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0214 - mse: 932.0251 - val_loss: 20.6101 - val_mse: 911.3630\n",
      "Epoch 1239/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0024 - mse: 936.5827 - val_loss: 20.5611 - val_mse: 934.5627\n",
      "Epoch 1240/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1330 - mse: 940.3681 - val_loss: 20.5720 - val_mse: 922.1439\n",
      "Epoch 1241/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1544 - mse: 939.2348 - val_loss: 20.5949 - val_mse: 952.9244\n",
      "Epoch 1242/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0714 - mse: 944.2440 - val_loss: 20.8393 - val_mse: 996.6205\n",
      "Epoch 1243/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0673 - mse: 934.5334 - val_loss: 20.5823 - val_mse: 918.3900\n",
      "Epoch 1244/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0434 - mse: 941.1459 - val_loss: 20.6282 - val_mse: 907.8538\n",
      "Epoch 1245/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0475 - mse: 939.6829 - val_loss: 20.5721 - val_mse: 943.0530\n",
      "Epoch 1246/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.1124 - mse: 938.5002 - val_loss: 20.6662 - val_mse: 969.6493\n",
      "Epoch 1247/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1655 - mse: 944.3999 - val_loss: 20.5604 - val_mse: 932.9961\n",
      "Epoch 1248/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0620 - mse: 941.0102 - val_loss: 20.5690 - val_mse: 923.4816\n",
      "Epoch 1249/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0071 - mse: 929.9097 - val_loss: 20.5630 - val_mse: 926.2362\n",
      "Epoch 1250/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0709 - mse: 945.0591 - val_loss: 20.5944 - val_mse: 952.7480\n",
      "Epoch 1251/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1182 - mse: 938.2951 - val_loss: 20.5604 - val_mse: 933.1113\n",
      "Epoch 1252/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9763 - mse: 933.2586 - val_loss: 20.5602 - val_mse: 928.9156\n",
      "Epoch 1253/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0564 - mse: 942.7905 - val_loss: 20.5960 - val_mse: 953.2825\n",
      "Epoch 1254/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0677 - mse: 942.5162 - val_loss: 20.5891 - val_mse: 950.9276\n",
      "Epoch 1255/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0913 - mse: 939.7967 - val_loss: 20.5674 - val_mse: 924.1898\n",
      "Epoch 1256/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1349 - mse: 936.5599 - val_loss: 20.5673 - val_mse: 940.1548\n",
      "Epoch 1257/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.2440 - mse: 949.9529 - val_loss: 20.6806 - val_mse: 900.3782\n",
      "Epoch 1258/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.1511 - mse: 947.4368 - val_loss: 20.5846 - val_mse: 949.0541\n",
      "Epoch 1259/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0774 - mse: 927.8260 - val_loss: 20.6287 - val_mse: 962.3013\n",
      "Epoch 1260/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1637 - mse: 949.5862 - val_loss: 20.5896 - val_mse: 951.0956\n",
      "Epoch 1261/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.1990 - mse: 948.2828 - val_loss: 20.5648 - val_mse: 925.3125\n",
      "Epoch 1262/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1558 - mse: 938.8322 - val_loss: 20.7556 - val_mse: 983.9523\n",
      "Epoch 1263/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9967 - mse: 938.4507 - val_loss: 20.5619 - val_mse: 935.8192\n",
      "Epoch 1264/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9210 - mse: 933.1354 - val_loss: 20.5599 - val_mse: 930.1261\n",
      "Epoch 1265/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1152 - mse: 946.5870 - val_loss: 20.6365 - val_mse: 963.9544\n",
      "Epoch 1266/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.2344 - mse: 946.8921 - val_loss: 20.6648 - val_mse: 969.4038\n",
      "Epoch 1267/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1301 - mse: 942.2682 - val_loss: 20.6358 - val_mse: 963.8050\n",
      "Epoch 1268/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0694 - mse: 940.6371 - val_loss: 20.5871 - val_mse: 916.9700\n",
      "Epoch 1269/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1612 - mse: 943.6448 - val_loss: 20.6716 - val_mse: 901.4301\n",
      "Epoch 1270/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0548 - mse: 942.2720 - val_loss: 20.5827 - val_mse: 948.1766\n",
      "Epoch 1271/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9988 - mse: 945.7701 - val_loss: 20.5827 - val_mse: 948.1865\n",
      "Epoch 1272/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0727 - mse: 941.4561 - val_loss: 20.5939 - val_mse: 952.5810\n",
      "Epoch 1273/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0616 - mse: 945.6422 - val_loss: 20.5684 - val_mse: 940.8575\n",
      "Epoch 1274/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1577 - mse: 945.1730 - val_loss: 20.5957 - val_mse: 953.1940\n",
      "Epoch 1275/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0172 - mse: 944.2921 - val_loss: 20.5825 - val_mse: 948.0865\n",
      "Epoch 1276/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 21.0733 - mse: 930.4499 - val_loss: 20.7122 - val_mse: 977.2067\n",
      "Epoch 1277/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0638 - mse: 942.8228 - val_loss: 20.6713 - val_mse: 901.4615\n",
      "Epoch 1278/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.1724 - mse: 933.4222 - val_loss: 20.5871 - val_mse: 950.1187\n",
      "Epoch 1279/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0598 - mse: 946.8581 - val_loss: 20.5638 - val_mse: 937.4907\n",
      "Epoch 1280/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1120 - mse: 941.9764 - val_loss: 20.5915 - val_mse: 915.8023\n",
      "Epoch 1281/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 21.2003 - mse: 950.9198 - val_loss: 20.5895 - val_mse: 916.3417\n",
      "Epoch 1282/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.1636 - mse: 934.5430 - val_loss: 20.5798 - val_mse: 946.8365\n",
      "Epoch 1283/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0369 - mse: 946.9066 - val_loss: 20.8792 - val_mse: 1002.5220\n",
      "Epoch 1284/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.2641 - mse: 956.3839 - val_loss: 20.5814 - val_mse: 918.6854\n",
      "Epoch 1285/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.9793 - mse: 924.5931 - val_loss: 20.7746 - val_mse: 986.9211\n",
      "Epoch 1286/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0624 - mse: 947.8746 - val_loss: 20.7211 - val_mse: 978.5933\n",
      "Epoch 1287/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0538 - mse: 934.7982 - val_loss: 20.5606 - val_mse: 933.3585\n",
      "Epoch 1288/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1307 - mse: 949.5018 - val_loss: 20.5634 - val_mse: 926.0078\n",
      "Epoch 1289/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1369 - mse: 951.2938 - val_loss: 20.6504 - val_mse: 904.2863\n",
      "Epoch 1290/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1364 - mse: 927.1088 - val_loss: 20.5866 - val_mse: 949.9373\n",
      "Epoch 1291/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0215 - mse: 942.8700 - val_loss: 20.5719 - val_mse: 942.9059\n",
      "Epoch 1292/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0957 - mse: 941.2628 - val_loss: 20.5610 - val_mse: 934.2203\n",
      "Epoch 1293/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0732 - mse: 949.7841 - val_loss: 20.6262 - val_mse: 908.2232\n",
      "Epoch 1294/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0719 - mse: 936.9627 - val_loss: 20.5627 - val_mse: 926.3836\n",
      "Epoch 1295/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0184 - mse: 931.9420 - val_loss: 20.6024 - val_mse: 955.2971\n",
      "Epoch 1296/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1407 - mse: 944.1941 - val_loss: 20.6353 - val_mse: 963.6914\n",
      "Epoch 1297/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.9703 - mse: 938.3238 - val_loss: 20.6793 - val_mse: 971.9001\n",
      "Epoch 1298/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0252 - mse: 938.9578 - val_loss: 20.5718 - val_mse: 922.2608\n",
      "Epoch 1299/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0345 - mse: 934.6584 - val_loss: 20.6514 - val_mse: 966.9798\n",
      "Epoch 1300/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1010 - mse: 947.0584 - val_loss: 20.6027 - val_mse: 955.3853\n",
      "Epoch 1301/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.1017 - mse: 943.8324 - val_loss: 20.5656 - val_mse: 924.9999\n",
      "Epoch 1302/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0766 - mse: 939.7936 - val_loss: 20.5900 - val_mse: 951.2589\n",
      "Epoch 1303/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0609 - mse: 940.9443 - val_loss: 20.5734 - val_mse: 943.7650\n",
      "Epoch 1304/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0177 - mse: 935.3365 - val_loss: 20.6205 - val_mse: 960.4261\n",
      "Epoch 1305/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.1397 - mse: 935.1184 - val_loss: 20.5598 - val_mse: 930.9108\n",
      "Epoch 1306/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0677 - mse: 948.8883 - val_loss: 20.5899 - val_mse: 951.2237\n",
      "Epoch 1307/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.1140 - mse: 939.7066 - val_loss: 20.5913 - val_mse: 951.6937\n",
      "Epoch 1308/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1508 - mse: 936.5403 - val_loss: 20.7012 - val_mse: 975.4898\n",
      "Epoch 1309/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9849 - mse: 939.5341 - val_loss: 20.5815 - val_mse: 947.6088\n",
      "Epoch 1310/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0774 - mse: 941.6417 - val_loss: 20.5681 - val_mse: 940.6727\n",
      "Epoch 1311/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0694 - mse: 940.8714 - val_loss: 20.5767 - val_mse: 920.3773\n",
      "Epoch 1312/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0745 - mse: 941.7811 - val_loss: 20.5926 - val_mse: 952.1440\n",
      "Epoch 1313/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9936 - mse: 927.8326 - val_loss: 20.6673 - val_mse: 969.8400\n",
      "Epoch 1314/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0284 - mse: 942.1439 - val_loss: 20.6067 - val_mse: 912.1169\n",
      "Epoch 1315/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9781 - mse: 923.8291 - val_loss: 20.5638 - val_mse: 937.5357\n",
      "Epoch 1316/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0362 - mse: 944.4376 - val_loss: 20.5719 - val_mse: 942.9060\n",
      "Epoch 1317/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9985 - mse: 926.0468 - val_loss: 20.7322 - val_mse: 980.3104\n",
      "Epoch 1318/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0828 - mse: 945.8253 - val_loss: 20.6112 - val_mse: 957.8525\n",
      "Epoch 1319/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1255 - mse: 953.7505 - val_loss: 20.5647 - val_mse: 938.1756\n",
      "Epoch 1320/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9565 - mse: 937.5916 - val_loss: 20.5610 - val_mse: 927.6548\n",
      "Epoch 1321/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0395 - mse: 936.1751 - val_loss: 20.6095 - val_mse: 957.3854\n",
      "Epoch 1322/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9833 - mse: 945.4986 - val_loss: 20.6330 - val_mse: 963.2198\n",
      "Epoch 1323/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9924 - mse: 932.0263 - val_loss: 20.7113 - val_mse: 977.0668\n",
      "Epoch 1324/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9483 - mse: 930.0898 - val_loss: 20.6545 - val_mse: 967.5853\n",
      "Epoch 1325/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0215 - mse: 939.8393 - val_loss: 20.5783 - val_mse: 946.1735\n",
      "Epoch 1326/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0597 - mse: 930.0576 - val_loss: 20.5668 - val_mse: 939.7975\n",
      "Epoch 1327/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0359 - mse: 948.3725 - val_loss: 20.5895 - val_mse: 951.0744\n",
      "Epoch 1328/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0742 - mse: 936.1646 - val_loss: 20.5630 - val_mse: 936.7896\n",
      "Epoch 1329/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9295 - mse: 937.1385 - val_loss: 20.5843 - val_mse: 917.7673\n",
      "Epoch 1330/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0181 - mse: 926.9168 - val_loss: 20.5983 - val_mse: 954.0132\n",
      "Epoch 1331/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9551 - mse: 941.3265 - val_loss: 20.5646 - val_mse: 938.0992\n",
      "Epoch 1332/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.8849 - mse: 931.3937 - val_loss: 20.5668 - val_mse: 939.7576\n",
      "Epoch 1333/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9891 - mse: 934.8983 - val_loss: 20.5613 - val_mse: 927.3068\n",
      "Epoch 1334/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9683 - mse: 931.8419 - val_loss: 20.5645 - val_mse: 938.0306\n",
      "Epoch 1335/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0834 - mse: 945.8322 - val_loss: 20.6088 - val_mse: 957.1624\n",
      "Epoch 1336/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9593 - mse: 933.1196 - val_loss: 20.6387 - val_mse: 964.3875\n",
      "Epoch 1337/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0319 - mse: 938.2769 - val_loss: 20.5705 - val_mse: 942.1267\n",
      "Epoch 1338/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0113 - mse: 942.7464 - val_loss: 20.6097 - val_mse: 957.4261\n",
      "Epoch 1339/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0759 - mse: 946.2819 - val_loss: 20.6435 - val_mse: 965.3865\n",
      "Epoch 1340/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1174 - mse: 947.6242 - val_loss: 20.5819 - val_mse: 947.7733\n",
      "Epoch 1341/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0562 - mse: 931.9981 - val_loss: 20.5828 - val_mse: 948.2115\n",
      "Epoch 1342/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0017 - mse: 937.5297 - val_loss: 20.5695 - val_mse: 923.2804\n",
      "Epoch 1343/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9969 - mse: 923.3001 - val_loss: 20.5755 - val_mse: 944.8552\n",
      "Epoch 1344/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0188 - mse: 936.6182 - val_loss: 20.5700 - val_mse: 941.8317\n",
      "Epoch 1345/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9863 - mse: 934.2031 - val_loss: 20.5846 - val_mse: 917.6664\n",
      "Epoch 1346/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0255 - mse: 941.1536 - val_loss: 20.5611 - val_mse: 927.5779\n",
      "Epoch 1347/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.8676 - mse: 924.6056 - val_loss: 20.6018 - val_mse: 955.1185\n",
      "Epoch 1348/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9729 - mse: 944.8203 - val_loss: 20.6032 - val_mse: 912.8763\n",
      "Epoch 1349/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9398 - mse: 928.0901 - val_loss: 20.5632 - val_mse: 936.9604\n",
      "Epoch 1350/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0371 - mse: 937.6841 - val_loss: 20.5947 - val_mse: 952.8508\n",
      "Epoch 1351/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0425 - mse: 935.3157 - val_loss: 20.6634 - val_mse: 969.1510\n",
      "Epoch 1352/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0011 - mse: 941.6214 - val_loss: 20.5900 - val_mse: 951.2444\n",
      "Epoch 1353/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0707 - mse: 934.9770 - val_loss: 20.6059 - val_mse: 956.3198\n",
      "Epoch 1354/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0763 - mse: 932.5573 - val_loss: 20.5748 - val_mse: 921.0616\n",
      "Epoch 1355/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0179 - mse: 940.3101 - val_loss: 20.5777 - val_mse: 945.9004\n",
      "Epoch 1356/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9243 - mse: 934.2082 - val_loss: 20.5733 - val_mse: 921.6581\n",
      "Epoch 1357/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0837 - mse: 943.2485 - val_loss: 20.5607 - val_mse: 933.6277\n",
      "Epoch 1358/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0259 - mse: 934.7072 - val_loss: 20.5835 - val_mse: 948.5228\n",
      "Epoch 1359/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0538 - mse: 943.6214 - val_loss: 20.5638 - val_mse: 937.5092\n",
      "Epoch 1360/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0409 - mse: 930.0059 - val_loss: 20.5895 - val_mse: 951.0801\n",
      "Epoch 1361/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9297 - mse: 940.5458 - val_loss: 20.5944 - val_mse: 952.7703\n",
      "Epoch 1362/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0524 - mse: 938.7262 - val_loss: 20.6918 - val_mse: 973.9866\n",
      "Epoch 1363/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0584 - mse: 938.7886 - val_loss: 20.6301 - val_mse: 962.6277\n",
      "Epoch 1364/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0013 - mse: 936.5254 - val_loss: 20.5628 - val_mse: 936.6341\n",
      "Epoch 1365/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9867 - mse: 936.3026 - val_loss: 20.7654 - val_mse: 985.4846\n",
      "Epoch 1366/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0927 - mse: 942.2993 - val_loss: 20.7668 - val_mse: 985.6920\n",
      "Epoch 1367/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9701 - mse: 936.8374 - val_loss: 20.5856 - val_mse: 917.3799\n",
      "Epoch 1368/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1259 - mse: 937.7573 - val_loss: 20.5992 - val_mse: 954.3139\n",
      "Epoch 1369/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0674 - mse: 945.2162 - val_loss: 20.5964 - val_mse: 953.4152\n",
      "Epoch 1370/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8891 - mse: 928.4433 - val_loss: 20.5627 - val_mse: 936.5619\n",
      "Epoch 1371/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0537 - mse: 952.3205 - val_loss: 20.5909 - val_mse: 915.9626\n",
      "Epoch 1372/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9760 - mse: 927.1823 - val_loss: 20.5737 - val_mse: 943.9433\n",
      "Epoch 1373/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0430 - mse: 938.6511 - val_loss: 20.8931 - val_mse: 1004.6157\n",
      "Epoch 1374/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0510 - mse: 942.5729 - val_loss: 20.6023 - val_mse: 955.2614\n",
      "Epoch 1375/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9996 - mse: 932.7026 - val_loss: 20.5781 - val_mse: 946.0792\n",
      "Epoch 1376/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0255 - mse: 927.4045 - val_loss: 20.5979 - val_mse: 914.1064\n",
      "Epoch 1377/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0748 - mse: 938.2629 - val_loss: 20.7096 - val_mse: 976.8044\n",
      "Epoch 1378/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0065 - mse: 938.5406 - val_loss: 20.5735 - val_mse: 943.8408\n",
      "Epoch 1379/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0616 - mse: 945.1627 - val_loss: 20.5655 - val_mse: 938.8012\n",
      "Epoch 1380/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0097 - mse: 937.6606 - val_loss: 20.5877 - val_mse: 950.3465\n",
      "Epoch 1381/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9979 - mse: 938.8241 - val_loss: 20.6103 - val_mse: 911.3386\n",
      "Epoch 1382/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1824 - mse: 941.9382 - val_loss: 20.5749 - val_mse: 921.0363\n",
      "Epoch 1383/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0067 - mse: 938.8608 - val_loss: 20.5699 - val_mse: 941.7619\n",
      "Epoch 1384/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1377 - mse: 949.3793 - val_loss: 20.5617 - val_mse: 935.5561\n",
      "Epoch 1385/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9721 - mse: 932.5974 - val_loss: 20.6109 - val_mse: 911.2156\n",
      "Epoch 1386/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9800 - mse: 929.1359 - val_loss: 20.5652 - val_mse: 938.5551\n",
      "Epoch 1387/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9662 - mse: 930.2657 - val_loss: 20.5768 - val_mse: 945.4648\n",
      "Epoch 1388/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0284 - mse: 933.2446 - val_loss: 20.5909 - val_mse: 951.5534\n",
      "Epoch 1389/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9985 - mse: 936.6885 - val_loss: 20.5676 - val_mse: 940.3676\n",
      "Epoch 1390/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9927 - mse: 927.5618 - val_loss: 20.5741 - val_mse: 944.1594\n",
      "Epoch 1391/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0165 - mse: 934.5674 - val_loss: 20.5663 - val_mse: 939.4137\n",
      "Epoch 1392/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0432 - mse: 934.5403 - val_loss: 20.5698 - val_mse: 941.7430\n",
      "Epoch 1393/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9657 - mse: 935.5440 - val_loss: 20.5964 - val_mse: 914.5044\n",
      "Epoch 1394/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9585 - mse: 936.8894 - val_loss: 20.5641 - val_mse: 937.7787\n",
      "Epoch 1395/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0156 - mse: 946.5383 - val_loss: 20.6010 - val_mse: 913.3596\n",
      "Epoch 1396/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0495 - mse: 931.4733 - val_loss: 20.6357 - val_mse: 906.5894\n",
      "Epoch 1397/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9574 - mse: 933.8488 - val_loss: 20.6287 - val_mse: 962.3012\n",
      "Epoch 1398/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0249 - mse: 935.6953 - val_loss: 20.6590 - val_mse: 968.3906\n",
      "Epoch 1399/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9691 - mse: 936.5540 - val_loss: 20.5708 - val_mse: 922.6784\n",
      "Epoch 1400/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9468 - mse: 937.6080 - val_loss: 20.5735 - val_mse: 943.8046\n",
      "Epoch 1401/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9730 - mse: 924.0937 - val_loss: 20.6946 - val_mse: 974.4513\n",
      "Epoch 1402/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0523 - mse: 945.0284 - val_loss: 20.5657 - val_mse: 938.9694\n",
      "Epoch 1403/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9082 - mse: 921.0532 - val_loss: 20.5827 - val_mse: 948.1703\n",
      "Epoch 1404/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0271 - mse: 949.7214 - val_loss: 20.6722 - val_mse: 901.3535\n",
      "Epoch 1405/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0977 - mse: 933.0375 - val_loss: 20.5682 - val_mse: 923.8207\n",
      "Epoch 1406/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1332 - mse: 948.4731 - val_loss: 20.5757 - val_mse: 920.7408\n",
      "Epoch 1407/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.1344 - mse: 937.3856 - val_loss: 20.5645 - val_mse: 938.0424\n",
      "Epoch 1408/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9701 - mse: 952.4910 - val_loss: 20.7073 - val_mse: 897.6388\n",
      "Epoch 1409/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0921 - mse: 937.4073 - val_loss: 20.6181 - val_mse: 909.7411\n",
      "Epoch 1410/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0590 - mse: 930.4330 - val_loss: 20.5609 - val_mse: 927.7125\n",
      "Epoch 1411/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0775 - mse: 942.8763 - val_loss: 20.5911 - val_mse: 915.9100\n",
      "Epoch 1412/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1227 - mse: 927.8599 - val_loss: 20.5768 - val_mse: 945.5077\n",
      "Epoch 1413/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0504 - mse: 946.8516 - val_loss: 20.5924 - val_mse: 952.0712\n",
      "Epoch 1414/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9395 - mse: 932.1701 - val_loss: 20.5815 - val_mse: 947.5991\n",
      "Epoch 1415/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9627 - mse: 929.8220 - val_loss: 20.8700 - val_mse: 1001.1487\n",
      "Epoch 1416/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.8983 - mse: 932.8312 - val_loss: 20.6118 - val_mse: 911.0145\n",
      "Epoch 1417/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9880 - mse: 938.3284 - val_loss: 20.6612 - val_mse: 902.7612\n",
      "Epoch 1418/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1005 - mse: 936.4882 - val_loss: 20.5721 - val_mse: 922.1298\n",
      "Epoch 1419/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0341 - mse: 936.5265 - val_loss: 20.5902 - val_mse: 951.3173\n",
      "Epoch 1420/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9256 - mse: 933.2462 - val_loss: 20.6568 - val_mse: 968.0115\n",
      "Epoch 1421/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0442 - mse: 939.6910 - val_loss: 20.5960 - val_mse: 953.2928\n",
      "Epoch 1422/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9897 - mse: 935.8560 - val_loss: 20.6515 - val_mse: 966.9936\n",
      "Epoch 1423/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0856 - mse: 948.6678 - val_loss: 20.5624 - val_mse: 926.5706\n",
      "Epoch 1424/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1052 - mse: 940.3451 - val_loss: 20.5666 - val_mse: 939.6497\n",
      "Epoch 1425/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9512 - mse: 932.5490 - val_loss: 20.5672 - val_mse: 924.2792\n",
      "Epoch 1426/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9960 - mse: 935.3107 - val_loss: 20.5751 - val_mse: 944.6544\n",
      "Epoch 1427/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9857 - mse: 930.2325 - val_loss: 20.5773 - val_mse: 945.7384\n",
      "Epoch 1428/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9769 - mse: 929.7511 - val_loss: 20.5693 - val_mse: 941.4414\n",
      "Epoch 1429/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9858 - mse: 938.3450 - val_loss: 20.6465 - val_mse: 966.0032\n",
      "Epoch 1430/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0460 - mse: 944.7181 - val_loss: 20.5732 - val_mse: 943.6309\n",
      "Epoch 1431/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0060 - mse: 937.2209 - val_loss: 20.5610 - val_mse: 927.6796\n",
      "Epoch 1432/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9706 - mse: 937.1722 - val_loss: 20.5653 - val_mse: 938.6547\n",
      "Epoch 1433/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1650 - mse: 948.5288 - val_loss: 20.6043 - val_mse: 912.6329\n",
      "Epoch 1434/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0391 - mse: 934.5671 - val_loss: 20.5958 - val_mse: 953.2042\n",
      "Epoch 1435/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9480 - mse: 930.7346 - val_loss: 20.5608 - val_mse: 933.8567\n",
      "Epoch 1436/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9428 - mse: 932.1536 - val_loss: 20.6096 - val_mse: 957.4054\n",
      "Epoch 1437/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0644 - mse: 939.6250 - val_loss: 20.5740 - val_mse: 921.3997\n",
      "Epoch 1438/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9967 - mse: 936.6054 - val_loss: 20.5850 - val_mse: 917.5600\n",
      "Epoch 1439/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.1522 - mse: 939.0157 - val_loss: 20.5851 - val_mse: 949.2474\n",
      "Epoch 1440/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9663 - mse: 935.7798 - val_loss: 20.5691 - val_mse: 941.3086\n",
      "Epoch 1441/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0565 - mse: 940.3387 - val_loss: 20.6191 - val_mse: 960.0692\n",
      "Epoch 1442/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0662 - mse: 938.2225 - val_loss: 20.6039 - val_mse: 955.7228\n",
      "Epoch 1443/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0359 - mse: 943.9658 - val_loss: 20.5852 - val_mse: 949.2983\n",
      "Epoch 1444/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1344 - mse: 934.6772 - val_loss: 20.7160 - val_mse: 977.8027\n",
      "Epoch 1445/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9643 - mse: 936.6623 - val_loss: 20.6090 - val_mse: 957.2334\n",
      "Epoch 1446/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9551 - mse: 940.7604 - val_loss: 20.5609 - val_mse: 933.9875\n",
      "Epoch 1447/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9532 - mse: 934.0459 - val_loss: 20.5652 - val_mse: 938.5412\n",
      "Epoch 1448/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0418 - mse: 935.1232 - val_loss: 20.5598 - val_mse: 931.2616\n",
      "Epoch 1449/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0512 - mse: 944.4979 - val_loss: 20.6174 - val_mse: 959.6339\n",
      "Epoch 1450/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8599 - mse: 931.6804 - val_loss: 20.5606 - val_mse: 933.4760\n",
      "Epoch 1451/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0448 - mse: 935.8135 - val_loss: 20.6522 - val_mse: 967.1431\n",
      "Epoch 1452/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0236 - mse: 933.4729 - val_loss: 20.7369 - val_mse: 981.0336\n",
      "Epoch 1453/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0231 - mse: 947.6957 - val_loss: 20.5804 - val_mse: 947.1335\n",
      "Epoch 1454/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0903 - mse: 942.9946 - val_loss: 20.6319 - val_mse: 962.9857\n",
      "Epoch 1455/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0685 - mse: 936.2021 - val_loss: 20.5699 - val_mse: 941.7772\n",
      "Epoch 1456/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9790 - mse: 936.0150 - val_loss: 20.5715 - val_mse: 942.6563\n",
      "Epoch 1457/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0435 - mse: 943.2834 - val_loss: 20.5739 - val_mse: 921.4077\n",
      "Epoch 1458/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9505 - mse: 936.4329 - val_loss: 20.5856 - val_mse: 917.3978\n",
      "Epoch 1459/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9534 - mse: 927.6970 - val_loss: 20.5657 - val_mse: 924.9531\n",
      "Epoch 1460/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9554 - mse: 930.4254 - val_loss: 20.5599 - val_mse: 930.5367\n",
      "Epoch 1461/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9306 - mse: 925.3364 - val_loss: 20.5605 - val_mse: 933.1403\n",
      "Epoch 1462/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0435 - mse: 930.6754 - val_loss: 20.5615 - val_mse: 927.1518\n",
      "Epoch 1463/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0485 - mse: 932.5355 - val_loss: 20.5797 - val_mse: 946.8127\n",
      "Epoch 1464/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0475 - mse: 937.8506 - val_loss: 20.6157 - val_mse: 959.1686\n",
      "Epoch 1465/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9852 - mse: 941.0203 - val_loss: 20.5598 - val_mse: 931.1584\n",
      "Epoch 1466/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.8790 - mse: 931.8262 - val_loss: 20.5658 - val_mse: 924.8853\n",
      "Epoch 1467/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9756 - mse: 928.1758 - val_loss: 20.5874 - val_mse: 950.2346\n",
      "Epoch 1468/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9493 - mse: 931.2446 - val_loss: 20.6034 - val_mse: 912.8338\n",
      "Epoch 1469/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1210 - mse: 946.9533 - val_loss: 20.5896 - val_mse: 916.2998\n",
      "Epoch 1470/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0242 - mse: 926.8913 - val_loss: 20.5782 - val_mse: 946.1443\n",
      "Epoch 1471/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0687 - mse: 939.3512 - val_loss: 20.5900 - val_mse: 951.2244\n",
      "Epoch 1472/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9215 - mse: 935.4531 - val_loss: 20.6329 - val_mse: 963.2035\n",
      "Epoch 1473/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9505 - mse: 937.4180 - val_loss: 20.5630 - val_mse: 936.8453\n",
      "Epoch 1474/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9879 - mse: 939.8842 - val_loss: 20.6361 - val_mse: 906.5258\n",
      "Epoch 1475/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1113 - mse: 933.6505 - val_loss: 20.5599 - val_mse: 930.0348\n",
      "Epoch 1476/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9281 - mse: 925.2410 - val_loss: 20.5648 - val_mse: 938.3051\n",
      "Epoch 1477/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9333 - mse: 934.1356 - val_loss: 20.5619 - val_mse: 926.8746\n",
      "Epoch 1478/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0707 - mse: 929.6002 - val_loss: 20.5598 - val_mse: 931.3467\n",
      "Epoch 1479/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9219 - mse: 928.8850 - val_loss: 20.6121 - val_mse: 958.1266\n",
      "Epoch 1480/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9389 - mse: 929.0162 - val_loss: 20.5671 - val_mse: 940.0133\n",
      "Epoch 1481/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9204 - mse: 933.1586 - val_loss: 20.5647 - val_mse: 925.3766\n",
      "Epoch 1482/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0115 - mse: 928.4487 - val_loss: 20.6131 - val_mse: 958.4293\n",
      "Epoch 1483/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.1028 - mse: 943.4841 - val_loss: 20.6291 - val_mse: 962.3910\n",
      "Epoch 1484/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0065 - mse: 943.6327 - val_loss: 20.5816 - val_mse: 947.6501\n",
      "Epoch 1485/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0093 - mse: 943.2129 - val_loss: 20.5663 - val_mse: 924.6812\n",
      "Epoch 1486/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0358 - mse: 938.3012 - val_loss: 20.5599 - val_mse: 930.3929\n",
      "Epoch 1487/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0396 - mse: 938.1450 - val_loss: 20.5735 - val_mse: 943.8093\n",
      "Epoch 1488/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0771 - mse: 933.3141 - val_loss: 20.5906 - val_mse: 951.4721\n",
      "Epoch 1489/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9630 - mse: 934.9944 - val_loss: 20.7943 - val_mse: 989.9462\n",
      "Epoch 1490/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0966 - mse: 940.3303 - val_loss: 20.5601 - val_mse: 929.2134\n",
      "Epoch 1491/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0333 - mse: 941.3233 - val_loss: 20.5598 - val_mse: 931.5883\n",
      "Epoch 1492/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.1105 - mse: 937.7248 - val_loss: 20.5723 - val_mse: 922.0769\n",
      "Epoch 1493/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.1242 - mse: 933.8911 - val_loss: 20.5643 - val_mse: 937.9108\n",
      "Epoch 1494/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9605 - mse: 940.0820 - val_loss: 20.8385 - val_mse: 996.5093\n",
      "Epoch 1495/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9864 - mse: 942.1991 - val_loss: 20.5872 - val_mse: 916.9631\n",
      "Epoch 1496/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0246 - mse: 933.5098 - val_loss: 20.6103 - val_mse: 957.6007\n",
      "Epoch 1497/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9976 - mse: 943.7938 - val_loss: 20.6158 - val_mse: 959.2015\n",
      "Epoch 1498/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9968 - mse: 940.5753 - val_loss: 20.5817 - val_mse: 947.7258\n",
      "Epoch 1499/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0174 - mse: 942.3370 - val_loss: 20.5970 - val_mse: 953.6165\n",
      "Epoch 1500/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9579 - mse: 935.9689 - val_loss: 20.5866 - val_mse: 949.9252\n",
      "Epoch 1501/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0114 - mse: 932.1455 - val_loss: 20.5854 - val_mse: 949.3737\n",
      "Epoch 1502/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.1011 - mse: 941.9650 - val_loss: 20.5680 - val_mse: 940.5850\n",
      "Epoch 1503/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9756 - mse: 936.8186 - val_loss: 20.5727 - val_mse: 921.9108\n",
      "Epoch 1504/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0169 - mse: 931.8419 - val_loss: 20.5728 - val_mse: 943.4142\n",
      "Epoch 1505/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0496 - mse: 945.2943 - val_loss: 20.6155 - val_mse: 959.1036\n",
      "Epoch 1506/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.1113 - mse: 940.6260 - val_loss: 20.5683 - val_mse: 940.8278\n",
      "Epoch 1507/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9915 - mse: 933.2183 - val_loss: 20.5806 - val_mse: 947.1957\n",
      "Epoch 1508/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0478 - mse: 933.4182 - val_loss: 20.6844 - val_mse: 972.7626\n",
      "Epoch 1509/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9467 - mse: 937.6079 - val_loss: 20.5823 - val_mse: 947.9561\n",
      "Epoch 1510/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.9725 - mse: 932.4017 - val_loss: 20.5925 - val_mse: 952.1098\n",
      "Epoch 1511/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.9748 - mse: 937.1037 - val_loss: 20.5926 - val_mse: 952.1348\n",
      "Epoch 1512/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.9878 - mse: 943.5036 - val_loss: 20.5604 - val_mse: 928.6031\n",
      "Epoch 1513/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0171 - mse: 935.8083 - val_loss: 20.6749 - val_mse: 971.1662\n",
      "Epoch 1514/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 21.0083 - mse: 936.7723 - val_loss: 20.5632 - val_mse: 937.0225\n",
      "Epoch 1515/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9722 - mse: 938.3258 - val_loss: 20.6007 - val_mse: 954.7804\n",
      "Epoch 1516/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0233 - mse: 937.1822 - val_loss: 20.5599 - val_mse: 931.8079\n",
      "Epoch 1517/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9642 - mse: 936.0938 - val_loss: 20.5604 - val_mse: 928.4439\n",
      "Epoch 1518/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1070 - mse: 942.4754 - val_loss: 20.6941 - val_mse: 898.9396\n",
      "Epoch 1519/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0387 - mse: 928.9689 - val_loss: 20.5619 - val_mse: 926.8950\n",
      "Epoch 1520/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0877 - mse: 942.1569 - val_loss: 20.5689 - val_mse: 923.5377\n",
      "Epoch 1521/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9289 - mse: 927.1003 - val_loss: 20.5735 - val_mse: 921.5761\n",
      "Epoch 1522/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0125 - mse: 939.8731 - val_loss: 20.5901 - val_mse: 916.1606\n",
      "Epoch 1523/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1089 - mse: 937.0309 - val_loss: 20.5883 - val_mse: 950.6000\n",
      "Epoch 1524/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0356 - mse: 937.4478 - val_loss: 20.5598 - val_mse: 931.3452\n",
      "Epoch 1525/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0017 - mse: 940.3369 - val_loss: 20.5598 - val_mse: 930.4979\n",
      "Epoch 1526/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0226 - mse: 942.7399 - val_loss: 20.5728 - val_mse: 943.4186\n",
      "Epoch 1527/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9418 - mse: 932.5004 - val_loss: 20.6199 - val_mse: 960.2881\n",
      "Epoch 1528/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9969 - mse: 930.8685 - val_loss: 20.5900 - val_mse: 951.2429\n",
      "Epoch 1529/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0205 - mse: 945.8097 - val_loss: 20.5604 - val_mse: 928.5178\n",
      "Epoch 1530/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0826 - mse: 933.0540 - val_loss: 20.5625 - val_mse: 936.3950\n",
      "Epoch 1531/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9604 - mse: 941.9992 - val_loss: 20.5844 - val_mse: 948.9572\n",
      "Epoch 1532/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9904 - mse: 939.8435 - val_loss: 20.5895 - val_mse: 916.3278\n",
      "Epoch 1533/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0022 - mse: 946.1534 - val_loss: 20.5698 - val_mse: 923.1483\n",
      "Epoch 1534/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0636 - mse: 938.6947 - val_loss: 20.6595 - val_mse: 902.9943\n",
      "Epoch 1535/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0496 - mse: 922.2200 - val_loss: 20.6073 - val_mse: 956.7446\n",
      "Epoch 1536/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9213 - mse: 935.5044 - val_loss: 20.5610 - val_mse: 927.6812\n",
      "Epoch 1537/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0685 - mse: 928.1836 - val_loss: 20.5864 - val_mse: 949.8214\n",
      "Epoch 1538/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.8750 - mse: 932.3850 - val_loss: 20.5740 - val_mse: 921.3694\n",
      "Epoch 1539/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0705 - mse: 934.0184 - val_loss: 20.6259 - val_mse: 908.2925\n",
      "Epoch 1540/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0511 - mse: 934.1065 - val_loss: 20.5607 - val_mse: 933.5662\n",
      "Epoch 1541/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.8953 - mse: 925.4091 - val_loss: 20.5780 - val_mse: 946.0256\n",
      "Epoch 1542/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9720 - mse: 934.9500 - val_loss: 20.6276 - val_mse: 962.0601\n",
      "Epoch 1543/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9425 - mse: 938.3525 - val_loss: 20.5610 - val_mse: 934.2161\n",
      "Epoch 1544/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0337 - mse: 942.1024 - val_loss: 20.5735 - val_mse: 921.5954\n",
      "Epoch 1545/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9677 - mse: 934.3329 - val_loss: 20.5797 - val_mse: 946.7857\n",
      "Epoch 1546/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9992 - mse: 938.6231 - val_loss: 20.7692 - val_mse: 986.0776\n",
      "Epoch 1547/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9963 - mse: 950.7108 - val_loss: 20.6886 - val_mse: 899.5052\n",
      "Epoch 1548/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9470 - mse: 929.7031 - val_loss: 20.6520 - val_mse: 967.1032\n",
      "Epoch 1549/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0291 - mse: 947.8804 - val_loss: 20.6923 - val_mse: 974.0793\n",
      "Epoch 1550/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0254 - mse: 945.1505 - val_loss: 20.5601 - val_mse: 929.0890\n",
      "Epoch 1551/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9105 - mse: 929.4324 - val_loss: 20.5769 - val_mse: 945.5292\n",
      "Epoch 1552/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0102 - mse: 938.3704 - val_loss: 20.5714 - val_mse: 942.6346\n",
      "Epoch 1553/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0313 - mse: 940.2638 - val_loss: 20.5732 - val_mse: 943.6171\n",
      "Epoch 1554/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9838 - mse: 939.3750 - val_loss: 20.6059 - val_mse: 912.2934\n",
      "Epoch 1555/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1013 - mse: 937.3329 - val_loss: 20.5662 - val_mse: 924.7086\n",
      "Epoch 1556/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9405 - mse: 929.2665 - val_loss: 20.6174 - val_mse: 959.6338\n",
      "Epoch 1557/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.1228 - mse: 946.5857 - val_loss: 20.5606 - val_mse: 933.4492\n",
      "Epoch 1558/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0933 - mse: 940.5414 - val_loss: 20.8722 - val_mse: 1001.4792\n",
      "Epoch 1559/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0149 - mse: 938.1390 - val_loss: 20.5892 - val_mse: 950.9650\n",
      "Epoch 1560/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0302 - mse: 926.6531 - val_loss: 20.5837 - val_mse: 948.6348\n",
      "Epoch 1561/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9483 - mse: 940.1615 - val_loss: 20.6172 - val_mse: 959.5843\n",
      "Epoch 1562/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0202 - mse: 940.3913 - val_loss: 20.5723 - val_mse: 922.0446\n",
      "Epoch 1563/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9658 - mse: 935.6768 - val_loss: 20.5860 - val_mse: 917.2886\n",
      "Epoch 1564/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0760 - mse: 941.4994 - val_loss: 20.6623 - val_mse: 902.6035\n",
      "Epoch 1565/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9783 - mse: 928.7024 - val_loss: 20.5985 - val_mse: 954.0734\n",
      "Epoch 1566/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0243 - mse: 944.2057 - val_loss: 20.5891 - val_mse: 950.9056\n",
      "Epoch 1567/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9296 - mse: 930.0294 - val_loss: 20.8472 - val_mse: 997.7725\n",
      "Epoch 1568/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9897 - mse: 935.4330 - val_loss: 20.5598 - val_mse: 931.7150\n",
      "Epoch 1569/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.8802 - mse: 924.3522 - val_loss: 20.5728 - val_mse: 943.4006\n",
      "Epoch 1570/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9595 - mse: 934.4889 - val_loss: 20.5831 - val_mse: 948.3273\n",
      "Epoch 1571/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.9907 - mse: 950.8690 - val_loss: 20.6105 - val_mse: 911.2919\n",
      "Epoch 1572/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9438 - mse: 925.8906 - val_loss: 20.5723 - val_mse: 943.1561\n",
      "Epoch 1573/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9700 - mse: 935.0879 - val_loss: 20.5950 - val_mse: 952.9635\n",
      "Epoch 1574/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0707 - mse: 942.2986 - val_loss: 20.5670 - val_mse: 939.9594\n",
      "Epoch 1575/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9720 - mse: 943.7778 - val_loss: 20.5948 - val_mse: 952.8836\n",
      "Epoch 1576/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9582 - mse: 925.0840 - val_loss: 20.5754 - val_mse: 944.7938\n",
      "Epoch 1577/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9747 - mse: 929.1093 - val_loss: 20.5629 - val_mse: 936.6899\n",
      "Epoch 1578/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9824 - mse: 936.1069 - val_loss: 20.6055 - val_mse: 956.1929\n",
      "Epoch 1579/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0613 - mse: 936.7657 - val_loss: 20.5837 - val_mse: 948.6205\n",
      "Epoch 1580/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9610 - mse: 942.9393 - val_loss: 20.5616 - val_mse: 935.3054\n",
      "Epoch 1581/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0542 - mse: 933.3097 - val_loss: 20.5816 - val_mse: 918.6186\n",
      "Epoch 1582/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.1459 - mse: 940.5405 - val_loss: 20.5831 - val_mse: 948.3273\n",
      "Epoch 1583/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9813 - mse: 930.5632 - val_loss: 20.6306 - val_mse: 962.7277\n",
      "Epoch 1584/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0410 - mse: 942.7596 - val_loss: 20.5880 - val_mse: 950.4798\n",
      "Epoch 1585/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9662 - mse: 933.7563 - val_loss: 20.5896 - val_mse: 951.0896\n",
      "Epoch 1586/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9656 - mse: 931.6014 - val_loss: 20.6194 - val_mse: 960.1425\n",
      "Epoch 1587/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9655 - mse: 930.9474 - val_loss: 20.5742 - val_mse: 921.3251\n",
      "Epoch 1588/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9922 - mse: 932.5439 - val_loss: 20.5650 - val_mse: 938.4235\n",
      "Epoch 1589/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9888 - mse: 937.6133 - val_loss: 20.5599 - val_mse: 931.9721\n",
      "Epoch 1590/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9031 - mse: 932.5496 - val_loss: 20.5940 - val_mse: 915.1344\n",
      "Epoch 1591/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9295 - mse: 921.7202 - val_loss: 20.8708 - val_mse: 1001.2717\n",
      "Epoch 1592/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1336 - mse: 949.7902 - val_loss: 20.5893 - val_mse: 950.9964\n",
      "Epoch 1593/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9784 - mse: 938.6826 - val_loss: 20.5598 - val_mse: 931.4321\n",
      "Epoch 1594/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.8987 - mse: 928.4210 - val_loss: 20.5914 - val_mse: 951.7292\n",
      "Epoch 1595/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9157 - mse: 937.3770 - val_loss: 20.6258 - val_mse: 961.6500\n",
      "Epoch 1596/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0252 - mse: 936.7930 - val_loss: 20.6174 - val_mse: 959.6181\n",
      "Epoch 1597/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9731 - mse: 936.4764 - val_loss: 20.6315 - val_mse: 962.9167\n",
      "Epoch 1598/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0089 - mse: 937.1910 - val_loss: 20.6696 - val_mse: 970.2448\n",
      "Epoch 1599/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9671 - mse: 936.4973 - val_loss: 20.5614 - val_mse: 935.1167\n",
      "Epoch 1600/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0507 - mse: 944.5728 - val_loss: 20.5640 - val_mse: 937.6776\n",
      "Epoch 1601/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9920 - mse: 921.4218 - val_loss: 20.9482 - val_mse: 1012.3926\n",
      "Epoch 1602/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0039 - mse: 942.8011 - val_loss: 20.5645 - val_mse: 938.0350\n",
      "Epoch 1603/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0010 - mse: 933.4526 - val_loss: 20.6574 - val_mse: 968.1190\n",
      "Epoch 1604/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9761 - mse: 937.3882 - val_loss: 20.5688 - val_mse: 923.5668\n",
      "Epoch 1605/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0746 - mse: 940.7921 - val_loss: 20.5607 - val_mse: 933.6071\n",
      "Epoch 1606/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0829 - mse: 933.7762 - val_loss: 20.6120 - val_mse: 958.0879\n",
      "Epoch 1607/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9091 - mse: 932.8426 - val_loss: 20.6152 - val_mse: 959.0355\n",
      "Epoch 1608/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.8956 - mse: 918.1095 - val_loss: 20.6995 - val_mse: 975.2258\n",
      "Epoch 1609/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9710 - mse: 937.7880 - val_loss: 20.8623 - val_mse: 1000.0077\n",
      "Epoch 1610/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9560 - mse: 939.0403 - val_loss: 20.5639 - val_mse: 937.5538\n",
      "Epoch 1611/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9581 - mse: 927.0843 - val_loss: 20.5766 - val_mse: 945.3873\n",
      "Epoch 1612/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9872 - mse: 926.4017 - val_loss: 20.6378 - val_mse: 964.2153\n",
      "Epoch 1613/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0310 - mse: 945.0859 - val_loss: 20.5603 - val_mse: 932.7946\n",
      "Epoch 1614/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9251 - mse: 926.7410 - val_loss: 20.5635 - val_mse: 937.2848\n",
      "Epoch 1615/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9406 - mse: 941.7210 - val_loss: 20.5602 - val_mse: 932.4426\n",
      "Epoch 1616/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.1368 - mse: 942.8627 - val_loss: 20.5722 - val_mse: 922.1154\n",
      "Epoch 1617/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9457 - mse: 919.9988 - val_loss: 20.5856 - val_mse: 949.4771\n",
      "Epoch 1618/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0257 - mse: 933.5780 - val_loss: 20.7287 - val_mse: 979.7753\n",
      "Epoch 1619/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1712 - mse: 950.8552 - val_loss: 20.5971 - val_mse: 953.6192\n",
      "Epoch 1620/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0193 - mse: 936.3958 - val_loss: 20.5760 - val_mse: 945.1023\n",
      "Epoch 1621/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9850 - mse: 940.9739 - val_loss: 20.6064 - val_mse: 912.1786\n",
      "Epoch 1622/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0903 - mse: 939.2136 - val_loss: 20.5602 - val_mse: 932.5312\n",
      "Epoch 1623/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9870 - mse: 938.9442 - val_loss: 20.5757 - val_mse: 920.7129\n",
      "Epoch 1624/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0099 - mse: 938.7281 - val_loss: 20.5651 - val_mse: 938.5240\n",
      "Epoch 1625/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0048 - mse: 935.2385 - val_loss: 20.5599 - val_mse: 930.4449\n",
      "Epoch 1626/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0256 - mse: 933.9985 - val_loss: 20.5853 - val_mse: 949.3505\n",
      "Epoch 1627/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0115 - mse: 934.1592 - val_loss: 20.6205 - val_mse: 960.4285\n",
      "Epoch 1628/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0354 - mse: 942.3608 - val_loss: 20.5638 - val_mse: 937.5350\n",
      "Epoch 1629/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0277 - mse: 937.0081 - val_loss: 20.5601 - val_mse: 932.2242\n",
      "Epoch 1630/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0215 - mse: 938.4728 - val_loss: 20.6002 - val_mse: 954.6127\n",
      "Epoch 1631/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.9974 - mse: 935.9797 - val_loss: 20.6709 - val_mse: 970.4694\n",
      "Epoch 1632/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9287 - mse: 933.4631 - val_loss: 20.5680 - val_mse: 940.6465\n",
      "Epoch 1633/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9820 - mse: 943.7473 - val_loss: 20.5738 - val_mse: 921.4729\n",
      "Epoch 1634/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.8993 - mse: 938.7360 - val_loss: 20.5603 - val_mse: 932.6544\n",
      "Epoch 1635/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9519 - mse: 934.7389 - val_loss: 20.5622 - val_mse: 926.7101\n",
      "Epoch 1636/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9758 - mse: 938.4168 - val_loss: 20.6432 - val_mse: 905.3686\n",
      "Epoch 1637/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0217 - mse: 929.2017 - val_loss: 20.5610 - val_mse: 927.6638\n",
      "Epoch 1638/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0179 - mse: 939.8967 - val_loss: 20.5806 - val_mse: 918.9791\n",
      "Epoch 1639/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9713 - mse: 938.2039 - val_loss: 20.5708 - val_mse: 922.7064\n",
      "Epoch 1640/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9961 - mse: 929.5403 - val_loss: 20.5598 - val_mse: 931.4680\n",
      "Epoch 1641/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0467 - mse: 926.7229 - val_loss: 20.5782 - val_mse: 946.1335\n",
      "Epoch 1642/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9815 - mse: 939.7655 - val_loss: 20.5689 - val_mse: 941.2103\n",
      "Epoch 1643/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0261 - mse: 942.3385 - val_loss: 20.5667 - val_mse: 939.7106\n",
      "Epoch 1644/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9448 - mse: 926.1029 - val_loss: 20.5865 - val_mse: 949.8871\n",
      "Epoch 1645/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0416 - mse: 944.4150 - val_loss: 20.5679 - val_mse: 940.5777\n",
      "Epoch 1646/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0499 - mse: 937.4335 - val_loss: 20.5786 - val_mse: 919.6929\n",
      "Epoch 1647/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9583 - mse: 932.9639 - val_loss: 20.5654 - val_mse: 938.7531\n",
      "Epoch 1648/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0764 - mse: 945.0276 - val_loss: 20.5805 - val_mse: 947.1447\n",
      "Epoch 1649/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9945 - mse: 935.0442 - val_loss: 20.5882 - val_mse: 916.6892\n",
      "Epoch 1650/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9558 - mse: 925.7073 - val_loss: 20.6425 - val_mse: 905.4877\n",
      "Epoch 1651/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9929 - mse: 933.1260 - val_loss: 20.6996 - val_mse: 975.2283\n",
      "Epoch 1652/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0307 - mse: 945.2118 - val_loss: 20.5988 - val_mse: 954.1688\n",
      "Epoch 1653/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9614 - mse: 933.7029 - val_loss: 20.5712 - val_mse: 942.5079\n",
      "Epoch 1654/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9939 - mse: 930.4946 - val_loss: 20.5627 - val_mse: 936.5881\n",
      "Epoch 1655/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9682 - mse: 941.2340 - val_loss: 20.6063 - val_mse: 912.2085\n",
      "Epoch 1656/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9416 - mse: 932.3828 - val_loss: 20.6379 - val_mse: 964.2346\n",
      "Epoch 1657/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9533 - mse: 938.6839 - val_loss: 20.6030 - val_mse: 955.4648\n",
      "Epoch 1658/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0056 - mse: 928.7923 - val_loss: 20.6474 - val_mse: 966.1773\n",
      "Epoch 1659/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9600 - mse: 938.1827 - val_loss: 20.5862 - val_mse: 949.7304\n",
      "Epoch 1660/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9448 - mse: 927.8740 - val_loss: 20.5609 - val_mse: 934.0246\n",
      "Epoch 1661/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0384 - mse: 937.7489 - val_loss: 20.5629 - val_mse: 926.3158\n",
      "Epoch 1662/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9123 - mse: 937.7844 - val_loss: 20.7503 - val_mse: 893.8610\n",
      "Epoch 1663/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0316 - mse: 931.5787 - val_loss: 20.5785 - val_mse: 919.7161\n",
      "Epoch 1664/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0343 - mse: 936.6940 - val_loss: 20.5616 - val_mse: 927.0875\n",
      "Epoch 1665/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9284 - mse: 941.8408 - val_loss: 20.5612 - val_mse: 934.6998\n",
      "Epoch 1666/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9242 - mse: 918.6749 - val_loss: 20.5710 - val_mse: 942.4084\n",
      "Epoch 1667/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9853 - mse: 939.8303 - val_loss: 20.5924 - val_mse: 952.0654\n",
      "Epoch 1668/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0162 - mse: 936.3903 - val_loss: 20.6370 - val_mse: 964.0367\n",
      "Epoch 1669/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8654 - mse: 920.9316 - val_loss: 20.6561 - val_mse: 967.8848\n",
      "Epoch 1670/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0072 - mse: 934.8544 - val_loss: 20.6037 - val_mse: 955.6746\n",
      "Epoch 1671/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0437 - mse: 945.6386 - val_loss: 20.5645 - val_mse: 938.0127\n",
      "Epoch 1672/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.9943 - mse: 949.1601 - val_loss: 20.7257 - val_mse: 895.9321\n",
      "Epoch 1673/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0450 - mse: 932.9899 - val_loss: 20.5618 - val_mse: 926.9637\n",
      "Epoch 1674/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9350 - mse: 929.6321 - val_loss: 20.5726 - val_mse: 921.9355\n",
      "Epoch 1675/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9678 - mse: 931.1448 - val_loss: 20.5695 - val_mse: 923.2524\n",
      "Epoch 1676/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9969 - mse: 933.3085 - val_loss: 20.6237 - val_mse: 961.1871\n",
      "Epoch 1677/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0456 - mse: 943.4935 - val_loss: 20.5616 - val_mse: 935.3427\n",
      "Epoch 1678/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0575 - mse: 942.8577 - val_loss: 20.5598 - val_mse: 931.5942\n",
      "Epoch 1679/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0817 - mse: 935.4987 - val_loss: 20.5604 - val_mse: 928.6229\n",
      "Epoch 1680/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9091 - mse: 934.5388 - val_loss: 20.5950 - val_mse: 952.9414\n",
      "Epoch 1681/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1045 - mse: 934.9021 - val_loss: 20.5655 - val_mse: 925.0475\n",
      "Epoch 1682/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0289 - mse: 938.8449 - val_loss: 20.5841 - val_mse: 948.7996\n",
      "Epoch 1683/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0400 - mse: 945.0353 - val_loss: 20.5602 - val_mse: 932.4962\n",
      "Epoch 1684/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9513 - mse: 938.6580 - val_loss: 20.6149 - val_mse: 958.9404\n",
      "Epoch 1685/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9496 - mse: 933.1516 - val_loss: 20.5600 - val_mse: 932.0287\n",
      "Epoch 1686/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9457 - mse: 933.6932 - val_loss: 20.5598 - val_mse: 931.6981\n",
      "Epoch 1687/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9299 - mse: 918.9910 - val_loss: 20.5616 - val_mse: 935.3868\n",
      "Epoch 1688/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9267 - mse: 933.2927 - val_loss: 20.6330 - val_mse: 963.2229\n",
      "Epoch 1689/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0238 - mse: 938.7285 - val_loss: 20.5610 - val_mse: 934.3546\n",
      "Epoch 1690/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9890 - mse: 930.3821 - val_loss: 20.7302 - val_mse: 980.0159\n",
      "Epoch 1691/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9964 - mse: 944.5338 - val_loss: 20.5605 - val_mse: 928.2673\n",
      "Epoch 1692/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0707 - mse: 948.6323 - val_loss: 20.5681 - val_mse: 940.6760\n",
      "Epoch 1693/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0957 - mse: 941.9195 - val_loss: 20.5611 - val_mse: 934.3933\n",
      "Epoch 1694/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0016 - mse: 932.3253 - val_loss: 20.6893 - val_mse: 973.5847\n",
      "Epoch 1695/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0557 - mse: 947.8902 - val_loss: 20.5662 - val_mse: 939.3802\n",
      "Epoch 1696/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0028 - mse: 932.9224 - val_loss: 20.5836 - val_mse: 948.5677\n",
      "Epoch 1697/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.8812 - mse: 922.0808 - val_loss: 20.5821 - val_mse: 947.8689\n",
      "Epoch 1698/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9426 - mse: 930.3090 - val_loss: 20.5601 - val_mse: 932.3138\n",
      "Epoch 1699/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9638 - mse: 937.0680 - val_loss: 20.6318 - val_mse: 962.9598\n",
      "Epoch 1700/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0065 - mse: 933.1210 - val_loss: 20.6085 - val_mse: 957.1033\n",
      "Epoch 1701/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0508 - mse: 933.4442 - val_loss: 20.5878 - val_mse: 950.3970\n",
      "Epoch 1702/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0334 - mse: 942.8136 - val_loss: 20.5746 - val_mse: 921.1307\n",
      "Epoch 1703/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9815 - mse: 924.7851 - val_loss: 20.5605 - val_mse: 933.2279\n",
      "Epoch 1704/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8852 - mse: 928.3878 - val_loss: 20.5675 - val_mse: 940.2391\n",
      "Epoch 1705/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0535 - mse: 938.9150 - val_loss: 20.7197 - val_mse: 978.3754\n",
      "Epoch 1706/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8051 - mse: 927.9493 - val_loss: 20.5636 - val_mse: 925.9377\n",
      "Epoch 1707/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0269 - mse: 937.7156 - val_loss: 20.5741 - val_mse: 921.3453\n",
      "Epoch 1708/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9616 - mse: 932.1983 - val_loss: 20.6292 - val_mse: 962.4154\n",
      "Epoch 1709/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0127 - mse: 940.1058 - val_loss: 20.6119 - val_mse: 958.0643\n",
      "Epoch 1710/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9079 - mse: 929.7961 - val_loss: 20.5889 - val_mse: 950.8261\n",
      "Epoch 1711/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0285 - mse: 942.2269 - val_loss: 20.5801 - val_mse: 946.9815\n",
      "Epoch 1712/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9762 - mse: 927.5803 - val_loss: 20.5612 - val_mse: 927.3873\n",
      "Epoch 1713/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9593 - mse: 938.2502 - val_loss: 20.5607 - val_mse: 927.9706\n",
      "Epoch 1714/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0117 - mse: 936.1157 - val_loss: 20.6186 - val_mse: 959.9471\n",
      "Epoch 1715/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0656 - mse: 938.6526 - val_loss: 20.5710 - val_mse: 942.3842\n",
      "Epoch 1716/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0345 - mse: 932.4948 - val_loss: 20.5692 - val_mse: 941.3452\n",
      "Epoch 1717/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.8762 - mse: 938.2042 - val_loss: 20.5961 - val_mse: 914.5816\n",
      "Epoch 1718/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9944 - mse: 935.1238 - val_loss: 20.5686 - val_mse: 940.9886\n",
      "Epoch 1719/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0143 - mse: 937.3452 - val_loss: 20.5827 - val_mse: 948.1521\n",
      "Epoch 1720/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9876 - mse: 936.5413 - val_loss: 20.5778 - val_mse: 945.9736\n",
      "Epoch 1721/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0630 - mse: 933.6611 - val_loss: 20.5847 - val_mse: 949.0815\n",
      "Epoch 1722/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.1493 - mse: 950.4428 - val_loss: 20.5616 - val_mse: 935.3839\n",
      "Epoch 1723/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9396 - mse: 931.1592 - val_loss: 20.6041 - val_mse: 912.6771\n",
      "Epoch 1724/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0390 - mse: 938.6521 - val_loss: 20.5682 - val_mse: 940.7211\n",
      "Epoch 1725/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9678 - mse: 938.9658 - val_loss: 20.6237 - val_mse: 961.1821\n",
      "Epoch 1726/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0554 - mse: 936.6646 - val_loss: 20.5726 - val_mse: 921.9279\n",
      "Epoch 1727/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0786 - mse: 930.7103 - val_loss: 20.5964 - val_mse: 953.3916\n",
      "Epoch 1728/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0682 - mse: 936.3438 - val_loss: 20.6158 - val_mse: 959.2028\n",
      "Epoch 1729/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9768 - mse: 937.0082 - val_loss: 20.5600 - val_mse: 929.3776\n",
      "Epoch 1730/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9816 - mse: 934.2969 - val_loss: 20.5837 - val_mse: 917.9581\n",
      "Epoch 1731/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0012 - mse: 934.9289 - val_loss: 20.5881 - val_mse: 916.7113\n",
      "Epoch 1732/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9803 - mse: 935.5537 - val_loss: 20.5604 - val_mse: 928.4987\n",
      "Epoch 1733/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9514 - mse: 933.2820 - val_loss: 20.6406 - val_mse: 964.7908\n",
      "Epoch 1734/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9628 - mse: 938.3938 - val_loss: 20.6014 - val_mse: 954.9958\n",
      "Epoch 1735/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0057 - mse: 933.2550 - val_loss: 20.5602 - val_mse: 932.5739\n",
      "Epoch 1736/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9416 - mse: 933.2092 - val_loss: 20.5690 - val_mse: 923.4633\n",
      "Epoch 1737/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9652 - mse: 940.0607 - val_loss: 20.5745 - val_mse: 921.1786\n",
      "Epoch 1738/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0477 - mse: 943.4017 - val_loss: 20.5956 - val_mse: 914.7235\n",
      "Epoch 1739/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1033 - mse: 946.6658 - val_loss: 20.5627 - val_mse: 936.5236\n",
      "Epoch 1740/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9705 - mse: 931.8110 - val_loss: 20.5599 - val_mse: 931.9423\n",
      "Epoch 1741/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9745 - mse: 941.4602 - val_loss: 20.5915 - val_mse: 951.7678\n",
      "Epoch 1742/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0027 - mse: 934.9996 - val_loss: 20.5621 - val_mse: 935.9909\n",
      "Epoch 1743/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0431 - mse: 927.3307 - val_loss: 20.5762 - val_mse: 945.2211\n",
      "Epoch 1744/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9328 - mse: 932.7440 - val_loss: 20.6016 - val_mse: 955.0306\n",
      "Epoch 1745/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0055 - mse: 931.8121 - val_loss: 20.5797 - val_mse: 946.8096\n",
      "Epoch 1746/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0207 - mse: 943.1780 - val_loss: 20.6235 - val_mse: 961.1379\n",
      "Epoch 1747/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9526 - mse: 938.3583 - val_loss: 20.6683 - val_mse: 901.8269\n",
      "Epoch 1748/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9556 - mse: 920.7097 - val_loss: 20.6335 - val_mse: 963.3136\n",
      "Epoch 1749/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0266 - mse: 932.9976 - val_loss: 20.8262 - val_mse: 994.6898\n",
      "Epoch 1750/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9790 - mse: 940.3141 - val_loss: 20.5735 - val_mse: 943.8077\n",
      "Epoch 1751/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9481 - mse: 928.7953 - val_loss: 20.5697 - val_mse: 941.6452\n",
      "Epoch 1752/5000\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 20.9524 - mse: 933.1342 - val_loss: 20.6368 - val_mse: 906.4125\n",
      "Epoch 1753/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9593 - mse: 922.0917 - val_loss: 20.5759 - val_mse: 945.0535\n",
      "Epoch 1754/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0905 - mse: 939.1256 - val_loss: 20.5647 - val_mse: 938.2302\n",
      "Epoch 1755/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0142 - mse: 934.9369 - val_loss: 20.5624 - val_mse: 936.2404\n",
      "Epoch 1756/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0320 - mse: 940.2628 - val_loss: 20.5737 - val_mse: 921.4883\n",
      "Epoch 1757/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0649 - mse: 936.2863 - val_loss: 20.5737 - val_mse: 921.5045\n",
      "Epoch 1758/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9597 - mse: 928.5001 - val_loss: 20.5709 - val_mse: 942.3489\n",
      "Epoch 1759/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9605 - mse: 943.4222 - val_loss: 20.6010 - val_mse: 913.3643\n",
      "Epoch 1760/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9793 - mse: 927.0233 - val_loss: 20.5609 - val_mse: 933.9746\n",
      "Epoch 1761/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9676 - mse: 936.9618 - val_loss: 20.5704 - val_mse: 922.8561\n",
      "Epoch 1762/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1349 - mse: 945.8816 - val_loss: 20.6698 - val_mse: 901.6490\n",
      "Epoch 1763/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8623 - mse: 926.0538 - val_loss: 20.5598 - val_mse: 931.5064\n",
      "Epoch 1764/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9460 - mse: 930.4808 - val_loss: 20.7082 - val_mse: 976.5877\n",
      "Epoch 1765/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.1168 - mse: 942.8180 - val_loss: 20.6044 - val_mse: 912.6231\n",
      "Epoch 1766/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1159 - mse: 950.3908 - val_loss: 20.6583 - val_mse: 903.1652\n",
      "Epoch 1767/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8777 - mse: 926.6058 - val_loss: 20.6034 - val_mse: 955.5801\n",
      "Epoch 1768/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0252 - mse: 948.2061 - val_loss: 20.5727 - val_mse: 943.3562\n",
      "Epoch 1769/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9983 - mse: 930.6167 - val_loss: 20.5722 - val_mse: 922.0881\n",
      "Epoch 1770/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9533 - mse: 932.4203 - val_loss: 20.5645 - val_mse: 938.0585\n",
      "Epoch 1771/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.8973 - mse: 931.6055 - val_loss: 20.5636 - val_mse: 937.2902\n",
      "Epoch 1772/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9296 - mse: 932.2206 - val_loss: 20.5627 - val_mse: 936.5635\n",
      "Epoch 1773/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0462 - mse: 941.8996 - val_loss: 20.6309 - val_mse: 962.7917\n",
      "Epoch 1774/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0627 - mse: 938.8880 - val_loss: 20.5735 - val_mse: 943.8190\n",
      "Epoch 1775/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0007 - mse: 932.4310 - val_loss: 20.9825 - val_mse: 1017.0770\n",
      "Epoch 1776/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1425 - mse: 948.6808 - val_loss: 20.6052 - val_mse: 956.1037\n",
      "Epoch 1777/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0003 - mse: 944.9260 - val_loss: 20.6250 - val_mse: 908.4506\n",
      "Epoch 1778/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0797 - mse: 928.8667 - val_loss: 20.5948 - val_mse: 952.8771\n",
      "Epoch 1779/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0138 - mse: 941.6113 - val_loss: 20.6184 - val_mse: 959.8907\n",
      "Epoch 1780/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9765 - mse: 930.9260 - val_loss: 20.5712 - val_mse: 942.5400\n",
      "Epoch 1781/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0403 - mse: 939.8824 - val_loss: 20.6200 - val_mse: 960.2902\n",
      "Epoch 1782/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9544 - mse: 927.7596 - val_loss: 20.5952 - val_mse: 953.0231\n",
      "Epoch 1783/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.1007 - mse: 942.1653 - val_loss: 20.5861 - val_mse: 949.7232\n",
      "Epoch 1784/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0470 - mse: 943.4595 - val_loss: 20.6281 - val_mse: 962.1804\n",
      "Epoch 1785/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9236 - mse: 951.5475 - val_loss: 20.6223 - val_mse: 908.9433\n",
      "Epoch 1786/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.8836 - mse: 928.3999 - val_loss: 20.5750 - val_mse: 920.9771\n",
      "Epoch 1787/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9375 - mse: 937.6812 - val_loss: 20.5715 - val_mse: 942.6936\n",
      "Epoch 1788/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0051 - mse: 928.8821 - val_loss: 20.6001 - val_mse: 954.5905\n",
      "Epoch 1789/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0051 - mse: 928.3453 - val_loss: 20.6774 - val_mse: 971.5777\n",
      "Epoch 1790/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9428 - mse: 937.7083 - val_loss: 20.5759 - val_mse: 945.0504\n",
      "Epoch 1791/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9656 - mse: 933.9257 - val_loss: 20.5609 - val_mse: 934.0081\n",
      "Epoch 1792/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0305 - mse: 936.1356 - val_loss: 20.6687 - val_mse: 901.7790\n",
      "Epoch 1793/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9867 - mse: 925.2295 - val_loss: 20.6621 - val_mse: 968.9336\n",
      "Epoch 1794/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0002 - mse: 948.9126 - val_loss: 20.5893 - val_mse: 916.4002\n",
      "Epoch 1795/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9536 - mse: 921.6732 - val_loss: 20.7269 - val_mse: 979.4881\n",
      "Epoch 1796/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9948 - mse: 937.5695 - val_loss: 20.6625 - val_mse: 969.0013\n",
      "Epoch 1797/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0476 - mse: 938.1191 - val_loss: 20.6401 - val_mse: 964.6948\n",
      "Epoch 1798/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9905 - mse: 948.5250 - val_loss: 20.5651 - val_mse: 938.4667\n",
      "Epoch 1799/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9464 - mse: 929.2475 - val_loss: 20.5921 - val_mse: 915.6544\n",
      "Epoch 1800/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9549 - mse: 937.5901 - val_loss: 20.5695 - val_mse: 923.2496\n",
      "Epoch 1801/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0190 - mse: 931.8469 - val_loss: 20.5598 - val_mse: 930.9573\n",
      "Epoch 1802/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9518 - mse: 937.0994 - val_loss: 20.5756 - val_mse: 944.8988\n",
      "Epoch 1803/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9368 - mse: 932.7552 - val_loss: 20.6361 - val_mse: 963.8600\n",
      "Epoch 1804/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0610 - mse: 938.0261 - val_loss: 20.6740 - val_mse: 971.0052\n",
      "Epoch 1805/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0323 - mse: 937.5239 - val_loss: 20.6011 - val_mse: 954.9087\n",
      "Epoch 1806/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9763 - mse: 935.1528 - val_loss: 20.5807 - val_mse: 947.2444\n",
      "Epoch 1807/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9791 - mse: 937.6373 - val_loss: 20.6351 - val_mse: 963.6444\n",
      "Epoch 1808/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9607 - mse: 932.7064 - val_loss: 20.5970 - val_mse: 953.5883\n",
      "Epoch 1809/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9123 - mse: 935.1088 - val_loss: 20.6704 - val_mse: 901.5764\n",
      "Epoch 1810/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0903 - mse: 935.7569 - val_loss: 20.5753 - val_mse: 920.8828\n",
      "Epoch 1811/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9364 - mse: 932.9835 - val_loss: 20.5609 - val_mse: 933.9779\n",
      "Epoch 1812/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9843 - mse: 935.6287 - val_loss: 20.5703 - val_mse: 922.8888\n",
      "Epoch 1813/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1508 - mse: 936.2421 - val_loss: 20.5675 - val_mse: 940.2706\n",
      "Epoch 1814/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1284 - mse: 946.3218 - val_loss: 20.5830 - val_mse: 918.1538\n",
      "Epoch 1815/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.8933 - mse: 932.6166 - val_loss: 20.5625 - val_mse: 926.5308\n",
      "Epoch 1816/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9857 - mse: 940.4867 - val_loss: 20.5756 - val_mse: 920.7849\n",
      "Epoch 1817/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8704 - mse: 926.5845 - val_loss: 20.6000 - val_mse: 954.5551\n",
      "Epoch 1818/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9502 - mse: 928.2322 - val_loss: 20.6469 - val_mse: 966.0956\n",
      "Epoch 1819/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0012 - mse: 932.3148 - val_loss: 20.5700 - val_mse: 923.0431\n",
      "Epoch 1820/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0004 - mse: 939.0623 - val_loss: 20.6223 - val_mse: 960.8569\n",
      "Epoch 1821/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0498 - mse: 945.6038 - val_loss: 20.5602 - val_mse: 928.9094\n",
      "Epoch 1822/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9327 - mse: 923.5858 - val_loss: 20.7158 - val_mse: 977.7654\n",
      "Epoch 1823/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9704 - mse: 930.4249 - val_loss: 20.6848 - val_mse: 972.8410\n",
      "Epoch 1824/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9361 - mse: 935.4265 - val_loss: 20.6124 - val_mse: 958.2219\n",
      "Epoch 1825/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0181 - mse: 941.4061 - val_loss: 20.8880 - val_mse: 1003.8502\n",
      "Epoch 1826/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0104 - mse: 937.3813 - val_loss: 20.5937 - val_mse: 952.5033\n",
      "Epoch 1827/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0211 - mse: 937.3017 - val_loss: 20.5610 - val_mse: 934.2505\n",
      "Epoch 1828/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9360 - mse: 933.4307 - val_loss: 20.6492 - val_mse: 966.5374\n",
      "Epoch 1829/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9489 - mse: 933.6776 - val_loss: 20.5842 - val_mse: 948.8521\n",
      "Epoch 1830/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0275 - mse: 936.3583 - val_loss: 20.5830 - val_mse: 918.1636\n",
      "Epoch 1831/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9581 - mse: 934.5222 - val_loss: 20.6024 - val_mse: 955.2931\n",
      "Epoch 1832/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9895 - mse: 939.2625 - val_loss: 20.6077 - val_mse: 911.8934\n",
      "Epoch 1833/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0385 - mse: 947.9781 - val_loss: 20.6019 - val_mse: 913.1642\n",
      "Epoch 1834/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9640 - mse: 926.5492 - val_loss: 20.5791 - val_mse: 946.5447\n",
      "Epoch 1835/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.8797 - mse: 926.9860 - val_loss: 20.5601 - val_mse: 932.2169\n",
      "Epoch 1836/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9915 - mse: 935.1018 - val_loss: 20.5732 - val_mse: 943.6294\n",
      "Epoch 1837/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9736 - mse: 942.2990 - val_loss: 20.6758 - val_mse: 971.3164\n",
      "Epoch 1838/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0336 - mse: 941.6123 - val_loss: 20.5983 - val_mse: 954.0383\n",
      "Epoch 1839/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9542 - mse: 932.9438 - val_loss: 20.5822 - val_mse: 947.9129\n",
      "Epoch 1840/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9423 - mse: 928.6738 - val_loss: 20.5618 - val_mse: 935.6019\n",
      "Epoch 1841/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9495 - mse: 938.7680 - val_loss: 20.5677 - val_mse: 940.3846\n",
      "Epoch 1842/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9344 - mse: 927.6504 - val_loss: 20.6448 - val_mse: 965.6747\n",
      "Epoch 1843/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0416 - mse: 941.8825 - val_loss: 20.5757 - val_mse: 944.9680\n",
      "Epoch 1844/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9773 - mse: 935.0903 - val_loss: 20.5696 - val_mse: 941.6198\n",
      "Epoch 1845/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9946 - mse: 931.7992 - val_loss: 20.5718 - val_mse: 942.8712\n",
      "Epoch 1846/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9481 - mse: 938.8691 - val_loss: 20.5623 - val_mse: 936.1292\n",
      "Epoch 1847/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0453 - mse: 944.1725 - val_loss: 20.5607 - val_mse: 927.9923\n",
      "Epoch 1848/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0711 - mse: 942.9578 - val_loss: 20.5858 - val_mse: 917.3423\n",
      "Epoch 1849/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9919 - mse: 932.9702 - val_loss: 20.5621 - val_mse: 935.9263\n",
      "Epoch 1850/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0547 - mse: 932.1041 - val_loss: 20.5767 - val_mse: 920.3666\n",
      "Epoch 1851/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9597 - mse: 934.2444 - val_loss: 20.6480 - val_mse: 966.3098\n",
      "Epoch 1852/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9343 - mse: 934.9022 - val_loss: 20.5703 - val_mse: 922.9073\n",
      "Epoch 1853/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0297 - mse: 930.6588 - val_loss: 20.5618 - val_mse: 935.6546\n",
      "Epoch 1854/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0574 - mse: 946.1108 - val_loss: 20.5747 - val_mse: 944.4595\n",
      "Epoch 1855/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9967 - mse: 938.2018 - val_loss: 20.5640 - val_mse: 925.7139\n",
      "Epoch 1856/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0025 - mse: 936.0159 - val_loss: 20.5651 - val_mse: 938.5036\n",
      "Epoch 1857/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9989 - mse: 937.6689 - val_loss: 20.6512 - val_mse: 966.9399\n",
      "Epoch 1858/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9709 - mse: 942.5693 - val_loss: 20.5827 - val_mse: 948.1379\n",
      "Epoch 1859/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9157 - mse: 922.0376 - val_loss: 20.7825 - val_mse: 988.1401\n",
      "Epoch 1860/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0325 - mse: 943.2241 - val_loss: 20.5767 - val_mse: 920.3519\n",
      "Epoch 1861/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0756 - mse: 935.4123 - val_loss: 20.5993 - val_mse: 954.3277\n",
      "Epoch 1862/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0098 - mse: 938.5582 - val_loss: 20.5913 - val_mse: 951.6883\n",
      "Epoch 1863/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9019 - mse: 933.1127 - val_loss: 20.5686 - val_mse: 941.0013\n",
      "Epoch 1864/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9985 - mse: 937.3844 - val_loss: 20.5598 - val_mse: 931.3713\n",
      "Epoch 1865/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9131 - mse: 923.6176 - val_loss: 20.6043 - val_mse: 955.8571\n",
      "Epoch 1866/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9998 - mse: 941.0066 - val_loss: 20.5910 - val_mse: 951.5917\n",
      "Epoch 1867/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9543 - mse: 928.3253 - val_loss: 20.5885 - val_mse: 950.6933\n",
      "Epoch 1868/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9630 - mse: 940.0007 - val_loss: 20.6152 - val_mse: 959.0267\n",
      "Epoch 1869/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9216 - mse: 926.1331 - val_loss: 20.5798 - val_mse: 946.8623\n",
      "Epoch 1870/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0591 - mse: 946.4890 - val_loss: 20.5777 - val_mse: 945.9142\n",
      "Epoch 1871/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0249 - mse: 928.1711 - val_loss: 20.5713 - val_mse: 942.5427\n",
      "Epoch 1872/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.8997 - mse: 929.1194 - val_loss: 20.5643 - val_mse: 937.9255\n",
      "Epoch 1873/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0582 - mse: 941.8821 - val_loss: 20.5718 - val_mse: 942.8779\n",
      "Epoch 1874/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9789 - mse: 943.2893 - val_loss: 20.5716 - val_mse: 942.7631\n",
      "Epoch 1875/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9217 - mse: 932.7193 - val_loss: 20.6051 - val_mse: 956.0908\n",
      "Epoch 1876/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0854 - mse: 950.4125 - val_loss: 20.5891 - val_mse: 950.9100\n",
      "Epoch 1877/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9007 - mse: 928.1993 - val_loss: 20.5606 - val_mse: 933.4846\n",
      "Epoch 1878/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0221 - mse: 932.7323 - val_loss: 20.5752 - val_mse: 944.7267\n",
      "Epoch 1879/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0425 - mse: 935.3035 - val_loss: 20.5705 - val_mse: 942.1003\n",
      "Epoch 1880/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9981 - mse: 942.3399 - val_loss: 20.5684 - val_mse: 940.9075\n",
      "Epoch 1881/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9013 - mse: 933.9012 - val_loss: 20.5654 - val_mse: 938.7550\n",
      "Epoch 1882/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9376 - mse: 937.1229 - val_loss: 20.5826 - val_mse: 948.1185\n",
      "Epoch 1883/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9686 - mse: 934.7563 - val_loss: 20.5677 - val_mse: 940.4078\n",
      "Epoch 1884/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0357 - mse: 937.6628 - val_loss: 20.5947 - val_mse: 952.8686\n",
      "Epoch 1885/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1168 - mse: 936.0227 - val_loss: 20.6352 - val_mse: 963.6625\n",
      "Epoch 1886/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.8849 - mse: 931.6117 - val_loss: 20.5806 - val_mse: 947.1987\n",
      "Epoch 1887/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9475 - mse: 946.0414 - val_loss: 20.5630 - val_mse: 926.2350\n",
      "Epoch 1888/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0366 - mse: 949.6288 - val_loss: 20.6214 - val_mse: 909.1047\n",
      "Epoch 1889/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.1153 - mse: 936.2255 - val_loss: 20.5605 - val_mse: 933.1189\n",
      "Epoch 1890/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0014 - mse: 934.5442 - val_loss: 20.5651 - val_mse: 925.2177\n",
      "Epoch 1891/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0508 - mse: 941.6284 - val_loss: 20.5750 - val_mse: 944.6010\n",
      "Epoch 1892/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0248 - mse: 931.9832 - val_loss: 20.5609 - val_mse: 933.9456\n",
      "Epoch 1893/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9172 - mse: 929.1502 - val_loss: 20.5647 - val_mse: 925.3950\n",
      "Epoch 1894/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.8961 - mse: 932.9987 - val_loss: 20.6278 - val_mse: 962.1131\n",
      "Epoch 1895/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0586 - mse: 940.1616 - val_loss: 20.5653 - val_mse: 925.1142\n",
      "Epoch 1896/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0026 - mse: 934.1683 - val_loss: 20.6043 - val_mse: 912.6459\n",
      "Epoch 1897/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0043 - mse: 932.9789 - val_loss: 20.5734 - val_mse: 921.6214\n",
      "Epoch 1898/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9383 - mse: 933.7957 - val_loss: 20.5973 - val_mse: 953.7053\n",
      "Epoch 1899/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9642 - mse: 944.2280 - val_loss: 20.6156 - val_mse: 910.2332\n",
      "Epoch 1900/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9348 - mse: 934.4617 - val_loss: 20.6144 - val_mse: 958.8039\n",
      "Epoch 1901/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0436 - mse: 938.9875 - val_loss: 20.5632 - val_mse: 926.1579\n",
      "Epoch 1902/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9703 - mse: 937.8730 - val_loss: 20.6119 - val_mse: 958.0669\n",
      "Epoch 1903/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9998 - mse: 935.8647 - val_loss: 20.6895 - val_mse: 973.6167\n",
      "Epoch 1904/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0370 - mse: 940.2474 - val_loss: 20.5902 - val_mse: 951.3223\n",
      "Epoch 1905/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9822 - mse: 924.4873 - val_loss: 20.6919 - val_mse: 974.0076\n",
      "Epoch 1906/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9970 - mse: 938.2239 - val_loss: 20.5693 - val_mse: 941.4094\n",
      "Epoch 1907/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0059 - mse: 947.3372 - val_loss: 20.5768 - val_mse: 945.4977\n",
      "Epoch 1908/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0211 - mse: 936.0969 - val_loss: 20.6057 - val_mse: 912.3266\n",
      "Epoch 1909/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0791 - mse: 944.1311 - val_loss: 20.5611 - val_mse: 927.4894\n",
      "Epoch 1910/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9958 - mse: 938.4434 - val_loss: 20.5604 - val_mse: 928.4663\n",
      "Epoch 1911/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9756 - mse: 925.1615 - val_loss: 20.5789 - val_mse: 946.4519\n",
      "Epoch 1912/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9715 - mse: 932.8295 - val_loss: 20.5886 - val_mse: 950.7029\n",
      "Epoch 1913/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9647 - mse: 936.1930 - val_loss: 20.5986 - val_mse: 913.9235\n",
      "Epoch 1914/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9594 - mse: 928.6179 - val_loss: 20.5853 - val_mse: 949.3569\n",
      "Epoch 1915/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0186 - mse: 943.7078 - val_loss: 20.5713 - val_mse: 942.5859\n",
      "Epoch 1916/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0223 - mse: 935.4296 - val_loss: 20.5649 - val_mse: 925.2917\n",
      "Epoch 1917/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0707 - mse: 943.9289 - val_loss: 20.5608 - val_mse: 927.8483\n",
      "Epoch 1918/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9676 - mse: 928.1392 - val_loss: 20.5804 - val_mse: 919.0502\n",
      "Epoch 1919/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0519 - mse: 940.1869 - val_loss: 20.5600 - val_mse: 932.1379\n",
      "Epoch 1920/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0338 - mse: 929.0056 - val_loss: 20.5604 - val_mse: 928.4874\n",
      "Epoch 1921/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0259 - mse: 937.7089 - val_loss: 20.8287 - val_mse: 995.0532\n",
      "Epoch 1922/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0070 - mse: 931.4178 - val_loss: 20.5797 - val_mse: 946.8212\n",
      "Epoch 1923/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9880 - mse: 933.8537 - val_loss: 20.5940 - val_mse: 952.6357\n",
      "Epoch 1924/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9807 - mse: 937.6619 - val_loss: 20.6066 - val_mse: 956.5475\n",
      "Epoch 1925/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9920 - mse: 941.5582 - val_loss: 20.5954 - val_mse: 953.0903\n",
      "Epoch 1926/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9565 - mse: 935.5602 - val_loss: 20.7994 - val_mse: 990.7159\n",
      "Epoch 1927/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9198 - mse: 929.0562 - val_loss: 20.5638 - val_mse: 937.5017\n",
      "Epoch 1928/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8808 - mse: 926.3199 - val_loss: 20.5618 - val_mse: 935.6830\n",
      "Epoch 1929/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9607 - mse: 942.4462 - val_loss: 20.5806 - val_mse: 918.9810\n",
      "Epoch 1930/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9621 - mse: 929.2933 - val_loss: 20.8251 - val_mse: 994.5200\n",
      "Epoch 1931/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0627 - mse: 939.9835 - val_loss: 20.7098 - val_mse: 976.8416\n",
      "Epoch 1932/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0368 - mse: 941.2152 - val_loss: 20.6512 - val_mse: 966.9439\n",
      "Epoch 1933/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0235 - mse: 942.0973 - val_loss: 20.5608 - val_mse: 933.7361\n",
      "Epoch 1934/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9777 - mse: 931.1508 - val_loss: 20.5650 - val_mse: 938.4439\n",
      "Epoch 1935/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9942 - mse: 939.2531 - val_loss: 20.5599 - val_mse: 929.9731\n",
      "Epoch 1936/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0061 - mse: 923.2853 - val_loss: 20.6076 - val_mse: 956.8166\n",
      "Epoch 1937/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.1167 - mse: 941.1562 - val_loss: 21.0376 - val_mse: 1024.1586\n",
      "Epoch 1938/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9923 - mse: 927.8574 - val_loss: 20.8990 - val_mse: 1005.5048\n",
      "Epoch 1939/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0947 - mse: 945.1520 - val_loss: 20.5656 - val_mse: 924.9724\n",
      "Epoch 1940/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9788 - mse: 934.6818 - val_loss: 20.5600 - val_mse: 932.1277\n",
      "Epoch 1941/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.8921 - mse: 923.6190 - val_loss: 20.5606 - val_mse: 933.4490\n",
      "Epoch 1942/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9855 - mse: 933.7728 - val_loss: 20.6100 - val_mse: 957.5358\n",
      "Epoch 1943/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9618 - mse: 939.0378 - val_loss: 20.6190 - val_mse: 960.0500\n",
      "Epoch 1944/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0223 - mse: 931.6622 - val_loss: 20.6044 - val_mse: 955.8638\n",
      "Epoch 1945/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0423 - mse: 950.9382 - val_loss: 20.7128 - val_mse: 977.3040\n",
      "Epoch 1946/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9785 - mse: 931.4991 - val_loss: 20.5696 - val_mse: 941.6300\n",
      "Epoch 1947/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9453 - mse: 936.6844 - val_loss: 20.6028 - val_mse: 955.3975\n",
      "Epoch 1948/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9900 - mse: 941.7586 - val_loss: 20.5933 - val_mse: 952.3981\n",
      "Epoch 1949/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9705 - mse: 933.5936 - val_loss: 20.5733 - val_mse: 943.7261\n",
      "Epoch 1950/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9312 - mse: 933.0937 - val_loss: 20.6759 - val_mse: 971.3350\n",
      "Epoch 1951/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9647 - mse: 939.6753 - val_loss: 20.6123 - val_mse: 958.1962\n",
      "Epoch 1952/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9620 - mse: 929.7648 - val_loss: 20.5781 - val_mse: 946.0806\n",
      "Epoch 1953/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9422 - mse: 936.9935 - val_loss: 20.5608 - val_mse: 927.8629\n",
      "Epoch 1954/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9785 - mse: 929.3049 - val_loss: 20.5621 - val_mse: 935.9672\n",
      "Epoch 1955/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9994 - mse: 932.6033 - val_loss: 20.5686 - val_mse: 941.0123\n",
      "Epoch 1956/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0333 - mse: 934.6930 - val_loss: 20.6210 - val_mse: 960.5322\n",
      "Epoch 1957/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0030 - mse: 937.3066 - val_loss: 20.6004 - val_mse: 954.6653\n",
      "Epoch 1958/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0127 - mse: 942.1043 - val_loss: 20.5757 - val_mse: 944.9371\n",
      "Epoch 1959/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9597 - mse: 928.1421 - val_loss: 20.6167 - val_mse: 959.4293\n",
      "Epoch 1960/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.1105 - mse: 946.6414 - val_loss: 20.5635 - val_mse: 937.2564\n",
      "Epoch 1961/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0017 - mse: 940.0001 - val_loss: 20.5610 - val_mse: 934.3275\n",
      "Epoch 1962/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9485 - mse: 930.8239 - val_loss: 20.5671 - val_mse: 939.9927\n",
      "Epoch 1963/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9978 - mse: 939.0893 - val_loss: 20.5791 - val_mse: 946.5304\n",
      "Epoch 1964/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0519 - mse: 937.0862 - val_loss: 20.6079 - val_mse: 956.9300\n",
      "Epoch 1965/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9198 - mse: 933.5401 - val_loss: 20.7514 - val_mse: 983.2910\n",
      "Epoch 1966/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0696 - mse: 942.8896 - val_loss: 20.6495 - val_mse: 966.6077\n",
      "Epoch 1967/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0481 - mse: 945.2656 - val_loss: 20.5875 - val_mse: 950.2673\n",
      "Epoch 1968/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0336 - mse: 946.5749 - val_loss: 20.5738 - val_mse: 943.9664\n",
      "Epoch 1969/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9898 - mse: 929.1974 - val_loss: 20.6592 - val_mse: 968.4323\n",
      "Epoch 1970/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0123 - mse: 945.3591 - val_loss: 20.5980 - val_mse: 914.0937\n",
      "Epoch 1971/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9207 - mse: 926.9882 - val_loss: 20.5685 - val_mse: 923.7004\n",
      "Epoch 1972/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9761 - mse: 929.5964 - val_loss: 20.6373 - val_mse: 964.1116\n",
      "Epoch 1973/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9864 - mse: 933.5748 - val_loss: 20.5621 - val_mse: 935.9746\n",
      "Epoch 1974/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0050 - mse: 932.9240 - val_loss: 20.6052 - val_mse: 912.4498\n",
      "Epoch 1975/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9568 - mse: 932.9705 - val_loss: 20.5922 - val_mse: 952.0142\n",
      "Epoch 1976/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0688 - mse: 945.9001 - val_loss: 20.5658 - val_mse: 939.0756\n",
      "Epoch 1977/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0606 - mse: 935.7431 - val_loss: 20.5662 - val_mse: 924.6960\n",
      "Epoch 1978/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.8062 - mse: 925.8964 - val_loss: 20.6942 - val_mse: 974.3769\n",
      "Epoch 1979/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9562 - mse: 935.1961 - val_loss: 20.5966 - val_mse: 953.4714\n",
      "Epoch 1980/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0466 - mse: 935.3579 - val_loss: 20.5713 - val_mse: 942.5928\n",
      "Epoch 1981/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0706 - mse: 931.3629 - val_loss: 20.5621 - val_mse: 935.9912\n",
      "Epoch 1982/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0069 - mse: 933.8349 - val_loss: 20.5841 - val_mse: 917.8375\n",
      "Epoch 1983/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0261 - mse: 933.2005 - val_loss: 20.5704 - val_mse: 942.0853\n",
      "Epoch 1984/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1035 - mse: 943.2498 - val_loss: 20.6566 - val_mse: 903.3967\n",
      "Epoch 1985/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9988 - mse: 931.0421 - val_loss: 20.5951 - val_mse: 914.8403\n",
      "Epoch 1986/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9266 - mse: 932.6174 - val_loss: 20.5598 - val_mse: 930.7365\n",
      "Epoch 1987/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9900 - mse: 927.9597 - val_loss: 20.8160 - val_mse: 993.1844\n",
      "Epoch 1988/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9617 - mse: 931.7734 - val_loss: 20.5951 - val_mse: 952.9772\n",
      "Epoch 1989/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0087 - mse: 936.3708 - val_loss: 20.5620 - val_mse: 935.9071\n",
      "Epoch 1990/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0587 - mse: 949.6512 - val_loss: 20.5717 - val_mse: 942.7675\n",
      "Epoch 1991/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0087 - mse: 932.7520 - val_loss: 20.5630 - val_mse: 936.7933\n",
      "Epoch 1992/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9112 - mse: 938.6732 - val_loss: 20.6169 - val_mse: 909.9844\n",
      "Epoch 1993/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0791 - mse: 932.5527 - val_loss: 20.5816 - val_mse: 918.6352\n",
      "Epoch 1994/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0538 - mse: 950.0176 - val_loss: 20.5744 - val_mse: 921.2307\n",
      "Epoch 1995/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0059 - mse: 937.3721 - val_loss: 20.5852 - val_mse: 949.2894\n",
      "Epoch 1996/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9606 - mse: 938.6601 - val_loss: 20.5678 - val_mse: 924.0118\n",
      "Epoch 1997/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0229 - mse: 935.2199 - val_loss: 20.6014 - val_mse: 913.2883\n",
      "Epoch 1998/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0393 - mse: 937.2471 - val_loss: 20.5921 - val_mse: 951.9597\n",
      "Epoch 1999/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0317 - mse: 927.2426 - val_loss: 20.6416 - val_mse: 965.0065\n",
      "Epoch 2000/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9419 - mse: 935.3804 - val_loss: 20.5903 - val_mse: 951.3656\n",
      "Epoch 2001/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0645 - mse: 943.9683 - val_loss: 20.5616 - val_mse: 935.4523\n",
      "Epoch 2002/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0118 - mse: 940.1615 - val_loss: 20.6300 - val_mse: 962.5981\n",
      "Epoch 2003/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9542 - mse: 938.6905 - val_loss: 20.6284 - val_mse: 907.8300\n",
      "Epoch 2004/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9310 - mse: 923.3669 - val_loss: 20.6010 - val_mse: 954.8664\n",
      "Epoch 2005/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9486 - mse: 940.1063 - val_loss: 20.7226 - val_mse: 896.2191\n",
      "Epoch 2006/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0396 - mse: 926.9213 - val_loss: 20.5733 - val_mse: 921.6667\n",
      "Epoch 2007/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9527 - mse: 934.3084 - val_loss: 20.7197 - val_mse: 978.3699\n",
      "Epoch 2008/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9321 - mse: 934.1097 - val_loss: 20.5980 - val_mse: 953.9200\n",
      "Epoch 2009/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9150 - mse: 932.9489 - val_loss: 20.5624 - val_mse: 936.2237\n",
      "Epoch 2010/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9256 - mse: 937.9055 - val_loss: 20.6160 - val_mse: 910.1504\n",
      "Epoch 2011/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0130 - mse: 922.8293 - val_loss: 20.5625 - val_mse: 936.3997\n",
      "Epoch 2012/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0712 - mse: 947.1165 - val_loss: 20.5668 - val_mse: 924.4625\n",
      "Epoch 2013/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.8888 - mse: 932.9672 - val_loss: 20.6150 - val_mse: 958.9576\n",
      "Epoch 2014/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0312 - mse: 934.7475 - val_loss: 20.6302 - val_mse: 962.6289\n",
      "Epoch 2015/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0476 - mse: 940.9829 - val_loss: 20.6171 - val_mse: 959.5612\n",
      "Epoch 2016/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9593 - mse: 928.2532 - val_loss: 20.6184 - val_mse: 959.8774\n",
      "Epoch 2017/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9427 - mse: 936.9863 - val_loss: 20.6238 - val_mse: 961.1946\n",
      "Epoch 2018/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9767 - mse: 933.5775 - val_loss: 20.5690 - val_mse: 941.2452\n",
      "Epoch 2019/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9885 - mse: 938.6475 - val_loss: 20.5598 - val_mse: 931.3029\n",
      "Epoch 2020/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9712 - mse: 930.6378 - val_loss: 20.6105 - val_mse: 957.6603\n",
      "Epoch 2021/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0112 - mse: 936.4741 - val_loss: 20.6167 - val_mse: 959.4387\n",
      "Epoch 2022/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9224 - mse: 935.7972 - val_loss: 20.7133 - val_mse: 977.3798\n",
      "Epoch 2023/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0202 - mse: 933.9438 - val_loss: 20.5802 - val_mse: 947.0175\n",
      "Epoch 2024/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0034 - mse: 927.3091 - val_loss: 20.5812 - val_mse: 947.4885\n",
      "Epoch 2025/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0183 - mse: 943.9242 - val_loss: 20.5872 - val_mse: 950.1451\n",
      "Epoch 2026/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9139 - mse: 936.6307 - val_loss: 20.5895 - val_mse: 951.0627\n",
      "Epoch 2027/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9644 - mse: 926.9037 - val_loss: 20.6962 - val_mse: 974.6990\n",
      "Epoch 2028/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9663 - mse: 932.2997 - val_loss: 20.6644 - val_mse: 969.3333\n",
      "Epoch 2029/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9559 - mse: 944.4307 - val_loss: 20.7015 - val_mse: 975.5286\n",
      "Epoch 2030/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.8312 - mse: 925.7206 - val_loss: 20.5768 - val_mse: 945.4922\n",
      "Epoch 2031/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0450 - mse: 935.5093 - val_loss: 20.7248 - val_mse: 979.1619\n",
      "Epoch 2032/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0451 - mse: 945.3226 - val_loss: 20.5822 - val_mse: 947.9266\n",
      "Epoch 2033/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9205 - mse: 930.9645 - val_loss: 20.6011 - val_mse: 954.9031\n",
      "Epoch 2034/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9319 - mse: 924.9415 - val_loss: 20.6643 - val_mse: 969.3238\n",
      "Epoch 2035/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0585 - mse: 945.3883 - val_loss: 20.5847 - val_mse: 949.0629\n",
      "Epoch 2036/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9743 - mse: 942.6094 - val_loss: 20.6050 - val_mse: 956.0552\n",
      "Epoch 2037/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.8618 - mse: 928.4192 - val_loss: 20.6718 - val_mse: 970.6255\n",
      "Epoch 2038/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0190 - mse: 933.8952 - val_loss: 20.5733 - val_mse: 943.7126\n",
      "Epoch 2039/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0405 - mse: 945.2484 - val_loss: 20.8424 - val_mse: 997.0782\n",
      "Epoch 2040/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0240 - mse: 942.1924 - val_loss: 20.5953 - val_mse: 914.7817\n",
      "Epoch 2041/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8852 - mse: 932.1361 - val_loss: 20.5837 - val_mse: 917.9357\n",
      "Epoch 2042/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9367 - mse: 931.5184 - val_loss: 20.5944 - val_mse: 915.0382\n",
      "Epoch 2043/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9796 - mse: 933.4775 - val_loss: 20.5620 - val_mse: 935.8644\n",
      "Epoch 2044/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9585 - mse: 928.5051 - val_loss: 20.6213 - val_mse: 960.6021\n",
      "Epoch 2045/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0452 - mse: 941.9034 - val_loss: 20.5651 - val_mse: 938.4702\n",
      "Epoch 2046/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.8822 - mse: 923.9207 - val_loss: 20.5792 - val_mse: 946.5903\n",
      "Epoch 2047/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9794 - mse: 937.4000 - val_loss: 20.5952 - val_mse: 953.0044\n",
      "Epoch 2048/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0020 - mse: 934.4973 - val_loss: 20.6657 - val_mse: 969.5610\n",
      "Epoch 2049/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9692 - mse: 936.2531 - val_loss: 20.6973 - val_mse: 974.8796\n",
      "Epoch 2050/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9869 - mse: 933.6715 - val_loss: 20.6146 - val_mse: 958.8460\n",
      "Epoch 2051/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9675 - mse: 922.7888 - val_loss: 20.6390 - val_mse: 964.4650\n",
      "Epoch 2052/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9160 - mse: 931.4041 - val_loss: 20.6113 - val_mse: 957.9106\n",
      "Epoch 2053/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9855 - mse: 947.5912 - val_loss: 20.5598 - val_mse: 930.8802\n",
      "Epoch 2054/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9936 - mse: 942.9562 - val_loss: 20.5782 - val_mse: 946.1169\n",
      "Epoch 2055/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.8889 - mse: 919.1869 - val_loss: 20.5793 - val_mse: 946.6263\n",
      "Epoch 2056/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9542 - mse: 938.5393 - val_loss: 20.5618 - val_mse: 935.6329\n",
      "Epoch 2057/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0887 - mse: 948.7692 - val_loss: 20.5818 - val_mse: 947.7337\n",
      "Epoch 2058/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9770 - mse: 929.3360 - val_loss: 20.6720 - val_mse: 970.6627\n",
      "Epoch 2059/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9849 - mse: 928.5312 - val_loss: 20.5671 - val_mse: 940.0021\n",
      "Epoch 2060/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9933 - mse: 937.8764 - val_loss: 20.5883 - val_mse: 950.6059\n",
      "Epoch 2061/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8887 - mse: 926.5444 - val_loss: 20.5644 - val_mse: 937.9457\n",
      "Epoch 2062/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0091 - mse: 940.5745 - val_loss: 20.5684 - val_mse: 940.8834\n",
      "Epoch 2063/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9425 - mse: 928.9500 - val_loss: 20.5725 - val_mse: 921.9642\n",
      "Epoch 2064/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0383 - mse: 936.2909 - val_loss: 20.5604 - val_mse: 932.9930\n",
      "Epoch 2065/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9811 - mse: 942.9547 - val_loss: 20.7449 - val_mse: 894.3033\n",
      "Epoch 2066/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0536 - mse: 945.6953 - val_loss: 20.5726 - val_mse: 921.9548\n",
      "Epoch 2067/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9234 - mse: 932.8337 - val_loss: 20.5656 - val_mse: 938.8964\n",
      "Epoch 2068/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9113 - mse: 928.6001 - val_loss: 20.5959 - val_mse: 914.6304\n",
      "Epoch 2069/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9684 - mse: 930.7283 - val_loss: 20.6587 - val_mse: 968.3398\n",
      "Epoch 2070/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9611 - mse: 943.7368 - val_loss: 20.5623 - val_mse: 936.1521\n",
      "Epoch 2071/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9919 - mse: 938.9478 - val_loss: 20.6562 - val_mse: 903.4496\n",
      "Epoch 2072/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9708 - mse: 932.1713 - val_loss: 20.6477 - val_mse: 966.2437\n",
      "Epoch 2073/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9756 - mse: 934.3047 - val_loss: 20.5653 - val_mse: 938.6675\n",
      "Epoch 2074/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9002 - mse: 934.4290 - val_loss: 20.6402 - val_mse: 964.7026\n",
      "Epoch 2075/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9297 - mse: 935.2343 - val_loss: 20.5837 - val_mse: 948.6036\n",
      "Epoch 2076/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0519 - mse: 943.1571 - val_loss: 20.5612 - val_mse: 927.4198\n",
      "Epoch 2077/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9884 - mse: 939.4654 - val_loss: 20.6305 - val_mse: 907.4667\n",
      "Epoch 2078/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0170 - mse: 926.4090 - val_loss: 20.5901 - val_mse: 916.1797\n",
      "Epoch 2079/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9450 - mse: 931.1961 - val_loss: 20.5677 - val_mse: 940.4196\n",
      "Epoch 2080/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9465 - mse: 933.4612 - val_loss: 20.5795 - val_mse: 946.7006\n",
      "Epoch 2081/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9689 - mse: 937.0023 - val_loss: 20.5599 - val_mse: 929.9994\n",
      "Epoch 2082/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9894 - mse: 940.5812 - val_loss: 20.5679 - val_mse: 940.5352\n",
      "Epoch 2083/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9660 - mse: 927.3152 - val_loss: 20.7078 - val_mse: 976.5231\n",
      "Epoch 2084/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0326 - mse: 942.6993 - val_loss: 20.5962 - val_mse: 953.3469\n",
      "Epoch 2085/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9886 - mse: 926.9633 - val_loss: 20.6131 - val_mse: 958.4062\n",
      "Epoch 2086/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0153 - mse: 940.8570 - val_loss: 20.5704 - val_mse: 922.8644\n",
      "Epoch 2087/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0876 - mse: 930.0395 - val_loss: 20.5613 - val_mse: 927.3294\n",
      "Epoch 2088/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8351 - mse: 925.5165 - val_loss: 20.5867 - val_mse: 949.9402\n",
      "Epoch 2089/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0862 - mse: 941.7831 - val_loss: 20.6118 - val_mse: 958.0482\n",
      "Epoch 2090/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0344 - mse: 941.3821 - val_loss: 20.5631 - val_mse: 926.2137\n",
      "Epoch 2091/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9599 - mse: 928.5967 - val_loss: 20.5663 - val_mse: 939.4414\n",
      "Epoch 2092/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9092 - mse: 931.5576 - val_loss: 20.5668 - val_mse: 939.7629\n",
      "Epoch 2093/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0081 - mse: 938.5588 - val_loss: 20.5952 - val_mse: 914.8276\n",
      "Epoch 2094/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9298 - mse: 926.6321 - val_loss: 20.5599 - val_mse: 929.9962\n",
      "Epoch 2095/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0213 - mse: 938.6703 - val_loss: 20.5635 - val_mse: 937.2112\n",
      "Epoch 2096/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9909 - mse: 934.4910 - val_loss: 20.5608 - val_mse: 933.9125\n",
      "Epoch 2097/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9284 - mse: 938.2459 - val_loss: 20.5879 - val_mse: 916.7621\n",
      "Epoch 2098/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0227 - mse: 939.2216 - val_loss: 20.6041 - val_mse: 955.7802\n",
      "Epoch 2099/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9137 - mse: 938.7233 - val_loss: 20.6192 - val_mse: 960.0923\n",
      "Epoch 2100/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8620 - mse: 914.5060 - val_loss: 20.6310 - val_mse: 962.7963\n",
      "Epoch 2101/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0171 - mse: 940.2598 - val_loss: 20.5598 - val_mse: 930.9819\n",
      "Epoch 2102/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0274 - mse: 933.2015 - val_loss: 20.5912 - val_mse: 915.8688\n",
      "Epoch 2103/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0324 - mse: 936.6008 - val_loss: 20.5607 - val_mse: 933.7023\n",
      "Epoch 2104/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9614 - mse: 943.7953 - val_loss: 20.5884 - val_mse: 950.6477\n",
      "Epoch 2105/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0665 - mse: 942.9481 - val_loss: 20.5765 - val_mse: 945.3489\n",
      "Epoch 2106/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8872 - mse: 935.0106 - val_loss: 20.5987 - val_mse: 913.9196\n",
      "Epoch 2107/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0232 - mse: 932.5726 - val_loss: 20.5617 - val_mse: 935.5178\n",
      "Epoch 2108/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9638 - mse: 933.4277 - val_loss: 20.5755 - val_mse: 944.8517\n",
      "Epoch 2109/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9387 - mse: 928.4303 - val_loss: 20.5813 - val_mse: 947.5190\n",
      "Epoch 2110/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9570 - mse: 936.2191 - val_loss: 20.5672 - val_mse: 940.0656\n",
      "Epoch 2111/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9188 - mse: 926.1617 - val_loss: 20.7621 - val_mse: 984.9658\n",
      "Epoch 2112/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0432 - mse: 950.1090 - val_loss: 20.5755 - val_mse: 944.8752\n",
      "Epoch 2113/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9571 - mse: 942.3262 - val_loss: 20.5607 - val_mse: 928.0258\n",
      "Epoch 2114/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0642 - mse: 936.7210 - val_loss: 20.5652 - val_mse: 925.1563\n",
      "Epoch 2115/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9499 - mse: 937.7266 - val_loss: 20.6095 - val_mse: 911.4990\n",
      "Epoch 2116/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9641 - mse: 937.8739 - val_loss: 20.6089 - val_mse: 911.6469\n",
      "Epoch 2117/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9367 - mse: 932.4062 - val_loss: 20.5626 - val_mse: 936.4987\n",
      "Epoch 2118/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9591 - mse: 932.0484 - val_loss: 20.6116 - val_mse: 957.9778\n",
      "Epoch 2119/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0125 - mse: 946.5455 - val_loss: 20.5606 - val_mse: 933.3129\n",
      "Epoch 2120/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0106 - mse: 940.4589 - val_loss: 20.5599 - val_mse: 931.8923\n",
      "Epoch 2121/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9864 - mse: 937.8501 - val_loss: 20.5724 - val_mse: 922.0269\n",
      "Epoch 2122/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8833 - mse: 923.6989 - val_loss: 20.5789 - val_mse: 946.4675\n",
      "Epoch 2123/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0410 - mse: 935.7313 - val_loss: 20.5708 - val_mse: 942.2665\n",
      "Epoch 2124/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9942 - mse: 936.8934 - val_loss: 20.5599 - val_mse: 929.9844\n",
      "Epoch 2125/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9367 - mse: 936.8685 - val_loss: 20.5867 - val_mse: 949.9747\n",
      "Epoch 2126/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0318 - mse: 940.4960 - val_loss: 20.5658 - val_mse: 939.0442\n",
      "Epoch 2127/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8520 - mse: 920.7756 - val_loss: 20.6277 - val_mse: 962.0808\n",
      "Epoch 2128/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9766 - mse: 931.8137 - val_loss: 20.6499 - val_mse: 966.6802\n",
      "Epoch 2129/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9935 - mse: 936.7473 - val_loss: 20.5661 - val_mse: 924.7686\n",
      "Epoch 2130/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9453 - mse: 931.9460 - val_loss: 20.6476 - val_mse: 966.2324\n",
      "Epoch 2131/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0104 - mse: 946.4304 - val_loss: 20.5725 - val_mse: 943.2302\n",
      "Epoch 2132/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8565 - mse: 922.3735 - val_loss: 20.5938 - val_mse: 952.5656\n",
      "Epoch 2133/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9637 - mse: 932.4559 - val_loss: 20.5613 - val_mse: 934.9053\n",
      "Epoch 2134/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9749 - mse: 934.0208 - val_loss: 20.5692 - val_mse: 941.3671\n",
      "Epoch 2135/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9182 - mse: 929.7441 - val_loss: 20.6016 - val_mse: 913.2256\n",
      "Epoch 2136/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9675 - mse: 935.5509 - val_loss: 20.5657 - val_mse: 938.9861\n",
      "Epoch 2137/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0335 - mse: 939.3109 - val_loss: 20.6899 - val_mse: 973.6788\n",
      "Epoch 2138/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9730 - mse: 931.3588 - val_loss: 20.5988 - val_mse: 954.1925\n",
      "Epoch 2139/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9009 - mse: 926.1127 - val_loss: 20.6206 - val_mse: 960.4367\n",
      "Epoch 2140/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0785 - mse: 945.8406 - val_loss: 20.5677 - val_mse: 940.4011\n",
      "Epoch 2141/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0388 - mse: 935.3033 - val_loss: 20.6128 - val_mse: 910.8002\n",
      "Epoch 2142/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0210 - mse: 938.0054 - val_loss: 20.5671 - val_mse: 924.3123\n",
      "Epoch 2143/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0006 - mse: 935.7427 - val_loss: 20.6752 - val_mse: 901.0051\n",
      "Epoch 2144/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9384 - mse: 929.3020 - val_loss: 20.5955 - val_mse: 953.1293\n",
      "Epoch 2145/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9243 - mse: 936.6385 - val_loss: 20.5598 - val_mse: 931.3195\n",
      "Epoch 2146/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9862 - mse: 936.5246 - val_loss: 20.6167 - val_mse: 959.4291\n",
      "Epoch 2147/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9417 - mse: 931.1481 - val_loss: 20.8286 - val_mse: 995.0412\n",
      "Epoch 2148/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9231 - mse: 932.5626 - val_loss: 20.5697 - val_mse: 923.1902\n",
      "Epoch 2149/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9667 - mse: 937.7775 - val_loss: 20.5845 - val_mse: 917.7071\n",
      "Epoch 2150/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0196 - mse: 934.1446 - val_loss: 20.5598 - val_mse: 931.5485\n",
      "Epoch 2151/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9793 - mse: 935.9430 - val_loss: 20.5599 - val_mse: 929.9714\n",
      "Epoch 2152/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0152 - mse: 942.2085 - val_loss: 20.5646 - val_mse: 938.1266\n",
      "Epoch 2153/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9122 - mse: 921.6315 - val_loss: 20.6117 - val_mse: 958.0177\n",
      "Epoch 2154/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0300 - mse: 935.7412 - val_loss: 20.5659 - val_mse: 939.1416\n",
      "Epoch 2155/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9966 - mse: 933.2435 - val_loss: 20.5875 - val_mse: 950.2640\n",
      "Epoch 2156/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.8908 - mse: 931.8846 - val_loss: 20.5928 - val_mse: 952.2181\n",
      "Epoch 2157/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9656 - mse: 932.1427 - val_loss: 20.5732 - val_mse: 943.6136\n",
      "Epoch 2158/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9513 - mse: 933.1296 - val_loss: 20.5599 - val_mse: 929.9631\n",
      "Epoch 2159/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0178 - mse: 938.4242 - val_loss: 20.6262 - val_mse: 961.7474\n",
      "Epoch 2160/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9287 - mse: 929.7888 - val_loss: 20.5952 - val_mse: 953.0067\n",
      "Epoch 2161/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9808 - mse: 929.1489 - val_loss: 20.5607 - val_mse: 933.5441\n",
      "Epoch 2162/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0258 - mse: 936.3076 - val_loss: 20.5914 - val_mse: 951.7271\n",
      "Epoch 2163/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.8889 - mse: 936.3463 - val_loss: 20.5622 - val_mse: 936.0538\n",
      "Epoch 2164/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9200 - mse: 926.7633 - val_loss: 20.5712 - val_mse: 942.5152\n",
      "Epoch 2165/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9046 - mse: 935.8948 - val_loss: 20.6039 - val_mse: 955.7283\n",
      "Epoch 2166/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0133 - mse: 930.3461 - val_loss: 20.5620 - val_mse: 935.8954\n",
      "Epoch 2167/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9481 - mse: 927.5220 - val_loss: 20.5820 - val_mse: 947.8585\n",
      "Epoch 2168/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9397 - mse: 936.5148 - val_loss: 20.6083 - val_mse: 911.7598\n",
      "Epoch 2169/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0341 - mse: 938.9556 - val_loss: 20.6155 - val_mse: 959.1201\n",
      "Epoch 2170/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9684 - mse: 938.7160 - val_loss: 20.5908 - val_mse: 915.9857\n",
      "Epoch 2171/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9625 - mse: 926.1578 - val_loss: 20.5639 - val_mse: 937.5561\n",
      "Epoch 2172/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.8967 - mse: 923.6156 - val_loss: 20.6798 - val_mse: 971.9898\n",
      "Epoch 2173/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0510 - mse: 939.9717 - val_loss: 20.5606 - val_mse: 928.1136\n",
      "Epoch 2174/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9182 - mse: 939.9050 - val_loss: 20.5922 - val_mse: 951.9991\n",
      "Epoch 2175/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9822 - mse: 934.5793 - val_loss: 20.5829 - val_mse: 918.2052\n",
      "Epoch 2176/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9582 - mse: 931.2605 - val_loss: 20.5708 - val_mse: 942.2761\n",
      "Epoch 2177/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9634 - mse: 933.7443 - val_loss: 20.6085 - val_mse: 957.0963\n",
      "Epoch 2178/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9087 - mse: 931.5009 - val_loss: 20.6697 - val_mse: 970.2668\n",
      "Epoch 2179/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9371 - mse: 940.8438 - val_loss: 20.5612 - val_mse: 934.7661\n",
      "Epoch 2180/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9920 - mse: 933.5893 - val_loss: 20.5624 - val_mse: 936.2595\n",
      "Epoch 2181/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9404 - mse: 934.9500 - val_loss: 20.6717 - val_mse: 970.6069\n",
      "Epoch 2182/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0034 - mse: 943.1177 - val_loss: 20.5766 - val_mse: 920.4056\n",
      "Epoch 2183/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9408 - mse: 928.4537 - val_loss: 20.5912 - val_mse: 951.6673\n",
      "Epoch 2184/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9877 - mse: 936.6086 - val_loss: 20.5615 - val_mse: 935.2007\n",
      "Epoch 2185/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0435 - mse: 930.9073 - val_loss: 20.6298 - val_mse: 962.5534\n",
      "Epoch 2186/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9888 - mse: 947.9114 - val_loss: 20.6007 - val_mse: 954.7798\n",
      "Epoch 2187/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0013 - mse: 939.2841 - val_loss: 20.6189 - val_mse: 960.0139\n",
      "Epoch 2188/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9478 - mse: 925.9683 - val_loss: 20.6188 - val_mse: 959.9915\n",
      "Epoch 2189/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9228 - mse: 929.6726 - val_loss: 20.5676 - val_mse: 924.1006\n",
      "Epoch 2190/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9976 - mse: 928.0463 - val_loss: 20.6299 - val_mse: 962.5803\n",
      "Epoch 2191/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9700 - mse: 944.1004 - val_loss: 20.5602 - val_mse: 928.9008\n",
      "Epoch 2192/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9834 - mse: 935.2285 - val_loss: 20.5829 - val_mse: 948.2502\n",
      "Epoch 2193/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9512 - mse: 932.6135 - val_loss: 20.5614 - val_mse: 935.1066\n",
      "Epoch 2194/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9157 - mse: 933.3271 - val_loss: 20.5895 - val_mse: 951.0508\n",
      "Epoch 2195/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0020 - mse: 931.4812 - val_loss: 20.5746 - val_mse: 944.3717\n",
      "Epoch 2196/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.8899 - mse: 928.5203 - val_loss: 20.6168 - val_mse: 959.4601\n",
      "Epoch 2197/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9386 - mse: 936.8097 - val_loss: 20.5761 - val_mse: 945.1677\n",
      "Epoch 2198/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9898 - mse: 936.6052 - val_loss: 20.5759 - val_mse: 920.6429\n",
      "Epoch 2199/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9062 - mse: 934.5628 - val_loss: 20.5598 - val_mse: 931.2959\n",
      "Epoch 2200/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9347 - mse: 931.0150 - val_loss: 20.6507 - val_mse: 966.8304\n",
      "Epoch 2201/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0056 - mse: 936.3885 - val_loss: 20.7000 - val_mse: 975.3046\n",
      "Epoch 2202/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9836 - mse: 926.6405 - val_loss: 20.6909 - val_mse: 973.8434\n",
      "Epoch 2203/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9980 - mse: 942.8892 - val_loss: 20.5634 - val_mse: 926.0514\n",
      "Epoch 2204/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.8939 - mse: 937.3185 - val_loss: 20.5874 - val_mse: 950.2236\n",
      "Epoch 2205/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9944 - mse: 937.3543 - val_loss: 20.5640 - val_mse: 937.6498\n",
      "Epoch 2206/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9628 - mse: 943.8558 - val_loss: 20.5883 - val_mse: 916.6465\n",
      "Epoch 2207/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9677 - mse: 937.4458 - val_loss: 20.5601 - val_mse: 929.2704\n",
      "Epoch 2208/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9524 - mse: 933.6096 - val_loss: 20.7786 - val_mse: 987.5454\n",
      "Epoch 2209/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9517 - mse: 936.7379 - val_loss: 20.8365 - val_mse: 996.2048\n",
      "Epoch 2210/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0170 - mse: 938.3979 - val_loss: 20.6171 - val_mse: 959.5555\n",
      "Epoch 2211/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9166 - mse: 928.4689 - val_loss: 20.6002 - val_mse: 954.6271\n",
      "Epoch 2212/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9461 - mse: 940.4427 - val_loss: 20.5728 - val_mse: 921.8575\n",
      "Epoch 2213/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9440 - mse: 937.6284 - val_loss: 20.5606 - val_mse: 933.3965\n",
      "Epoch 2214/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8805 - mse: 930.5565 - val_loss: 20.6138 - val_mse: 910.5791\n",
      "Epoch 2215/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9391 - mse: 926.9505 - val_loss: 20.5810 - val_mse: 947.4055\n",
      "Epoch 2216/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9604 - mse: 932.7308 - val_loss: 20.6296 - val_mse: 962.5103\n",
      "Epoch 2217/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9876 - mse: 935.5607 - val_loss: 20.6405 - val_mse: 964.7648\n",
      "Epoch 2218/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0055 - mse: 940.2407 - val_loss: 20.5720 - val_mse: 942.9782\n",
      "Epoch 2219/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9977 - mse: 938.9989 - val_loss: 20.5598 - val_mse: 931.4650\n",
      "Epoch 2220/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9359 - mse: 938.4033 - val_loss: 20.6042 - val_mse: 912.6517\n",
      "Epoch 2221/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9580 - mse: 932.7102 - val_loss: 20.5710 - val_mse: 922.6032\n",
      "Epoch 2222/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9056 - mse: 928.7764 - val_loss: 20.7187 - val_mse: 896.5659\n",
      "Epoch 2223/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8885 - mse: 924.0403 - val_loss: 20.5661 - val_mse: 924.7377\n",
      "Epoch 2224/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9130 - mse: 928.7611 - val_loss: 20.6451 - val_mse: 905.0739\n",
      "Epoch 2225/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9580 - mse: 920.9820 - val_loss: 20.5603 - val_mse: 928.7192\n",
      "Epoch 2226/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9042 - mse: 930.5696 - val_loss: 20.6853 - val_mse: 972.9172\n",
      "Epoch 2227/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.8922 - mse: 918.1742 - val_loss: 20.6392 - val_mse: 964.5063\n",
      "Epoch 2228/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0511 - mse: 941.3280 - val_loss: 20.6066 - val_mse: 912.1393\n",
      "Epoch 2229/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0562 - mse: 927.6381 - val_loss: 20.6113 - val_mse: 957.8920\n",
      "Epoch 2230/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9852 - mse: 937.2036 - val_loss: 20.6155 - val_mse: 959.1068\n",
      "Epoch 2231/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8994 - mse: 939.1125 - val_loss: 20.5756 - val_mse: 944.8960\n",
      "Epoch 2232/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0510 - mse: 941.8443 - val_loss: 20.6056 - val_mse: 956.2386\n",
      "Epoch 2233/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9694 - mse: 941.8417 - val_loss: 20.5598 - val_mse: 930.7719\n",
      "Epoch 2234/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0023 - mse: 936.4449 - val_loss: 20.5975 - val_mse: 953.7542\n",
      "Epoch 2235/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0411 - mse: 941.5555 - val_loss: 20.6148 - val_mse: 910.3893\n",
      "Epoch 2236/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0463 - mse: 938.3370 - val_loss: 20.5843 - val_mse: 917.7593\n",
      "Epoch 2237/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9842 - mse: 932.5229 - val_loss: 20.5797 - val_mse: 919.2879\n",
      "Epoch 2238/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0396 - mse: 932.9634 - val_loss: 20.6323 - val_mse: 963.0676\n",
      "Epoch 2239/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9183 - mse: 922.4157 - val_loss: 20.7161 - val_mse: 977.8192\n",
      "Epoch 2240/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0892 - mse: 945.9180 - val_loss: 20.7108 - val_mse: 976.9936\n",
      "Epoch 2241/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0401 - mse: 936.7855 - val_loss: 20.5604 - val_mse: 928.6037\n",
      "Epoch 2242/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0503 - mse: 941.0994 - val_loss: 20.5652 - val_mse: 925.1674\n",
      "Epoch 2243/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9403 - mse: 917.6094 - val_loss: 20.6599 - val_mse: 968.5469\n",
      "Epoch 2244/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9769 - mse: 927.4092 - val_loss: 20.5700 - val_mse: 941.8269\n",
      "Epoch 2245/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9873 - mse: 936.9976 - val_loss: 20.5737 - val_mse: 943.9532\n",
      "Epoch 2246/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9244 - mse: 931.7527 - val_loss: 20.6129 - val_mse: 958.3525\n",
      "Epoch 2247/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0840 - mse: 941.7746 - val_loss: 20.6971 - val_mse: 974.8400\n",
      "Epoch 2248/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9544 - mse: 933.6077 - val_loss: 20.5631 - val_mse: 936.8618\n",
      "Epoch 2249/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0021 - mse: 940.2600 - val_loss: 20.5606 - val_mse: 928.2188\n",
      "Epoch 2250/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9433 - mse: 930.5208 - val_loss: 20.5835 - val_mse: 948.5158\n",
      "Epoch 2251/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9606 - mse: 933.8969 - val_loss: 20.5913 - val_mse: 951.7029\n",
      "Epoch 2252/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9885 - mse: 934.3290 - val_loss: 20.5913 - val_mse: 951.7100\n",
      "Epoch 2253/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9503 - mse: 932.4130 - val_loss: 20.6072 - val_mse: 912.0129\n",
      "Epoch 2254/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.1135 - mse: 927.7437 - val_loss: 20.5747 - val_mse: 944.4277\n",
      "Epoch 2255/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9702 - mse: 943.0013 - val_loss: 20.5602 - val_mse: 932.4796\n",
      "Epoch 2256/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9143 - mse: 931.0760 - val_loss: 20.6379 - val_mse: 964.2386\n",
      "Epoch 2257/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9794 - mse: 942.9796 - val_loss: 20.6375 - val_mse: 964.1398\n",
      "Epoch 2258/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9831 - mse: 931.6882 - val_loss: 20.5944 - val_mse: 952.7479\n",
      "Epoch 2259/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9393 - mse: 934.1538 - val_loss: 20.5817 - val_mse: 918.5955\n",
      "Epoch 2260/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9322 - mse: 926.6293 - val_loss: 20.5764 - val_mse: 945.2997\n",
      "Epoch 2261/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.8763 - mse: 933.3660 - val_loss: 20.5630 - val_mse: 936.8208\n",
      "Epoch 2262/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9256 - mse: 924.5634 - val_loss: 20.6177 - val_mse: 959.7075\n",
      "Epoch 2263/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9670 - mse: 937.0934 - val_loss: 20.5626 - val_mse: 936.4711\n",
      "Epoch 2264/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0133 - mse: 943.2744 - val_loss: 20.5611 - val_mse: 934.5091\n",
      "Epoch 2265/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9378 - mse: 927.4688 - val_loss: 20.5606 - val_mse: 928.1756\n",
      "Epoch 2266/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9359 - mse: 933.3843 - val_loss: 20.5763 - val_mse: 945.2330\n",
      "Epoch 2267/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9856 - mse: 937.9566 - val_loss: 20.5806 - val_mse: 947.2102\n",
      "Epoch 2268/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0195 - mse: 938.6127 - val_loss: 20.5694 - val_mse: 941.5229\n",
      "Epoch 2269/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9769 - mse: 937.6530 - val_loss: 20.5646 - val_mse: 925.4503\n",
      "Epoch 2270/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0094 - mse: 943.1371 - val_loss: 20.5650 - val_mse: 938.4377\n",
      "Epoch 2271/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9119 - mse: 927.5649 - val_loss: 20.6410 - val_mse: 964.8762\n",
      "Epoch 2272/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9780 - mse: 940.2318 - val_loss: 20.5665 - val_mse: 939.5413\n",
      "Epoch 2273/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9504 - mse: 939.5866 - val_loss: 20.5646 - val_mse: 925.4362\n",
      "Epoch 2274/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.8937 - mse: 920.9959 - val_loss: 20.5722 - val_mse: 943.0527\n",
      "Epoch 2275/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0333 - mse: 937.8958 - val_loss: 20.5956 - val_mse: 953.1567\n",
      "Epoch 2276/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8790 - mse: 927.4520 - val_loss: 20.5690 - val_mse: 941.2429\n",
      "Epoch 2277/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9813 - mse: 935.9922 - val_loss: 20.5718 - val_mse: 942.8465\n",
      "Epoch 2278/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.8719 - mse: 928.5401 - val_loss: 20.5620 - val_mse: 926.8376\n",
      "Epoch 2279/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9282 - mse: 932.4498 - val_loss: 20.5662 - val_mse: 939.3660\n",
      "Epoch 2280/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9299 - mse: 929.6592 - val_loss: 20.5677 - val_mse: 940.3913\n",
      "Epoch 2281/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9132 - mse: 931.6832 - val_loss: 20.5607 - val_mse: 933.6848\n",
      "Epoch 2282/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9289 - mse: 921.2838 - val_loss: 20.5939 - val_mse: 952.6019\n",
      "Epoch 2283/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9979 - mse: 933.7941 - val_loss: 20.7108 - val_mse: 977.0002\n",
      "Epoch 2284/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0305 - mse: 947.2821 - val_loss: 20.5887 - val_mse: 950.7629\n",
      "Epoch 2285/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9074 - mse: 929.4954 - val_loss: 20.6848 - val_mse: 972.8408\n",
      "Epoch 2286/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9468 - mse: 931.1542 - val_loss: 20.5602 - val_mse: 932.4771\n",
      "Epoch 2287/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9964 - mse: 944.4863 - val_loss: 20.5612 - val_mse: 934.7198\n",
      "Epoch 2288/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0283 - mse: 931.8505 - val_loss: 20.5715 - val_mse: 922.4070\n",
      "Epoch 2289/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9206 - mse: 934.1082 - val_loss: 20.5736 - val_mse: 921.5544\n",
      "Epoch 2290/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0281 - mse: 932.3710 - val_loss: 20.5872 - val_mse: 950.1498\n",
      "Epoch 2291/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0188 - mse: 938.6331 - val_loss: 20.5696 - val_mse: 923.2138\n",
      "Epoch 2292/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9993 - mse: 933.3397 - val_loss: 20.5729 - val_mse: 921.8273\n",
      "Epoch 2293/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9499 - mse: 936.1561 - val_loss: 20.5993 - val_mse: 913.7571\n",
      "Epoch 2294/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9940 - mse: 928.5999 - val_loss: 20.5941 - val_mse: 952.6502\n",
      "Epoch 2295/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0170 - mse: 947.1909 - val_loss: 20.5805 - val_mse: 947.1492\n",
      "Epoch 2296/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9323 - mse: 932.9011 - val_loss: 20.5622 - val_mse: 926.6669\n",
      "Epoch 2297/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8968 - mse: 922.3370 - val_loss: 20.5623 - val_mse: 936.1254\n",
      "Epoch 2298/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9887 - mse: 941.7751 - val_loss: 20.5688 - val_mse: 941.1406\n",
      "Epoch 2299/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0157 - mse: 933.5184 - val_loss: 20.5607 - val_mse: 933.5369\n",
      "Epoch 2300/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9812 - mse: 929.6552 - val_loss: 20.6584 - val_mse: 968.2917\n",
      "Epoch 2301/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8701 - mse: 936.2769 - val_loss: 20.5727 - val_mse: 921.8925\n",
      "Epoch 2302/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9603 - mse: 924.6112 - val_loss: 20.5610 - val_mse: 927.6786\n",
      "Epoch 2303/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9422 - mse: 931.6174 - val_loss: 20.5603 - val_mse: 928.7708\n",
      "Epoch 2304/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9794 - mse: 936.8564 - val_loss: 20.5725 - val_mse: 943.2442\n",
      "Epoch 2305/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0063 - mse: 944.7707 - val_loss: 20.6545 - val_mse: 903.6819\n",
      "Epoch 2306/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0586 - mse: 933.8981 - val_loss: 20.5709 - val_mse: 942.3239\n",
      "Epoch 2307/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0234 - mse: 931.7778 - val_loss: 20.5740 - val_mse: 944.0878\n",
      "Epoch 2308/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9698 - mse: 932.1617 - val_loss: 20.5868 - val_mse: 949.9973\n",
      "Epoch 2309/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9573 - mse: 929.1090 - val_loss: 20.6108 - val_mse: 957.7618\n",
      "Epoch 2310/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9843 - mse: 938.6948 - val_loss: 20.5664 - val_mse: 939.4968\n",
      "Epoch 2311/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9815 - mse: 937.8403 - val_loss: 20.5748 - val_mse: 944.5140\n",
      "Epoch 2312/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9855 - mse: 932.7982 - val_loss: 20.5936 - val_mse: 915.2303\n",
      "Epoch 2313/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0023 - mse: 936.6988 - val_loss: 20.5889 - val_mse: 916.4855\n",
      "Epoch 2314/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8934 - mse: 921.6158 - val_loss: 20.5678 - val_mse: 924.0250\n",
      "Epoch 2315/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9173 - mse: 936.7402 - val_loss: 20.5598 - val_mse: 930.8723\n",
      "Epoch 2316/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0055 - mse: 936.7551 - val_loss: 20.5775 - val_mse: 920.0865\n",
      "Epoch 2317/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8893 - mse: 928.0657 - val_loss: 20.7476 - val_mse: 894.0807\n",
      "Epoch 2318/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9498 - mse: 923.0958 - val_loss: 20.5649 - val_mse: 938.3185\n",
      "Epoch 2319/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9453 - mse: 934.1093 - val_loss: 20.5611 - val_mse: 927.5756\n",
      "Epoch 2320/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8757 - mse: 920.4568 - val_loss: 20.5609 - val_mse: 933.9666\n",
      "Epoch 2321/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9813 - mse: 937.6678 - val_loss: 20.6220 - val_mse: 960.7869\n",
      "Epoch 2322/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0231 - mse: 939.3483 - val_loss: 20.7216 - val_mse: 978.6633\n",
      "Epoch 2323/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0012 - mse: 926.8094 - val_loss: 20.6413 - val_mse: 964.9446\n",
      "Epoch 2324/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9595 - mse: 927.7504 - val_loss: 20.6746 - val_mse: 971.1071\n",
      "Epoch 2325/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8404 - mse: 934.0806 - val_loss: 20.5897 - val_mse: 916.2748\n",
      "Epoch 2326/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.1043 - mse: 940.0781 - val_loss: 20.6291 - val_mse: 907.7097\n",
      "Epoch 2327/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0357 - mse: 929.7853 - val_loss: 20.6096 - val_mse: 911.4825\n",
      "Epoch 2328/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9692 - mse: 937.9254 - val_loss: 20.5606 - val_mse: 933.2844\n",
      "Epoch 2329/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9387 - mse: 925.3434 - val_loss: 20.5635 - val_mse: 925.9755\n",
      "Epoch 2330/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8988 - mse: 930.6717 - val_loss: 20.5659 - val_mse: 924.8639\n",
      "Epoch 2331/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9598 - mse: 937.7048 - val_loss: 20.5875 - val_mse: 916.8743\n",
      "Epoch 2332/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0323 - mse: 936.2807 - val_loss: 20.5642 - val_mse: 937.8077\n",
      "Epoch 2333/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9615 - mse: 942.9756 - val_loss: 20.6221 - val_mse: 908.9808\n",
      "Epoch 2334/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9866 - mse: 927.9949 - val_loss: 20.5631 - val_mse: 936.9009\n",
      "Epoch 2335/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0067 - mse: 942.2176 - val_loss: 20.5995 - val_mse: 954.3906\n",
      "Epoch 2336/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.8870 - mse: 932.8606 - val_loss: 20.5621 - val_mse: 926.7239\n",
      "Epoch 2337/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9552 - mse: 926.3374 - val_loss: 20.6879 - val_mse: 973.3559\n",
      "Epoch 2338/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9005 - mse: 933.9841 - val_loss: 20.5891 - val_mse: 916.4458\n",
      "Epoch 2339/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9606 - mse: 927.5630 - val_loss: 20.5603 - val_mse: 932.8158\n",
      "Epoch 2340/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9757 - mse: 928.6657 - val_loss: 20.6499 - val_mse: 966.6774\n",
      "Epoch 2341/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9406 - mse: 935.3558 - val_loss: 20.5644 - val_mse: 937.9931\n",
      "Epoch 2342/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9258 - mse: 929.3759 - val_loss: 20.5815 - val_mse: 947.6387\n",
      "Epoch 2343/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9754 - mse: 929.5367 - val_loss: 20.5828 - val_mse: 948.2094\n",
      "Epoch 2344/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9823 - mse: 935.2345 - val_loss: 20.5795 - val_mse: 919.3569\n",
      "Epoch 2345/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0134 - mse: 932.9321 - val_loss: 20.5906 - val_mse: 916.0421\n",
      "Epoch 2346/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0429 - mse: 939.6907 - val_loss: 20.5854 - val_mse: 949.3948\n",
      "Epoch 2347/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0369 - mse: 937.1030 - val_loss: 20.5719 - val_mse: 942.9077\n",
      "Epoch 2348/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9834 - mse: 931.7900 - val_loss: 20.5640 - val_mse: 925.6812\n",
      "Epoch 2349/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9802 - mse: 933.3197 - val_loss: 20.5599 - val_mse: 929.9810\n",
      "Epoch 2350/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9175 - mse: 934.0425 - val_loss: 20.5769 - val_mse: 945.5434\n",
      "Epoch 2351/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0048 - mse: 933.0026 - val_loss: 20.6143 - val_mse: 958.7739\n",
      "Epoch 2352/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9654 - mse: 931.9597 - val_loss: 20.6905 - val_mse: 973.7752\n",
      "Epoch 2353/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9291 - mse: 941.3826 - val_loss: 20.5661 - val_mse: 939.2471\n",
      "Epoch 2354/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9532 - mse: 928.7850 - val_loss: 20.5633 - val_mse: 937.0605\n",
      "Epoch 2355/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0672 - mse: 933.5524 - val_loss: 20.5826 - val_mse: 948.1344\n",
      "Epoch 2356/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9192 - mse: 932.5139 - val_loss: 20.6441 - val_mse: 965.5233\n",
      "Epoch 2357/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9476 - mse: 928.1835 - val_loss: 20.5654 - val_mse: 938.7485\n",
      "Epoch 2358/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0042 - mse: 941.6550 - val_loss: 20.5605 - val_mse: 933.2287\n",
      "Epoch 2359/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9583 - mse: 937.4127 - val_loss: 20.5599 - val_mse: 930.5454\n",
      "Epoch 2360/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9603 - mse: 925.4292 - val_loss: 20.6418 - val_mse: 965.0362\n",
      "Epoch 2361/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9670 - mse: 939.5666 - val_loss: 20.6799 - val_mse: 972.0129\n",
      "Epoch 2362/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.8746 - mse: 933.0714 - val_loss: 20.5684 - val_mse: 940.8486\n",
      "Epoch 2363/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9391 - mse: 932.9671 - val_loss: 20.6692 - val_mse: 970.1824\n",
      "Epoch 2364/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9557 - mse: 940.5508 - val_loss: 20.5824 - val_mse: 948.0267\n",
      "Epoch 2365/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9586 - mse: 936.5603 - val_loss: 20.5854 - val_mse: 949.4106\n",
      "Epoch 2366/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9531 - mse: 942.1646 - val_loss: 20.6504 - val_mse: 904.2786\n",
      "Epoch 2367/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0358 - mse: 936.9324 - val_loss: 20.5645 - val_mse: 925.4510\n",
      "Epoch 2368/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9624 - mse: 931.6963 - val_loss: 20.5606 - val_mse: 933.3844\n",
      "Epoch 2369/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8757 - mse: 926.3510 - val_loss: 20.5599 - val_mse: 929.5919\n",
      "Epoch 2370/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9382 - mse: 930.9124 - val_loss: 20.5598 - val_mse: 931.6642\n",
      "Epoch 2371/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9269 - mse: 931.5202 - val_loss: 20.5598 - val_mse: 930.7266\n",
      "Epoch 2372/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9595 - mse: 925.5056 - val_loss: 20.6097 - val_mse: 911.4727\n",
      "Epoch 2373/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0798 - mse: 944.0889 - val_loss: 20.5607 - val_mse: 933.7115\n",
      "Epoch 2374/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0082 - mse: 932.6099 - val_loss: 20.6033 - val_mse: 912.8638\n",
      "Epoch 2375/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0224 - mse: 942.8663 - val_loss: 20.5723 - val_mse: 922.0605\n",
      "Epoch 2376/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0108 - mse: 935.5410 - val_loss: 20.5598 - val_mse: 931.6446\n",
      "Epoch 2377/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0482 - mse: 941.3995 - val_loss: 20.5628 - val_mse: 926.3684\n",
      "Epoch 2378/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9078 - mse: 931.8115 - val_loss: 20.8461 - val_mse: 997.6105\n",
      "Epoch 2379/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9828 - mse: 938.5983 - val_loss: 20.6149 - val_mse: 910.3711\n",
      "Epoch 2380/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9207 - mse: 924.9041 - val_loss: 20.6203 - val_mse: 909.3304\n",
      "Epoch 2381/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0175 - mse: 940.6836 - val_loss: 20.5616 - val_mse: 927.1029\n",
      "Epoch 2382/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9922 - mse: 933.6162 - val_loss: 20.5665 - val_mse: 939.5833\n",
      "Epoch 2383/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.8831 - mse: 922.7508 - val_loss: 20.6530 - val_mse: 967.2954\n",
      "Epoch 2384/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9648 - mse: 932.9556 - val_loss: 20.5728 - val_mse: 943.4279\n",
      "Epoch 2385/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.8996 - mse: 935.7880 - val_loss: 20.5860 - val_mse: 917.2758\n",
      "Epoch 2386/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0426 - mse: 937.5779 - val_loss: 20.6073 - val_mse: 956.7534\n",
      "Epoch 2387/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9441 - mse: 938.2043 - val_loss: 20.5946 - val_mse: 914.9824\n",
      "Epoch 2388/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0732 - mse: 940.1815 - val_loss: 20.5949 - val_mse: 914.8850\n",
      "Epoch 2389/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9307 - mse: 929.5816 - val_loss: 20.5602 - val_mse: 929.0587\n",
      "Epoch 2390/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0304 - mse: 934.3265 - val_loss: 20.5947 - val_mse: 952.8693\n",
      "Epoch 2391/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9309 - mse: 929.6797 - val_loss: 20.5911 - val_mse: 951.6281\n",
      "Epoch 2392/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9659 - mse: 934.8730 - val_loss: 20.5621 - val_mse: 935.9904\n",
      "Epoch 2393/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0291 - mse: 936.2664 - val_loss: 20.5629 - val_mse: 936.6939\n",
      "Epoch 2394/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9241 - mse: 925.9364 - val_loss: 20.5996 - val_mse: 954.4409\n",
      "Epoch 2395/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 21.0244 - mse: 944.7022 - val_loss: 20.5712 - val_mse: 942.5101\n",
      "Epoch 2396/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9489 - mse: 933.0448 - val_loss: 20.6144 - val_mse: 958.7988\n",
      "Epoch 2397/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9788 - mse: 933.1678 - val_loss: 20.6347 - val_mse: 963.5606\n",
      "Epoch 2398/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8915 - mse: 931.9863 - val_loss: 20.6073 - val_mse: 956.7406\n",
      "Epoch 2399/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9642 - mse: 944.0391 - val_loss: 20.5629 - val_mse: 926.2993\n",
      "Epoch 2400/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9346 - mse: 929.3920 - val_loss: 20.5613 - val_mse: 934.8906\n",
      "Epoch 2401/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9373 - mse: 932.5264 - val_loss: 20.6451 - val_mse: 965.7265\n",
      "Epoch 2402/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9414 - mse: 933.9276 - val_loss: 20.5808 - val_mse: 947.2869\n",
      "Epoch 2403/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9251 - mse: 934.1569 - val_loss: 20.5622 - val_mse: 936.0814\n",
      "Epoch 2404/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9676 - mse: 935.6765 - val_loss: 20.5617 - val_mse: 927.0466\n",
      "Epoch 2405/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0216 - mse: 945.7030 - val_loss: 20.6255 - val_mse: 908.3544\n",
      "Epoch 2406/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9993 - mse: 929.1692 - val_loss: 20.5874 - val_mse: 950.2389\n",
      "Epoch 2407/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9236 - mse: 931.2007 - val_loss: 20.5639 - val_mse: 937.5630\n",
      "Epoch 2408/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9626 - mse: 931.1506 - val_loss: 20.6162 - val_mse: 959.2921\n",
      "Epoch 2409/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9279 - mse: 937.8114 - val_loss: 20.5705 - val_mse: 922.8170\n",
      "Epoch 2410/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9387 - mse: 929.0284 - val_loss: 20.5687 - val_mse: 923.5954\n",
      "Epoch 2411/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9579 - mse: 931.9510 - val_loss: 20.5706 - val_mse: 922.7874\n",
      "Epoch 2412/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8214 - mse: 926.3201 - val_loss: 20.6389 - val_mse: 906.0716\n",
      "Epoch 2413/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0910 - mse: 943.5866 - val_loss: 20.5856 - val_mse: 917.4002\n",
      "Epoch 2414/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0068 - mse: 926.6283 - val_loss: 20.5639 - val_mse: 937.5472\n",
      "Epoch 2415/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9766 - mse: 931.1970 - val_loss: 20.5603 - val_mse: 928.7131\n",
      "Epoch 2416/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9371 - mse: 937.9374 - val_loss: 20.6102 - val_mse: 911.3474\n",
      "Epoch 2417/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9602 - mse: 921.6304 - val_loss: 20.5675 - val_mse: 940.2737\n",
      "Epoch 2418/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9708 - mse: 924.1682 - val_loss: 20.7603 - val_mse: 984.6848\n",
      "Epoch 2419/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0981 - mse: 946.1521 - val_loss: 20.8472 - val_mse: 997.7781\n",
      "Epoch 2420/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9433 - mse: 942.1417 - val_loss: 20.5609 - val_mse: 934.1131\n",
      "Epoch 2421/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.1196 - mse: 947.7135 - val_loss: 20.5857 - val_mse: 949.5076\n",
      "Epoch 2422/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9069 - mse: 928.9270 - val_loss: 20.5957 - val_mse: 953.1885\n",
      "Epoch 2423/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9543 - mse: 935.5217 - val_loss: 20.5606 - val_mse: 928.1046\n",
      "Epoch 2424/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9923 - mse: 936.7498 - val_loss: 20.5811 - val_mse: 918.7933\n",
      "Epoch 2425/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9646 - mse: 933.4721 - val_loss: 20.5966 - val_mse: 953.4827\n",
      "Epoch 2426/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9184 - mse: 934.4922 - val_loss: 20.6037 - val_mse: 955.6550\n",
      "Epoch 2427/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9392 - mse: 929.1418 - val_loss: 20.6826 - val_mse: 972.4590\n",
      "Epoch 2428/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9509 - mse: 941.9130 - val_loss: 20.6410 - val_mse: 964.8829\n",
      "Epoch 2429/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0950 - mse: 946.1288 - val_loss: 20.5686 - val_mse: 923.6359\n",
      "Epoch 2430/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9064 - mse: 928.5154 - val_loss: 20.5979 - val_mse: 953.8934\n",
      "Epoch 2431/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9068 - mse: 931.4233 - val_loss: 20.6078 - val_mse: 956.8878\n",
      "Epoch 2432/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0024 - mse: 931.8210 - val_loss: 20.6082 - val_mse: 956.9975\n",
      "Epoch 2433/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0202 - mse: 930.8907 - val_loss: 20.7369 - val_mse: 981.0327\n",
      "Epoch 2434/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9774 - mse: 939.1732 - val_loss: 20.5683 - val_mse: 940.8315\n",
      "Epoch 2435/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9373 - mse: 932.5484 - val_loss: 20.5611 - val_mse: 934.3926\n",
      "Epoch 2436/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9348 - mse: 931.3369 - val_loss: 20.6954 - val_mse: 974.5744\n",
      "Epoch 2437/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.8770 - mse: 943.8208 - val_loss: 20.5654 - val_mse: 938.7348\n",
      "Epoch 2438/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9728 - mse: 939.6160 - val_loss: 20.5838 - val_mse: 948.6619\n",
      "Epoch 2439/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9977 - mse: 931.4808 - val_loss: 20.5944 - val_mse: 915.0233\n",
      "Epoch 2440/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0030 - mse: 934.9322 - val_loss: 20.5986 - val_mse: 954.1084\n",
      "Epoch 2441/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9906 - mse: 938.5632 - val_loss: 20.7853 - val_mse: 988.5698\n",
      "Epoch 2442/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9225 - mse: 942.4708 - val_loss: 20.6335 - val_mse: 906.9456\n",
      "Epoch 2443/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9936 - mse: 933.2585 - val_loss: 20.6528 - val_mse: 903.9280\n",
      "Epoch 2444/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9174 - mse: 929.6655 - val_loss: 20.6790 - val_mse: 971.8515\n",
      "Epoch 2445/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9545 - mse: 934.7953 - val_loss: 20.5919 - val_mse: 951.8944\n",
      "Epoch 2446/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0011 - mse: 932.4362 - val_loss: 20.5716 - val_mse: 922.3612\n",
      "Epoch 2447/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0141 - mse: 932.4339 - val_loss: 20.7252 - val_mse: 979.2292\n",
      "Epoch 2448/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0257 - mse: 940.2523 - val_loss: 20.5808 - val_mse: 947.2845\n",
      "Epoch 2449/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9847 - mse: 930.4864 - val_loss: 20.5849 - val_mse: 949.1789\n",
      "Epoch 2450/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9207 - mse: 928.6112 - val_loss: 20.6041 - val_mse: 955.7934\n",
      "Epoch 2451/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9583 - mse: 933.3940 - val_loss: 20.5738 - val_mse: 943.9854\n",
      "Epoch 2452/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9806 - mse: 933.4349 - val_loss: 20.6460 - val_mse: 965.9119\n",
      "Epoch 2453/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9651 - mse: 939.0375 - val_loss: 20.6613 - val_mse: 968.7844\n",
      "Epoch 2454/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0145 - mse: 931.6135 - val_loss: 20.5669 - val_mse: 939.8810\n",
      "Epoch 2455/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9565 - mse: 938.2911 - val_loss: 20.5599 - val_mse: 929.7520\n",
      "Epoch 2456/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9014 - mse: 922.3333 - val_loss: 20.5741 - val_mse: 944.1304\n",
      "Epoch 2457/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0360 - mse: 938.2365 - val_loss: 20.6044 - val_mse: 912.6202\n",
      "Epoch 2458/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9438 - mse: 925.5001 - val_loss: 20.5857 - val_mse: 949.5073\n",
      "Epoch 2459/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8700 - mse: 926.2168 - val_loss: 20.5694 - val_mse: 923.2865\n",
      "Epoch 2460/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9916 - mse: 933.4731 - val_loss: 20.5611 - val_mse: 934.4866\n",
      "Epoch 2461/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8563 - mse: 924.1515 - val_loss: 20.5641 - val_mse: 925.6539\n",
      "Epoch 2462/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0165 - mse: 937.6013 - val_loss: 20.5640 - val_mse: 925.7035\n",
      "Epoch 2463/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0464 - mse: 937.1064 - val_loss: 20.5650 - val_mse: 938.4123\n",
      "Epoch 2464/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0009 - mse: 940.4748 - val_loss: 20.5681 - val_mse: 940.6761\n",
      "Epoch 2465/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0285 - mse: 937.1924 - val_loss: 20.5602 - val_mse: 928.9735\n",
      "Epoch 2466/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9394 - mse: 940.8486 - val_loss: 20.6451 - val_mse: 905.0740\n",
      "Epoch 2467/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9393 - mse: 936.0823 - val_loss: 20.5701 - val_mse: 941.9141\n",
      "Epoch 2468/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8853 - mse: 931.3199 - val_loss: 20.5706 - val_mse: 942.1527\n",
      "Epoch 2469/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9802 - mse: 934.9989 - val_loss: 20.5798 - val_mse: 946.8623\n",
      "Epoch 2470/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8791 - mse: 926.9366 - val_loss: 20.6004 - val_mse: 954.6887\n",
      "Epoch 2471/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9510 - mse: 929.6204 - val_loss: 20.5778 - val_mse: 945.9465\n",
      "Epoch 2472/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9567 - mse: 940.5157 - val_loss: 20.6949 - val_mse: 898.8612\n",
      "Epoch 2473/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0473 - mse: 940.4935 - val_loss: 20.6064 - val_mse: 912.1777\n",
      "Epoch 2474/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9209 - mse: 929.0492 - val_loss: 20.5631 - val_mse: 936.8752\n",
      "Epoch 2475/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8647 - mse: 925.9323 - val_loss: 20.5624 - val_mse: 936.2771\n",
      "Epoch 2476/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.8827 - mse: 925.4228 - val_loss: 20.5861 - val_mse: 949.7042\n",
      "Epoch 2477/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9335 - mse: 930.4541 - val_loss: 20.5667 - val_mse: 939.7043\n",
      "Epoch 2478/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9757 - mse: 939.0591 - val_loss: 20.5638 - val_mse: 925.8083\n",
      "Epoch 2479/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9394 - mse: 934.5747 - val_loss: 20.6032 - val_mse: 955.5313\n",
      "Epoch 2480/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9416 - mse: 935.2520 - val_loss: 20.7076 - val_mse: 976.4869\n",
      "Epoch 2481/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9957 - mse: 930.1872 - val_loss: 20.5768 - val_mse: 945.4714\n",
      "Epoch 2482/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9190 - mse: 937.0478 - val_loss: 20.5961 - val_mse: 953.3039\n",
      "Epoch 2483/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9390 - mse: 937.8617 - val_loss: 20.5781 - val_mse: 946.0864\n",
      "Epoch 2484/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9665 - mse: 937.0073 - val_loss: 20.5755 - val_mse: 944.8529\n",
      "Epoch 2485/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9987 - mse: 942.9661 - val_loss: 20.5977 - val_mse: 953.8271\n",
      "Epoch 2486/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9559 - mse: 927.5580 - val_loss: 20.6303 - val_mse: 962.6505\n",
      "Epoch 2487/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9411 - mse: 929.9314 - val_loss: 20.5814 - val_mse: 947.5928\n",
      "Epoch 2488/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0348 - mse: 939.8447 - val_loss: 20.6131 - val_mse: 958.4229\n",
      "Epoch 2489/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9494 - mse: 929.6870 - val_loss: 20.5944 - val_mse: 952.7678\n",
      "Epoch 2490/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9279 - mse: 936.6642 - val_loss: 20.5832 - val_mse: 918.1003\n",
      "Epoch 2491/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9803 - mse: 937.2779 - val_loss: 20.5599 - val_mse: 930.2500\n",
      "Epoch 2492/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9917 - mse: 925.8713 - val_loss: 20.6784 - val_mse: 971.7548\n",
      "Epoch 2493/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0295 - mse: 946.6578 - val_loss: 20.5681 - val_mse: 940.6533\n",
      "Epoch 2494/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9874 - mse: 934.3408 - val_loss: 20.5618 - val_mse: 926.9393\n",
      "Epoch 2495/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8859 - mse: 926.6974 - val_loss: 20.5611 - val_mse: 934.4602\n",
      "Epoch 2496/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9265 - mse: 921.7607 - val_loss: 20.6096 - val_mse: 957.4058\n",
      "Epoch 2497/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8895 - mse: 932.6985 - val_loss: 20.5646 - val_mse: 938.0938\n",
      "Epoch 2498/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9919 - mse: 944.3821 - val_loss: 20.6034 - val_mse: 955.5934\n",
      "Epoch 2499/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9468 - mse: 934.8853 - val_loss: 20.5599 - val_mse: 931.8271\n",
      "Epoch 2500/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9915 - mse: 936.2745 - val_loss: 20.5656 - val_mse: 924.9925\n",
      "Epoch 2501/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.8691 - mse: 926.1685 - val_loss: 20.5648 - val_mse: 938.2726\n",
      "Epoch 2502/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9715 - mse: 927.2636 - val_loss: 20.5991 - val_mse: 954.2777\n",
      "Epoch 2503/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9992 - mse: 941.4863 - val_loss: 20.6509 - val_mse: 966.8751\n",
      "Epoch 2504/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9799 - mse: 935.4792 - val_loss: 20.5873 - val_mse: 950.2115\n",
      "Epoch 2505/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.8925 - mse: 932.4662 - val_loss: 20.6129 - val_mse: 958.3503\n",
      "Epoch 2506/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9847 - mse: 940.9118 - val_loss: 20.6239 - val_mse: 908.6544\n",
      "Epoch 2507/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9018 - mse: 929.5787 - val_loss: 20.6079 - val_mse: 956.9293\n",
      "Epoch 2508/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9910 - mse: 949.3820 - val_loss: 20.5946 - val_mse: 914.9769\n",
      "Epoch 2509/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0071 - mse: 928.3046 - val_loss: 20.6081 - val_mse: 956.9760\n",
      "Epoch 2510/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9864 - mse: 942.6698 - val_loss: 20.5789 - val_mse: 946.4618\n",
      "Epoch 2511/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9684 - mse: 939.2905 - val_loss: 20.5835 - val_mse: 948.5229\n",
      "Epoch 2512/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0261 - mse: 942.1955 - val_loss: 20.5608 - val_mse: 933.9158\n",
      "Epoch 2513/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9618 - mse: 930.8632 - val_loss: 20.5949 - val_mse: 914.9092\n",
      "Epoch 2514/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9504 - mse: 930.4064 - val_loss: 20.6998 - val_mse: 975.2652\n",
      "Epoch 2515/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9255 - mse: 927.4295 - val_loss: 20.5641 - val_mse: 937.7581\n",
      "Epoch 2516/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9834 - mse: 940.5976 - val_loss: 20.5912 - val_mse: 951.6592\n",
      "Epoch 2517/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9179 - mse: 922.1690 - val_loss: 20.5603 - val_mse: 932.6315\n",
      "Epoch 2518/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0156 - mse: 935.3135 - val_loss: 20.5634 - val_mse: 926.0294\n",
      "Epoch 2519/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.8902 - mse: 934.6031 - val_loss: 20.5615 - val_mse: 935.1710\n",
      "Epoch 2520/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.8779 - mse: 926.5599 - val_loss: 20.5663 - val_mse: 939.4382\n",
      "Epoch 2521/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9091 - mse: 936.4843 - val_loss: 20.5793 - val_mse: 946.6139\n",
      "Epoch 2522/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.8590 - mse: 925.8851 - val_loss: 20.6120 - val_mse: 958.0972\n",
      "Epoch 2523/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9874 - mse: 936.8716 - val_loss: 20.5749 - val_mse: 944.5631\n",
      "Epoch 2524/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9483 - mse: 923.9758 - val_loss: 20.5600 - val_mse: 932.0524\n",
      "Epoch 2525/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0666 - mse: 948.1592 - val_loss: 20.5802 - val_mse: 947.0254\n",
      "Epoch 2526/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9783 - mse: 943.8427 - val_loss: 20.5674 - val_mse: 940.2179\n",
      "Epoch 2527/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0596 - mse: 931.1561 - val_loss: 20.5839 - val_mse: 917.8768\n",
      "Epoch 2528/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9162 - mse: 927.4873 - val_loss: 20.7002 - val_mse: 975.3350\n",
      "Epoch 2529/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9823 - mse: 928.5070 - val_loss: 20.5954 - val_mse: 953.0687\n",
      "Epoch 2530/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0430 - mse: 937.8783 - val_loss: 20.5715 - val_mse: 942.6834\n",
      "Epoch 2531/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9603 - mse: 937.6461 - val_loss: 20.5909 - val_mse: 951.5708\n",
      "Epoch 2532/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9315 - mse: 934.0170 - val_loss: 20.5663 - val_mse: 939.4003\n",
      "Epoch 2533/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0141 - mse: 938.5643 - val_loss: 20.5814 - val_mse: 947.5771\n",
      "Epoch 2534/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9462 - mse: 939.3669 - val_loss: 20.8084 - val_mse: 992.0627\n",
      "Epoch 2535/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0109 - mse: 933.8414 - val_loss: 20.5927 - val_mse: 915.4702\n",
      "Epoch 2536/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0200 - mse: 934.6194 - val_loss: 20.5714 - val_mse: 942.6523\n",
      "Epoch 2537/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8681 - mse: 927.6611 - val_loss: 20.5617 - val_mse: 935.5312\n",
      "Epoch 2538/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0349 - mse: 935.0738 - val_loss: 20.5653 - val_mse: 938.6545\n",
      "Epoch 2539/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0780 - mse: 946.0445 - val_loss: 20.5853 - val_mse: 917.4629\n",
      "Epoch 2540/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9088 - mse: 926.2556 - val_loss: 20.5750 - val_mse: 944.6115\n",
      "Epoch 2541/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9667 - mse: 936.5834 - val_loss: 20.6010 - val_mse: 954.8661\n",
      "Epoch 2542/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8740 - mse: 935.6174 - val_loss: 20.7075 - val_mse: 976.4819\n",
      "Epoch 2543/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9870 - mse: 923.4372 - val_loss: 20.6621 - val_mse: 968.9260\n",
      "Epoch 2544/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9540 - mse: 937.7373 - val_loss: 20.5849 - val_mse: 949.1818\n",
      "Epoch 2545/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0075 - mse: 938.3721 - val_loss: 20.5615 - val_mse: 935.1943\n",
      "Epoch 2546/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9440 - mse: 928.1380 - val_loss: 20.5843 - val_mse: 948.9026\n",
      "Epoch 2547/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9580 - mse: 925.3867 - val_loss: 20.6720 - val_mse: 970.6680\n",
      "Epoch 2548/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9616 - mse: 942.2059 - val_loss: 20.5706 - val_mse: 942.1586\n",
      "Epoch 2549/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9900 - mse: 935.1226 - val_loss: 20.5928 - val_mse: 952.2130\n",
      "Epoch 2550/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0074 - mse: 930.6430 - val_loss: 20.6472 - val_mse: 966.1441\n",
      "Epoch 2551/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9636 - mse: 937.4570 - val_loss: 20.6392 - val_mse: 964.5007\n",
      "Epoch 2552/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9708 - mse: 933.2308 - val_loss: 20.6103 - val_mse: 957.6012\n",
      "Epoch 2553/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0085 - mse: 933.5962 - val_loss: 20.5952 - val_mse: 914.8298\n",
      "Epoch 2554/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9542 - mse: 933.7079 - val_loss: 20.7659 - val_mse: 985.5515\n",
      "Epoch 2555/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9785 - mse: 939.3965 - val_loss: 20.5836 - val_mse: 917.9658\n",
      "Epoch 2556/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.8997 - mse: 926.8662 - val_loss: 20.5667 - val_mse: 924.4807\n",
      "Epoch 2557/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9137 - mse: 930.6860 - val_loss: 20.5680 - val_mse: 940.6046\n",
      "Epoch 2558/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9246 - mse: 936.1802 - val_loss: 20.5760 - val_mse: 945.1130\n",
      "Epoch 2559/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9870 - mse: 937.2053 - val_loss: 20.6007 - val_mse: 954.7835\n",
      "Epoch 2560/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9365 - mse: 942.7045 - val_loss: 20.5674 - val_mse: 940.2208\n",
      "Epoch 2561/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9888 - mse: 928.4999 - val_loss: 20.5601 - val_mse: 932.3373\n",
      "Epoch 2562/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0294 - mse: 929.2938 - val_loss: 20.6727 - val_mse: 970.7852\n",
      "Epoch 2563/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9532 - mse: 928.8174 - val_loss: 20.6063 - val_mse: 956.4526\n",
      "Epoch 2564/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9135 - mse: 936.9933 - val_loss: 20.5746 - val_mse: 921.1672\n",
      "Epoch 2565/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8900 - mse: 929.6031 - val_loss: 20.5773 - val_mse: 945.7138\n",
      "Epoch 2566/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9594 - mse: 927.9968 - val_loss: 20.5621 - val_mse: 935.9238\n",
      "Epoch 2567/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.8768 - mse: 918.9326 - val_loss: 20.6441 - val_mse: 965.5125\n",
      "Epoch 2568/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9154 - mse: 940.2466 - val_loss: 20.5950 - val_mse: 952.9568\n",
      "Epoch 2569/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0033 - mse: 941.9586 - val_loss: 20.5847 - val_mse: 949.0725\n",
      "Epoch 2570/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9404 - mse: 927.6156 - val_loss: 20.5599 - val_mse: 929.5894\n",
      "Epoch 2571/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9199 - mse: 928.6373 - val_loss: 20.5891 - val_mse: 950.9249\n",
      "Epoch 2572/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9632 - mse: 940.7251 - val_loss: 20.6430 - val_mse: 965.2885\n",
      "Epoch 2573/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0315 - mse: 935.3982 - val_loss: 20.5657 - val_mse: 938.9352\n",
      "Epoch 2574/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0095 - mse: 946.5200 - val_loss: 20.5608 - val_mse: 933.9033\n",
      "Epoch 2575/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9780 - mse: 938.2723 - val_loss: 20.5798 - val_mse: 946.8448\n",
      "Epoch 2576/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9536 - mse: 923.7809 - val_loss: 20.6480 - val_mse: 966.3050\n",
      "Epoch 2577/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9512 - mse: 941.6902 - val_loss: 20.6319 - val_mse: 907.2283\n",
      "Epoch 2578/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8474 - mse: 923.9647 - val_loss: 20.5882 - val_mse: 950.5546\n",
      "Epoch 2579/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9174 - mse: 930.0711 - val_loss: 20.5702 - val_mse: 922.9490\n",
      "Epoch 2580/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9833 - mse: 934.9098 - val_loss: 20.5684 - val_mse: 940.8756\n",
      "Epoch 2581/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9383 - mse: 920.8802 - val_loss: 20.6933 - val_mse: 974.2379\n",
      "Epoch 2582/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9596 - mse: 945.1777 - val_loss: 20.5850 - val_mse: 917.5389\n",
      "Epoch 2583/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0327 - mse: 934.7054 - val_loss: 20.5613 - val_mse: 934.8289\n",
      "Epoch 2584/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0207 - mse: 935.4046 - val_loss: 20.5830 - val_mse: 948.3076\n",
      "Epoch 2585/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9504 - mse: 927.6878 - val_loss: 20.5888 - val_mse: 950.8188\n",
      "Epoch 2586/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9364 - mse: 930.5580 - val_loss: 20.5600 - val_mse: 929.3415\n",
      "Epoch 2587/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0325 - mse: 940.7087 - val_loss: 20.6421 - val_mse: 965.1117\n",
      "Epoch 2588/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0587 - mse: 939.6125 - val_loss: 20.5630 - val_mse: 936.8434\n",
      "Epoch 2589/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9908 - mse: 934.9726 - val_loss: 20.5631 - val_mse: 926.2130\n",
      "Epoch 2590/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0104 - mse: 935.0368 - val_loss: 20.5816 - val_mse: 947.6669\n",
      "Epoch 2591/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9848 - mse: 934.2291 - val_loss: 20.5610 - val_mse: 934.2771\n",
      "Epoch 2592/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21.0471 - mse: 941.3842 - val_loss: 20.5605 - val_mse: 928.2784\n",
      "Epoch 2593/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9164 - mse: 931.4706 - val_loss: 20.5965 - val_mse: 953.4548\n",
      "Epoch 2594/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.8546 - mse: 931.4694 - val_loss: 20.6266 - val_mse: 961.8256\n",
      "Epoch 2595/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9912 - mse: 934.3416 - val_loss: 20.5606 - val_mse: 933.2890\n",
      "Epoch 2596/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9723 - mse: 945.0049 - val_loss: 20.5653 - val_mse: 938.6191\n",
      "Epoch 2597/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9629 - mse: 936.7536 - val_loss: 20.5968 - val_mse: 953.5403\n",
      "Epoch 2598/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0309 - mse: 938.7769 - val_loss: 20.5858 - val_mse: 949.5779\n",
      "Epoch 2599/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9706 - mse: 932.5350 - val_loss: 20.5599 - val_mse: 930.5657\n",
      "Epoch 2600/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9820 - mse: 942.9850 - val_loss: 20.5680 - val_mse: 940.6447\n",
      "Epoch 2601/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9128 - mse: 926.1148 - val_loss: 20.6213 - val_mse: 909.1326\n",
      "Epoch 2602/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0160 - mse: 942.7176 - val_loss: 20.5680 - val_mse: 923.9335\n",
      "Epoch 2603/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9528 - mse: 919.8694 - val_loss: 20.5714 - val_mse: 942.6410\n",
      "Epoch 2604/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9686 - mse: 942.5728 - val_loss: 20.5795 - val_mse: 919.3654\n",
      "Epoch 2605/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9066 - mse: 930.8467 - val_loss: 20.5598 - val_mse: 930.8719\n",
      "Epoch 2606/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9834 - mse: 939.7500 - val_loss: 20.5632 - val_mse: 936.9340\n",
      "Epoch 2607/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9093 - mse: 939.4639 - val_loss: 20.5790 - val_mse: 946.4983\n",
      "Epoch 2608/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.8966 - mse: 925.0705 - val_loss: 20.5794 - val_mse: 946.6862\n",
      "Epoch 2609/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9019 - mse: 941.0005 - val_loss: 20.6079 - val_mse: 956.9067\n",
      "Epoch 2610/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9535 - mse: 932.7662 - val_loss: 20.6508 - val_mse: 966.8506\n",
      "Epoch 2611/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9081 - mse: 923.5359 - val_loss: 20.5732 - val_mse: 943.6310\n",
      "Epoch 2612/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0221 - mse: 933.5430 - val_loss: 20.6321 - val_mse: 963.0397\n",
      "Epoch 2613/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.8895 - mse: 929.8351 - val_loss: 20.5663 - val_mse: 939.4583\n",
      "Epoch 2614/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0334 - mse: 930.0236 - val_loss: 20.5763 - val_mse: 945.2438\n",
      "Epoch 2615/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9840 - mse: 937.2646 - val_loss: 20.6539 - val_mse: 903.7656\n",
      "Epoch 2616/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.8699 - mse: 921.6849 - val_loss: 20.5633 - val_mse: 937.0661\n",
      "Epoch 2617/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8823 - mse: 928.5251 - val_loss: 20.6468 - val_mse: 966.0766\n",
      "Epoch 2618/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9432 - mse: 933.4894 - val_loss: 20.5716 - val_mse: 942.7422\n",
      "Epoch 2619/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9664 - mse: 934.5103 - val_loss: 20.5666 - val_mse: 924.5352\n",
      "Epoch 2620/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0008 - mse: 938.8758 - val_loss: 20.5802 - val_mse: 947.0521\n",
      "Epoch 2621/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9756 - mse: 933.2372 - val_loss: 20.6567 - val_mse: 903.3865\n",
      "Epoch 2622/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9076 - mse: 934.7700 - val_loss: 20.5598 - val_mse: 931.5394\n",
      "Epoch 2623/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9613 - mse: 936.9852 - val_loss: 20.5629 - val_mse: 936.7067\n",
      "Epoch 2624/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9462 - mse: 928.8259 - val_loss: 20.5944 - val_mse: 915.0316\n",
      "Epoch 2625/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0373 - mse: 932.3518 - val_loss: 20.6626 - val_mse: 969.0136\n",
      "Epoch 2626/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8971 - mse: 932.9627 - val_loss: 20.5963 - val_mse: 914.5414\n",
      "Epoch 2627/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9604 - mse: 932.4630 - val_loss: 20.5609 - val_mse: 927.7255\n",
      "Epoch 2628/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9669 - mse: 932.3085 - val_loss: 20.5985 - val_mse: 913.9577\n",
      "Epoch 2629/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9918 - mse: 936.1057 - val_loss: 20.5855 - val_mse: 917.4029\n",
      "Epoch 2630/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0445 - mse: 933.8561 - val_loss: 20.6604 - val_mse: 968.6395\n",
      "Epoch 2631/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9187 - mse: 941.9123 - val_loss: 20.5609 - val_mse: 934.0287\n",
      "Epoch 2632/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9451 - mse: 934.5346 - val_loss: 20.5598 - val_mse: 931.2141\n",
      "Epoch 2633/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0185 - mse: 928.9589 - val_loss: 20.5604 - val_mse: 928.4750\n",
      "Epoch 2634/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9734 - mse: 926.7264 - val_loss: 20.5710 - val_mse: 922.6098\n",
      "Epoch 2635/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9511 - mse: 933.4854 - val_loss: 20.6026 - val_mse: 955.3539\n",
      "Epoch 2636/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0437 - mse: 938.2346 - val_loss: 20.5789 - val_mse: 946.4390\n",
      "Epoch 2637/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9447 - mse: 936.3018 - val_loss: 20.5727 - val_mse: 921.9048\n",
      "Epoch 2638/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9475 - mse: 940.9326 - val_loss: 20.5606 - val_mse: 933.3641\n",
      "Epoch 2639/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9405 - mse: 934.7569 - val_loss: 20.5599 - val_mse: 930.4396\n",
      "Epoch 2640/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9588 - mse: 931.0955 - val_loss: 20.5811 - val_mse: 947.4395\n",
      "Epoch 2641/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9074 - mse: 934.0934 - val_loss: 20.5935 - val_mse: 952.4625\n",
      "Epoch 2642/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9699 - mse: 935.2819 - val_loss: 20.5611 - val_mse: 934.4256\n",
      "Epoch 2643/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9646 - mse: 935.2895 - val_loss: 20.5613 - val_mse: 927.3609\n",
      "Epoch 2644/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9882 - mse: 933.2185 - val_loss: 20.5690 - val_mse: 941.2606\n",
      "Epoch 2645/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9417 - mse: 927.6553 - val_loss: 20.7566 - val_mse: 984.1007\n",
      "Epoch 2646/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9229 - mse: 931.4585 - val_loss: 20.6308 - val_mse: 962.7729\n",
      "Epoch 2647/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9734 - mse: 936.4793 - val_loss: 20.5630 - val_mse: 936.7695\n",
      "Epoch 2648/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9327 - mse: 928.1769 - val_loss: 20.5600 - val_mse: 929.5052\n",
      "Epoch 2649/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9473 - mse: 939.3592 - val_loss: 20.5683 - val_mse: 923.7734\n",
      "Epoch 2650/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0563 - mse: 938.6423 - val_loss: 20.5890 - val_mse: 950.8959\n",
      "Epoch 2651/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9985 - mse: 936.1561 - val_loss: 20.5776 - val_mse: 920.0461\n",
      "Epoch 2652/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9947 - mse: 932.2169 - val_loss: 20.7278 - val_mse: 979.6429\n",
      "Epoch 2653/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.9918 - mse: 939.2896 - val_loss: 20.5827 - val_mse: 948.1540\n",
      "Epoch 2654/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0624 - mse: 939.6595 - val_loss: 20.6041 - val_mse: 955.7989\n",
      "Epoch 2655/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0036 - mse: 951.6581 - val_loss: 20.5621 - val_mse: 926.7750\n",
      "Epoch 2656/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9883 - mse: 928.7507 - val_loss: 20.5954 - val_mse: 914.7619\n",
      "Epoch 2657/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0312 - mse: 940.0402 - val_loss: 20.6074 - val_mse: 956.7744\n",
      "Epoch 2658/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0133 - mse: 936.2738 - val_loss: 20.5775 - val_mse: 920.0636\n",
      "Epoch 2659/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0021 - mse: 937.3323 - val_loss: 20.5599 - val_mse: 929.5404\n",
      "Epoch 2660/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8535 - mse: 936.0178 - val_loss: 20.6291 - val_mse: 907.7115\n",
      "Epoch 2661/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8207 - mse: 924.1523 - val_loss: 20.5644 - val_mse: 925.5018\n",
      "Epoch 2662/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0180 - mse: 934.9443 - val_loss: 20.5717 - val_mse: 922.3094\n",
      "Epoch 2663/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8548 - mse: 929.0353 - val_loss: 20.5681 - val_mse: 940.6812\n",
      "Epoch 2664/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0475 - mse: 932.5551 - val_loss: 20.5879 - val_mse: 950.4597\n",
      "Epoch 2665/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9988 - mse: 936.2833 - val_loss: 20.5801 - val_mse: 947.0046\n",
      "Epoch 2666/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0114 - mse: 936.5493 - val_loss: 20.5787 - val_mse: 919.6342\n",
      "Epoch 2667/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0216 - mse: 938.9411 - val_loss: 20.6155 - val_mse: 959.1094\n",
      "Epoch 2668/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0635 - mse: 939.7053 - val_loss: 20.5600 - val_mse: 929.4348\n",
      "Epoch 2669/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9420 - mse: 934.3260 - val_loss: 20.5751 - val_mse: 944.6734\n",
      "Epoch 2670/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0047 - mse: 939.4321 - val_loss: 20.5599 - val_mse: 930.5328\n",
      "Epoch 2671/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0786 - mse: 946.7192 - val_loss: 20.5733 - val_mse: 921.6600\n",
      "Epoch 2672/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9713 - mse: 919.5964 - val_loss: 20.6407 - val_mse: 964.8073\n",
      "Epoch 2673/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9700 - mse: 943.5762 - val_loss: 20.5763 - val_mse: 945.2280\n",
      "Epoch 2674/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0097 - mse: 939.9775 - val_loss: 20.5629 - val_mse: 936.6868\n",
      "Epoch 2675/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9452 - mse: 932.3380 - val_loss: 20.5823 - val_mse: 947.9663\n",
      "Epoch 2676/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8814 - mse: 927.3990 - val_loss: 20.5605 - val_mse: 928.3736\n",
      "Epoch 2677/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.1502 - mse: 938.8794 - val_loss: 20.5631 - val_mse: 926.1743\n",
      "Epoch 2678/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9956 - mse: 942.4844 - val_loss: 20.5998 - val_mse: 913.6436\n",
      "Epoch 2679/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9405 - mse: 932.1016 - val_loss: 20.5932 - val_mse: 952.3423\n",
      "Epoch 2680/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9584 - mse: 932.7947 - val_loss: 20.5603 - val_mse: 928.8108\n",
      "Epoch 2681/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9827 - mse: 933.9712 - val_loss: 20.5807 - val_mse: 918.9383\n",
      "Epoch 2682/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9947 - mse: 925.2541 - val_loss: 20.6140 - val_mse: 958.6776\n",
      "Epoch 2683/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0203 - mse: 938.5073 - val_loss: 20.5854 - val_mse: 949.3738\n",
      "Epoch 2684/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9725 - mse: 939.1918 - val_loss: 20.5601 - val_mse: 932.1943\n",
      "Epoch 2685/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9725 - mse: 932.2803 - val_loss: 20.5763 - val_mse: 945.2352\n",
      "Epoch 2686/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9627 - mse: 933.7902 - val_loss: 20.5932 - val_mse: 915.3416\n",
      "Epoch 2687/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9596 - mse: 931.2179 - val_loss: 20.5603 - val_mse: 928.8567\n",
      "Epoch 2688/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9355 - mse: 940.0283 - val_loss: 20.5750 - val_mse: 921.0063\n",
      "Epoch 2689/5000\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20.8953 - mse: 930.4302 - val_loss: 20.5685 - val_mse: 940.9492\n",
      "Epoch 2690/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9708 - mse: 937.1475 - val_loss: 20.5603 - val_mse: 932.7650\n",
      "Epoch 2691/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9720 - mse: 927.0361 - val_loss: 20.6485 - val_mse: 966.4113\n",
      "Epoch 2692/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9431 - mse: 930.3748 - val_loss: 20.6643 - val_mse: 969.3152\n",
      "Epoch 2693/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9379 - mse: 932.5584 - val_loss: 20.5788 - val_mse: 946.4067\n",
      "Epoch 2694/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.8768 - mse: 925.7172 - val_loss: 20.6434 - val_mse: 965.3771\n",
      "Epoch 2695/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9889 - mse: 932.3076 - val_loss: 20.7250 - val_mse: 979.2063\n",
      "Epoch 2696/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9386 - mse: 936.9849 - val_loss: 20.5963 - val_mse: 953.3588\n",
      "Epoch 2697/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0411 - mse: 945.1696 - val_loss: 20.5669 - val_mse: 939.8888\n",
      "Epoch 2698/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0044 - mse: 933.3948 - val_loss: 20.5835 - val_mse: 948.5064\n",
      "Epoch 2699/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9720 - mse: 931.9780 - val_loss: 20.6782 - val_mse: 971.7164\n",
      "Epoch 2700/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9953 - mse: 932.1525 - val_loss: 20.6118 - val_mse: 958.0544\n",
      "Epoch 2701/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9128 - mse: 933.0749 - val_loss: 20.5654 - val_mse: 938.7252\n",
      "Epoch 2702/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9481 - mse: 934.6874 - val_loss: 20.5915 - val_mse: 915.8005\n",
      "Epoch 2703/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9515 - mse: 931.1357 - val_loss: 20.5598 - val_mse: 931.2242\n",
      "Epoch 2704/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9919 - mse: 935.0313 - val_loss: 20.5707 - val_mse: 942.2190\n",
      "Epoch 2705/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9507 - mse: 942.9213 - val_loss: 20.5809 - val_mse: 947.3261\n",
      "Epoch 2706/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.8852 - mse: 930.2161 - val_loss: 20.5712 - val_mse: 942.5228\n",
      "Epoch 2707/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9155 - mse: 925.7692 - val_loss: 20.5610 - val_mse: 934.3801\n",
      "Epoch 2708/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8974 - mse: 936.1448 - val_loss: 20.5599 - val_mse: 929.6688\n",
      "Epoch 2709/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8993 - mse: 925.3135 - val_loss: 20.6210 - val_mse: 960.5421\n",
      "Epoch 2710/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9975 - mse: 934.1219 - val_loss: 20.5850 - val_mse: 949.1952\n",
      "Epoch 2711/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.7989 - mse: 925.3595 - val_loss: 20.6494 - val_mse: 966.5809\n",
      "Epoch 2712/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9876 - mse: 932.9979 - val_loss: 20.6857 - val_mse: 972.9921\n",
      "Epoch 2713/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9149 - mse: 934.6425 - val_loss: 20.5670 - val_mse: 939.8987\n",
      "Epoch 2714/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0045 - mse: 936.8950 - val_loss: 20.5607 - val_mse: 933.6979\n",
      "Epoch 2715/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9160 - mse: 932.9138 - val_loss: 20.5737 - val_mse: 921.4860\n",
      "Epoch 2716/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9555 - mse: 929.7526 - val_loss: 20.5620 - val_mse: 935.8223\n",
      "Epoch 2717/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9569 - mse: 937.5590 - val_loss: 20.6377 - val_mse: 906.2608\n",
      "Epoch 2718/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.8487 - mse: 924.3828 - val_loss: 20.5657 - val_mse: 938.9954\n",
      "Epoch 2719/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9791 - mse: 928.9095 - val_loss: 20.5628 - val_mse: 936.6546\n",
      "Epoch 2720/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0123 - mse: 933.0775 - val_loss: 20.5753 - val_mse: 944.7534\n",
      "Epoch 2721/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9111 - mse: 936.1427 - val_loss: 20.5709 - val_mse: 942.3365\n",
      "Epoch 2722/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9372 - mse: 929.6492 - val_loss: 20.7051 - val_mse: 976.1061\n",
      "Epoch 2723/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9084 - mse: 931.1677 - val_loss: 20.5753 - val_mse: 944.7629\n",
      "Epoch 2724/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9704 - mse: 937.1354 - val_loss: 20.5599 - val_mse: 931.8770\n",
      "Epoch 2725/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8816 - mse: 937.8283 - val_loss: 20.6196 - val_mse: 960.2061\n",
      "Epoch 2726/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9231 - mse: 925.6584 - val_loss: 20.5700 - val_mse: 923.0580\n",
      "Epoch 2727/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21.0175 - mse: 936.6252 - val_loss: 20.5602 - val_mse: 929.0111\n",
      "Epoch 2728/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9680 - mse: 927.6923 - val_loss: 20.5860 - val_mse: 917.2661\n",
      "Epoch 2729/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0348 - mse: 931.3358 - val_loss: 20.5602 - val_mse: 932.5662\n",
      "Epoch 2730/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9572 - mse: 924.9505 - val_loss: 20.6976 - val_mse: 974.9250\n",
      "Epoch 2731/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0126 - mse: 930.0270 - val_loss: 20.6009 - val_mse: 954.8267\n",
      "Epoch 2732/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9970 - mse: 950.2350 - val_loss: 20.5790 - val_mse: 919.5296\n",
      "Epoch 2733/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0693 - mse: 935.9393 - val_loss: 20.5707 - val_mse: 942.2045\n",
      "Epoch 2734/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0037 - mse: 933.7669 - val_loss: 20.5700 - val_mse: 923.0297\n",
      "Epoch 2735/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0191 - mse: 933.8992 - val_loss: 20.5761 - val_mse: 945.1296\n",
      "Epoch 2736/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9283 - mse: 932.0708 - val_loss: 20.5721 - val_mse: 943.0377\n",
      "Epoch 2737/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0034 - mse: 927.4106 - val_loss: 20.5694 - val_mse: 941.4975\n",
      "Epoch 2738/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9742 - mse: 933.5482 - val_loss: 20.5903 - val_mse: 951.3600\n",
      "Epoch 2739/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0170 - mse: 930.3255 - val_loss: 20.6827 - val_mse: 972.4809\n",
      "Epoch 2740/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0196 - mse: 940.4342 - val_loss: 20.6302 - val_mse: 962.6306\n",
      "Epoch 2741/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8912 - mse: 934.7454 - val_loss: 20.6150 - val_mse: 958.9706\n",
      "Epoch 2742/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9616 - mse: 931.1998 - val_loss: 20.6156 - val_mse: 959.1517\n",
      "Epoch 2743/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0015 - mse: 939.1258 - val_loss: 20.5608 - val_mse: 933.8984\n",
      "Epoch 2744/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9970 - mse: 944.7573 - val_loss: 20.5656 - val_mse: 938.9092\n",
      "Epoch 2745/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9447 - mse: 932.3160 - val_loss: 20.6133 - val_mse: 958.4783\n",
      "Epoch 2746/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9361 - mse: 931.8303 - val_loss: 20.6215 - val_mse: 960.6673\n",
      "Epoch 2747/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8812 - mse: 928.0549 - val_loss: 20.5766 - val_mse: 920.3915\n",
      "Epoch 2748/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9952 - mse: 927.2264 - val_loss: 20.6037 - val_mse: 912.7788\n",
      "Epoch 2749/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0662 - mse: 936.9510 - val_loss: 20.5785 - val_mse: 946.2725\n",
      "Epoch 2750/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9098 - mse: 934.1368 - val_loss: 20.5644 - val_mse: 937.9969\n",
      "Epoch 2751/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9293 - mse: 930.0910 - val_loss: 20.5731 - val_mse: 943.6104\n",
      "Epoch 2752/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0626 - mse: 937.0121 - val_loss: 20.6717 - val_mse: 901.4157\n",
      "Epoch 2753/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9443 - mse: 931.0688 - val_loss: 20.5602 - val_mse: 928.9142\n",
      "Epoch 2754/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9185 - mse: 934.7131 - val_loss: 20.5668 - val_mse: 924.4486\n",
      "Epoch 2755/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9074 - mse: 936.3098 - val_loss: 20.6265 - val_mse: 961.8167\n",
      "Epoch 2756/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0231 - mse: 920.5167 - val_loss: 20.6853 - val_mse: 972.9217\n",
      "Epoch 2757/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0063 - mse: 944.0887 - val_loss: 20.5712 - val_mse: 942.5005\n",
      "Epoch 2758/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0648 - mse: 937.5765 - val_loss: 20.6271 - val_mse: 908.0710\n",
      "Epoch 2759/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9455 - mse: 932.3564 - val_loss: 20.5638 - val_mse: 937.5339\n",
      "Epoch 2760/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9707 - mse: 941.3329 - val_loss: 20.6447 - val_mse: 905.1320\n",
      "Epoch 2761/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9906 - mse: 932.2468 - val_loss: 20.5731 - val_mse: 921.7300\n",
      "Epoch 2762/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8871 - mse: 935.7145 - val_loss: 20.5599 - val_mse: 929.6477\n",
      "Epoch 2763/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9624 - mse: 938.4359 - val_loss: 20.6025 - val_mse: 955.3088\n",
      "Epoch 2764/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9348 - mse: 928.1600 - val_loss: 20.5794 - val_mse: 946.6604\n",
      "Epoch 2765/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9142 - mse: 934.2218 - val_loss: 20.6641 - val_mse: 902.3679\n",
      "Epoch 2766/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0234 - mse: 934.7930 - val_loss: 20.5601 - val_mse: 932.3641\n",
      "Epoch 2767/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9383 - mse: 938.4420 - val_loss: 20.5779 - val_mse: 946.0140\n",
      "Epoch 2768/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0295 - mse: 935.1041 - val_loss: 20.6519 - val_mse: 967.0720\n",
      "Epoch 2769/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0225 - mse: 936.0604 - val_loss: 20.6665 - val_mse: 969.6988\n",
      "Epoch 2770/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9709 - mse: 937.0200 - val_loss: 20.6589 - val_mse: 968.3694\n",
      "Epoch 2771/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9876 - mse: 940.3314 - val_loss: 20.5859 - val_mse: 949.6219\n",
      "Epoch 2772/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9841 - mse: 940.6924 - val_loss: 20.5599 - val_mse: 931.7794\n",
      "Epoch 2773/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0395 - mse: 935.4210 - val_loss: 20.5867 - val_mse: 949.9507\n",
      "Epoch 2774/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.7983 - mse: 930.4873 - val_loss: 20.5612 - val_mse: 927.3852\n",
      "Epoch 2775/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9883 - mse: 930.2543 - val_loss: 20.5627 - val_mse: 936.5342\n",
      "Epoch 2776/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9414 - mse: 927.6657 - val_loss: 20.5871 - val_mse: 950.1237\n",
      "Epoch 2777/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9457 - mse: 935.4053 - val_loss: 20.5650 - val_mse: 938.4334\n",
      "Epoch 2778/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9057 - mse: 934.4434 - val_loss: 20.5629 - val_mse: 936.6985\n",
      "Epoch 2779/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9968 - mse: 934.9929 - val_loss: 20.5600 - val_mse: 929.3634\n",
      "Epoch 2780/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0116 - mse: 938.5867 - val_loss: 20.6168 - val_mse: 909.9861\n",
      "Epoch 2781/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9540 - mse: 933.2097 - val_loss: 20.5629 - val_mse: 936.7202\n",
      "Epoch 2782/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9097 - mse: 932.9416 - val_loss: 20.5798 - val_mse: 919.2382\n",
      "Epoch 2783/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9802 - mse: 932.9896 - val_loss: 20.5813 - val_mse: 947.5115\n",
      "Epoch 2784/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8555 - mse: 927.1678 - val_loss: 20.6228 - val_mse: 960.9611\n",
      "Epoch 2785/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9130 - mse: 935.6486 - val_loss: 20.5783 - val_mse: 919.7971\n",
      "Epoch 2786/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0060 - mse: 929.4131 - val_loss: 20.5704 - val_mse: 942.0912\n",
      "Epoch 2787/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9295 - mse: 934.9946 - val_loss: 20.5600 - val_mse: 929.3439\n",
      "Epoch 2788/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8708 - mse: 922.0621 - val_loss: 20.6344 - val_mse: 963.5148\n",
      "Epoch 2789/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0103 - mse: 943.8783 - val_loss: 20.6254 - val_mse: 961.5607\n",
      "Epoch 2790/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9399 - mse: 940.1949 - val_loss: 20.6650 - val_mse: 902.2543\n",
      "Epoch 2791/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9602 - mse: 933.8348 - val_loss: 20.5725 - val_mse: 921.9642\n",
      "Epoch 2792/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9366 - mse: 929.8361 - val_loss: 20.5682 - val_mse: 923.8383\n",
      "Epoch 2793/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9767 - mse: 928.5648 - val_loss: 20.5866 - val_mse: 949.8958\n",
      "Epoch 2794/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8708 - mse: 931.2012 - val_loss: 20.6057 - val_mse: 956.2652\n",
      "Epoch 2795/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0130 - mse: 928.7021 - val_loss: 20.5759 - val_mse: 945.0674\n",
      "Epoch 2796/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9459 - mse: 934.4442 - val_loss: 20.5603 - val_mse: 932.6806\n",
      "Epoch 2797/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9724 - mse: 941.2092 - val_loss: 20.5600 - val_mse: 929.5009\n",
      "Epoch 2798/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9874 - mse: 939.7812 - val_loss: 20.5848 - val_mse: 949.1271\n",
      "Epoch 2799/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9183 - mse: 934.1730 - val_loss: 20.5703 - val_mse: 941.9840\n",
      "Epoch 2800/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9306 - mse: 932.3518 - val_loss: 20.6311 - val_mse: 962.8343\n",
      "Epoch 2801/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.8626 - mse: 927.8683 - val_loss: 20.5781 - val_mse: 919.8517\n",
      "Epoch 2802/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9760 - mse: 929.5459 - val_loss: 20.5851 - val_mse: 917.5315\n",
      "Epoch 2803/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9639 - mse: 925.8865 - val_loss: 20.5602 - val_mse: 932.4030\n",
      "Epoch 2804/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9286 - mse: 932.2606 - val_loss: 20.5625 - val_mse: 936.3386\n",
      "Epoch 2805/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9736 - mse: 932.1914 - val_loss: 20.5835 - val_mse: 948.5084\n",
      "Epoch 2806/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8639 - mse: 927.9899 - val_loss: 20.5956 - val_mse: 953.1528\n",
      "Epoch 2807/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0879 - mse: 938.2167 - val_loss: 20.5728 - val_mse: 921.8554\n",
      "Epoch 2808/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8759 - mse: 933.4860 - val_loss: 20.5866 - val_mse: 949.9106\n",
      "Epoch 2809/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0056 - mse: 939.6475 - val_loss: 20.5600 - val_mse: 929.4120\n",
      "Epoch 2810/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9751 - mse: 937.9057 - val_loss: 20.7208 - val_mse: 978.5377\n",
      "Epoch 2811/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9983 - mse: 942.0175 - val_loss: 20.5721 - val_mse: 943.0179\n",
      "Epoch 2812/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0581 - mse: 929.1340 - val_loss: 20.5610 - val_mse: 934.3395\n",
      "Epoch 2813/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9215 - mse: 929.4650 - val_loss: 20.5885 - val_mse: 950.6705\n",
      "Epoch 2814/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9614 - mse: 933.9718 - val_loss: 20.6027 - val_mse: 955.3572\n",
      "Epoch 2815/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9101 - mse: 939.6038 - val_loss: 20.5598 - val_mse: 931.1663\n",
      "Epoch 2816/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9970 - mse: 938.3727 - val_loss: 20.5598 - val_mse: 930.6097\n",
      "Epoch 2817/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9265 - mse: 935.3959 - val_loss: 20.6103 - val_mse: 957.6081\n",
      "Epoch 2818/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9174 - mse: 932.2227 - val_loss: 20.5608 - val_mse: 927.9224\n",
      "Epoch 2819/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8971 - mse: 924.2903 - val_loss: 20.5631 - val_mse: 936.9200\n",
      "Epoch 2820/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0137 - mse: 930.1281 - val_loss: 20.5630 - val_mse: 936.8450\n",
      "Epoch 2821/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9573 - mse: 936.5448 - val_loss: 20.6306 - val_mse: 907.4504\n",
      "Epoch 2822/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9866 - mse: 933.7494 - val_loss: 20.5615 - val_mse: 927.2002\n",
      "Epoch 2823/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9346 - mse: 933.2368 - val_loss: 20.5912 - val_mse: 915.8802\n",
      "Epoch 2824/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9159 - mse: 926.6304 - val_loss: 20.5876 - val_mse: 950.3395\n",
      "Epoch 2825/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9331 - mse: 938.3444 - val_loss: 20.5656 - val_mse: 924.9913\n",
      "Epoch 2826/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8909 - mse: 929.3332 - val_loss: 20.6138 - val_mse: 910.5758\n",
      "Epoch 2827/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0158 - mse: 939.1877 - val_loss: 20.5682 - val_mse: 940.7760\n",
      "Epoch 2828/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9491 - mse: 930.1418 - val_loss: 20.5906 - val_mse: 951.4465\n",
      "Epoch 2829/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9747 - mse: 933.4892 - val_loss: 20.5757 - val_mse: 944.9494\n",
      "Epoch 2830/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0624 - mse: 936.7946 - val_loss: 20.5821 - val_mse: 947.9031\n",
      "Epoch 2831/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9613 - mse: 940.1895 - val_loss: 20.6257 - val_mse: 908.3295\n",
      "Epoch 2832/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0032 - mse: 928.2773 - val_loss: 20.5603 - val_mse: 932.6877\n",
      "Epoch 2833/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9758 - mse: 944.6636 - val_loss: 20.5776 - val_mse: 920.0237\n",
      "Epoch 2834/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0126 - mse: 939.3311 - val_loss: 20.5684 - val_mse: 923.7344\n",
      "Epoch 2835/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9847 - mse: 938.1414 - val_loss: 20.5835 - val_mse: 948.5372\n",
      "Epoch 2836/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0186 - mse: 935.2765 - val_loss: 20.5615 - val_mse: 927.1571\n",
      "Epoch 2837/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9846 - mse: 939.0129 - val_loss: 20.5640 - val_mse: 937.6934\n",
      "Epoch 2838/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0274 - mse: 932.2513 - val_loss: 20.6019 - val_mse: 955.1336\n",
      "Epoch 2839/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9849 - mse: 935.9066 - val_loss: 20.5602 - val_mse: 932.5148\n",
      "Epoch 2840/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8218 - mse: 918.9396 - val_loss: 20.5775 - val_mse: 945.8025\n",
      "Epoch 2841/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8708 - mse: 931.0105 - val_loss: 20.6461 - val_mse: 965.9293\n",
      "Epoch 2842/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0068 - mse: 943.5164 - val_loss: 20.6155 - val_mse: 959.1074\n",
      "Epoch 2843/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0289 - mse: 940.4368 - val_loss: 20.6054 - val_mse: 912.3961\n",
      "Epoch 2844/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9642 - mse: 926.7015 - val_loss: 20.7665 - val_mse: 985.6578\n",
      "Epoch 2845/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9467 - mse: 932.6599 - val_loss: 20.5654 - val_mse: 925.0590\n",
      "Epoch 2846/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8774 - mse: 930.8694 - val_loss: 20.5689 - val_mse: 923.5432\n",
      "Epoch 2847/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8405 - mse: 926.8633 - val_loss: 20.5704 - val_mse: 922.8496\n",
      "Epoch 2848/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9182 - mse: 927.5238 - val_loss: 20.6028 - val_mse: 955.4052\n",
      "Epoch 2849/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0311 - mse: 940.8151 - val_loss: 20.5780 - val_mse: 919.8906\n",
      "Epoch 2850/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9990 - mse: 937.0734 - val_loss: 20.5837 - val_mse: 917.9355\n",
      "Epoch 2851/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9233 - mse: 926.2214 - val_loss: 20.6010 - val_mse: 954.8619\n",
      "Epoch 2852/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9447 - mse: 938.1741 - val_loss: 20.5696 - val_mse: 941.5944\n",
      "Epoch 2853/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9298 - mse: 936.4250 - val_loss: 20.6792 - val_mse: 971.8806\n",
      "Epoch 2854/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9537 - mse: 931.5937 - val_loss: 20.5616 - val_mse: 927.0601\n",
      "Epoch 2855/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0166 - mse: 928.5421 - val_loss: 20.6858 - val_mse: 973.0005\n",
      "Epoch 2856/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0306 - mse: 934.6375 - val_loss: 20.8578 - val_mse: 999.3342\n",
      "Epoch 2857/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9632 - mse: 937.5746 - val_loss: 20.7735 - val_mse: 986.7525\n",
      "Epoch 2858/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9925 - mse: 947.9359 - val_loss: 20.5601 - val_mse: 929.2856\n",
      "Epoch 2859/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9539 - mse: 937.7833 - val_loss: 20.5607 - val_mse: 933.5746\n",
      "Epoch 2860/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9991 - mse: 929.1991 - val_loss: 20.6371 - val_mse: 964.0546\n",
      "Epoch 2861/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0362 - mse: 941.3781 - val_loss: 20.6212 - val_mse: 909.1522\n",
      "Epoch 2862/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9672 - mse: 932.7930 - val_loss: 20.5605 - val_mse: 933.2040\n",
      "Epoch 2863/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9831 - mse: 936.7440 - val_loss: 20.5620 - val_mse: 926.8283\n",
      "Epoch 2864/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8723 - mse: 931.3115 - val_loss: 20.5599 - val_mse: 930.2816\n",
      "Epoch 2865/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9134 - mse: 935.2882 - val_loss: 20.5601 - val_mse: 932.2529\n",
      "Epoch 2866/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9349 - mse: 930.9228 - val_loss: 20.6114 - val_mse: 957.9171\n",
      "Epoch 2867/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9321 - mse: 934.4008 - val_loss: 20.6432 - val_mse: 965.3240\n",
      "Epoch 2868/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9551 - mse: 932.8708 - val_loss: 20.5778 - val_mse: 945.9690\n",
      "Epoch 2869/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0417 - mse: 940.2753 - val_loss: 20.5644 - val_mse: 937.9635\n",
      "Epoch 2870/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8173 - mse: 925.3270 - val_loss: 20.6440 - val_mse: 965.5039\n",
      "Epoch 2871/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9307 - mse: 939.2346 - val_loss: 20.6161 - val_mse: 959.2903\n",
      "Epoch 2872/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0246 - mse: 942.0392 - val_loss: 20.5759 - val_mse: 945.0485\n",
      "Epoch 2873/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 21.0152 - mse: 929.9637 - val_loss: 20.5855 - val_mse: 917.4033\n",
      "Epoch 2874/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9189 - mse: 934.0787 - val_loss: 20.5667 - val_mse: 939.7307\n",
      "Epoch 2875/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9205 - mse: 937.6624 - val_loss: 20.5775 - val_mse: 920.0754\n",
      "Epoch 2876/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8573 - mse: 923.0803 - val_loss: 20.6485 - val_mse: 904.5562\n",
      "Epoch 2877/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0058 - mse: 936.7095 - val_loss: 20.5792 - val_mse: 919.4827\n",
      "Epoch 2878/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0582 - mse: 935.3364 - val_loss: 20.5737 - val_mse: 943.9290\n",
      "Epoch 2879/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9017 - mse: 936.4814 - val_loss: 20.5892 - val_mse: 916.4268\n",
      "Epoch 2880/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0170 - mse: 930.4658 - val_loss: 20.6137 - val_mse: 958.5877\n",
      "Epoch 2881/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9177 - mse: 940.2421 - val_loss: 20.5643 - val_mse: 937.8647\n",
      "Epoch 2882/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9539 - mse: 930.6351 - val_loss: 20.5701 - val_mse: 923.0181\n",
      "Epoch 2883/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9130 - mse: 933.1746 - val_loss: 20.5607 - val_mse: 933.5827\n",
      "Epoch 2884/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9404 - mse: 942.0309 - val_loss: 20.5851 - val_mse: 917.5303\n",
      "Epoch 2885/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 21.0349 - mse: 932.3228 - val_loss: 20.5797 - val_mse: 946.7964\n",
      "Epoch 2886/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9773 - mse: 940.6246 - val_loss: 20.6085 - val_mse: 957.1008\n",
      "Epoch 2887/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9231 - mse: 931.1772 - val_loss: 20.6329 - val_mse: 963.1973\n",
      "Epoch 2888/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9693 - mse: 937.0106 - val_loss: 20.5684 - val_mse: 923.7250\n",
      "Epoch 2889/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8473 - mse: 928.8829 - val_loss: 20.6452 - val_mse: 965.7559\n",
      "Epoch 2890/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9843 - mse: 940.3844 - val_loss: 20.5680 - val_mse: 940.6423\n",
      "Epoch 2891/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8512 - mse: 928.9628 - val_loss: 20.5784 - val_mse: 946.2310\n",
      "Epoch 2892/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8924 - mse: 938.1444 - val_loss: 20.6828 - val_mse: 972.5007\n",
      "Epoch 2893/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0295 - mse: 937.2028 - val_loss: 20.5600 - val_mse: 932.0587\n",
      "Epoch 2894/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8883 - mse: 943.2227 - val_loss: 20.6396 - val_mse: 905.9511\n",
      "Epoch 2895/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0278 - mse: 932.8217 - val_loss: 20.5599 - val_mse: 930.1819\n",
      "Epoch 2896/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9316 - mse: 938.7310 - val_loss: 20.6129 - val_mse: 910.7753\n",
      "Epoch 2897/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0234 - mse: 939.3756 - val_loss: 20.5978 - val_mse: 953.8635\n",
      "Epoch 2898/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9396 - mse: 933.3896 - val_loss: 20.5644 - val_mse: 937.9952\n",
      "Epoch 2899/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9527 - mse: 939.9875 - val_loss: 20.5599 - val_mse: 930.5002\n",
      "Epoch 2900/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0308 - mse: 928.8320 - val_loss: 20.6226 - val_mse: 908.8784\n",
      "Epoch 2901/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9545 - mse: 933.8109 - val_loss: 20.5823 - val_mse: 918.3914\n",
      "Epoch 2902/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9411 - mse: 937.6304 - val_loss: 20.6260 - val_mse: 908.2762\n",
      "Epoch 2903/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0031 - mse: 929.5472 - val_loss: 20.5636 - val_mse: 937.2883\n",
      "Epoch 2904/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9893 - mse: 933.7167 - val_loss: 20.5720 - val_mse: 942.9615\n",
      "Epoch 2905/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9346 - mse: 937.7871 - val_loss: 20.5629 - val_mse: 926.2847\n",
      "Epoch 2906/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9550 - mse: 937.9964 - val_loss: 20.5620 - val_mse: 935.8321\n",
      "Epoch 2907/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9636 - mse: 930.5880 - val_loss: 20.5861 - val_mse: 949.6991\n",
      "Epoch 2908/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9319 - mse: 931.0552 - val_loss: 20.7831 - val_mse: 988.2309\n",
      "Epoch 2909/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0229 - mse: 944.1454 - val_loss: 20.5939 - val_mse: 915.1652\n",
      "Epoch 2910/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9512 - mse: 928.7176 - val_loss: 20.5655 - val_mse: 938.8286\n",
      "Epoch 2911/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9220 - mse: 928.0941 - val_loss: 20.5707 - val_mse: 922.7169\n",
      "Epoch 2912/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9827 - mse: 931.3300 - val_loss: 20.5755 - val_mse: 944.8738\n",
      "Epoch 2913/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.1165 - mse: 943.4369 - val_loss: 20.5931 - val_mse: 952.3121\n",
      "Epoch 2914/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0278 - mse: 932.6951 - val_loss: 20.6230 - val_mse: 961.0089\n",
      "Epoch 2915/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9612 - mse: 938.7521 - val_loss: 20.5782 - val_mse: 946.1365\n",
      "Epoch 2916/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9294 - mse: 930.1385 - val_loss: 20.5722 - val_mse: 943.0492\n",
      "Epoch 2917/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0092 - mse: 934.7331 - val_loss: 20.5930 - val_mse: 915.4073\n",
      "Epoch 2918/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9816 - mse: 933.7610 - val_loss: 20.5619 - val_mse: 926.9013\n",
      "Epoch 2919/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9596 - mse: 928.6169 - val_loss: 20.5926 - val_mse: 952.1384\n",
      "Epoch 2920/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0084 - mse: 935.7125 - val_loss: 20.6251 - val_mse: 961.4962\n",
      "Epoch 2921/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9707 - mse: 937.3203 - val_loss: 20.5734 - val_mse: 921.6173\n",
      "Epoch 2922/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9443 - mse: 932.9278 - val_loss: 20.5676 - val_mse: 924.1148\n",
      "Epoch 2923/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9665 - mse: 935.9889 - val_loss: 20.5913 - val_mse: 915.8471\n",
      "Epoch 2924/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9530 - mse: 927.2033 - val_loss: 20.5622 - val_mse: 926.7020\n",
      "Epoch 2925/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9554 - mse: 937.2696 - val_loss: 20.6009 - val_mse: 954.8315\n",
      "Epoch 2926/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9513 - mse: 937.0978 - val_loss: 20.5905 - val_mse: 951.4127\n",
      "Epoch 2927/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9239 - mse: 936.0466 - val_loss: 20.5604 - val_mse: 928.6031\n",
      "Epoch 2928/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9509 - mse: 931.0063 - val_loss: 20.5645 - val_mse: 938.0456\n",
      "Epoch 2929/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9986 - mse: 934.0874 - val_loss: 20.6238 - val_mse: 961.1991\n",
      "Epoch 2930/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0021 - mse: 937.6827 - val_loss: 20.5791 - val_mse: 946.5346\n",
      "Epoch 2931/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9142 - mse: 927.6172 - val_loss: 20.7958 - val_mse: 990.1604\n",
      "Epoch 2932/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9194 - mse: 935.9190 - val_loss: 20.5601 - val_mse: 929.1501\n",
      "Epoch 2933/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9203 - mse: 929.7260 - val_loss: 20.5864 - val_mse: 949.8116\n",
      "Epoch 2934/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9733 - mse: 931.1570 - val_loss: 20.5818 - val_mse: 947.7429\n",
      "Epoch 2935/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9230 - mse: 930.1429 - val_loss: 20.5598 - val_mse: 930.8229\n",
      "Epoch 2936/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9628 - mse: 933.1846 - val_loss: 20.5787 - val_mse: 946.3654\n",
      "Epoch 2937/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9293 - mse: 943.6847 - val_loss: 20.6058 - val_mse: 912.3109\n",
      "Epoch 2938/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9344 - mse: 928.5457 - val_loss: 20.5645 - val_mse: 938.0090\n",
      "Epoch 2939/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9305 - mse: 923.8348 - val_loss: 20.6935 - val_mse: 974.2731\n",
      "Epoch 2940/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9231 - mse: 934.6371 - val_loss: 20.5861 - val_mse: 949.6956\n",
      "Epoch 2941/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9968 - mse: 938.1636 - val_loss: 20.5694 - val_mse: 941.4713\n",
      "Epoch 2942/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0153 - mse: 940.1261 - val_loss: 20.5598 - val_mse: 930.6789\n",
      "Epoch 2943/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8644 - mse: 926.6448 - val_loss: 20.5749 - val_mse: 944.5601\n",
      "Epoch 2944/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9895 - mse: 926.8748 - val_loss: 20.5768 - val_mse: 945.4986\n",
      "Epoch 2945/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9588 - mse: 937.0457 - val_loss: 20.6129 - val_mse: 958.3612\n",
      "Epoch 2946/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9057 - mse: 921.8047 - val_loss: 20.5822 - val_mse: 947.9406\n",
      "Epoch 2947/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9976 - mse: 938.4163 - val_loss: 20.5624 - val_mse: 936.2252\n",
      "Epoch 2948/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0334 - mse: 937.1592 - val_loss: 20.5599 - val_mse: 931.9709\n",
      "Epoch 2949/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9449 - mse: 931.2698 - val_loss: 20.5667 - val_mse: 939.6939\n",
      "Epoch 2950/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9378 - mse: 937.3973 - val_loss: 20.5638 - val_mse: 937.5083\n",
      "Epoch 2951/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9056 - mse: 937.9958 - val_loss: 20.5608 - val_mse: 927.8779\n",
      "Epoch 2952/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9696 - mse: 937.5313 - val_loss: 20.5695 - val_mse: 923.2558\n",
      "Epoch 2953/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9490 - mse: 930.9198 - val_loss: 20.5855 - val_mse: 917.4056\n",
      "Epoch 2954/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8615 - mse: 926.2444 - val_loss: 20.5995 - val_mse: 954.3900\n",
      "Epoch 2955/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8349 - mse: 923.9254 - val_loss: 20.6288 - val_mse: 962.3308\n",
      "Epoch 2956/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8943 - mse: 928.6158 - val_loss: 20.5954 - val_mse: 953.0877\n",
      "Epoch 2957/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0145 - mse: 931.1965 - val_loss: 20.5686 - val_mse: 941.0242\n",
      "Epoch 2958/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9655 - mse: 942.6110 - val_loss: 20.5929 - val_mse: 915.4262\n",
      "Epoch 2959/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9290 - mse: 933.0869 - val_loss: 20.5649 - val_mse: 938.3596\n",
      "Epoch 2960/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9939 - mse: 935.9169 - val_loss: 20.6569 - val_mse: 968.0290\n",
      "Epoch 2961/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9961 - mse: 943.8259 - val_loss: 20.5690 - val_mse: 941.2482\n",
      "Epoch 2962/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9445 - mse: 934.0985 - val_loss: 20.7093 - val_mse: 976.7637\n",
      "Epoch 2963/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9109 - mse: 935.9828 - val_loss: 20.5739 - val_mse: 944.0258\n",
      "Epoch 2964/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 21.0362 - mse: 935.6553 - val_loss: 20.8295 - val_mse: 995.1788\n",
      "Epoch 2965/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0041 - mse: 935.1961 - val_loss: 20.7144 - val_mse: 977.5469\n",
      "Epoch 2966/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0323 - mse: 944.5848 - val_loss: 20.5858 - val_mse: 917.3304\n",
      "Epoch 2967/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8520 - mse: 928.1631 - val_loss: 20.5730 - val_mse: 943.5084\n",
      "Epoch 2968/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8253 - mse: 923.6918 - val_loss: 20.5607 - val_mse: 933.6715\n",
      "Epoch 2969/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9604 - mse: 935.3855 - val_loss: 20.6195 - val_mse: 909.4671\n",
      "Epoch 2970/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9529 - mse: 926.3386 - val_loss: 20.5794 - val_mse: 946.6558\n",
      "Epoch 2971/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0189 - mse: 942.5684 - val_loss: 20.5979 - val_mse: 953.8997\n",
      "Epoch 2972/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8720 - mse: 940.9672 - val_loss: 20.6086 - val_mse: 911.7111\n",
      "Epoch 2973/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9804 - mse: 927.9685 - val_loss: 20.5610 - val_mse: 927.6231\n",
      "Epoch 2974/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0431 - mse: 937.7246 - val_loss: 20.5835 - val_mse: 918.0121\n",
      "Epoch 2975/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9628 - mse: 936.0660 - val_loss: 20.5599 - val_mse: 930.1276\n",
      "Epoch 2976/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9594 - mse: 940.6546 - val_loss: 20.5633 - val_mse: 926.0856\n",
      "Epoch 2977/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0106 - mse: 930.5403 - val_loss: 20.6155 - val_mse: 959.1209\n",
      "Epoch 2978/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9537 - mse: 933.9885 - val_loss: 20.6158 - val_mse: 959.2025\n",
      "Epoch 2979/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9277 - mse: 931.7721 - val_loss: 20.6106 - val_mse: 957.6996\n",
      "Epoch 2980/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9339 - mse: 935.8610 - val_loss: 20.5666 - val_mse: 939.6627\n",
      "Epoch 2981/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9917 - mse: 938.8851 - val_loss: 20.5840 - val_mse: 948.7310\n",
      "Epoch 2982/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9083 - mse: 932.4658 - val_loss: 20.5658 - val_mse: 939.0760\n",
      "Epoch 2983/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9167 - mse: 933.0148 - val_loss: 20.6547 - val_mse: 967.6189\n",
      "Epoch 2984/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9431 - mse: 939.6164 - val_loss: 20.5601 - val_mse: 932.3773\n",
      "Epoch 2985/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9478 - mse: 928.7017 - val_loss: 20.5609 - val_mse: 934.0117\n",
      "Epoch 2986/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9415 - mse: 933.9934 - val_loss: 20.6087 - val_mse: 957.1611\n",
      "Epoch 2987/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9669 - mse: 939.1312 - val_loss: 20.5858 - val_mse: 917.3445\n",
      "Epoch 2988/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9634 - mse: 931.8062 - val_loss: 20.5600 - val_mse: 932.1604\n",
      "Epoch 2989/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9717 - mse: 936.3243 - val_loss: 20.5882 - val_mse: 950.5538\n",
      "Epoch 2990/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0501 - mse: 931.2541 - val_loss: 20.6878 - val_mse: 973.3328\n",
      "Epoch 2991/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9672 - mse: 926.4659 - val_loss: 20.6041 - val_mse: 955.7742\n",
      "Epoch 2992/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0404 - mse: 941.9802 - val_loss: 20.5637 - val_mse: 937.3958\n",
      "Epoch 2993/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9456 - mse: 928.4312 - val_loss: 20.5731 - val_mse: 943.5962\n",
      "Epoch 2994/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9475 - mse: 934.6776 - val_loss: 20.5815 - val_mse: 947.6022\n",
      "Epoch 2995/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.8956 - mse: 928.9118 - val_loss: 20.5636 - val_mse: 937.2968\n",
      "Epoch 2996/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9277 - mse: 932.6349 - val_loss: 20.5616 - val_mse: 935.4454\n",
      "Epoch 2997/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.8993 - mse: 928.2865 - val_loss: 20.5638 - val_mse: 925.8104\n",
      "Epoch 2998/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21.0923 - mse: 935.3787 - val_loss: 20.5604 - val_mse: 933.0073\n",
      "Epoch 2999/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9537 - mse: 932.4299 - val_loss: 20.5771 - val_mse: 945.6375\n",
      "Epoch 3000/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8622 - mse: 928.8466 - val_loss: 20.5998 - val_mse: 954.5087\n",
      "Epoch 3001/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9769 - mse: 932.8253 - val_loss: 20.7590 - val_mse: 984.4678\n",
      "Epoch 3002/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9716 - mse: 940.0661 - val_loss: 20.6012 - val_mse: 954.9327\n",
      "Epoch 3003/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9312 - mse: 938.3510 - val_loss: 20.5789 - val_mse: 946.4532\n",
      "Epoch 3004/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9827 - mse: 936.8188 - val_loss: 20.6194 - val_mse: 960.1542\n",
      "Epoch 3005/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0069 - mse: 935.7243 - val_loss: 20.6483 - val_mse: 966.3727\n",
      "Epoch 3006/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9296 - mse: 931.1639 - val_loss: 20.6475 - val_mse: 966.2023\n",
      "Epoch 3007/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9618 - mse: 938.3853 - val_loss: 20.7531 - val_mse: 983.5493\n",
      "Epoch 3008/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9775 - mse: 933.0916 - val_loss: 20.6267 - val_mse: 961.8544\n",
      "Epoch 3009/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9348 - mse: 929.1066 - val_loss: 20.6209 - val_mse: 960.5109\n",
      "Epoch 3010/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9427 - mse: 930.9077 - val_loss: 20.7549 - val_mse: 983.8256\n",
      "Epoch 3011/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9400 - mse: 937.3853 - val_loss: 20.5797 - val_mse: 946.7962\n",
      "Epoch 3012/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9849 - mse: 940.0227 - val_loss: 20.5599 - val_mse: 929.9996\n",
      "Epoch 3013/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9309 - mse: 925.6824 - val_loss: 20.5785 - val_mse: 946.2806\n",
      "Epoch 3014/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9814 - mse: 936.4146 - val_loss: 20.5837 - val_mse: 948.6327\n",
      "Epoch 3015/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9144 - mse: 933.5806 - val_loss: 20.6089 - val_mse: 957.1998\n",
      "Epoch 3016/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0401 - mse: 940.9614 - val_loss: 20.6432 - val_mse: 965.3343\n",
      "Epoch 3017/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9422 - mse: 935.0826 - val_loss: 20.5603 - val_mse: 932.6268\n",
      "Epoch 3018/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9809 - mse: 943.7256 - val_loss: 20.6247 - val_mse: 961.4154\n",
      "Epoch 3019/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9785 - mse: 938.8901 - val_loss: 20.5891 - val_mse: 950.9167\n",
      "Epoch 3020/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9235 - mse: 932.7855 - val_loss: 20.5605 - val_mse: 933.1740\n",
      "Epoch 3021/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9730 - mse: 929.3573 - val_loss: 20.8351 - val_mse: 996.0006\n",
      "Epoch 3022/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9895 - mse: 938.9157 - val_loss: 20.5718 - val_mse: 942.8602\n",
      "Epoch 3023/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9521 - mse: 935.4572 - val_loss: 20.5699 - val_mse: 941.8006\n",
      "Epoch 3024/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9992 - mse: 933.2706 - val_loss: 20.7481 - val_mse: 982.7743\n",
      "Epoch 3025/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0367 - mse: 936.5474 - val_loss: 20.5697 - val_mse: 941.6875\n",
      "Epoch 3026/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0051 - mse: 942.1118 - val_loss: 20.5619 - val_mse: 935.7144\n",
      "Epoch 3027/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9381 - mse: 927.1099 - val_loss: 20.5849 - val_mse: 917.5767\n",
      "Epoch 3028/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8867 - mse: 931.4365 - val_loss: 20.5678 - val_mse: 940.4669\n",
      "Epoch 3029/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9812 - mse: 919.5468 - val_loss: 20.5986 - val_mse: 954.1324\n",
      "Epoch 3030/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8728 - mse: 936.2932 - val_loss: 20.5718 - val_mse: 922.2583\n",
      "Epoch 3031/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9474 - mse: 929.7238 - val_loss: 20.6744 - val_mse: 971.0779\n",
      "Epoch 3032/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0275 - mse: 940.9812 - val_loss: 20.5677 - val_mse: 940.4083\n",
      "Epoch 3033/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9185 - mse: 930.9316 - val_loss: 20.5711 - val_mse: 942.4669\n",
      "Epoch 3034/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9141 - mse: 938.5251 - val_loss: 20.5930 - val_mse: 952.2861\n",
      "Epoch 3035/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9311 - mse: 933.3229 - val_loss: 20.5965 - val_mse: 953.4279\n",
      "Epoch 3036/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9606 - mse: 938.9294 - val_loss: 20.5965 - val_mse: 914.4669\n",
      "Epoch 3037/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8861 - mse: 929.4290 - val_loss: 20.5753 - val_mse: 920.8850\n",
      "Epoch 3038/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9289 - mse: 931.2928 - val_loss: 20.5599 - val_mse: 930.2558\n",
      "Epoch 3039/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8923 - mse: 927.1837 - val_loss: 20.5650 - val_mse: 938.3929\n",
      "Epoch 3040/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9565 - mse: 932.3691 - val_loss: 20.6262 - val_mse: 908.2252\n",
      "Epoch 3041/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9731 - mse: 932.0292 - val_loss: 20.5870 - val_mse: 950.0609\n",
      "Epoch 3042/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9522 - mse: 929.9756 - val_loss: 20.6932 - val_mse: 974.2290\n",
      "Epoch 3043/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9177 - mse: 930.7256 - val_loss: 20.5762 - val_mse: 920.5514\n",
      "Epoch 3044/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9638 - mse: 926.8377 - val_loss: 20.5651 - val_mse: 938.4854\n",
      "Epoch 3045/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9596 - mse: 931.2914 - val_loss: 20.5696 - val_mse: 941.6422\n",
      "Epoch 3046/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9306 - mse: 933.2193 - val_loss: 20.5625 - val_mse: 936.3315\n",
      "Epoch 3047/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9288 - mse: 938.5424 - val_loss: 20.5756 - val_mse: 944.9260\n",
      "Epoch 3048/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9661 - mse: 936.0634 - val_loss: 20.5805 - val_mse: 918.9979\n",
      "Epoch 3049/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9187 - mse: 933.3549 - val_loss: 20.5608 - val_mse: 933.8179\n",
      "Epoch 3050/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9954 - mse: 935.5372 - val_loss: 20.5603 - val_mse: 928.7617\n",
      "Epoch 3051/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9711 - mse: 923.2366 - val_loss: 20.5606 - val_mse: 933.4336\n",
      "Epoch 3052/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0465 - mse: 936.9067 - val_loss: 20.6300 - val_mse: 962.5939\n",
      "Epoch 3053/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0370 - mse: 943.0206 - val_loss: 20.5783 - val_mse: 946.1816\n",
      "Epoch 3054/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8232 - mse: 919.3673 - val_loss: 20.6642 - val_mse: 969.2983\n",
      "Epoch 3055/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9960 - mse: 939.1066 - val_loss: 20.5661 - val_mse: 939.2903\n",
      "Epoch 3056/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9460 - mse: 939.2287 - val_loss: 20.5601 - val_mse: 932.3684\n",
      "Epoch 3057/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8429 - mse: 922.0283 - val_loss: 20.5651 - val_mse: 938.4790\n",
      "Epoch 3058/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0334 - mse: 939.5996 - val_loss: 20.6342 - val_mse: 906.8315\n",
      "Epoch 3059/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9246 - mse: 919.0375 - val_loss: 20.5742 - val_mse: 944.1854\n",
      "Epoch 3060/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0542 - mse: 932.1334 - val_loss: 20.5977 - val_mse: 953.8196\n",
      "Epoch 3061/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.1018 - mse: 946.0780 - val_loss: 20.6643 - val_mse: 969.3218\n",
      "Epoch 3062/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0092 - mse: 937.8902 - val_loss: 20.5603 - val_mse: 932.7135\n",
      "Epoch 3063/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9824 - mse: 930.5307 - val_loss: 20.5714 - val_mse: 942.6118\n",
      "Epoch 3064/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0297 - mse: 942.0584 - val_loss: 20.6319 - val_mse: 907.2232\n",
      "Epoch 3065/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9697 - mse: 930.4610 - val_loss: 20.5674 - val_mse: 940.2324\n",
      "Epoch 3066/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8495 - mse: 918.7890 - val_loss: 20.6701 - val_mse: 970.3375\n",
      "Epoch 3067/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9472 - mse: 937.3881 - val_loss: 20.5697 - val_mse: 941.6856\n",
      "Epoch 3068/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0197 - mse: 939.6914 - val_loss: 20.5746 - val_mse: 944.4062\n",
      "Epoch 3069/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8623 - mse: 926.5089 - val_loss: 20.6513 - val_mse: 966.9600\n",
      "Epoch 3070/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8976 - mse: 927.8364 - val_loss: 20.7714 - val_mse: 986.4216\n",
      "Epoch 3071/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0126 - mse: 936.7849 - val_loss: 20.5599 - val_mse: 930.4027\n",
      "Epoch 3072/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9728 - mse: 934.0785 - val_loss: 20.5767 - val_mse: 945.4275\n",
      "Epoch 3073/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9838 - mse: 927.9877 - val_loss: 20.5792 - val_mse: 946.5612\n",
      "Epoch 3074/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8589 - mse: 933.9113 - val_loss: 20.5598 - val_mse: 931.0715\n",
      "Epoch 3075/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9260 - mse: 925.4497 - val_loss: 20.6083 - val_mse: 957.0380\n",
      "Epoch 3076/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9802 - mse: 938.4870 - val_loss: 20.5620 - val_mse: 935.8287\n",
      "Epoch 3077/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9489 - mse: 930.4793 - val_loss: 20.5728 - val_mse: 921.8622\n",
      "Epoch 3078/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0159 - mse: 937.1517 - val_loss: 20.5852 - val_mse: 917.5018\n",
      "Epoch 3079/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8964 - mse: 933.9015 - val_loss: 20.5952 - val_mse: 914.8125\n",
      "Epoch 3080/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9839 - mse: 929.5743 - val_loss: 20.6209 - val_mse: 960.5290\n",
      "Epoch 3081/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8878 - mse: 923.9468 - val_loss: 20.6164 - val_mse: 959.3684\n",
      "Epoch 3082/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9933 - mse: 937.8606 - val_loss: 20.5902 - val_mse: 951.3096\n",
      "Epoch 3083/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8975 - mse: 937.6387 - val_loss: 20.5847 - val_mse: 917.6252\n",
      "Epoch 3084/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9714 - mse: 929.5565 - val_loss: 20.5900 - val_mse: 916.1946\n",
      "Epoch 3085/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9830 - mse: 927.9369 - val_loss: 20.5628 - val_mse: 936.6050\n",
      "Epoch 3086/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9007 - mse: 937.4376 - val_loss: 20.6249 - val_mse: 961.4553\n",
      "Epoch 3087/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0309 - mse: 940.5652 - val_loss: 20.6132 - val_mse: 958.4376\n",
      "Epoch 3088/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9618 - mse: 933.8502 - val_loss: 20.5703 - val_mse: 942.0156\n",
      "Epoch 3089/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8577 - mse: 930.5488 - val_loss: 20.5609 - val_mse: 927.7516\n",
      "Epoch 3090/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9757 - mse: 926.5632 - val_loss: 20.5598 - val_mse: 931.2019\n",
      "Epoch 3091/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0059 - mse: 937.7513 - val_loss: 20.5786 - val_mse: 946.3112\n",
      "Epoch 3092/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9241 - mse: 934.5792 - val_loss: 20.5748 - val_mse: 921.0546\n",
      "Epoch 3093/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0174 - mse: 940.5014 - val_loss: 20.5725 - val_mse: 943.2277\n",
      "Epoch 3094/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9652 - mse: 939.4008 - val_loss: 20.6122 - val_mse: 910.9207\n",
      "Epoch 3095/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0140 - mse: 935.8865 - val_loss: 20.5606 - val_mse: 933.3937\n",
      "Epoch 3096/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9775 - mse: 935.2565 - val_loss: 20.5873 - val_mse: 950.1926\n",
      "Epoch 3097/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9587 - mse: 930.6392 - val_loss: 20.5650 - val_mse: 938.4456\n",
      "Epoch 3098/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9271 - mse: 929.3478 - val_loss: 20.5615 - val_mse: 935.2181\n",
      "Epoch 3099/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9360 - mse: 934.8854 - val_loss: 20.6706 - val_mse: 970.4173\n",
      "Epoch 3100/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9374 - mse: 939.8088 - val_loss: 20.6164 - val_mse: 910.0718\n",
      "Epoch 3101/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9530 - mse: 928.9528 - val_loss: 20.5602 - val_mse: 928.9777\n",
      "Epoch 3102/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9026 - mse: 929.9627 - val_loss: 20.5827 - val_mse: 948.1696\n",
      "Epoch 3103/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0120 - mse: 932.5904 - val_loss: 20.5615 - val_mse: 927.1341\n",
      "Epoch 3104/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9586 - mse: 939.2203 - val_loss: 20.5608 - val_mse: 933.8353\n",
      "Epoch 3105/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9879 - mse: 935.9635 - val_loss: 20.5623 - val_mse: 936.1336\n",
      "Epoch 3106/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9847 - mse: 936.8598 - val_loss: 20.6015 - val_mse: 955.0140\n",
      "Epoch 3107/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9122 - mse: 931.1814 - val_loss: 20.5737 - val_mse: 943.9091\n",
      "Epoch 3108/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9581 - mse: 933.5213 - val_loss: 20.5608 - val_mse: 927.8310\n",
      "Epoch 3109/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9222 - mse: 933.2794 - val_loss: 20.6184 - val_mse: 959.8954\n",
      "Epoch 3110/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9540 - mse: 941.9344 - val_loss: 20.5720 - val_mse: 922.1899\n",
      "Epoch 3111/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9173 - mse: 928.3449 - val_loss: 20.5603 - val_mse: 928.7661\n",
      "Epoch 3112/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8816 - mse: 926.2660 - val_loss: 20.5647 - val_mse: 938.2071\n",
      "Epoch 3113/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9859 - mse: 936.3699 - val_loss: 20.5683 - val_mse: 940.7894\n",
      "Epoch 3114/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9539 - mse: 926.2083 - val_loss: 20.6189 - val_mse: 960.0087\n",
      "Epoch 3115/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9438 - mse: 933.1426 - val_loss: 20.6410 - val_mse: 964.8766\n",
      "Epoch 3116/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8897 - mse: 934.5234 - val_loss: 20.5710 - val_mse: 922.6154\n",
      "Epoch 3117/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8706 - mse: 918.3226 - val_loss: 20.7244 - val_mse: 979.0973\n",
      "Epoch 3118/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0360 - mse: 943.2866 - val_loss: 20.5801 - val_mse: 946.9683\n",
      "Epoch 3119/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9583 - mse: 941.1212 - val_loss: 20.5672 - val_mse: 940.0371\n",
      "Epoch 3120/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9859 - mse: 937.2802 - val_loss: 20.5616 - val_mse: 927.1236\n",
      "Epoch 3121/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0015 - mse: 939.3178 - val_loss: 20.5716 - val_mse: 942.7363\n",
      "Epoch 3122/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9681 - mse: 934.1458 - val_loss: 20.5650 - val_mse: 925.2619\n",
      "Epoch 3123/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9538 - mse: 929.7285 - val_loss: 20.5930 - val_mse: 952.2638\n",
      "Epoch 3124/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9573 - mse: 942.6331 - val_loss: 20.5708 - val_mse: 942.2838\n",
      "Epoch 3125/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 21.0117 - mse: 942.1025 - val_loss: 20.5988 - val_mse: 913.8779\n",
      "Epoch 3126/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9584 - mse: 942.9937 - val_loss: 20.5696 - val_mse: 941.6404\n",
      "Epoch 3127/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0002 - mse: 938.3742 - val_loss: 20.5640 - val_mse: 937.6498\n",
      "Epoch 3128/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9644 - mse: 933.7310 - val_loss: 20.5953 - val_mse: 953.0502\n",
      "Epoch 3129/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9476 - mse: 929.0150 - val_loss: 20.6356 - val_mse: 963.7596\n",
      "Epoch 3130/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9621 - mse: 921.5002 - val_loss: 20.5764 - val_mse: 945.2962\n",
      "Epoch 3131/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9951 - mse: 941.6628 - val_loss: 20.5616 - val_mse: 927.1260\n",
      "Epoch 3132/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9467 - mse: 933.4994 - val_loss: 20.5644 - val_mse: 925.4973\n",
      "Epoch 3133/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0432 - mse: 940.8412 - val_loss: 20.5599 - val_mse: 929.9360\n",
      "Epoch 3134/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8648 - mse: 920.4833 - val_loss: 20.6089 - val_mse: 957.1923\n",
      "Epoch 3135/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9642 - mse: 935.0912 - val_loss: 20.5664 - val_mse: 939.5275\n",
      "Epoch 3136/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0565 - mse: 948.2961 - val_loss: 20.5787 - val_mse: 919.6531\n",
      "Epoch 3137/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9664 - mse: 926.2135 - val_loss: 20.5598 - val_mse: 931.3617\n",
      "Epoch 3138/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8590 - mse: 920.8902 - val_loss: 20.5600 - val_mse: 929.5163\n",
      "Epoch 3139/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8957 - mse: 925.9712 - val_loss: 20.6676 - val_mse: 969.8940\n",
      "Epoch 3140/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0167 - mse: 936.2851 - val_loss: 20.6007 - val_mse: 954.7704\n",
      "Epoch 3141/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0292 - mse: 942.2701 - val_loss: 20.5644 - val_mse: 937.9884\n",
      "Epoch 3142/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8732 - mse: 932.7361 - val_loss: 20.5599 - val_mse: 930.3241\n",
      "Epoch 3143/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9143 - mse: 931.2611 - val_loss: 20.6443 - val_mse: 965.5537\n",
      "Epoch 3144/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9660 - mse: 933.3020 - val_loss: 20.5685 - val_mse: 923.6805\n",
      "Epoch 3145/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9723 - mse: 935.0616 - val_loss: 20.5682 - val_mse: 923.8194\n",
      "Epoch 3146/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9913 - mse: 930.3541 - val_loss: 20.7215 - val_mse: 978.6483\n",
      "Epoch 3147/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9505 - mse: 938.4233 - val_loss: 20.5684 - val_mse: 923.7287\n",
      "Epoch 3148/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9975 - mse: 937.3157 - val_loss: 20.6574 - val_mse: 968.1137\n",
      "Epoch 3149/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9556 - mse: 932.3183 - val_loss: 20.6166 - val_mse: 959.4146\n",
      "Epoch 3150/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0092 - mse: 945.6058 - val_loss: 20.5600 - val_mse: 929.3333\n",
      "Epoch 3151/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9523 - mse: 931.2339 - val_loss: 20.5777 - val_mse: 945.9296\n",
      "Epoch 3152/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9944 - mse: 938.4220 - val_loss: 20.5614 - val_mse: 927.2255\n",
      "Epoch 3153/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8748 - mse: 928.1675 - val_loss: 20.5602 - val_mse: 929.0063\n",
      "Epoch 3154/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9936 - mse: 932.4522 - val_loss: 20.5598 - val_mse: 931.7448\n",
      "Epoch 3155/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9221 - mse: 936.2037 - val_loss: 20.5610 - val_mse: 934.3557\n",
      "Epoch 3156/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9406 - mse: 920.4384 - val_loss: 20.6772 - val_mse: 971.5562\n",
      "Epoch 3157/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9788 - mse: 935.7953 - val_loss: 20.5982 - val_mse: 953.9760\n",
      "Epoch 3158/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9120 - mse: 922.6649 - val_loss: 20.6942 - val_mse: 974.3901\n",
      "Epoch 3159/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8991 - mse: 921.0250 - val_loss: 20.5798 - val_mse: 946.8323\n",
      "Epoch 3160/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 21.0271 - mse: 944.9789 - val_loss: 20.5599 - val_mse: 929.7366\n",
      "Epoch 3161/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 21.0353 - mse: 941.9954 - val_loss: 20.5958 - val_mse: 953.2053\n",
      "Epoch 3162/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9794 - mse: 941.0922 - val_loss: 20.5607 - val_mse: 933.5357\n",
      "Epoch 3163/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0000 - mse: 933.3210 - val_loss: 20.5693 - val_mse: 941.4451\n",
      "Epoch 3164/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0133 - mse: 945.1171 - val_loss: 20.5750 - val_mse: 920.9769\n",
      "Epoch 3165/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8914 - mse: 932.3445 - val_loss: 20.5941 - val_mse: 952.6596\n",
      "Epoch 3166/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9026 - mse: 936.9781 - val_loss: 20.5711 - val_mse: 922.5531\n",
      "Epoch 3167/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8576 - mse: 924.3485 - val_loss: 20.6211 - val_mse: 960.5731\n",
      "Epoch 3168/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9652 - mse: 935.3539 - val_loss: 20.5961 - val_mse: 953.3062\n",
      "Epoch 3169/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9170 - mse: 934.5704 - val_loss: 20.6366 - val_mse: 906.4437\n",
      "Epoch 3170/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9699 - mse: 924.6888 - val_loss: 20.5623 - val_mse: 926.6588\n",
      "Epoch 3171/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9920 - mse: 934.7575 - val_loss: 20.5682 - val_mse: 923.8220\n",
      "Epoch 3172/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9967 - mse: 937.3621 - val_loss: 20.5751 - val_mse: 944.6467\n",
      "Epoch 3173/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9247 - mse: 933.2124 - val_loss: 20.6616 - val_mse: 902.7020\n",
      "Epoch 3174/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9936 - mse: 937.8237 - val_loss: 20.5911 - val_mse: 915.9155\n",
      "Epoch 3175/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9166 - mse: 934.6077 - val_loss: 20.5899 - val_mse: 951.2153\n",
      "Epoch 3176/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9202 - mse: 932.6208 - val_loss: 20.5604 - val_mse: 933.0344\n",
      "Epoch 3177/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9531 - mse: 938.6495 - val_loss: 20.5781 - val_mse: 946.0723\n",
      "Epoch 3178/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9015 - mse: 927.8394 - val_loss: 20.5961 - val_mse: 953.3129\n",
      "Epoch 3179/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9750 - mse: 930.5389 - val_loss: 20.5603 - val_mse: 932.6854\n",
      "Epoch 3180/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9044 - mse: 928.3317 - val_loss: 20.5637 - val_mse: 937.4299\n",
      "Epoch 3181/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9426 - mse: 924.4449 - val_loss: 20.5609 - val_mse: 934.0983\n",
      "Epoch 3182/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9620 - mse: 942.3961 - val_loss: 20.6076 - val_mse: 911.9179\n",
      "Epoch 3183/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8958 - mse: 926.8867 - val_loss: 20.5605 - val_mse: 928.3976\n",
      "Epoch 3184/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9804 - mse: 928.8718 - val_loss: 20.7406 - val_mse: 981.6104\n",
      "Epoch 3185/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9810 - mse: 935.3076 - val_loss: 20.6248 - val_mse: 961.4323\n",
      "Epoch 3186/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9206 - mse: 930.0136 - val_loss: 20.5624 - val_mse: 936.2409\n",
      "Epoch 3187/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9250 - mse: 933.2214 - val_loss: 20.5685 - val_mse: 940.9618\n",
      "Epoch 3188/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9462 - mse: 932.1417 - val_loss: 20.5612 - val_mse: 934.6444\n",
      "Epoch 3189/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9757 - mse: 931.0835 - val_loss: 20.5853 - val_mse: 949.3250\n",
      "Epoch 3190/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9339 - mse: 927.1531 - val_loss: 20.7117 - val_mse: 977.1284\n",
      "Epoch 3191/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9047 - mse: 933.7204 - val_loss: 20.5705 - val_mse: 922.8121\n",
      "Epoch 3192/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9388 - mse: 930.3239 - val_loss: 20.5600 - val_mse: 929.5242\n",
      "Epoch 3193/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9061 - mse: 927.6177 - val_loss: 20.6118 - val_mse: 958.0367\n",
      "Epoch 3194/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9041 - mse: 929.8132 - val_loss: 20.5917 - val_mse: 951.8352\n",
      "Epoch 3195/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9041 - mse: 944.4666 - val_loss: 20.6235 - val_mse: 961.1404\n",
      "Epoch 3196/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9114 - mse: 924.1125 - val_loss: 20.7663 - val_mse: 985.6176\n",
      "Epoch 3197/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9045 - mse: 935.9009 - val_loss: 20.5823 - val_mse: 918.3865\n",
      "Epoch 3198/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9014 - mse: 921.7605 - val_loss: 20.5600 - val_mse: 932.1465\n",
      "Epoch 3199/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8734 - mse: 934.9553 - val_loss: 20.5707 - val_mse: 942.2162\n",
      "Epoch 3200/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9842 - mse: 944.1517 - val_loss: 20.5773 - val_mse: 945.7261\n",
      "Epoch 3201/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8602 - mse: 931.2375 - val_loss: 20.6894 - val_mse: 973.6044\n",
      "Epoch 3202/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9302 - mse: 938.9990 - val_loss: 20.5610 - val_mse: 934.2257\n",
      "Epoch 3203/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9127 - mse: 933.1129 - val_loss: 20.5718 - val_mse: 942.8246\n",
      "Epoch 3204/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9916 - mse: 935.5781 - val_loss: 20.7076 - val_mse: 976.4994\n",
      "Epoch 3205/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0100 - mse: 945.4232 - val_loss: 20.5611 - val_mse: 934.4111\n",
      "Epoch 3206/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9654 - mse: 929.7360 - val_loss: 20.5748 - val_mse: 944.4954\n",
      "Epoch 3207/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9422 - mse: 935.8500 - val_loss: 20.5607 - val_mse: 928.0450\n",
      "Epoch 3208/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9604 - mse: 937.2698 - val_loss: 20.6665 - val_mse: 969.7089\n",
      "Epoch 3209/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9399 - mse: 937.2285 - val_loss: 20.5598 - val_mse: 931.6094\n",
      "Epoch 3210/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9541 - mse: 935.6979 - val_loss: 20.6068 - val_mse: 912.0875\n",
      "Epoch 3211/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9081 - mse: 930.5112 - val_loss: 20.5809 - val_mse: 918.8528\n",
      "Epoch 3212/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0191 - mse: 932.5508 - val_loss: 20.6062 - val_mse: 956.4038\n",
      "Epoch 3213/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9194 - mse: 936.3246 - val_loss: 20.5881 - val_mse: 950.5313\n",
      "Epoch 3214/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9610 - mse: 934.4524 - val_loss: 20.5979 - val_mse: 953.8868\n",
      "Epoch 3215/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8604 - mse: 925.9296 - val_loss: 20.6217 - val_mse: 960.7128\n",
      "Epoch 3216/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0073 - mse: 950.6661 - val_loss: 20.5776 - val_mse: 945.8511\n",
      "Epoch 3217/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8977 - mse: 927.8754 - val_loss: 20.5691 - val_mse: 923.4546\n",
      "Epoch 3218/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9377 - mse: 929.1277 - val_loss: 20.6349 - val_mse: 906.7128\n",
      "Epoch 3219/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9704 - mse: 929.5540 - val_loss: 20.5598 - val_mse: 930.7827\n",
      "Epoch 3220/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9520 - mse: 935.3246 - val_loss: 20.5610 - val_mse: 927.6907\n",
      "Epoch 3221/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0028 - mse: 938.0989 - val_loss: 20.5599 - val_mse: 929.7565\n",
      "Epoch 3222/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9317 - mse: 931.7979 - val_loss: 20.5598 - val_mse: 930.6758\n",
      "Epoch 3223/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9541 - mse: 940.0749 - val_loss: 20.5665 - val_mse: 939.5800\n",
      "Epoch 3224/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9419 - mse: 932.3395 - val_loss: 20.5952 - val_mse: 914.8134\n",
      "Epoch 3225/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9958 - mse: 932.3958 - val_loss: 20.5609 - val_mse: 934.1467\n",
      "Epoch 3226/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9515 - mse: 920.7449 - val_loss: 20.7911 - val_mse: 989.4617\n",
      "Epoch 3227/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9751 - mse: 938.9314 - val_loss: 20.5609 - val_mse: 927.8080\n",
      "Epoch 3228/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8942 - mse: 928.8362 - val_loss: 20.5637 - val_mse: 937.3744\n",
      "Epoch 3229/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9447 - mse: 933.8549 - val_loss: 20.5807 - val_mse: 947.2464\n",
      "Epoch 3230/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 21.0555 - mse: 937.4528 - val_loss: 20.7687 - val_mse: 985.9977\n",
      "Epoch 3231/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9175 - mse: 921.3938 - val_loss: 20.6326 - val_mse: 963.1284\n",
      "Epoch 3232/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9918 - mse: 939.1472 - val_loss: 20.5896 - val_mse: 951.0952\n",
      "Epoch 3233/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9061 - mse: 928.7925 - val_loss: 20.5716 - val_mse: 942.7578\n",
      "Epoch 3234/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9162 - mse: 935.1048 - val_loss: 20.6237 - val_mse: 908.6918\n",
      "Epoch 3235/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9216 - mse: 926.7041 - val_loss: 20.6095 - val_mse: 957.3625\n",
      "Epoch 3236/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8714 - mse: 927.6068 - val_loss: 20.5741 - val_mse: 921.3295\n",
      "Epoch 3237/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9215 - mse: 930.4268 - val_loss: 20.5979 - val_mse: 914.1085\n",
      "Epoch 3238/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0478 - mse: 936.7839 - val_loss: 20.5850 - val_mse: 949.1915\n",
      "Epoch 3239/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9950 - mse: 932.3952 - val_loss: 20.5893 - val_mse: 950.9830\n",
      "Epoch 3240/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9252 - mse: 936.3771 - val_loss: 20.5775 - val_mse: 945.7984\n",
      "Epoch 3241/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9435 - mse: 944.4158 - val_loss: 20.5612 - val_mse: 927.4187\n",
      "Epoch 3242/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9227 - mse: 937.1312 - val_loss: 20.6089 - val_mse: 957.2173\n",
      "Epoch 3243/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9996 - mse: 929.7001 - val_loss: 20.6994 - val_mse: 975.1990\n",
      "Epoch 3244/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8032 - mse: 926.8307 - val_loss: 20.5739 - val_mse: 944.0443\n",
      "Epoch 3245/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9556 - mse: 935.3900 - val_loss: 20.5823 - val_mse: 947.9627\n",
      "Epoch 3246/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9018 - mse: 928.6724 - val_loss: 20.5609 - val_mse: 927.8071\n",
      "Epoch 3247/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8786 - mse: 931.7664 - val_loss: 20.5651 - val_mse: 938.5220\n",
      "Epoch 3248/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9500 - mse: 928.7661 - val_loss: 20.7004 - val_mse: 975.3573\n",
      "Epoch 3249/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0213 - mse: 936.4647 - val_loss: 20.5804 - val_mse: 947.1061\n",
      "Epoch 3250/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9049 - mse: 930.3818 - val_loss: 20.5986 - val_mse: 954.1329\n",
      "Epoch 3251/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0194 - mse: 939.4754 - val_loss: 20.5678 - val_mse: 940.4865\n",
      "Epoch 3252/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9026 - mse: 926.3570 - val_loss: 20.5619 - val_mse: 926.8506\n",
      "Epoch 3253/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9507 - mse: 934.0378 - val_loss: 20.6223 - val_mse: 908.9468\n",
      "Epoch 3254/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 21.0587 - mse: 938.2230 - val_loss: 20.5651 - val_mse: 938.4879\n",
      "Epoch 3255/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9618 - mse: 934.1588 - val_loss: 20.5668 - val_mse: 924.4410\n",
      "Epoch 3256/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9462 - mse: 937.9934 - val_loss: 20.5750 - val_mse: 944.6164\n",
      "Epoch 3257/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.8910 - mse: 920.4660 - val_loss: 20.5780 - val_mse: 946.0333\n",
      "Epoch 3258/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9176 - mse: 938.5395 - val_loss: 20.5883 - val_mse: 950.6094\n",
      "Epoch 3259/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8991 - mse: 929.4756 - val_loss: 20.6820 - val_mse: 972.3515\n",
      "Epoch 3260/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9674 - mse: 939.4634 - val_loss: 20.6109 - val_mse: 957.7903\n",
      "Epoch 3261/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9830 - mse: 938.6923 - val_loss: 20.5782 - val_mse: 946.1436\n",
      "Epoch 3262/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9412 - mse: 940.5044 - val_loss: 20.5816 - val_mse: 947.6732\n",
      "Epoch 3263/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9640 - mse: 934.4875 - val_loss: 20.5599 - val_mse: 930.0688\n",
      "Epoch 3264/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9212 - mse: 925.5445 - val_loss: 20.5795 - val_mse: 946.7386\n",
      "Epoch 3265/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9615 - mse: 935.3895 - val_loss: 20.6401 - val_mse: 964.6910\n",
      "Epoch 3266/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8844 - mse: 938.1740 - val_loss: 20.5769 - val_mse: 920.3101\n",
      "Epoch 3267/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9501 - mse: 924.1974 - val_loss: 20.6819 - val_mse: 972.3377\n",
      "Epoch 3268/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9277 - mse: 929.6794 - val_loss: 20.5781 - val_mse: 919.8746\n",
      "Epoch 3269/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9465 - mse: 931.2802 - val_loss: 20.5812 - val_mse: 918.7577\n",
      "Epoch 3270/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0551 - mse: 935.4088 - val_loss: 20.5684 - val_mse: 940.8713\n",
      "Epoch 3271/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9878 - mse: 936.8468 - val_loss: 20.6272 - val_mse: 961.9825\n",
      "Epoch 3272/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9474 - mse: 933.4767 - val_loss: 20.6260 - val_mse: 961.6986\n",
      "Epoch 3273/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9354 - mse: 932.5685 - val_loss: 20.5746 - val_mse: 944.3748\n",
      "Epoch 3274/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9709 - mse: 938.0017 - val_loss: 20.5805 - val_mse: 947.1608\n",
      "Epoch 3275/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8671 - mse: 936.3416 - val_loss: 20.6130 - val_mse: 958.3763\n",
      "Epoch 3276/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9301 - mse: 937.1609 - val_loss: 20.5784 - val_mse: 946.2117\n",
      "Epoch 3277/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9191 - mse: 923.1554 - val_loss: 20.5857 - val_mse: 949.5434\n",
      "Epoch 3278/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9075 - mse: 938.4203 - val_loss: 20.5713 - val_mse: 942.5576\n",
      "Epoch 3279/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9718 - mse: 931.5295 - val_loss: 20.5878 - val_mse: 950.3846\n",
      "Epoch 3280/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8548 - mse: 923.7446 - val_loss: 20.6462 - val_mse: 965.9435\n",
      "Epoch 3281/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9291 - mse: 926.2563 - val_loss: 20.5992 - val_mse: 954.3049\n",
      "Epoch 3282/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9243 - mse: 942.8058 - val_loss: 20.5915 - val_mse: 915.7992\n",
      "Epoch 3283/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9401 - mse: 936.6791 - val_loss: 20.5835 - val_mse: 918.0206\n",
      "Epoch 3284/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9880 - mse: 931.5488 - val_loss: 20.5756 - val_mse: 944.8866\n",
      "Epoch 3285/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9227 - mse: 926.4868 - val_loss: 20.5758 - val_mse: 944.9911\n",
      "Epoch 3286/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9486 - mse: 927.5760 - val_loss: 20.5996 - val_mse: 954.4323\n",
      "Epoch 3287/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0607 - mse: 950.6294 - val_loss: 20.5600 - val_mse: 932.0258\n",
      "Epoch 3288/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9372 - mse: 930.8308 - val_loss: 20.6220 - val_mse: 960.7769\n",
      "Epoch 3289/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9107 - mse: 928.4203 - val_loss: 20.5620 - val_mse: 935.8195\n",
      "Epoch 3290/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9780 - mse: 937.6316 - val_loss: 20.5655 - val_mse: 925.0383\n",
      "Epoch 3291/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8932 - mse: 933.9406 - val_loss: 20.5672 - val_mse: 940.0663\n",
      "Epoch 3292/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9557 - mse: 936.8139 - val_loss: 20.6298 - val_mse: 962.5574\n",
      "Epoch 3293/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9118 - mse: 927.6000 - val_loss: 20.5604 - val_mse: 928.4866\n",
      "Epoch 3294/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9655 - mse: 937.1499 - val_loss: 20.5833 - val_mse: 918.0605\n",
      "Epoch 3295/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9866 - mse: 927.9052 - val_loss: 20.5598 - val_mse: 930.6771\n",
      "Epoch 3296/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9108 - mse: 929.8935 - val_loss: 20.5701 - val_mse: 941.9132\n",
      "Epoch 3297/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9555 - mse: 925.6248 - val_loss: 20.5867 - val_mse: 949.9556\n",
      "Epoch 3298/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9692 - mse: 944.8193 - val_loss: 20.6978 - val_mse: 974.9500\n",
      "Epoch 3299/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9518 - mse: 936.9448 - val_loss: 20.5686 - val_mse: 941.0071\n",
      "Epoch 3300/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9209 - mse: 931.7253 - val_loss: 20.5661 - val_mse: 939.2391\n",
      "Epoch 3301/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9982 - mse: 934.4313 - val_loss: 20.6034 - val_mse: 955.5696\n",
      "Epoch 3302/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0089 - mse: 938.1697 - val_loss: 20.6467 - val_mse: 966.0494\n",
      "Epoch 3303/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9213 - mse: 933.1517 - val_loss: 20.6122 - val_mse: 958.1500\n",
      "Epoch 3304/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9383 - mse: 933.6963 - val_loss: 20.5992 - val_mse: 954.2967\n",
      "Epoch 3305/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0024 - mse: 936.7440 - val_loss: 20.5705 - val_mse: 922.8027\n",
      "Epoch 3306/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9419 - mse: 931.9587 - val_loss: 20.5695 - val_mse: 941.5575\n",
      "Epoch 3307/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9436 - mse: 922.0259 - val_loss: 20.5660 - val_mse: 939.1790\n",
      "Epoch 3308/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9209 - mse: 937.4516 - val_loss: 20.5604 - val_mse: 928.5364\n",
      "Epoch 3309/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9984 - mse: 941.9451 - val_loss: 20.6051 - val_mse: 956.0802\n",
      "Epoch 3310/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9630 - mse: 936.8185 - val_loss: 20.6088 - val_mse: 911.6627\n",
      "Epoch 3311/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0287 - mse: 933.9159 - val_loss: 20.5629 - val_mse: 936.7167\n",
      "Epoch 3312/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9752 - mse: 929.1749 - val_loss: 20.6425 - val_mse: 965.1884\n",
      "Epoch 3313/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9794 - mse: 937.5119 - val_loss: 20.5932 - val_mse: 952.3470\n",
      "Epoch 3314/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9794 - mse: 931.1302 - val_loss: 20.5923 - val_mse: 952.0484\n",
      "Epoch 3315/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0323 - mse: 942.6078 - val_loss: 20.6755 - val_mse: 971.2588\n",
      "Epoch 3316/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9761 - mse: 927.9783 - val_loss: 20.6137 - val_mse: 958.5858\n",
      "Epoch 3317/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9316 - mse: 937.7682 - val_loss: 20.6212 - val_mse: 909.1536\n",
      "Epoch 3318/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.7820 - mse: 917.4354 - val_loss: 20.6668 - val_mse: 969.7609\n",
      "Epoch 3319/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0563 - mse: 940.5234 - val_loss: 20.6204 - val_mse: 960.3904\n",
      "Epoch 3320/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9995 - mse: 944.5177 - val_loss: 20.6090 - val_mse: 957.2236\n",
      "Epoch 3321/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9236 - mse: 929.3511 - val_loss: 20.5729 - val_mse: 943.4557\n",
      "Epoch 3322/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0585 - mse: 945.2776 - val_loss: 20.5862 - val_mse: 949.7422\n",
      "Epoch 3323/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9492 - mse: 934.5693 - val_loss: 20.6115 - val_mse: 957.9577\n",
      "Epoch 3324/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9066 - mse: 926.6049 - val_loss: 20.5737 - val_mse: 921.5200\n",
      "Epoch 3325/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9136 - mse: 918.0165 - val_loss: 20.6499 - val_mse: 966.6821\n",
      "Epoch 3326/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.8700 - mse: 937.4050 - val_loss: 20.5922 - val_mse: 915.6256\n",
      "Epoch 3327/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0098 - mse: 940.6664 - val_loss: 20.5729 - val_mse: 921.8343\n",
      "Epoch 3328/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0525 - mse: 941.4105 - val_loss: 20.5603 - val_mse: 928.7596\n",
      "Epoch 3329/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9852 - mse: 936.1348 - val_loss: 20.6661 - val_mse: 902.1156\n",
      "Epoch 3330/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.1011 - mse: 942.9990 - val_loss: 20.5605 - val_mse: 933.2398\n",
      "Epoch 3331/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9293 - mse: 928.7137 - val_loss: 20.5691 - val_mse: 923.4434\n",
      "Epoch 3332/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9849 - mse: 938.1494 - val_loss: 20.6436 - val_mse: 905.3091\n",
      "Epoch 3333/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9492 - mse: 929.2394 - val_loss: 20.6510 - val_mse: 966.8987\n",
      "Epoch 3334/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0498 - mse: 941.6396 - val_loss: 20.5760 - val_mse: 945.1235\n",
      "Epoch 3335/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8836 - mse: 926.8902 - val_loss: 20.5738 - val_mse: 943.9760\n",
      "Epoch 3336/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9811 - mse: 933.4171 - val_loss: 20.5942 - val_mse: 952.7000\n",
      "Epoch 3337/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9491 - mse: 926.5319 - val_loss: 20.5609 - val_mse: 927.7041\n",
      "Epoch 3338/5000\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 20.9503 - mse: 929.7982 - val_loss: 20.5782 - val_mse: 946.1254\n",
      "Epoch 3339/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8181 - mse: 923.6703 - val_loss: 20.5636 - val_mse: 937.3400\n",
      "Epoch 3340/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9321 - mse: 937.4169 - val_loss: 20.5672 - val_mse: 940.0751\n",
      "Epoch 3341/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9018 - mse: 940.0768 - val_loss: 20.5807 - val_mse: 918.9191\n",
      "Epoch 3342/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9343 - mse: 930.2126 - val_loss: 20.5600 - val_mse: 931.9922\n",
      "Epoch 3343/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9413 - mse: 927.7596 - val_loss: 20.5599 - val_mse: 930.1932\n",
      "Epoch 3344/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9805 - mse: 936.7844 - val_loss: 20.5868 - val_mse: 950.0171\n",
      "Epoch 3345/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9407 - mse: 930.3017 - val_loss: 20.5719 - val_mse: 942.9115\n",
      "Epoch 3346/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9470 - mse: 932.8026 - val_loss: 20.5603 - val_mse: 928.7139\n",
      "Epoch 3347/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9475 - mse: 933.3945 - val_loss: 20.5779 - val_mse: 945.9771\n",
      "Epoch 3348/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9983 - mse: 930.6901 - val_loss: 20.5610 - val_mse: 927.6965\n",
      "Epoch 3349/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8962 - mse: 940.5958 - val_loss: 20.5912 - val_mse: 915.8884\n",
      "Epoch 3350/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9227 - mse: 921.0753 - val_loss: 20.7077 - val_mse: 976.5066\n",
      "Epoch 3351/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8992 - mse: 927.1210 - val_loss: 20.5818 - val_mse: 947.7344\n",
      "Epoch 3352/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9673 - mse: 937.8487 - val_loss: 20.5967 - val_mse: 914.4167\n",
      "Epoch 3353/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8854 - mse: 936.0933 - val_loss: 20.5599 - val_mse: 930.3836\n",
      "Epoch 3354/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8854 - mse: 929.5461 - val_loss: 20.5813 - val_mse: 947.5298\n",
      "Epoch 3355/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9800 - mse: 936.8088 - val_loss: 20.6316 - val_mse: 907.2709\n",
      "Epoch 3356/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9121 - mse: 925.7112 - val_loss: 20.5912 - val_mse: 915.8832\n",
      "Epoch 3357/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9537 - mse: 932.4517 - val_loss: 20.5639 - val_mse: 937.5608\n",
      "Epoch 3358/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9390 - mse: 926.5842 - val_loss: 20.5735 - val_mse: 943.8240\n",
      "Epoch 3359/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9581 - mse: 928.5624 - val_loss: 20.6679 - val_mse: 969.9495\n",
      "Epoch 3360/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9293 - mse: 926.4384 - val_loss: 20.5646 - val_mse: 938.1003\n",
      "Epoch 3361/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9384 - mse: 925.2037 - val_loss: 20.5739 - val_mse: 944.0245\n",
      "Epoch 3362/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0075 - mse: 941.0564 - val_loss: 20.7061 - val_mse: 976.2536\n",
      "Epoch 3363/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8874 - mse: 927.2836 - val_loss: 20.5692 - val_mse: 941.3846\n",
      "Epoch 3364/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9725 - mse: 936.4288 - val_loss: 20.5921 - val_mse: 951.9621\n",
      "Epoch 3365/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9503 - mse: 936.6255 - val_loss: 20.5887 - val_mse: 950.7432\n",
      "Epoch 3366/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8904 - mse: 934.4579 - val_loss: 20.5718 - val_mse: 942.8627\n",
      "Epoch 3367/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9443 - mse: 940.7437 - val_loss: 20.5921 - val_mse: 915.6290\n",
      "Epoch 3368/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0422 - mse: 930.5038 - val_loss: 20.5645 - val_mse: 938.0439\n",
      "Epoch 3369/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9502 - mse: 932.5741 - val_loss: 20.6985 - val_mse: 975.0713\n",
      "Epoch 3370/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9178 - mse: 941.6761 - val_loss: 20.6133 - val_mse: 910.6896\n",
      "Epoch 3371/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9192 - mse: 935.6233 - val_loss: 20.5872 - val_mse: 916.9491\n",
      "Epoch 3372/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9217 - mse: 924.8210 - val_loss: 20.5765 - val_mse: 945.3569\n",
      "Epoch 3373/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9995 - mse: 935.2391 - val_loss: 20.5923 - val_mse: 915.5871\n",
      "Epoch 3374/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0498 - mse: 932.8179 - val_loss: 20.5614 - val_mse: 935.0336\n",
      "Epoch 3375/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9835 - mse: 931.8027 - val_loss: 20.5635 - val_mse: 937.2734\n",
      "Epoch 3376/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9069 - mse: 927.4758 - val_loss: 20.5811 - val_mse: 918.8022\n",
      "Epoch 3377/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8678 - mse: 934.1147 - val_loss: 20.5861 - val_mse: 917.2479\n",
      "Epoch 3378/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8996 - mse: 927.3475 - val_loss: 20.5637 - val_mse: 937.4398\n",
      "Epoch 3379/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9937 - mse: 928.1353 - val_loss: 20.6060 - val_mse: 956.3490\n",
      "Epoch 3380/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9338 - mse: 939.1133 - val_loss: 20.5774 - val_mse: 945.7842\n",
      "Epoch 3381/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9459 - mse: 938.0246 - val_loss: 20.5763 - val_mse: 920.5201\n",
      "Epoch 3382/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9225 - mse: 920.2490 - val_loss: 20.5788 - val_mse: 919.6174\n",
      "Epoch 3383/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8436 - mse: 931.4139 - val_loss: 20.5702 - val_mse: 941.9427\n",
      "Epoch 3384/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8814 - mse: 930.0430 - val_loss: 20.5870 - val_mse: 950.0776\n",
      "Epoch 3385/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0603 - mse: 940.7137 - val_loss: 20.5979 - val_mse: 914.1077\n",
      "Epoch 3386/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9075 - mse: 922.3191 - val_loss: 20.5652 - val_mse: 938.6023\n",
      "Epoch 3387/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0123 - mse: 940.2148 - val_loss: 20.5615 - val_mse: 935.2648\n",
      "Epoch 3388/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9242 - mse: 926.8787 - val_loss: 20.5754 - val_mse: 944.7937\n",
      "Epoch 3389/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9028 - mse: 922.6141 - val_loss: 20.6356 - val_mse: 963.7626\n",
      "Epoch 3390/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9721 - mse: 938.1471 - val_loss: 20.5947 - val_mse: 952.8688\n",
      "Epoch 3391/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9535 - mse: 938.4656 - val_loss: 20.5842 - val_mse: 917.7786\n",
      "Epoch 3392/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0550 - mse: 928.7917 - val_loss: 20.6014 - val_mse: 954.9921\n",
      "Epoch 3393/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9522 - mse: 935.9781 - val_loss: 20.5693 - val_mse: 923.3340\n",
      "Epoch 3394/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9401 - mse: 931.8334 - val_loss: 20.5805 - val_mse: 947.1710\n",
      "Epoch 3395/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8987 - mse: 934.3284 - val_loss: 20.5689 - val_mse: 923.5056\n",
      "Epoch 3396/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9670 - mse: 932.7404 - val_loss: 20.5598 - val_mse: 930.6409\n",
      "Epoch 3397/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9667 - mse: 934.2521 - val_loss: 20.5601 - val_mse: 932.3777\n",
      "Epoch 3398/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9610 - mse: 924.8733 - val_loss: 20.7210 - val_mse: 978.5752\n",
      "Epoch 3399/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9538 - mse: 944.1475 - val_loss: 20.6941 - val_mse: 974.3702\n",
      "Epoch 3400/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9158 - mse: 940.0661 - val_loss: 20.5599 - val_mse: 930.5556\n",
      "Epoch 3401/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9238 - mse: 932.7762 - val_loss: 20.5699 - val_mse: 923.0831\n",
      "Epoch 3402/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8940 - mse: 926.8327 - val_loss: 20.5817 - val_mse: 918.5779\n",
      "Epoch 3403/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9899 - mse: 930.8405 - val_loss: 20.7434 - val_mse: 982.0479\n",
      "Epoch 3404/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9538 - mse: 933.9238 - val_loss: 20.5640 - val_mse: 925.6898\n",
      "Epoch 3405/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9162 - mse: 934.8749 - val_loss: 20.5641 - val_mse: 937.7538\n",
      "Epoch 3406/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8989 - mse: 918.8701 - val_loss: 20.7061 - val_mse: 976.2598\n",
      "Epoch 3407/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9787 - mse: 937.1400 - val_loss: 20.5910 - val_mse: 951.6072\n",
      "Epoch 3408/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9752 - mse: 931.3178 - val_loss: 20.7767 - val_mse: 987.2504\n",
      "Epoch 3409/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9596 - mse: 946.9258 - val_loss: 20.6128 - val_mse: 910.7947\n",
      "Epoch 3410/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8799 - mse: 922.9225 - val_loss: 20.5610 - val_mse: 927.6768\n",
      "Epoch 3411/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.7825 - mse: 924.1302 - val_loss: 20.6982 - val_mse: 975.0208\n",
      "Epoch 3412/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9433 - mse: 939.4091 - val_loss: 20.6501 - val_mse: 966.7272\n",
      "Epoch 3413/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9338 - mse: 934.1290 - val_loss: 20.5844 - val_mse: 948.9379\n",
      "Epoch 3414/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9791 - mse: 945.2247 - val_loss: 20.5615 - val_mse: 935.2922\n",
      "Epoch 3415/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9786 - mse: 933.1985 - val_loss: 20.5606 - val_mse: 928.1237\n",
      "Epoch 3416/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8258 - mse: 932.2673 - val_loss: 20.5675 - val_mse: 924.1545\n",
      "Epoch 3417/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8998 - mse: 929.7392 - val_loss: 20.6200 - val_mse: 909.3773\n",
      "Epoch 3418/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9232 - mse: 929.6695 - val_loss: 20.5606 - val_mse: 933.2881\n",
      "Epoch 3419/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8518 - mse: 937.6750 - val_loss: 20.6809 - val_mse: 900.3455\n",
      "Epoch 3420/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0469 - mse: 931.5374 - val_loss: 20.5681 - val_mse: 923.8662\n",
      "Epoch 3421/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9836 - mse: 932.3382 - val_loss: 20.5777 - val_mse: 945.9129\n",
      "Epoch 3422/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9311 - mse: 930.2966 - val_loss: 20.5729 - val_mse: 943.4860\n",
      "Epoch 3423/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8918 - mse: 932.8781 - val_loss: 20.5605 - val_mse: 933.2038\n",
      "Epoch 3424/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9611 - mse: 932.1113 - val_loss: 20.5740 - val_mse: 944.0935\n",
      "Epoch 3425/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9209 - mse: 931.7206 - val_loss: 20.5598 - val_mse: 931.0944\n",
      "Epoch 3426/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8468 - mse: 930.8965 - val_loss: 20.5638 - val_mse: 925.8369\n",
      "Epoch 3427/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0040 - mse: 941.2513 - val_loss: 20.5663 - val_mse: 924.6581\n",
      "Epoch 3428/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8993 - mse: 929.7496 - val_loss: 20.5764 - val_mse: 945.2919\n",
      "Epoch 3429/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0052 - mse: 931.2542 - val_loss: 20.5606 - val_mse: 928.2225\n",
      "Epoch 3430/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9422 - mse: 938.0726 - val_loss: 20.5640 - val_mse: 925.6977\n",
      "Epoch 3431/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8686 - mse: 929.4827 - val_loss: 20.6882 - val_mse: 899.5544\n",
      "Epoch 3432/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8668 - mse: 921.9684 - val_loss: 20.5804 - val_mse: 947.1044\n",
      "Epoch 3433/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9377 - mse: 932.3134 - val_loss: 20.6175 - val_mse: 909.8557\n",
      "Epoch 3434/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9655 - mse: 941.3892 - val_loss: 20.5747 - val_mse: 944.4268\n",
      "Epoch 3435/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9849 - mse: 924.1512 - val_loss: 20.5726 - val_mse: 943.3179\n",
      "Epoch 3436/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9752 - mse: 938.9882 - val_loss: 20.5855 - val_mse: 949.4565\n",
      "Epoch 3437/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9372 - mse: 932.3939 - val_loss: 20.5647 - val_mse: 938.1910\n",
      "Epoch 3438/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9201 - mse: 932.3080 - val_loss: 20.6635 - val_mse: 969.1768\n",
      "Epoch 3439/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9492 - mse: 933.5483 - val_loss: 20.5704 - val_mse: 942.0621\n",
      "Epoch 3440/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.7908 - mse: 935.3276 - val_loss: 20.5844 - val_mse: 917.7417\n",
      "Epoch 3441/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9979 - mse: 929.1638 - val_loss: 20.5639 - val_mse: 925.7803\n",
      "Epoch 3442/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9211 - mse: 922.7487 - val_loss: 20.5696 - val_mse: 941.6403\n",
      "Epoch 3443/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9038 - mse: 929.9202 - val_loss: 20.5811 - val_mse: 947.4181\n",
      "Epoch 3444/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9730 - mse: 931.4902 - val_loss: 20.6071 - val_mse: 956.6974\n",
      "Epoch 3445/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9999 - mse: 941.2670 - val_loss: 20.5642 - val_mse: 925.6213\n",
      "Epoch 3446/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9066 - mse: 926.3861 - val_loss: 20.6127 - val_mse: 910.8287\n",
      "Epoch 3447/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9333 - mse: 930.4711 - val_loss: 20.5607 - val_mse: 928.0875\n",
      "Epoch 3448/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9666 - mse: 940.4622 - val_loss: 20.5615 - val_mse: 935.1729\n",
      "Epoch 3449/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0031 - mse: 932.6152 - val_loss: 20.5682 - val_mse: 923.8348\n",
      "Epoch 3450/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9963 - mse: 928.4728 - val_loss: 20.6330 - val_mse: 963.2101\n",
      "Epoch 3451/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9490 - mse: 942.1836 - val_loss: 20.5634 - val_mse: 937.1844\n",
      "Epoch 3452/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8816 - mse: 923.0840 - val_loss: 20.6088 - val_mse: 957.1714\n",
      "Epoch 3453/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9754 - mse: 938.8671 - val_loss: 20.5602 - val_mse: 932.4335\n",
      "Epoch 3454/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9087 - mse: 937.6907 - val_loss: 20.5924 - val_mse: 915.5635\n",
      "Epoch 3455/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9939 - mse: 925.9416 - val_loss: 20.5795 - val_mse: 946.7365\n",
      "Epoch 3456/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9580 - mse: 934.1500 - val_loss: 20.5641 - val_mse: 925.6591\n",
      "Epoch 3457/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9759 - mse: 938.6784 - val_loss: 20.5695 - val_mse: 923.2760\n",
      "Epoch 3458/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9073 - mse: 929.0018 - val_loss: 20.5661 - val_mse: 924.7798\n",
      "Epoch 3459/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9639 - mse: 928.8084 - val_loss: 20.5619 - val_mse: 926.8549\n",
      "Epoch 3460/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 21.0281 - mse: 941.0551 - val_loss: 20.5661 - val_mse: 924.7473\n",
      "Epoch 3461/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9383 - mse: 928.4084 - val_loss: 20.5605 - val_mse: 933.1846\n",
      "Epoch 3462/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8773 - mse: 926.9360 - val_loss: 20.5689 - val_mse: 941.1600\n",
      "Epoch 3463/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9495 - mse: 940.5530 - val_loss: 20.5717 - val_mse: 942.7938\n",
      "Epoch 3464/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9863 - mse: 932.8137 - val_loss: 20.6020 - val_mse: 913.1547\n",
      "Epoch 3465/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8322 - mse: 926.4078 - val_loss: 20.6061 - val_mse: 912.2377\n",
      "Epoch 3466/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9354 - mse: 922.3640 - val_loss: 20.5744 - val_mse: 944.2652\n",
      "Epoch 3467/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9929 - mse: 940.9541 - val_loss: 20.5747 - val_mse: 944.4413\n",
      "Epoch 3468/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9197 - mse: 934.6672 - val_loss: 20.5710 - val_mse: 942.3763\n",
      "Epoch 3469/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9106 - mse: 923.7935 - val_loss: 20.6011 - val_mse: 954.8802\n",
      "Epoch 3470/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9699 - mse: 935.0129 - val_loss: 20.5680 - val_mse: 940.6215\n",
      "Epoch 3471/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9242 - mse: 927.3369 - val_loss: 20.6304 - val_mse: 962.6809\n",
      "Epoch 3472/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0151 - mse: 939.1004 - val_loss: 20.5727 - val_mse: 943.3417\n",
      "Epoch 3473/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0014 - mse: 927.9241 - val_loss: 20.5833 - val_mse: 948.4358\n",
      "Epoch 3474/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8889 - mse: 930.1703 - val_loss: 20.5920 - val_mse: 951.9323\n",
      "Epoch 3475/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8996 - mse: 931.4572 - val_loss: 20.5866 - val_mse: 949.9187\n",
      "Epoch 3476/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9590 - mse: 944.7423 - val_loss: 20.6079 - val_mse: 956.9222\n",
      "Epoch 3477/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9184 - mse: 938.8610 - val_loss: 20.5750 - val_mse: 920.9824\n",
      "Epoch 3478/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.8454 - mse: 924.5825 - val_loss: 20.8077 - val_mse: 991.9536\n",
      "Epoch 3479/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9400 - mse: 938.1445 - val_loss: 20.5832 - val_mse: 948.3758\n",
      "Epoch 3480/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9627 - mse: 937.0618 - val_loss: 20.6467 - val_mse: 966.0525\n",
      "Epoch 3481/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0810 - mse: 947.9088 - val_loss: 20.8760 - val_mse: 1002.0378\n",
      "Epoch 3482/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0392 - mse: 934.7703 - val_loss: 20.7121 - val_mse: 977.1907\n",
      "Epoch 3483/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9145 - mse: 929.4847 - val_loss: 20.5775 - val_mse: 945.8090\n",
      "Epoch 3484/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9730 - mse: 937.5225 - val_loss: 20.6492 - val_mse: 904.4554\n",
      "Epoch 3485/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9747 - mse: 935.4574 - val_loss: 20.5716 - val_mse: 922.3328\n",
      "Epoch 3486/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9969 - mse: 939.7791 - val_loss: 20.5969 - val_mse: 914.3837\n",
      "Epoch 3487/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9542 - mse: 928.1724 - val_loss: 20.6684 - val_mse: 970.0394\n",
      "Epoch 3488/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 21.0808 - mse: 944.4310 - val_loss: 20.5940 - val_mse: 952.6298\n",
      "Epoch 3489/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9631 - mse: 928.7792 - val_loss: 20.7288 - val_mse: 979.7989\n",
      "Epoch 3490/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9364 - mse: 934.5764 - val_loss: 20.5606 - val_mse: 928.2056\n",
      "Epoch 3491/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9574 - mse: 941.9556 - val_loss: 20.5635 - val_mse: 937.2127\n",
      "Epoch 3492/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8945 - mse: 932.0746 - val_loss: 20.6182 - val_mse: 909.7338\n",
      "Epoch 3493/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0253 - mse: 934.8829 - val_loss: 20.5688 - val_mse: 941.1052\n",
      "Epoch 3494/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9131 - mse: 929.4958 - val_loss: 20.5603 - val_mse: 932.7125\n",
      "Epoch 3495/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9380 - mse: 925.5185 - val_loss: 20.6300 - val_mse: 962.5979\n",
      "Epoch 3496/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9849 - mse: 934.3403 - val_loss: 20.5602 - val_mse: 932.4421\n",
      "Epoch 3497/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9195 - mse: 935.4892 - val_loss: 20.5604 - val_mse: 932.9533\n",
      "Epoch 3498/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9999 - mse: 927.9354 - val_loss: 20.5610 - val_mse: 934.1790\n",
      "Epoch 3499/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0493 - mse: 935.8170 - val_loss: 20.5865 - val_mse: 949.8774\n",
      "Epoch 3500/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9472 - mse: 937.3566 - val_loss: 20.5723 - val_mse: 943.1339\n",
      "Epoch 3501/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9155 - mse: 939.9493 - val_loss: 20.5633 - val_mse: 926.0699\n",
      "Epoch 3502/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8399 - mse: 922.3768 - val_loss: 20.6058 - val_mse: 912.3042\n",
      "Epoch 3503/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0246 - mse: 942.7842 - val_loss: 20.6090 - val_mse: 911.6191\n",
      "Epoch 3504/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8776 - mse: 927.1791 - val_loss: 20.5885 - val_mse: 950.6882\n",
      "Epoch 3505/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9762 - mse: 938.2576 - val_loss: 20.5599 - val_mse: 929.9092\n",
      "Epoch 3506/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9530 - mse: 921.6270 - val_loss: 20.5837 - val_mse: 948.6340\n",
      "Epoch 3507/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8813 - mse: 926.7534 - val_loss: 20.5774 - val_mse: 945.7839\n",
      "Epoch 3508/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8919 - mse: 934.3401 - val_loss: 20.6754 - val_mse: 900.9790\n",
      "Epoch 3509/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8962 - mse: 923.6776 - val_loss: 20.5775 - val_mse: 920.0612\n",
      "Epoch 3510/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9839 - mse: 937.3919 - val_loss: 20.5799 - val_mse: 946.9052\n",
      "Epoch 3511/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9269 - mse: 929.9170 - val_loss: 20.5789 - val_mse: 946.4566\n",
      "Epoch 3512/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9285 - mse: 930.8292 - val_loss: 20.5641 - val_mse: 925.6704\n",
      "Epoch 3513/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9806 - mse: 941.7076 - val_loss: 20.5605 - val_mse: 928.3427\n",
      "Epoch 3514/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9624 - mse: 932.7016 - val_loss: 20.5618 - val_mse: 935.6525\n",
      "Epoch 3515/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9123 - mse: 929.7775 - val_loss: 20.5817 - val_mse: 947.6988\n",
      "Epoch 3516/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9755 - mse: 940.3712 - val_loss: 20.5839 - val_mse: 948.7113\n",
      "Epoch 3517/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9100 - mse: 926.4962 - val_loss: 20.5706 - val_mse: 942.1573\n",
      "Epoch 3518/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9635 - mse: 935.8969 - val_loss: 20.5616 - val_mse: 927.1079\n",
      "Epoch 3519/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 21.0163 - mse: 935.3350 - val_loss: 20.6199 - val_mse: 909.3973\n",
      "Epoch 3520/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9287 - mse: 925.1475 - val_loss: 20.5650 - val_mse: 938.4541\n",
      "Epoch 3521/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8971 - mse: 931.6135 - val_loss: 20.5599 - val_mse: 930.3465\n",
      "Epoch 3522/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8723 - mse: 927.8289 - val_loss: 20.6392 - val_mse: 964.4984\n",
      "Epoch 3523/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0080 - mse: 934.7541 - val_loss: 20.5598 - val_mse: 930.9837\n",
      "Epoch 3524/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9411 - mse: 929.5604 - val_loss: 20.6523 - val_mse: 967.1646\n",
      "Epoch 3525/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9944 - mse: 938.5735 - val_loss: 20.5653 - val_mse: 925.1042\n",
      "Epoch 3526/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9411 - mse: 934.5093 - val_loss: 20.5602 - val_mse: 932.4551\n",
      "Epoch 3527/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9587 - mse: 928.8829 - val_loss: 20.5761 - val_mse: 945.1509\n",
      "Epoch 3528/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9251 - mse: 931.5953 - val_loss: 20.6260 - val_mse: 961.7017\n",
      "Epoch 3529/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9827 - mse: 936.8498 - val_loss: 20.6184 - val_mse: 959.9006\n",
      "Epoch 3530/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9868 - mse: 936.2484 - val_loss: 20.6075 - val_mse: 956.8086\n",
      "Epoch 3531/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9108 - mse: 933.3817 - val_loss: 20.5678 - val_mse: 923.9921\n",
      "Epoch 3532/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9625 - mse: 928.6062 - val_loss: 20.5721 - val_mse: 922.1516\n",
      "Epoch 3533/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9185 - mse: 929.1351 - val_loss: 20.5724 - val_mse: 943.1935\n",
      "Epoch 3534/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9401 - mse: 934.1340 - val_loss: 20.5854 - val_mse: 949.3860\n",
      "Epoch 3535/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8718 - mse: 929.3257 - val_loss: 20.5619 - val_mse: 926.8525\n",
      "Epoch 3536/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9027 - mse: 930.2346 - val_loss: 20.5614 - val_mse: 935.1359\n",
      "Epoch 3537/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8872 - mse: 931.5604 - val_loss: 20.5686 - val_mse: 940.9822\n",
      "Epoch 3538/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8991 - mse: 927.7610 - val_loss: 20.5756 - val_mse: 944.8906\n",
      "Epoch 3539/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8947 - mse: 933.2639 - val_loss: 20.5752 - val_mse: 944.6849\n",
      "Epoch 3540/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0267 - mse: 940.6705 - val_loss: 20.5829 - val_mse: 948.2740\n",
      "Epoch 3541/5000\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 20.8956 - mse: 927.4913 - val_loss: 20.5598 - val_mse: 930.6792\n",
      "Epoch 3542/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 21.0242 - mse: 934.8138 - val_loss: 20.5972 - val_mse: 953.6810\n",
      "Epoch 3543/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9330 - mse: 928.8755 - val_loss: 20.5662 - val_mse: 939.3390\n",
      "Epoch 3544/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9040 - mse: 929.5145 - val_loss: 20.5600 - val_mse: 932.0417\n",
      "Epoch 3545/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8881 - mse: 927.8719 - val_loss: 20.5650 - val_mse: 925.2501\n",
      "Epoch 3546/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9212 - mse: 934.1117 - val_loss: 20.5842 - val_mse: 948.8469\n",
      "Epoch 3547/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9625 - mse: 934.6143 - val_loss: 20.5962 - val_mse: 953.3419\n",
      "Epoch 3548/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8617 - mse: 922.9468 - val_loss: 20.5633 - val_mse: 937.0821\n",
      "Epoch 3549/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0096 - mse: 928.7803 - val_loss: 20.6159 - val_mse: 959.2167\n",
      "Epoch 3550/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9800 - mse: 948.0542 - val_loss: 20.5780 - val_mse: 946.0584\n",
      "Epoch 3551/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9448 - mse: 936.0966 - val_loss: 20.5599 - val_mse: 929.9659\n",
      "Epoch 3552/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9831 - mse: 931.6627 - val_loss: 20.5788 - val_mse: 946.3807\n",
      "Epoch 3553/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8837 - mse: 930.6967 - val_loss: 20.5605 - val_mse: 933.2327\n",
      "Epoch 3554/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9334 - mse: 926.3931 - val_loss: 20.6396 - val_mse: 964.5912\n",
      "Epoch 3555/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9651 - mse: 947.2634 - val_loss: 20.5602 - val_mse: 929.0525\n",
      "Epoch 3556/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9629 - mse: 930.3281 - val_loss: 20.5663 - val_mse: 939.4309\n",
      "Epoch 3557/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8773 - mse: 938.3693 - val_loss: 20.5606 - val_mse: 928.2177\n",
      "Epoch 3558/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9897 - mse: 931.4257 - val_loss: 20.5713 - val_mse: 942.5826\n",
      "Epoch 3559/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8804 - mse: 937.7888 - val_loss: 20.5990 - val_mse: 954.2325\n",
      "Epoch 3560/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9068 - mse: 935.9201 - val_loss: 20.7210 - val_mse: 978.5742\n",
      "Epoch 3561/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8708 - mse: 926.3691 - val_loss: 20.6114 - val_mse: 957.9169\n",
      "Epoch 3562/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9295 - mse: 925.3281 - val_loss: 20.5905 - val_mse: 951.4191\n",
      "Epoch 3563/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0166 - mse: 941.0710 - val_loss: 20.5878 - val_mse: 916.7852\n",
      "Epoch 3564/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9874 - mse: 940.3850 - val_loss: 20.5604 - val_mse: 928.6289\n",
      "Epoch 3565/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9327 - mse: 927.2211 - val_loss: 20.5603 - val_mse: 932.8102\n",
      "Epoch 3566/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9174 - mse: 929.0275 - val_loss: 20.6145 - val_mse: 958.8298\n",
      "Epoch 3567/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9616 - mse: 930.7371 - val_loss: 20.6321 - val_mse: 963.0362\n",
      "Epoch 3568/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8923 - mse: 939.4574 - val_loss: 20.5638 - val_mse: 925.7991\n",
      "Epoch 3569/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9927 - mse: 932.1745 - val_loss: 20.5603 - val_mse: 928.7291\n",
      "Epoch 3570/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0317 - mse: 934.8121 - val_loss: 20.5612 - val_mse: 934.6520\n",
      "Epoch 3571/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9246 - mse: 938.8864 - val_loss: 20.5677 - val_mse: 940.4023\n",
      "Epoch 3572/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9343 - mse: 929.5487 - val_loss: 20.6460 - val_mse: 965.9108\n",
      "Epoch 3573/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9444 - mse: 928.5711 - val_loss: 20.7389 - val_mse: 981.3425\n",
      "Epoch 3574/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9659 - mse: 932.7859 - val_loss: 20.7054 - val_mse: 976.1427\n",
      "Epoch 3575/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9186 - mse: 932.9820 - val_loss: 20.5602 - val_mse: 928.9432\n",
      "Epoch 3576/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9819 - mse: 927.2684 - val_loss: 20.6191 - val_mse: 960.0686\n",
      "Epoch 3577/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9364 - mse: 930.9954 - val_loss: 20.7164 - val_mse: 977.8544\n",
      "Epoch 3578/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9245 - mse: 929.1664 - val_loss: 20.5931 - val_mse: 952.3266\n",
      "Epoch 3579/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8694 - mse: 930.9733 - val_loss: 20.6234 - val_mse: 961.1192\n",
      "Epoch 3580/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9004 - mse: 934.0079 - val_loss: 20.5621 - val_mse: 935.9672\n",
      "Epoch 3581/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9309 - mse: 929.7446 - val_loss: 20.5604 - val_mse: 932.8394\n",
      "Epoch 3582/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8899 - mse: 930.4723 - val_loss: 20.5637 - val_mse: 937.3937\n",
      "Epoch 3583/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9167 - mse: 924.8082 - val_loss: 20.7746 - val_mse: 986.9348\n",
      "Epoch 3584/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9225 - mse: 933.5919 - val_loss: 20.5742 - val_mse: 944.1959\n",
      "Epoch 3585/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8808 - mse: 930.2941 - val_loss: 20.5677 - val_mse: 924.0662\n",
      "Epoch 3586/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9721 - mse: 938.0588 - val_loss: 20.5693 - val_mse: 941.4386\n",
      "Epoch 3587/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9318 - mse: 924.9116 - val_loss: 20.5627 - val_mse: 936.5311\n",
      "Epoch 3588/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8874 - mse: 933.5953 - val_loss: 20.5804 - val_mse: 919.0306\n",
      "Epoch 3589/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9603 - mse: 929.7122 - val_loss: 20.6252 - val_mse: 961.5262\n",
      "Epoch 3590/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8287 - mse: 922.7856 - val_loss: 20.5604 - val_mse: 933.0408\n",
      "Epoch 3591/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9020 - mse: 932.4681 - val_loss: 20.5605 - val_mse: 933.1387\n",
      "Epoch 3592/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8911 - mse: 939.2439 - val_loss: 20.5639 - val_mse: 925.7546\n",
      "Epoch 3593/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9398 - mse: 928.1976 - val_loss: 20.6118 - val_mse: 958.0425\n",
      "Epoch 3594/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9760 - mse: 932.4184 - val_loss: 20.5781 - val_mse: 919.8575\n",
      "Epoch 3595/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8964 - mse: 935.6556 - val_loss: 20.6186 - val_mse: 959.9306\n",
      "Epoch 3596/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9436 - mse: 931.3804 - val_loss: 20.6363 - val_mse: 963.9055\n",
      "Epoch 3597/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9420 - mse: 931.0246 - val_loss: 20.6842 - val_mse: 972.7244\n",
      "Epoch 3598/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9263 - mse: 938.3378 - val_loss: 20.5752 - val_mse: 944.7224\n",
      "Epoch 3599/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9159 - mse: 934.9219 - val_loss: 20.5633 - val_mse: 937.0461\n",
      "Epoch 3600/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9149 - mse: 928.0713 - val_loss: 20.5623 - val_mse: 926.6221\n",
      "Epoch 3601/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9149 - mse: 930.7910 - val_loss: 20.5726 - val_mse: 943.3173\n",
      "Epoch 3602/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9678 - mse: 933.3384 - val_loss: 20.5754 - val_mse: 920.8417\n",
      "Epoch 3603/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8949 - mse: 917.4822 - val_loss: 20.6011 - val_mse: 954.9012\n",
      "Epoch 3604/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9935 - mse: 944.0627 - val_loss: 20.5608 - val_mse: 933.9162\n",
      "Epoch 3605/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8487 - mse: 934.8856 - val_loss: 20.5612 - val_mse: 934.6998\n",
      "Epoch 3606/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9432 - mse: 948.1019 - val_loss: 20.6155 - val_mse: 910.2519\n",
      "Epoch 3607/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9088 - mse: 931.8737 - val_loss: 20.5620 - val_mse: 935.8398\n",
      "Epoch 3608/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9265 - mse: 919.7275 - val_loss: 20.6192 - val_mse: 960.0971\n",
      "Epoch 3609/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8990 - mse: 936.5242 - val_loss: 20.5601 - val_mse: 932.3639\n",
      "Epoch 3610/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9096 - mse: 923.8262 - val_loss: 20.5718 - val_mse: 942.8271\n",
      "Epoch 3611/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0303 - mse: 942.7657 - val_loss: 20.6527 - val_mse: 967.2360\n",
      "Epoch 3612/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9136 - mse: 934.2127 - val_loss: 20.5833 - val_mse: 918.0736\n",
      "Epoch 3613/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 21.0095 - mse: 936.6011 - val_loss: 20.5806 - val_mse: 947.2200\n",
      "Epoch 3614/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9345 - mse: 933.0347 - val_loss: 20.6693 - val_mse: 970.1906\n",
      "Epoch 3615/5000\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 20.9898 - mse: 938.0948 - val_loss: 20.5612 - val_mse: 927.4268\n",
      "Epoch 3616/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9406 - mse: 935.3032 - val_loss: 20.5600 - val_mse: 929.5261\n",
      "Epoch 3617/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8445 - mse: 927.7452 - val_loss: 20.5742 - val_mse: 944.1962\n",
      "Epoch 3618/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9505 - mse: 931.2631 - val_loss: 20.5716 - val_mse: 942.7142\n",
      "Epoch 3619/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8160 - mse: 936.2595 - val_loss: 20.5601 - val_mse: 929.2715\n",
      "Epoch 3620/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9447 - mse: 938.5522 - val_loss: 20.5604 - val_mse: 932.8617\n",
      "Epoch 3621/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9647 - mse: 936.7726 - val_loss: 20.5622 - val_mse: 936.0477\n",
      "Epoch 3622/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9533 - mse: 934.5467 - val_loss: 20.5938 - val_mse: 915.1812\n",
      "Epoch 3623/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9793 - mse: 936.0101 - val_loss: 20.5599 - val_mse: 930.2177\n",
      "Epoch 3624/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9601 - mse: 939.3168 - val_loss: 20.5623 - val_mse: 936.1216\n",
      "Epoch 3625/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8754 - mse: 924.5889 - val_loss: 20.5670 - val_mse: 939.9608\n",
      "Epoch 3626/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9488 - mse: 927.3336 - val_loss: 20.5687 - val_mse: 941.0513\n",
      "Epoch 3627/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9023 - mse: 928.6874 - val_loss: 20.6078 - val_mse: 956.8900\n",
      "Epoch 3628/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9145 - mse: 935.5432 - val_loss: 20.5660 - val_mse: 924.8004\n",
      "Epoch 3629/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0104 - mse: 934.7865 - val_loss: 20.6436 - val_mse: 965.4221\n",
      "Epoch 3630/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9620 - mse: 930.8320 - val_loss: 20.6582 - val_mse: 968.2510\n",
      "Epoch 3631/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8988 - mse: 932.0286 - val_loss: 20.5657 - val_mse: 938.9860\n",
      "Epoch 3632/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8828 - mse: 927.9457 - val_loss: 20.6860 - val_mse: 973.0346\n",
      "Epoch 3633/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9478 - mse: 939.7527 - val_loss: 20.5777 - val_mse: 945.9232\n",
      "Epoch 3634/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9998 - mse: 940.2898 - val_loss: 20.5748 - val_mse: 944.5052\n",
      "Epoch 3635/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9332 - mse: 928.1683 - val_loss: 20.5913 - val_mse: 951.6968\n",
      "Epoch 3636/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8757 - mse: 933.2434 - val_loss: 20.5598 - val_mse: 930.7285\n",
      "Epoch 3637/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0666 - mse: 934.9952 - val_loss: 20.5621 - val_mse: 935.9919\n",
      "Epoch 3638/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8162 - mse: 921.8702 - val_loss: 20.6544 - val_mse: 967.5656\n",
      "Epoch 3639/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9333 - mse: 937.7013 - val_loss: 20.6200 - val_mse: 960.3093\n",
      "Epoch 3640/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8969 - mse: 926.2185 - val_loss: 20.5625 - val_mse: 936.4013\n",
      "Epoch 3641/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9559 - mse: 942.7943 - val_loss: 20.5682 - val_mse: 940.7565\n",
      "Epoch 3642/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9988 - mse: 934.5071 - val_loss: 20.5691 - val_mse: 941.2816\n",
      "Epoch 3643/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.8899 - mse: 931.0509 - val_loss: 20.5692 - val_mse: 923.4099\n",
      "Epoch 3644/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9453 - mse: 936.8665 - val_loss: 20.7462 - val_mse: 894.1923\n",
      "Epoch 3645/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9913 - mse: 929.4169 - val_loss: 20.5603 - val_mse: 928.8609\n",
      "Epoch 3646/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9710 - mse: 930.1151 - val_loss: 20.5803 - val_mse: 947.0607\n",
      "Epoch 3647/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9784 - mse: 932.7248 - val_loss: 20.5803 - val_mse: 947.0744\n",
      "Epoch 3648/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0400 - mse: 937.2902 - val_loss: 20.7018 - val_mse: 975.5746\n",
      "Epoch 3649/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9904 - mse: 946.1234 - val_loss: 20.5729 - val_mse: 943.4913\n",
      "Epoch 3650/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9300 - mse: 931.2437 - val_loss: 20.6157 - val_mse: 959.1796\n",
      "Epoch 3651/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9536 - mse: 934.5766 - val_loss: 20.5850 - val_mse: 949.2278\n",
      "Epoch 3652/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9151 - mse: 933.4467 - val_loss: 20.5600 - val_mse: 932.1733\n",
      "Epoch 3653/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9169 - mse: 932.6022 - val_loss: 20.5921 - val_mse: 951.9700\n",
      "Epoch 3654/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9606 - mse: 930.1826 - val_loss: 20.5603 - val_mse: 928.8402\n",
      "Epoch 3655/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9177 - mse: 936.6939 - val_loss: 20.5884 - val_mse: 950.6531\n",
      "Epoch 3656/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9048 - mse: 931.3664 - val_loss: 20.5609 - val_mse: 934.0944\n",
      "Epoch 3657/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8960 - mse: 937.5695 - val_loss: 20.5625 - val_mse: 926.5071\n",
      "Epoch 3658/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9138 - mse: 929.1139 - val_loss: 20.6140 - val_mse: 958.6775\n",
      "Epoch 3659/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9171 - mse: 940.8623 - val_loss: 20.5650 - val_mse: 925.2534\n",
      "Epoch 3660/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8420 - mse: 925.1498 - val_loss: 20.5673 - val_mse: 924.2288\n",
      "Epoch 3661/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9158 - mse: 925.8295 - val_loss: 20.6111 - val_mse: 957.8281\n",
      "Epoch 3662/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8803 - mse: 926.7914 - val_loss: 20.7105 - val_mse: 976.9414\n",
      "Epoch 3663/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0093 - mse: 941.3627 - val_loss: 20.5783 - val_mse: 946.1896\n",
      "Epoch 3664/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9092 - mse: 931.8322 - val_loss: 20.5928 - val_mse: 952.2046\n",
      "Epoch 3665/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8929 - mse: 931.3522 - val_loss: 20.5601 - val_mse: 929.1544\n",
      "Epoch 3666/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9041 - mse: 936.4725 - val_loss: 20.5738 - val_mse: 921.4623\n",
      "Epoch 3667/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9050 - mse: 932.6544 - val_loss: 20.5604 - val_mse: 928.5264\n",
      "Epoch 3668/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8922 - mse: 928.7595 - val_loss: 20.5878 - val_mse: 950.4089\n",
      "Epoch 3669/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9645 - mse: 935.6576 - val_loss: 20.5831 - val_mse: 948.3398\n",
      "Epoch 3670/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9276 - mse: 932.3389 - val_loss: 20.5757 - val_mse: 944.9590\n",
      "Epoch 3671/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9618 - mse: 931.2905 - val_loss: 20.5931 - val_mse: 952.3046\n",
      "Epoch 3672/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9491 - mse: 932.0768 - val_loss: 20.5990 - val_mse: 954.2327\n",
      "Epoch 3673/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9769 - mse: 939.7033 - val_loss: 20.6133 - val_mse: 958.4692\n",
      "Epoch 3674/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9430 - mse: 940.8668 - val_loss: 20.6252 - val_mse: 908.4116\n",
      "Epoch 3675/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9621 - mse: 932.5572 - val_loss: 20.5677 - val_mse: 924.0374\n",
      "Epoch 3676/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9981 - mse: 932.5433 - val_loss: 20.5601 - val_mse: 932.3150\n",
      "Epoch 3677/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9528 - mse: 925.1461 - val_loss: 20.7738 - val_mse: 986.8064\n",
      "Epoch 3678/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8911 - mse: 935.4931 - val_loss: 20.5785 - val_mse: 919.7148\n",
      "Epoch 3679/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9374 - mse: 932.8503 - val_loss: 20.5960 - val_mse: 953.2922\n",
      "Epoch 3680/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8520 - mse: 926.7394 - val_loss: 20.5745 - val_mse: 944.3679\n",
      "Epoch 3681/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9085 - mse: 933.7181 - val_loss: 20.5602 - val_mse: 932.5267\n",
      "Epoch 3682/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9478 - mse: 934.0564 - val_loss: 20.5611 - val_mse: 927.5491\n",
      "Epoch 3683/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9856 - mse: 932.4365 - val_loss: 20.5629 - val_mse: 936.7477\n",
      "Epoch 3684/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9203 - mse: 938.0809 - val_loss: 20.5620 - val_mse: 935.9025\n",
      "Epoch 3685/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8519 - mse: 925.3671 - val_loss: 20.5638 - val_mse: 937.4926\n",
      "Epoch 3686/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9597 - mse: 932.2803 - val_loss: 20.5996 - val_mse: 913.6855\n",
      "Epoch 3687/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9526 - mse: 930.2807 - val_loss: 20.5746 - val_mse: 944.3763\n",
      "Epoch 3688/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8781 - mse: 932.6263 - val_loss: 20.5632 - val_mse: 936.9461\n",
      "Epoch 3689/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9039 - mse: 920.9525 - val_loss: 20.6083 - val_mse: 957.0190\n",
      "Epoch 3690/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9354 - mse: 941.6273 - val_loss: 20.5840 - val_mse: 917.8517\n",
      "Epoch 3691/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8595 - mse: 925.7352 - val_loss: 20.5757 - val_mse: 944.9394\n",
      "Epoch 3692/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9990 - mse: 936.0066 - val_loss: 20.5655 - val_mse: 938.8260\n",
      "Epoch 3693/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9702 - mse: 928.6597 - val_loss: 20.5953 - val_mse: 953.0587\n",
      "Epoch 3694/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8971 - mse: 918.4155 - val_loss: 20.5684 - val_mse: 940.8870\n",
      "Epoch 3695/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8903 - mse: 930.1533 - val_loss: 20.5687 - val_mse: 941.0640\n",
      "Epoch 3696/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0255 - mse: 946.7820 - val_loss: 20.6582 - val_mse: 903.1790\n",
      "Epoch 3697/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9100 - mse: 923.4944 - val_loss: 20.5631 - val_mse: 926.1898\n",
      "Epoch 3698/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9642 - mse: 926.0220 - val_loss: 20.7212 - val_mse: 978.6102\n",
      "Epoch 3699/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9183 - mse: 929.3239 - val_loss: 20.6379 - val_mse: 964.2380\n",
      "Epoch 3700/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9830 - mse: 931.9816 - val_loss: 20.6246 - val_mse: 961.3758\n",
      "Epoch 3701/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0507 - mse: 945.1711 - val_loss: 20.6369 - val_mse: 964.0283\n",
      "Epoch 3702/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8542 - mse: 929.1140 - val_loss: 20.6401 - val_mse: 964.6761\n",
      "Epoch 3703/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9128 - mse: 928.9791 - val_loss: 20.6326 - val_mse: 907.1119\n",
      "Epoch 3704/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0335 - mse: 931.4733 - val_loss: 20.5939 - val_mse: 915.1533\n",
      "Epoch 3705/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9356 - mse: 928.2147 - val_loss: 20.5698 - val_mse: 923.1132\n",
      "Epoch 3706/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8767 - mse: 931.5215 - val_loss: 20.6627 - val_mse: 902.5589\n",
      "Epoch 3707/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9047 - mse: 920.2991 - val_loss: 20.5815 - val_mse: 947.6379\n",
      "Epoch 3708/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9386 - mse: 932.4758 - val_loss: 20.5598 - val_mse: 931.4629\n",
      "Epoch 3709/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8702 - mse: 931.2206 - val_loss: 20.5598 - val_mse: 931.0648\n",
      "Epoch 3710/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8927 - mse: 931.4841 - val_loss: 20.5650 - val_mse: 938.4568\n",
      "Epoch 3711/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9477 - mse: 921.6489 - val_loss: 20.5862 - val_mse: 949.7560\n",
      "Epoch 3712/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0094 - mse: 936.1050 - val_loss: 20.7144 - val_mse: 977.5536\n",
      "Epoch 3713/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0346 - mse: 950.5085 - val_loss: 20.5662 - val_mse: 924.7191\n",
      "Epoch 3714/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9740 - mse: 932.6271 - val_loss: 20.5623 - val_mse: 936.1789\n",
      "Epoch 3715/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9953 - mse: 920.2922 - val_loss: 20.5949 - val_mse: 952.9099\n",
      "Epoch 3716/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9844 - mse: 938.0557 - val_loss: 20.5690 - val_mse: 941.2690\n",
      "Epoch 3717/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9792 - mse: 936.1418 - val_loss: 20.5902 - val_mse: 951.3088\n",
      "Epoch 3718/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8919 - mse: 932.7347 - val_loss: 20.5691 - val_mse: 941.3373\n",
      "Epoch 3719/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9512 - mse: 936.8040 - val_loss: 20.5605 - val_mse: 928.3433\n",
      "Epoch 3720/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9629 - mse: 934.1777 - val_loss: 20.5770 - val_mse: 920.2592\n",
      "Epoch 3721/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0534 - mse: 939.8039 - val_loss: 20.5601 - val_mse: 929.1008\n",
      "Epoch 3722/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9512 - mse: 935.1325 - val_loss: 20.5746 - val_mse: 921.1646\n",
      "Epoch 3723/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8782 - mse: 931.4319 - val_loss: 20.5773 - val_mse: 945.7415\n",
      "Epoch 3724/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9331 - mse: 928.8076 - val_loss: 20.5819 - val_mse: 947.8179\n",
      "Epoch 3725/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9031 - mse: 937.2686 - val_loss: 20.6182 - val_mse: 909.7342\n",
      "Epoch 3726/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9133 - mse: 922.8817 - val_loss: 20.5815 - val_mse: 918.6539\n",
      "Epoch 3727/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8939 - mse: 924.2782 - val_loss: 20.6191 - val_mse: 960.0624\n",
      "Epoch 3728/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9211 - mse: 932.9366 - val_loss: 20.5930 - val_mse: 915.4075\n",
      "Epoch 3729/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9440 - mse: 930.9796 - val_loss: 20.5697 - val_mse: 941.6479\n",
      "Epoch 3730/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9619 - mse: 932.3512 - val_loss: 20.5899 - val_mse: 951.2077\n",
      "Epoch 3731/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9462 - mse: 938.8223 - val_loss: 20.5649 - val_mse: 938.3665\n",
      "Epoch 3732/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9425 - mse: 922.9408 - val_loss: 20.5765 - val_mse: 945.3294\n",
      "Epoch 3733/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0879 - mse: 940.7908 - val_loss: 20.7282 - val_mse: 979.6974\n",
      "Epoch 3734/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8559 - mse: 919.0157 - val_loss: 20.6521 - val_mse: 967.1254\n",
      "Epoch 3735/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9846 - mse: 933.4030 - val_loss: 20.5883 - val_mse: 950.6142\n",
      "Epoch 3736/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9081 - mse: 940.5950 - val_loss: 20.6573 - val_mse: 903.3054\n",
      "Epoch 3737/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9381 - mse: 933.2188 - val_loss: 20.6468 - val_mse: 904.8154\n",
      "Epoch 3738/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9446 - mse: 920.6316 - val_loss: 20.5697 - val_mse: 941.6908\n",
      "Epoch 3739/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9329 - mse: 942.5021 - val_loss: 20.5598 - val_mse: 931.1771\n",
      "Epoch 3740/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 21.0093 - mse: 941.2709 - val_loss: 20.5796 - val_mse: 919.3318\n",
      "Epoch 3741/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8742 - mse: 924.6223 - val_loss: 20.6419 - val_mse: 965.0704\n",
      "Epoch 3742/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9434 - mse: 933.0806 - val_loss: 20.5608 - val_mse: 933.9055\n",
      "Epoch 3743/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0368 - mse: 937.4224 - val_loss: 20.5600 - val_mse: 929.3168\n",
      "Epoch 3744/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9770 - mse: 936.3205 - val_loss: 20.5610 - val_mse: 927.6953\n",
      "Epoch 3745/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 21.0009 - mse: 936.5593 - val_loss: 20.5780 - val_mse: 946.0406\n",
      "Epoch 3746/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8934 - mse: 925.4487 - val_loss: 20.5857 - val_mse: 949.5375\n",
      "Epoch 3747/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9420 - mse: 936.1017 - val_loss: 20.6041 - val_mse: 955.7766\n",
      "Epoch 3748/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8747 - mse: 932.7940 - val_loss: 20.5741 - val_mse: 944.1216\n",
      "Epoch 3749/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8988 - mse: 921.9506 - val_loss: 20.5663 - val_mse: 924.6585\n",
      "Epoch 3750/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8790 - mse: 937.4243 - val_loss: 20.5598 - val_mse: 931.4643\n",
      "Epoch 3751/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8702 - mse: 924.5401 - val_loss: 20.6204 - val_mse: 909.2989\n",
      "Epoch 3752/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9993 - mse: 938.8489 - val_loss: 20.5598 - val_mse: 931.0344\n",
      "Epoch 3753/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9308 - mse: 928.5228 - val_loss: 20.5608 - val_mse: 933.7214\n",
      "Epoch 3754/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9340 - mse: 926.1730 - val_loss: 20.5612 - val_mse: 934.6583\n",
      "Epoch 3755/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9496 - mse: 934.9744 - val_loss: 20.5604 - val_mse: 932.9348\n",
      "Epoch 3756/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9700 - mse: 929.1256 - val_loss: 20.6537 - val_mse: 967.4357\n",
      "Epoch 3757/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9526 - mse: 932.8032 - val_loss: 20.6517 - val_mse: 967.0378\n",
      "Epoch 3758/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8505 - mse: 929.3846 - val_loss: 20.6261 - val_mse: 908.2527\n",
      "Epoch 3759/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9056 - mse: 936.8729 - val_loss: 20.6002 - val_mse: 913.5617\n",
      "Epoch 3760/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9508 - mse: 925.9049 - val_loss: 20.8032 - val_mse: 991.2833\n",
      "Epoch 3761/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0427 - mse: 934.9098 - val_loss: 20.7865 - val_mse: 988.7496\n",
      "Epoch 3762/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9574 - mse: 928.0167 - val_loss: 20.6463 - val_mse: 965.9600\n",
      "Epoch 3763/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9826 - mse: 940.4637 - val_loss: 20.5679 - val_mse: 940.5568\n",
      "Epoch 3764/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8697 - mse: 923.0524 - val_loss: 20.6469 - val_mse: 966.0927\n",
      "Epoch 3765/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9906 - mse: 939.9210 - val_loss: 20.5619 - val_mse: 935.8092\n",
      "Epoch 3766/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9591 - mse: 923.0670 - val_loss: 20.6733 - val_mse: 970.8932\n",
      "Epoch 3767/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9507 - mse: 940.9668 - val_loss: 20.5602 - val_mse: 932.4774\n",
      "Epoch 3768/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9715 - mse: 923.4510 - val_loss: 20.7132 - val_mse: 977.3694\n",
      "Epoch 3769/5000\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 20.9076 - mse: 938.3912 - val_loss: 20.5633 - val_mse: 937.0701\n",
      "Epoch 3770/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9308 - mse: 932.4597 - val_loss: 20.5799 - val_mse: 919.2296\n",
      "Epoch 3771/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8964 - mse: 933.8788 - val_loss: 20.5686 - val_mse: 923.6602\n",
      "Epoch 3772/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9824 - mse: 933.4293 - val_loss: 20.5681 - val_mse: 940.6622\n",
      "Epoch 3773/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9214 - mse: 930.2581 - val_loss: 20.5807 - val_mse: 918.9286\n",
      "Epoch 3774/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8618 - mse: 918.3248 - val_loss: 20.6056 - val_mse: 956.2380\n",
      "Epoch 3775/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9066 - mse: 940.9573 - val_loss: 20.5817 - val_mse: 918.5959\n",
      "Epoch 3776/5000\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20.9316 - mse: 936.1841 - val_loss: 20.5699 - val_mse: 923.1006\n",
      "Epoch 3777/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9414 - mse: 931.3595 - val_loss: 20.5903 - val_mse: 951.3423\n",
      "Epoch 3778/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9606 - mse: 928.9513 - val_loss: 20.6018 - val_mse: 955.0985\n",
      "Epoch 3779/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9955 - mse: 931.8489 - val_loss: 20.5630 - val_mse: 936.8071\n",
      "Epoch 3780/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8765 - mse: 927.5317 - val_loss: 20.5899 - val_mse: 951.2007\n",
      "Epoch 3781/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9255 - mse: 925.2067 - val_loss: 20.5739 - val_mse: 944.0561\n",
      "Epoch 3782/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9414 - mse: 934.1921 - val_loss: 20.5921 - val_mse: 951.9777\n",
      "Epoch 3783/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9223 - mse: 937.9428 - val_loss: 20.5992 - val_mse: 954.3145\n",
      "Epoch 3784/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9511 - mse: 938.4703 - val_loss: 20.5633 - val_mse: 937.0974\n",
      "Epoch 3785/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9237 - mse: 930.2236 - val_loss: 20.5660 - val_mse: 939.1857\n",
      "Epoch 3786/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9168 - mse: 931.2127 - val_loss: 20.5848 - val_mse: 949.1002\n",
      "Epoch 3787/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 21.0010 - mse: 929.0023 - val_loss: 20.5840 - val_mse: 948.7581\n",
      "Epoch 3788/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9321 - mse: 934.7778 - val_loss: 20.5649 - val_mse: 938.3237\n",
      "Epoch 3789/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9421 - mse: 932.4854 - val_loss: 20.5603 - val_mse: 932.8254\n",
      "Epoch 3790/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9699 - mse: 932.4892 - val_loss: 20.5611 - val_mse: 934.5798\n",
      "Epoch 3791/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9539 - mse: 939.9924 - val_loss: 20.5821 - val_mse: 918.4592\n",
      "Epoch 3792/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9176 - mse: 934.3472 - val_loss: 20.5654 - val_mse: 938.7562\n",
      "Epoch 3793/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8843 - mse: 933.3495 - val_loss: 20.5721 - val_mse: 922.1505\n",
      "Epoch 3794/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9791 - mse: 933.4950 - val_loss: 20.5706 - val_mse: 942.1875\n",
      "Epoch 3795/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9120 - mse: 927.4963 - val_loss: 20.5680 - val_mse: 940.6398\n",
      "Epoch 3796/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9722 - mse: 937.5648 - val_loss: 20.6064 - val_mse: 912.1736\n",
      "Epoch 3797/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9522 - mse: 930.9528 - val_loss: 20.5685 - val_mse: 923.6832\n",
      "Epoch 3798/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9466 - mse: 933.3994 - val_loss: 20.5612 - val_mse: 927.3931\n",
      "Epoch 3799/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9603 - mse: 932.9717 - val_loss: 20.5748 - val_mse: 921.0596\n",
      "Epoch 3800/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8681 - mse: 925.5551 - val_loss: 20.6092 - val_mse: 957.2941\n",
      "Epoch 3801/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9178 - mse: 934.2055 - val_loss: 20.5745 - val_mse: 944.3523\n",
      "Epoch 3802/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9229 - mse: 941.0198 - val_loss: 20.5694 - val_mse: 923.3121\n",
      "Epoch 3803/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9446 - mse: 927.8958 - val_loss: 20.6358 - val_mse: 963.7997\n",
      "Epoch 3804/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9444 - mse: 935.1816 - val_loss: 20.5687 - val_mse: 941.0394\n",
      "Epoch 3805/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8997 - mse: 931.5660 - val_loss: 20.5607 - val_mse: 927.9558\n",
      "Epoch 3806/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9670 - mse: 929.6240 - val_loss: 20.5734 - val_mse: 943.7828\n",
      "Epoch 3807/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9333 - mse: 932.7102 - val_loss: 20.5769 - val_mse: 945.5350\n",
      "Epoch 3808/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8881 - mse: 930.2926 - val_loss: 20.5676 - val_mse: 924.1138\n",
      "Epoch 3809/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9260 - mse: 924.7602 - val_loss: 20.5682 - val_mse: 923.8464\n",
      "Epoch 3810/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8832 - mse: 937.2701 - val_loss: 20.5791 - val_mse: 919.4877\n",
      "Epoch 3811/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9487 - mse: 931.2906 - val_loss: 20.5967 - val_mse: 914.4384\n",
      "Epoch 3812/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9335 - mse: 928.4063 - val_loss: 20.5611 - val_mse: 934.4604\n",
      "Epoch 3813/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9785 - mse: 939.0883 - val_loss: 20.5783 - val_mse: 946.1594\n",
      "Epoch 3814/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8895 - mse: 930.0936 - val_loss: 20.5645 - val_mse: 938.0139\n",
      "Epoch 3815/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8285 - mse: 923.2722 - val_loss: 20.5608 - val_mse: 927.9027\n",
      "Epoch 3816/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9256 - mse: 935.9766 - val_loss: 20.5616 - val_mse: 927.0706\n",
      "Epoch 3817/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9740 - mse: 927.9050 - val_loss: 20.5609 - val_mse: 927.7965\n",
      "Epoch 3818/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8703 - mse: 935.3600 - val_loss: 20.5601 - val_mse: 932.2675\n",
      "Epoch 3819/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9340 - mse: 926.0917 - val_loss: 20.6238 - val_mse: 961.1938\n",
      "Epoch 3820/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9403 - mse: 940.6670 - val_loss: 20.5608 - val_mse: 933.7648\n",
      "Epoch 3821/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9669 - mse: 936.5802 - val_loss: 20.6149 - val_mse: 958.9366\n",
      "Epoch 3822/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8735 - mse: 918.4158 - val_loss: 20.6675 - val_mse: 969.8727\n",
      "Epoch 3823/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9720 - mse: 936.8259 - val_loss: 20.6134 - val_mse: 958.5129\n",
      "Epoch 3824/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8952 - mse: 938.6392 - val_loss: 20.5609 - val_mse: 927.7938\n",
      "Epoch 3825/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0045 - mse: 935.5824 - val_loss: 20.5638 - val_mse: 925.8187\n",
      "Epoch 3826/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9813 - mse: 939.1515 - val_loss: 20.5764 - val_mse: 945.2696\n",
      "Epoch 3827/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9082 - mse: 926.7742 - val_loss: 20.5797 - val_mse: 946.8116\n",
      "Epoch 3828/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9592 - mse: 938.1546 - val_loss: 20.5998 - val_mse: 954.5069\n",
      "Epoch 3829/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9771 - mse: 931.3499 - val_loss: 20.6834 - val_mse: 972.6002\n",
      "Epoch 3830/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9866 - mse: 941.5895 - val_loss: 20.5808 - val_mse: 947.3202\n",
      "Epoch 3831/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9284 - mse: 927.6525 - val_loss: 20.7128 - val_mse: 977.2980\n",
      "Epoch 3832/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9815 - mse: 940.8645 - val_loss: 20.6078 - val_mse: 956.8760\n",
      "Epoch 3833/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9642 - mse: 936.8334 - val_loss: 20.5889 - val_mse: 950.8296\n",
      "Epoch 3834/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9263 - mse: 923.5858 - val_loss: 20.5849 - val_mse: 949.1661\n",
      "Epoch 3835/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9656 - mse: 940.7482 - val_loss: 20.5633 - val_mse: 926.0679\n",
      "Epoch 3836/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9240 - mse: 935.3842 - val_loss: 20.5921 - val_mse: 951.9706\n",
      "Epoch 3837/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9023 - mse: 926.9205 - val_loss: 20.5999 - val_mse: 954.5181\n",
      "Epoch 3838/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9160 - mse: 932.7433 - val_loss: 20.5599 - val_mse: 929.5794\n",
      "Epoch 3839/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9676 - mse: 935.3185 - val_loss: 20.5611 - val_mse: 934.5138\n",
      "Epoch 3840/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9573 - mse: 929.7281 - val_loss: 20.5737 - val_mse: 943.9235\n",
      "Epoch 3841/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8760 - mse: 938.0156 - val_loss: 20.5606 - val_mse: 933.4720\n",
      "Epoch 3842/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8999 - mse: 925.6114 - val_loss: 20.5827 - val_mse: 948.1792\n",
      "Epoch 3843/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8687 - mse: 931.7293 - val_loss: 20.5679 - val_mse: 940.5612\n",
      "Epoch 3844/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9759 - mse: 932.4610 - val_loss: 20.6269 - val_mse: 961.8967\n",
      "Epoch 3845/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8559 - mse: 931.5088 - val_loss: 20.5754 - val_mse: 944.8104\n",
      "Epoch 3846/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9336 - mse: 944.4171 - val_loss: 20.5699 - val_mse: 923.1042\n",
      "Epoch 3847/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9300 - mse: 926.7723 - val_loss: 20.5919 - val_mse: 951.9112\n",
      "Epoch 3848/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8632 - mse: 931.2784 - val_loss: 20.6011 - val_mse: 954.9016\n",
      "Epoch 3849/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8831 - mse: 930.7174 - val_loss: 20.5650 - val_mse: 938.4205\n",
      "Epoch 3850/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8706 - mse: 938.1453 - val_loss: 20.5766 - val_mse: 920.3958\n",
      "Epoch 3851/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8468 - mse: 926.8518 - val_loss: 20.5985 - val_mse: 954.0819\n",
      "Epoch 3852/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9517 - mse: 936.1755 - val_loss: 20.5642 - val_mse: 937.7844\n",
      "Epoch 3853/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9666 - mse: 938.6375 - val_loss: 20.5612 - val_mse: 934.7905\n",
      "Epoch 3854/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8936 - mse: 927.1387 - val_loss: 20.5599 - val_mse: 929.6425\n",
      "Epoch 3855/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9752 - mse: 942.1196 - val_loss: 20.5613 - val_mse: 927.3160\n",
      "Epoch 3856/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 21.0011 - mse: 930.1822 - val_loss: 20.5999 - val_mse: 913.6288\n",
      "Epoch 3857/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8347 - mse: 924.7642 - val_loss: 20.5609 - val_mse: 927.7373\n",
      "Epoch 3858/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8504 - mse: 923.4658 - val_loss: 20.5615 - val_mse: 935.1475\n",
      "Epoch 3859/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8864 - mse: 937.7630 - val_loss: 20.5926 - val_mse: 915.4977\n",
      "Epoch 3860/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0725 - mse: 938.2910 - val_loss: 20.5600 - val_mse: 931.9925\n",
      "Epoch 3861/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8998 - mse: 922.4541 - val_loss: 20.5616 - val_mse: 935.3861\n",
      "Epoch 3862/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8378 - mse: 925.2340 - val_loss: 20.6459 - val_mse: 965.8798\n",
      "Epoch 3863/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8697 - mse: 929.3594 - val_loss: 20.5988 - val_mse: 954.1712\n",
      "Epoch 3864/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8869 - mse: 927.4322 - val_loss: 20.5609 - val_mse: 927.7167\n",
      "Epoch 3865/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0087 - mse: 936.7642 - val_loss: 20.6784 - val_mse: 971.7499\n",
      "Epoch 3866/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9081 - mse: 926.7740 - val_loss: 20.5604 - val_mse: 932.9592\n",
      "Epoch 3867/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8570 - mse: 926.8052 - val_loss: 20.5719 - val_mse: 942.9177\n",
      "Epoch 3868/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9671 - mse: 937.3205 - val_loss: 20.5630 - val_mse: 936.7607\n",
      "Epoch 3869/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8579 - mse: 923.3372 - val_loss: 20.6230 - val_mse: 961.0160\n",
      "Epoch 3870/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8725 - mse: 926.6052 - val_loss: 20.6158 - val_mse: 959.2036\n",
      "Epoch 3871/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9175 - mse: 929.5693 - val_loss: 20.5844 - val_mse: 948.9175\n",
      "Epoch 3872/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9643 - mse: 938.2431 - val_loss: 20.5967 - val_mse: 953.5008\n",
      "Epoch 3873/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8670 - mse: 927.5143 - val_loss: 20.5681 - val_mse: 923.8687\n",
      "Epoch 3874/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8395 - mse: 927.3744 - val_loss: 20.5598 - val_mse: 930.7100\n",
      "Epoch 3875/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9983 - mse: 932.6501 - val_loss: 20.6405 - val_mse: 964.7765\n",
      "Epoch 3876/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8503 - mse: 925.7964 - val_loss: 20.5620 - val_mse: 935.8589\n",
      "Epoch 3877/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9265 - mse: 936.7679 - val_loss: 20.6685 - val_mse: 970.0480\n",
      "Epoch 3878/5000\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 20.8969 - mse: 917.9906 - val_loss: 20.6306 - val_mse: 962.7244\n",
      "Epoch 3879/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8630 - mse: 933.9727 - val_loss: 20.5716 - val_mse: 942.7531\n",
      "Epoch 3880/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8934 - mse: 931.8511 - val_loss: 20.5627 - val_mse: 936.5753\n",
      "Epoch 3881/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8973 - mse: 929.4973 - val_loss: 20.5628 - val_mse: 936.6373\n",
      "Epoch 3882/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9060 - mse: 935.2415 - val_loss: 20.5676 - val_mse: 940.3259\n",
      "Epoch 3883/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9507 - mse: 931.0855 - val_loss: 20.5976 - val_mse: 914.2047\n",
      "Epoch 3884/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9638 - mse: 930.8873 - val_loss: 20.5748 - val_mse: 921.0898\n",
      "Epoch 3885/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9130 - mse: 928.1658 - val_loss: 20.5706 - val_mse: 942.1979\n",
      "Epoch 3886/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8858 - mse: 941.0120 - val_loss: 20.5927 - val_mse: 915.4700\n",
      "Epoch 3887/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9525 - mse: 931.5883 - val_loss: 20.5611 - val_mse: 934.5134\n",
      "Epoch 3888/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9709 - mse: 930.8462 - val_loss: 20.6721 - val_mse: 970.6793\n",
      "Epoch 3889/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9703 - mse: 939.1913 - val_loss: 20.6173 - val_mse: 959.6075\n",
      "Epoch 3890/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9273 - mse: 927.7988 - val_loss: 20.5818 - val_mse: 947.7499\n",
      "Epoch 3891/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0536 - mse: 937.3892 - val_loss: 20.7170 - val_mse: 977.9501\n",
      "Epoch 3892/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0070 - mse: 940.4562 - val_loss: 20.5666 - val_mse: 924.5300\n",
      "Epoch 3893/5000\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 20.8620 - mse: 927.6750 - val_loss: 20.5656 - val_mse: 938.8467\n",
      "Epoch 3894/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9803 - mse: 925.6931 - val_loss: 20.6065 - val_mse: 956.5020\n",
      "Epoch 3895/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9860 - mse: 943.4656 - val_loss: 20.5657 - val_mse: 938.9305\n",
      "Epoch 3896/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9245 - mse: 934.7298 - val_loss: 20.5633 - val_mse: 926.0950\n",
      "Epoch 3897/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8976 - mse: 929.3508 - val_loss: 20.5914 - val_mse: 951.7202\n",
      "Epoch 3898/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8962 - mse: 928.4534 - val_loss: 20.5643 - val_mse: 937.9011\n",
      "Epoch 3899/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9054 - mse: 936.4647 - val_loss: 20.6025 - val_mse: 913.0377\n",
      "Epoch 3900/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9149 - mse: 927.8729 - val_loss: 20.5603 - val_mse: 932.7247\n",
      "Epoch 3901/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9133 - mse: 925.0588 - val_loss: 20.5598 - val_mse: 931.6073\n",
      "Epoch 3902/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8857 - mse: 928.7895 - val_loss: 20.5885 - val_mse: 950.6633\n",
      "Epoch 3903/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9501 - mse: 930.7546 - val_loss: 20.6611 - val_mse: 968.7578\n",
      "Epoch 3904/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9142 - mse: 925.7449 - val_loss: 20.5687 - val_mse: 923.6159\n",
      "Epoch 3905/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9730 - mse: 931.7331 - val_loss: 20.6398 - val_mse: 964.6189\n",
      "Epoch 3906/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9685 - mse: 932.0775 - val_loss: 20.5599 - val_mse: 931.9244\n",
      "Epoch 3907/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9120 - mse: 932.8787 - val_loss: 20.5700 - val_mse: 923.0191\n",
      "Epoch 3908/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9729 - mse: 935.7712 - val_loss: 20.6034 - val_mse: 955.5909\n",
      "Epoch 3909/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8652 - mse: 930.1383 - val_loss: 20.5706 - val_mse: 942.2029\n",
      "Epoch 3910/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8578 - mse: 940.9178 - val_loss: 20.6283 - val_mse: 907.8530\n",
      "Epoch 3911/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9117 - mse: 930.8876 - val_loss: 20.5687 - val_mse: 941.0785\n",
      "Epoch 3912/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9270 - mse: 932.3750 - val_loss: 20.5691 - val_mse: 923.4563\n",
      "Epoch 3913/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9236 - mse: 930.1154 - val_loss: 20.5648 - val_mse: 938.2809\n",
      "Epoch 3914/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8878 - mse: 926.5547 - val_loss: 20.5650 - val_mse: 925.2596\n",
      "Epoch 3915/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8756 - mse: 923.5436 - val_loss: 20.5773 - val_mse: 945.7177\n",
      "Epoch 3916/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9611 - mse: 922.1949 - val_loss: 20.5644 - val_mse: 937.9458\n",
      "Epoch 3917/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9208 - mse: 948.4979 - val_loss: 20.5803 - val_mse: 947.0854\n",
      "Epoch 3918/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9281 - mse: 942.6864 - val_loss: 20.6404 - val_mse: 905.8291\n",
      "Epoch 3919/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9193 - mse: 928.7799 - val_loss: 20.5610 - val_mse: 927.6000\n",
      "Epoch 3920/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9726 - mse: 930.7170 - val_loss: 20.6490 - val_mse: 966.4975\n",
      "Epoch 3921/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9617 - mse: 938.7303 - val_loss: 20.5927 - val_mse: 952.1777\n",
      "Epoch 3922/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8968 - mse: 930.9429 - val_loss: 20.5678 - val_mse: 940.4613\n",
      "Epoch 3923/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9298 - mse: 930.9570 - val_loss: 20.5724 - val_mse: 943.1764\n",
      "Epoch 3924/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8940 - mse: 941.3119 - val_loss: 20.5639 - val_mse: 925.7693\n",
      "Epoch 3925/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9311 - mse: 931.4342 - val_loss: 20.5644 - val_mse: 937.9387\n",
      "Epoch 3926/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9611 - mse: 928.9207 - val_loss: 20.5822 - val_mse: 947.9433\n",
      "Epoch 3927/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8840 - mse: 936.1868 - val_loss: 20.5599 - val_mse: 931.8580\n",
      "Epoch 3928/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9574 - mse: 928.6194 - val_loss: 20.5980 - val_mse: 953.9150\n",
      "Epoch 3929/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8920 - mse: 935.3024 - val_loss: 20.5599 - val_mse: 930.3838\n",
      "Epoch 3930/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9325 - mse: 935.6998 - val_loss: 20.5608 - val_mse: 927.8845\n",
      "Epoch 3931/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9907 - mse: 938.8072 - val_loss: 20.5855 - val_mse: 949.4390\n",
      "Epoch 3932/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9448 - mse: 936.6480 - val_loss: 20.5953 - val_mse: 953.0441\n",
      "Epoch 3933/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9065 - mse: 934.3356 - val_loss: 20.5636 - val_mse: 925.9239\n",
      "Epoch 3934/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9324 - mse: 925.7872 - val_loss: 20.7931 - val_mse: 989.7665\n",
      "Epoch 3935/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0021 - mse: 935.5716 - val_loss: 20.6096 - val_mse: 957.4182\n",
      "Epoch 3936/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9478 - mse: 934.9804 - val_loss: 20.5722 - val_mse: 922.1050\n",
      "Epoch 3937/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.7740 - mse: 928.5695 - val_loss: 20.5665 - val_mse: 939.5913\n",
      "Epoch 3938/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0039 - mse: 933.4904 - val_loss: 20.5606 - val_mse: 933.2988\n",
      "Epoch 3939/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8753 - mse: 925.0046 - val_loss: 20.5760 - val_mse: 945.1028\n",
      "Epoch 3940/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8872 - mse: 930.8336 - val_loss: 20.5598 - val_mse: 931.6353\n",
      "Epoch 3941/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9034 - mse: 928.4842 - val_loss: 20.6066 - val_mse: 956.5421\n",
      "Epoch 3942/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8896 - mse: 934.0453 - val_loss: 20.5902 - val_mse: 951.3034\n",
      "Epoch 3943/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9456 - mse: 937.9969 - val_loss: 20.5602 - val_mse: 929.0629\n",
      "Epoch 3944/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8838 - mse: 921.9725 - val_loss: 20.6003 - val_mse: 954.6382\n",
      "Epoch 3945/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9361 - mse: 936.7258 - val_loss: 20.5690 - val_mse: 923.4687\n",
      "Epoch 3946/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9774 - mse: 933.9168 - val_loss: 20.5750 - val_mse: 944.6225\n",
      "Epoch 3947/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9058 - mse: 924.3516 - val_loss: 20.5858 - val_mse: 949.5731\n",
      "Epoch 3948/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0496 - mse: 942.2487 - val_loss: 20.5622 - val_mse: 926.6786\n",
      "Epoch 3949/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9015 - mse: 924.8867 - val_loss: 20.5622 - val_mse: 936.0170\n",
      "Epoch 3950/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9278 - mse: 934.0135 - val_loss: 20.5876 - val_mse: 950.3375\n",
      "Epoch 3951/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9632 - mse: 933.8428 - val_loss: 20.5761 - val_mse: 945.1378\n",
      "Epoch 3952/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9004 - mse: 929.9309 - val_loss: 20.5895 - val_mse: 951.0790\n",
      "Epoch 3953/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8841 - mse: 936.1413 - val_loss: 20.5655 - val_mse: 925.0054\n",
      "Epoch 3954/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0584 - mse: 941.8102 - val_loss: 20.5946 - val_mse: 952.8100\n",
      "Epoch 3955/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9568 - mse: 936.4205 - val_loss: 20.5618 - val_mse: 935.6760\n",
      "Epoch 3956/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8443 - mse: 920.6120 - val_loss: 20.6438 - val_mse: 965.4525\n",
      "Epoch 3957/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9016 - mse: 930.3308 - val_loss: 20.5655 - val_mse: 925.0077\n",
      "Epoch 3958/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8892 - mse: 926.9632 - val_loss: 20.5680 - val_mse: 923.9225\n",
      "Epoch 3959/5000\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 20.9446 - mse: 928.3102 - val_loss: 20.5695 - val_mse: 923.2619\n",
      "Epoch 3960/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9168 - mse: 929.9301 - val_loss: 20.6255 - val_mse: 908.3646\n",
      "Epoch 3961/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9500 - mse: 937.5897 - val_loss: 20.5599 - val_mse: 930.1193\n",
      "Epoch 3962/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9228 - mse: 921.8633 - val_loss: 20.5644 - val_mse: 937.9334\n",
      "Epoch 3963/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9681 - mse: 939.0632 - val_loss: 20.5871 - val_mse: 916.9727\n",
      "Epoch 3964/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9656 - mse: 930.6053 - val_loss: 20.5982 - val_mse: 953.9940\n",
      "Epoch 3965/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8902 - mse: 935.6603 - val_loss: 20.5601 - val_mse: 929.1343\n",
      "Epoch 3966/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9272 - mse: 919.5269 - val_loss: 20.7136 - val_mse: 977.4197\n",
      "Epoch 3967/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9139 - mse: 937.2469 - val_loss: 20.5678 - val_mse: 940.4526\n",
      "Epoch 3968/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8875 - mse: 936.2779 - val_loss: 20.5700 - val_mse: 941.8524\n",
      "Epoch 3969/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9133 - mse: 937.4418 - val_loss: 20.5664 - val_mse: 939.5081\n",
      "Epoch 3970/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8958 - mse: 927.8012 - val_loss: 20.5868 - val_mse: 950.0157\n",
      "Epoch 3971/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9188 - mse: 932.9062 - val_loss: 20.5610 - val_mse: 934.2003\n",
      "Epoch 3972/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8202 - mse: 917.5375 - val_loss: 20.5714 - val_mse: 922.4374\n",
      "Epoch 3973/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9376 - mse: 937.4761 - val_loss: 20.5625 - val_mse: 936.3236\n",
      "Epoch 3974/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9426 - mse: 927.6663 - val_loss: 20.5772 - val_mse: 945.6939\n",
      "Epoch 3975/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9487 - mse: 934.8867 - val_loss: 20.5758 - val_mse: 920.6902\n",
      "Epoch 3976/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9471 - mse: 933.5372 - val_loss: 20.5917 - val_mse: 951.8542\n",
      "Epoch 3977/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8898 - mse: 936.4832 - val_loss: 20.5903 - val_mse: 916.1083\n",
      "Epoch 3978/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9339 - mse: 925.9192 - val_loss: 20.5606 - val_mse: 933.4018\n",
      "Epoch 3979/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9132 - mse: 929.7331 - val_loss: 20.5756 - val_mse: 920.7828\n",
      "Epoch 3980/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8110 - mse: 920.9697 - val_loss: 20.8353 - val_mse: 996.0369\n",
      "Epoch 3981/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9319 - mse: 937.1897 - val_loss: 20.5602 - val_mse: 928.9069\n",
      "Epoch 3982/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9131 - mse: 930.9424 - val_loss: 20.5663 - val_mse: 939.3921\n",
      "Epoch 3983/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8817 - mse: 921.7477 - val_loss: 20.7172 - val_mse: 977.9896\n",
      "Epoch 3984/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9459 - mse: 939.9887 - val_loss: 20.6461 - val_mse: 965.9255\n",
      "Epoch 3985/5000\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 20.9060 - mse: 936.8521 - val_loss: 20.5918 - val_mse: 915.7229\n",
      "Epoch 3986/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9637 - mse: 930.0684 - val_loss: 20.5989 - val_mse: 954.2292\n",
      "Epoch 3987/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9325 - mse: 938.1674 - val_loss: 20.6030 - val_mse: 912.9192\n",
      "Epoch 3988/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9542 - mse: 936.4101 - val_loss: 20.5958 - val_mse: 914.6657\n",
      "Epoch 3989/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9729 - mse: 932.6118 - val_loss: 20.5680 - val_mse: 940.6008\n",
      "Epoch 3990/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0120 - mse: 937.0579 - val_loss: 20.5857 - val_mse: 917.3562\n",
      "Epoch 3991/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9243 - mse: 930.6498 - val_loss: 20.6347 - val_mse: 963.5679\n",
      "Epoch 3992/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9977 - mse: 935.1430 - val_loss: 20.5657 - val_mse: 938.9629\n",
      "Epoch 3993/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9570 - mse: 943.3320 - val_loss: 20.5603 - val_mse: 928.6600\n",
      "Epoch 3994/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0054 - mse: 926.2696 - val_loss: 20.5793 - val_mse: 946.6400\n",
      "Epoch 3995/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8589 - mse: 934.1417 - val_loss: 20.5786 - val_mse: 946.3241\n",
      "Epoch 3996/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8955 - mse: 927.1079 - val_loss: 20.6292 - val_mse: 962.4271\n",
      "Epoch 3997/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9017 - mse: 935.4927 - val_loss: 20.5972 - val_mse: 953.6560\n",
      "Epoch 3998/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9128 - mse: 929.2888 - val_loss: 20.5623 - val_mse: 936.1352\n",
      "Epoch 3999/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9768 - mse: 931.7496 - val_loss: 20.5830 - val_mse: 948.2842\n",
      "Epoch 4000/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9025 - mse: 925.9295 - val_loss: 20.6737 - val_mse: 970.9600\n",
      "Epoch 4001/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9174 - mse: 931.7961 - val_loss: 20.5607 - val_mse: 933.5529\n",
      "Epoch 4002/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8394 - mse: 932.4069 - val_loss: 20.5897 - val_mse: 916.2758\n",
      "Epoch 4003/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8604 - mse: 926.4528 - val_loss: 20.5727 - val_mse: 943.3395\n",
      "Epoch 4004/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.7949 - mse: 920.4197 - val_loss: 20.5691 - val_mse: 941.2960\n",
      "Epoch 4005/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9972 - mse: 938.4857 - val_loss: 20.5651 - val_mse: 925.2133\n",
      "Epoch 4006/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8888 - mse: 919.5261 - val_loss: 20.6152 - val_mse: 959.0292\n",
      "Epoch 4007/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8864 - mse: 934.3796 - val_loss: 20.5631 - val_mse: 936.8640\n",
      "Epoch 4008/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9743 - mse: 933.4906 - val_loss: 20.6113 - val_mse: 957.9010\n",
      "Epoch 4009/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9315 - mse: 938.4887 - val_loss: 20.5646 - val_mse: 938.0896\n",
      "Epoch 4010/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8716 - mse: 934.1643 - val_loss: 20.5941 - val_mse: 915.1017\n",
      "Epoch 4011/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0498 - mse: 940.3426 - val_loss: 20.5712 - val_mse: 922.5156\n",
      "Epoch 4012/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8571 - mse: 927.7815 - val_loss: 20.5719 - val_mse: 942.8818\n",
      "Epoch 4013/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9696 - mse: 935.0330 - val_loss: 20.5599 - val_mse: 930.4263\n",
      "Epoch 4014/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9196 - mse: 932.2759 - val_loss: 20.6719 - val_mse: 970.6517\n",
      "Epoch 4015/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9298 - mse: 933.6273 - val_loss: 20.5762 - val_mse: 945.1752\n",
      "Epoch 4016/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8314 - mse: 920.6077 - val_loss: 20.9007 - val_mse: 1005.7488\n",
      "Epoch 4017/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9743 - mse: 944.4096 - val_loss: 20.6400 - val_mse: 964.6641\n",
      "Epoch 4018/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9485 - mse: 942.1426 - val_loss: 20.5731 - val_mse: 943.5795\n",
      "Epoch 4019/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9309 - mse: 931.2762 - val_loss: 20.5624 - val_mse: 936.2434\n",
      "Epoch 4020/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9094 - mse: 933.8955 - val_loss: 20.5612 - val_mse: 934.6694\n",
      "Epoch 4021/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8840 - mse: 922.0916 - val_loss: 20.7041 - val_mse: 975.9463\n",
      "Epoch 4022/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9033 - mse: 942.7844 - val_loss: 20.6271 - val_mse: 908.0719\n",
      "Epoch 4023/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9777 - mse: 935.1442 - val_loss: 20.5692 - val_mse: 941.3923\n",
      "Epoch 4024/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8994 - mse: 924.2471 - val_loss: 20.5633 - val_mse: 926.1127\n",
      "Epoch 4025/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9391 - mse: 935.1763 - val_loss: 20.5624 - val_mse: 936.2751\n",
      "Epoch 4026/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9034 - mse: 928.6762 - val_loss: 20.6392 - val_mse: 964.4950\n",
      "Epoch 4027/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9327 - mse: 931.5037 - val_loss: 20.5701 - val_mse: 922.9899\n",
      "Epoch 4028/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9323 - mse: 933.0444 - val_loss: 20.6368 - val_mse: 964.0068\n",
      "Epoch 4029/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9780 - mse: 939.7856 - val_loss: 20.5927 - val_mse: 952.1796\n",
      "Epoch 4030/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8977 - mse: 932.6874 - val_loss: 20.5631 - val_mse: 926.2137\n",
      "Epoch 4031/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9295 - mse: 926.6480 - val_loss: 20.5610 - val_mse: 934.2427\n",
      "Epoch 4032/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8663 - mse: 920.3263 - val_loss: 20.7104 - val_mse: 976.9364\n",
      "Epoch 4033/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0156 - mse: 937.5824 - val_loss: 20.6082 - val_mse: 957.0152\n",
      "Epoch 4034/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9502 - mse: 936.7866 - val_loss: 20.5797 - val_mse: 946.8167\n",
      "Epoch 4035/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9584 - mse: 942.2427 - val_loss: 20.5687 - val_mse: 923.6311\n",
      "Epoch 4036/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8851 - mse: 932.1390 - val_loss: 20.5821 - val_mse: 947.8973\n",
      "Epoch 4037/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9436 - mse: 928.2454 - val_loss: 20.6296 - val_mse: 962.5204\n",
      "Epoch 4038/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9364 - mse: 935.3560 - val_loss: 20.5640 - val_mse: 925.6860\n",
      "Epoch 4039/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9433 - mse: 925.1230 - val_loss: 20.5722 - val_mse: 943.0668\n",
      "Epoch 4040/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8655 - mse: 932.7191 - val_loss: 20.5598 - val_mse: 931.5779\n",
      "Epoch 4041/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9329 - mse: 930.1356 - val_loss: 20.5682 - val_mse: 940.7713\n",
      "Epoch 4042/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9716 - mse: 932.5171 - val_loss: 20.5643 - val_mse: 925.5590\n",
      "Epoch 4043/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8384 - mse: 918.6774 - val_loss: 20.5642 - val_mse: 937.7899\n",
      "Epoch 4044/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9166 - mse: 932.7653 - val_loss: 20.5754 - val_mse: 944.8021\n",
      "Epoch 4045/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9083 - mse: 920.8687 - val_loss: 20.5907 - val_mse: 951.4807\n",
      "Epoch 4046/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9003 - mse: 938.5280 - val_loss: 20.5648 - val_mse: 925.3398\n",
      "Epoch 4047/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8512 - mse: 929.3664 - val_loss: 20.5635 - val_mse: 925.9781\n",
      "Epoch 4048/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 21.0320 - mse: 933.1413 - val_loss: 20.5734 - val_mse: 943.7602\n",
      "Epoch 4049/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9184 - mse: 934.2388 - val_loss: 20.5803 - val_mse: 919.0758\n",
      "Epoch 4050/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9328 - mse: 922.0040 - val_loss: 20.6044 - val_mse: 955.8834\n",
      "Epoch 4051/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9182 - mse: 934.2670 - val_loss: 20.6122 - val_mse: 958.1710\n",
      "Epoch 4052/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9665 - mse: 938.5173 - val_loss: 20.5688 - val_mse: 941.1154\n",
      "Epoch 4053/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9073 - mse: 938.0851 - val_loss: 20.5939 - val_mse: 915.1652\n",
      "Epoch 4054/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9092 - mse: 930.4798 - val_loss: 20.5635 - val_mse: 937.2615\n",
      "Epoch 4055/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9406 - mse: 930.7039 - val_loss: 20.5741 - val_mse: 944.1435\n",
      "Epoch 4056/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0240 - mse: 944.0170 - val_loss: 20.5609 - val_mse: 927.7238\n",
      "Epoch 4057/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9436 - mse: 928.4274 - val_loss: 20.6168 - val_mse: 909.9909\n",
      "Epoch 4058/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8750 - mse: 926.0595 - val_loss: 20.5634 - val_mse: 937.1964\n",
      "Epoch 4059/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8788 - mse: 919.8036 - val_loss: 20.6626 - val_mse: 969.0235\n",
      "Epoch 4060/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8356 - mse: 939.9182 - val_loss: 20.6362 - val_mse: 906.4967\n",
      "Epoch 4061/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9449 - mse: 928.2978 - val_loss: 20.6098 - val_mse: 957.4550\n",
      "Epoch 4062/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9411 - mse: 932.5938 - val_loss: 20.5624 - val_mse: 936.2367\n",
      "Epoch 4063/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9469 - mse: 937.3343 - val_loss: 20.6083 - val_mse: 911.7648\n",
      "Epoch 4064/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8943 - mse: 926.6614 - val_loss: 20.5738 - val_mse: 943.9911\n",
      "Epoch 4065/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9977 - mse: 932.3373 - val_loss: 20.6484 - val_mse: 966.3865\n",
      "Epoch 4066/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9077 - mse: 928.5098 - val_loss: 20.5602 - val_mse: 928.9252\n",
      "Epoch 4067/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8765 - mse: 929.5302 - val_loss: 20.5879 - val_mse: 916.7615\n",
      "Epoch 4068/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9083 - mse: 925.2756 - val_loss: 20.5634 - val_mse: 937.1528\n",
      "Epoch 4069/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8805 - mse: 929.3548 - val_loss: 20.6111 - val_mse: 957.8308\n",
      "Epoch 4070/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8892 - mse: 933.4507 - val_loss: 20.5654 - val_mse: 938.7290\n",
      "Epoch 4071/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8847 - mse: 927.3489 - val_loss: 20.5843 - val_mse: 948.8984\n",
      "Epoch 4072/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 21.0759 - mse: 942.7260 - val_loss: 20.6358 - val_mse: 963.8017\n",
      "Epoch 4073/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9168 - mse: 925.5287 - val_loss: 20.6077 - val_mse: 956.8473\n",
      "Epoch 4074/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8948 - mse: 928.7542 - val_loss: 20.6085 - val_mse: 957.0923\n",
      "Epoch 4075/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8942 - mse: 935.7154 - val_loss: 20.5689 - val_mse: 941.1933\n",
      "Epoch 4076/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9813 - mse: 924.2307 - val_loss: 20.5976 - val_mse: 953.7866\n",
      "Epoch 4077/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9197 - mse: 936.7003 - val_loss: 20.6178 - val_mse: 959.7413\n",
      "Epoch 4078/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8840 - mse: 931.4852 - val_loss: 20.5628 - val_mse: 926.3596\n",
      "Epoch 4079/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8513 - mse: 931.0423 - val_loss: 20.5693 - val_mse: 923.3613\n",
      "Epoch 4080/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0162 - mse: 936.4971 - val_loss: 20.5760 - val_mse: 920.6363\n",
      "Epoch 4081/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0233 - mse: 934.1445 - val_loss: 20.5672 - val_mse: 924.2794\n",
      "Epoch 4082/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9018 - mse: 931.3570 - val_loss: 20.7441 - val_mse: 982.1473\n",
      "Epoch 4083/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9852 - mse: 939.5040 - val_loss: 20.6049 - val_mse: 956.0237\n",
      "Epoch 4084/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8983 - mse: 932.0735 - val_loss: 20.5606 - val_mse: 928.0894\n",
      "Epoch 4085/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9504 - mse: 931.0609 - val_loss: 20.6068 - val_mse: 956.5915\n",
      "Epoch 4086/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9235 - mse: 930.9729 - val_loss: 20.5660 - val_mse: 939.1542\n",
      "Epoch 4087/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9180 - mse: 933.4282 - val_loss: 20.5879 - val_mse: 916.7723\n",
      "Epoch 4088/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 21.0434 - mse: 942.6740 - val_loss: 20.5605 - val_mse: 933.1814\n",
      "Epoch 4089/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8859 - mse: 932.1607 - val_loss: 20.6326 - val_mse: 963.1373\n",
      "Epoch 4090/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9890 - mse: 939.5864 - val_loss: 20.6097 - val_mse: 957.4379\n",
      "Epoch 4091/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8952 - mse: 917.2491 - val_loss: 20.5813 - val_mse: 947.5113\n",
      "Epoch 4092/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9878 - mse: 937.1636 - val_loss: 20.5884 - val_mse: 950.6334\n",
      "Epoch 4093/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8897 - mse: 938.1943 - val_loss: 20.5601 - val_mse: 932.3185\n",
      "Epoch 4094/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9127 - mse: 923.6832 - val_loss: 20.5616 - val_mse: 935.3972\n",
      "Epoch 4095/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8820 - mse: 927.9146 - val_loss: 20.5802 - val_mse: 947.0235\n",
      "Epoch 4096/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8602 - mse: 922.5106 - val_loss: 20.7449 - val_mse: 982.2825\n",
      "Epoch 4097/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0403 - mse: 954.4989 - val_loss: 20.5650 - val_mse: 938.4117\n",
      "Epoch 4098/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9564 - mse: 935.8610 - val_loss: 20.5639 - val_mse: 937.5616\n",
      "Epoch 4099/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9142 - mse: 928.2310 - val_loss: 20.5629 - val_mse: 936.6816\n",
      "Epoch 4100/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8893 - mse: 926.0397 - val_loss: 20.5637 - val_mse: 937.4062\n",
      "Epoch 4101/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9478 - mse: 937.7039 - val_loss: 20.5771 - val_mse: 945.6179\n",
      "Epoch 4102/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9080 - mse: 928.4107 - val_loss: 20.5866 - val_mse: 949.9174\n",
      "Epoch 4103/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9302 - mse: 932.6071 - val_loss: 20.5658 - val_mse: 939.0593\n",
      "Epoch 4104/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9508 - mse: 933.0934 - val_loss: 20.6609 - val_mse: 968.7152\n",
      "Epoch 4105/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0358 - mse: 943.9012 - val_loss: 20.5676 - val_mse: 924.0878\n",
      "Epoch 4106/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8818 - mse: 928.9194 - val_loss: 20.5654 - val_mse: 925.0538\n",
      "Epoch 4107/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8817 - mse: 925.7233 - val_loss: 20.6128 - val_mse: 958.3406\n",
      "Epoch 4108/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8821 - mse: 924.3237 - val_loss: 20.5938 - val_mse: 952.5417\n",
      "Epoch 4109/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8837 - mse: 928.5098 - val_loss: 20.6018 - val_mse: 955.1115\n",
      "Epoch 4110/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9103 - mse: 932.8735 - val_loss: 20.5613 - val_mse: 927.3243\n",
      "Epoch 4111/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9328 - mse: 933.0286 - val_loss: 20.5862 - val_mse: 917.2125\n",
      "Epoch 4112/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8657 - mse: 939.6707 - val_loss: 20.5851 - val_mse: 949.2601\n",
      "Epoch 4113/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9003 - mse: 931.9463 - val_loss: 20.5702 - val_mse: 922.9585\n",
      "Epoch 4114/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8498 - mse: 930.9470 - val_loss: 20.5611 - val_mse: 934.5048\n",
      "Epoch 4115/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8954 - mse: 925.4177 - val_loss: 20.5667 - val_mse: 939.7546\n",
      "Epoch 4116/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9100 - mse: 944.6060 - val_loss: 20.5650 - val_mse: 925.2675\n",
      "Epoch 4117/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8620 - mse: 924.7153 - val_loss: 20.5796 - val_mse: 946.7535\n",
      "Epoch 4118/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8737 - mse: 930.8235 - val_loss: 20.6210 - val_mse: 960.5406\n",
      "Epoch 4119/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9289 - mse: 926.7036 - val_loss: 20.6359 - val_mse: 963.8096\n",
      "Epoch 4120/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9548 - mse: 942.8613 - val_loss: 20.5780 - val_mse: 946.0554\n",
      "Epoch 4121/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9371 - mse: 925.7103 - val_loss: 20.5999 - val_mse: 954.5102\n",
      "Epoch 4122/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 21.0428 - mse: 942.2040 - val_loss: 20.5634 - val_mse: 926.0381\n",
      "Epoch 4123/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8939 - mse: 932.8863 - val_loss: 20.5662 - val_mse: 939.3365\n",
      "Epoch 4124/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9657 - mse: 938.6258 - val_loss: 20.5879 - val_mse: 916.7709\n",
      "Epoch 4125/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9582 - mse: 921.2082 - val_loss: 20.5634 - val_mse: 937.1371\n",
      "Epoch 4126/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9113 - mse: 936.0842 - val_loss: 20.5598 - val_mse: 931.1721\n",
      "Epoch 4127/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9344 - mse: 936.1414 - val_loss: 20.6018 - val_mse: 913.1877\n",
      "Epoch 4128/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9505 - mse: 932.1649 - val_loss: 20.5839 - val_mse: 917.8958\n",
      "Epoch 4129/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9432 - mse: 932.5219 - val_loss: 20.5702 - val_mse: 941.9386\n",
      "Epoch 4130/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8768 - mse: 923.3109 - val_loss: 20.7616 - val_mse: 984.8859\n",
      "Epoch 4131/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9426 - mse: 935.0073 - val_loss: 20.5609 - val_mse: 934.0770\n",
      "Epoch 4132/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9272 - mse: 927.0832 - val_loss: 20.5872 - val_mse: 950.1644\n",
      "Epoch 4133/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9331 - mse: 928.2809 - val_loss: 20.5608 - val_mse: 933.8364\n",
      "Epoch 4134/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8564 - mse: 928.8428 - val_loss: 20.5650 - val_mse: 938.4419\n",
      "Epoch 4135/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8749 - mse: 928.1252 - val_loss: 20.5665 - val_mse: 939.5781\n",
      "Epoch 4136/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9256 - mse: 933.7663 - val_loss: 20.5610 - val_mse: 934.3356\n",
      "Epoch 4137/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8607 - mse: 924.1895 - val_loss: 20.5992 - val_mse: 954.2927\n",
      "Epoch 4138/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9243 - mse: 936.3439 - val_loss: 20.6168 - val_mse: 959.4767\n",
      "Epoch 4139/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0124 - mse: 932.1254 - val_loss: 20.5685 - val_mse: 940.9534\n",
      "Epoch 4140/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9707 - mse: 940.6697 - val_loss: 20.5733 - val_mse: 921.6497\n",
      "Epoch 4141/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9761 - mse: 932.6285 - val_loss: 20.6754 - val_mse: 971.2414\n",
      "Epoch 4142/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9058 - mse: 930.1631 - val_loss: 20.5668 - val_mse: 924.4401\n",
      "Epoch 4143/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9320 - mse: 932.7147 - val_loss: 20.5669 - val_mse: 939.8951\n",
      "Epoch 4144/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8771 - mse: 923.4949 - val_loss: 20.6307 - val_mse: 962.7400\n",
      "Epoch 4145/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9428 - mse: 941.2996 - val_loss: 20.6202 - val_mse: 960.3442\n",
      "Epoch 4146/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9708 - mse: 933.5402 - val_loss: 20.6142 - val_mse: 958.7473\n",
      "Epoch 4147/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8634 - mse: 932.9641 - val_loss: 20.5854 - val_mse: 917.4352\n",
      "Epoch 4148/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9306 - mse: 922.0165 - val_loss: 20.5957 - val_mse: 953.1763\n",
      "Epoch 4149/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8751 - mse: 934.4491 - val_loss: 20.5623 - val_mse: 926.6127\n",
      "Epoch 4150/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9304 - mse: 925.5951 - val_loss: 20.5611 - val_mse: 934.4783\n",
      "Epoch 4151/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9343 - mse: 939.7269 - val_loss: 20.5611 - val_mse: 934.4785\n",
      "Epoch 4152/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8818 - mse: 927.9474 - val_loss: 20.5645 - val_mse: 938.0530\n",
      "Epoch 4153/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9412 - mse: 936.9437 - val_loss: 20.6438 - val_mse: 965.4556\n",
      "Epoch 4154/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9330 - mse: 931.2527 - val_loss: 20.5630 - val_mse: 936.7748\n",
      "Epoch 4155/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9237 - mse: 933.6582 - val_loss: 20.6663 - val_mse: 969.6592\n",
      "Epoch 4156/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9196 - mse: 926.5211 - val_loss: 20.6165 - val_mse: 959.3890\n",
      "Epoch 4157/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9537 - mse: 944.6845 - val_loss: 20.5603 - val_mse: 932.6656\n",
      "Epoch 4158/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8756 - mse: 931.1413 - val_loss: 20.6002 - val_mse: 954.6121\n",
      "Epoch 4159/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9697 - mse: 933.6899 - val_loss: 20.6475 - val_mse: 966.2031\n",
      "Epoch 4160/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8870 - mse: 926.5632 - val_loss: 20.6124 - val_mse: 958.2073\n",
      "Epoch 4161/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9032 - mse: 935.9319 - val_loss: 20.6135 - val_mse: 958.5258\n",
      "Epoch 4162/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9362 - mse: 933.4885 - val_loss: 20.8039 - val_mse: 991.3953\n",
      "Epoch 4163/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 21.0289 - mse: 944.2546 - val_loss: 20.6303 - val_mse: 962.6586\n",
      "Epoch 4164/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9256 - mse: 932.4777 - val_loss: 20.5599 - val_mse: 931.8894\n",
      "Epoch 4165/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9505 - mse: 935.1954 - val_loss: 20.5598 - val_mse: 931.6619\n",
      "Epoch 4166/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8948 - mse: 922.4798 - val_loss: 20.5664 - val_mse: 939.4648\n",
      "Epoch 4167/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8915 - mse: 931.3931 - val_loss: 20.5723 - val_mse: 943.1338\n",
      "Epoch 4168/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9458 - mse: 938.8059 - val_loss: 20.5836 - val_mse: 948.5933\n",
      "Epoch 4169/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9512 - mse: 930.2072 - val_loss: 20.6009 - val_mse: 954.8267\n",
      "Epoch 4170/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9364 - mse: 925.7621 - val_loss: 20.5916 - val_mse: 951.8212\n",
      "Epoch 4171/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0011 - mse: 943.4922 - val_loss: 20.5621 - val_mse: 935.9954\n",
      "Epoch 4172/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0142 - mse: 927.7506 - val_loss: 20.5964 - val_mse: 953.3985\n",
      "Epoch 4173/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9782 - mse: 940.0378 - val_loss: 20.5807 - val_mse: 947.2437\n",
      "Epoch 4174/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8467 - mse: 924.5208 - val_loss: 20.7125 - val_mse: 977.2529\n",
      "Epoch 4175/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9461 - mse: 937.6946 - val_loss: 20.5925 - val_mse: 915.5374\n",
      "Epoch 4176/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9820 - mse: 933.6187 - val_loss: 20.5615 - val_mse: 935.2386\n",
      "Epoch 4177/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8835 - mse: 924.4202 - val_loss: 20.6589 - val_mse: 968.3667\n",
      "Epoch 4178/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 21.0036 - mse: 936.5142 - val_loss: 20.5795 - val_mse: 946.7048\n",
      "Epoch 4179/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9973 - mse: 943.2587 - val_loss: 20.5865 - val_mse: 949.8725\n",
      "Epoch 4180/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8395 - mse: 928.5521 - val_loss: 20.5767 - val_mse: 945.4559\n",
      "Epoch 4181/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8439 - mse: 924.7267 - val_loss: 20.6178 - val_mse: 959.7285\n",
      "Epoch 4182/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9423 - mse: 926.7373 - val_loss: 20.5654 - val_mse: 938.7266\n",
      "Epoch 4183/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8541 - mse: 936.0172 - val_loss: 20.5600 - val_mse: 929.4265\n",
      "Epoch 4184/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9501 - mse: 932.4863 - val_loss: 20.5747 - val_mse: 921.0992\n",
      "Epoch 4185/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8667 - mse: 925.7700 - val_loss: 20.5755 - val_mse: 920.7840\n",
      "Epoch 4186/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9748 - mse: 929.6724 - val_loss: 20.6933 - val_mse: 974.2314\n",
      "Epoch 4187/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9239 - mse: 931.1761 - val_loss: 20.5647 - val_mse: 938.1976\n",
      "Epoch 4188/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9107 - mse: 927.5569 - val_loss: 20.5631 - val_mse: 936.9058\n",
      "Epoch 4189/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9097 - mse: 935.2226 - val_loss: 20.5836 - val_mse: 917.9858\n",
      "Epoch 4190/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9965 - mse: 933.9235 - val_loss: 20.5962 - val_mse: 953.3428\n",
      "Epoch 4191/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9411 - mse: 927.0873 - val_loss: 20.5617 - val_mse: 935.5765\n",
      "Epoch 4192/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9565 - mse: 932.1212 - val_loss: 20.6149 - val_mse: 958.9337\n",
      "Epoch 4193/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0035 - mse: 931.1727 - val_loss: 20.6384 - val_mse: 964.3318\n",
      "Epoch 4194/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8619 - mse: 930.4731 - val_loss: 20.5601 - val_mse: 929.0833\n",
      "Epoch 4195/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9877 - mse: 933.0963 - val_loss: 20.5598 - val_mse: 931.0083\n",
      "Epoch 4196/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8852 - mse: 930.4973 - val_loss: 20.6024 - val_mse: 955.2915\n",
      "Epoch 4197/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8554 - mse: 930.6565 - val_loss: 20.5621 - val_mse: 926.7583\n",
      "Epoch 4198/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8799 - mse: 922.3036 - val_loss: 20.5753 - val_mse: 944.7759\n",
      "Epoch 4199/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9272 - mse: 932.2274 - val_loss: 20.5605 - val_mse: 933.2708\n",
      "Epoch 4200/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9428 - mse: 943.1050 - val_loss: 20.5667 - val_mse: 924.4864\n",
      "Epoch 4201/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8664 - mse: 926.9289 - val_loss: 20.6073 - val_mse: 956.7463\n",
      "Epoch 4202/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9106 - mse: 929.8053 - val_loss: 20.5655 - val_mse: 925.0190\n",
      "Epoch 4203/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8859 - mse: 924.2491 - val_loss: 20.5600 - val_mse: 929.3929\n",
      "Epoch 4204/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9446 - mse: 928.5029 - val_loss: 20.5609 - val_mse: 934.0489\n",
      "Epoch 4205/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8975 - mse: 929.3940 - val_loss: 20.6438 - val_mse: 965.4658\n",
      "Epoch 4206/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8881 - mse: 931.1064 - val_loss: 20.5599 - val_mse: 929.7923\n",
      "Epoch 4207/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8978 - mse: 933.6874 - val_loss: 20.5603 - val_mse: 932.6658\n",
      "Epoch 4208/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9031 - mse: 931.7726 - val_loss: 20.5870 - val_mse: 950.0771\n",
      "Epoch 4209/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9413 - mse: 936.5351 - val_loss: 20.6001 - val_mse: 954.5804\n",
      "Epoch 4210/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8941 - mse: 926.4730 - val_loss: 20.5648 - val_mse: 938.2906\n",
      "Epoch 4211/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9498 - mse: 939.1102 - val_loss: 20.5752 - val_mse: 944.7175\n",
      "Epoch 4212/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9226 - mse: 936.2828 - val_loss: 20.5910 - val_mse: 951.6112\n",
      "Epoch 4213/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9372 - mse: 932.7218 - val_loss: 20.5667 - val_mse: 924.5064\n",
      "Epoch 4214/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9121 - mse: 930.9514 - val_loss: 20.6507 - val_mse: 904.2346\n",
      "Epoch 4215/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8691 - mse: 924.2337 - val_loss: 20.5963 - val_mse: 953.3650\n",
      "Epoch 4216/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9511 - mse: 939.7187 - val_loss: 20.5772 - val_mse: 920.1940\n",
      "Epoch 4217/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8409 - mse: 925.7012 - val_loss: 20.5701 - val_mse: 922.9843\n",
      "Epoch 4218/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9772 - mse: 923.7518 - val_loss: 20.5693 - val_mse: 941.4365\n",
      "Epoch 4219/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9101 - mse: 938.6815 - val_loss: 20.5962 - val_mse: 914.5582\n",
      "Epoch 4220/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9705 - mse: 932.7538 - val_loss: 20.6406 - val_mse: 964.7873\n",
      "Epoch 4221/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9110 - mse: 932.3063 - val_loss: 20.5628 - val_mse: 936.6180\n",
      "Epoch 4222/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9129 - mse: 935.6207 - val_loss: 20.5638 - val_mse: 937.4727\n",
      "Epoch 4223/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8690 - mse: 928.8035 - val_loss: 20.6069 - val_mse: 956.6307\n",
      "Epoch 4224/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9002 - mse: 932.8881 - val_loss: 20.5651 - val_mse: 938.5054\n",
      "Epoch 4225/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9439 - mse: 930.0305 - val_loss: 20.5984 - val_mse: 954.0482\n",
      "Epoch 4226/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9535 - mse: 939.0388 - val_loss: 20.5604 - val_mse: 928.4697\n",
      "Epoch 4227/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9371 - mse: 931.6849 - val_loss: 20.5605 - val_mse: 928.4144\n",
      "Epoch 4228/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9481 - mse: 930.7438 - val_loss: 20.5708 - val_mse: 942.2848\n",
      "Epoch 4229/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9041 - mse: 937.7031 - val_loss: 20.5745 - val_mse: 944.3285\n",
      "Epoch 4230/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9557 - mse: 936.0549 - val_loss: 20.5652 - val_mse: 925.1467\n",
      "Epoch 4231/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9865 - mse: 937.1487 - val_loss: 20.5598 - val_mse: 931.6516\n",
      "Epoch 4232/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9772 - mse: 928.7643 - val_loss: 20.5659 - val_mse: 939.1375\n",
      "Epoch 4233/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8655 - mse: 927.1124 - val_loss: 20.5689 - val_mse: 941.1969\n",
      "Epoch 4234/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8278 - mse: 924.5604 - val_loss: 20.5937 - val_mse: 952.5014\n",
      "Epoch 4235/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9374 - mse: 934.6158 - val_loss: 20.5673 - val_mse: 940.1395\n",
      "Epoch 4236/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8756 - mse: 930.5338 - val_loss: 20.5675 - val_mse: 940.2908\n",
      "Epoch 4237/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9300 - mse: 926.7018 - val_loss: 20.6292 - val_mse: 962.4308\n",
      "Epoch 4238/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9088 - mse: 935.1648 - val_loss: 20.5962 - val_mse: 953.3377\n",
      "Epoch 4239/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8896 - mse: 931.7496 - val_loss: 20.5659 - val_mse: 924.8613\n",
      "Epoch 4240/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9526 - mse: 935.6127 - val_loss: 20.5600 - val_mse: 929.5025\n",
      "Epoch 4241/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9100 - mse: 927.0677 - val_loss: 20.5621 - val_mse: 936.0100\n",
      "Epoch 4242/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0150 - mse: 940.7617 - val_loss: 20.6255 - val_mse: 961.5987\n",
      "Epoch 4243/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9110 - mse: 929.4332 - val_loss: 20.6583 - val_mse: 903.1609\n",
      "Epoch 4244/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9489 - mse: 933.0881 - val_loss: 20.6660 - val_mse: 902.1190\n",
      "Epoch 4245/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 21.0191 - mse: 935.8855 - val_loss: 20.6529 - val_mse: 903.9225\n",
      "Epoch 4246/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9198 - mse: 928.2504 - val_loss: 20.5599 - val_mse: 930.2965\n",
      "Epoch 4247/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9611 - mse: 925.2139 - val_loss: 20.5644 - val_mse: 925.5352\n",
      "Epoch 4248/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8255 - mse: 928.2127 - val_loss: 20.5773 - val_mse: 920.1398\n",
      "Epoch 4249/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9457 - mse: 938.4220 - val_loss: 20.6333 - val_mse: 963.2849\n",
      "Epoch 4250/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9416 - mse: 931.6415 - val_loss: 20.6256 - val_mse: 961.6054\n",
      "Epoch 4251/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8955 - mse: 928.7331 - val_loss: 20.5879 - val_mse: 950.4569\n",
      "Epoch 4252/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9785 - mse: 940.0862 - val_loss: 20.5606 - val_mse: 933.4954\n",
      "Epoch 4253/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 21.0060 - mse: 932.7992 - val_loss: 20.5632 - val_mse: 936.9943\n",
      "Epoch 4254/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8628 - mse: 930.4605 - val_loss: 20.5641 - val_mse: 937.7327\n",
      "Epoch 4255/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8892 - mse: 929.3999 - val_loss: 20.5633 - val_mse: 926.0790\n",
      "Epoch 4256/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8641 - mse: 928.8447 - val_loss: 20.5600 - val_mse: 931.9935\n",
      "Epoch 4257/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8875 - mse: 924.8186 - val_loss: 20.6175 - val_mse: 959.6538\n",
      "Epoch 4258/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9017 - mse: 936.9272 - val_loss: 20.5672 - val_mse: 940.0808\n",
      "Epoch 4259/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8986 - mse: 926.5251 - val_loss: 20.5734 - val_mse: 943.7657\n",
      "Epoch 4260/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9381 - mse: 926.8831 - val_loss: 20.5607 - val_mse: 933.6615\n",
      "Epoch 4261/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9259 - mse: 940.7906 - val_loss: 20.5686 - val_mse: 941.0302\n",
      "Epoch 4262/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9189 - mse: 934.1359 - val_loss: 20.6144 - val_mse: 958.7827\n",
      "Epoch 4263/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9420 - mse: 942.0900 - val_loss: 20.5604 - val_mse: 933.0427\n",
      "Epoch 4264/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8995 - mse: 927.0893 - val_loss: 20.6045 - val_mse: 955.9181\n",
      "Epoch 4265/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9139 - mse: 936.7949 - val_loss: 20.5598 - val_mse: 930.8220\n",
      "Epoch 4266/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9129 - mse: 922.3400 - val_loss: 20.5912 - val_mse: 951.6810\n",
      "Epoch 4267/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8693 - mse: 934.9385 - val_loss: 20.5896 - val_mse: 951.0950\n",
      "Epoch 4268/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8945 - mse: 925.0815 - val_loss: 20.6083 - val_mse: 957.0367\n",
      "Epoch 4269/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9901 - mse: 945.8179 - val_loss: 20.5674 - val_mse: 940.2304\n",
      "Epoch 4270/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0140 - mse: 931.7013 - val_loss: 20.5814 - val_mse: 947.5706\n",
      "Epoch 4271/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8794 - mse: 927.3276 - val_loss: 20.7297 - val_mse: 979.9324\n",
      "Epoch 4272/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9069 - mse: 929.0185 - val_loss: 20.6935 - val_mse: 974.2629\n",
      "Epoch 4273/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9072 - mse: 935.6655 - val_loss: 20.5633 - val_mse: 937.1075\n",
      "Epoch 4274/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9216 - mse: 928.6702 - val_loss: 20.5621 - val_mse: 926.7643\n",
      "Epoch 4275/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8866 - mse: 934.4183 - val_loss: 20.5606 - val_mse: 928.1919\n",
      "Epoch 4276/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9011 - mse: 935.9418 - val_loss: 20.5732 - val_mse: 943.6498\n",
      "Epoch 4277/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9292 - mse: 939.0491 - val_loss: 20.5688 - val_mse: 941.1152\n",
      "Epoch 4278/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8895 - mse: 921.3059 - val_loss: 20.6161 - val_mse: 959.2844\n",
      "Epoch 4279/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8848 - mse: 927.5624 - val_loss: 20.5861 - val_mse: 949.6934\n",
      "Epoch 4280/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9607 - mse: 939.6025 - val_loss: 20.6372 - val_mse: 964.0904\n",
      "Epoch 4281/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9313 - mse: 936.2792 - val_loss: 20.5802 - val_mse: 947.0455\n",
      "Epoch 4282/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9042 - mse: 922.7479 - val_loss: 20.6736 - val_mse: 970.9391\n",
      "Epoch 4283/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8771 - mse: 933.4366 - val_loss: 20.5887 - val_mse: 950.7461\n",
      "Epoch 4284/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9640 - mse: 942.8871 - val_loss: 20.5620 - val_mse: 935.9061\n",
      "Epoch 4285/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9315 - mse: 926.1976 - val_loss: 20.6300 - val_mse: 962.5925\n",
      "Epoch 4286/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9504 - mse: 937.0096 - val_loss: 20.5725 - val_mse: 921.9717\n",
      "Epoch 4287/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9495 - mse: 924.2561 - val_loss: 20.5708 - val_mse: 922.6813\n",
      "Epoch 4288/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9462 - mse: 926.6931 - val_loss: 20.5639 - val_mse: 925.7509\n",
      "Epoch 4289/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9188 - mse: 934.5632 - val_loss: 20.5604 - val_mse: 928.5644\n",
      "Epoch 4290/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9119 - mse: 928.7782 - val_loss: 20.5808 - val_mse: 947.2827\n",
      "Epoch 4291/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9047 - mse: 924.0024 - val_loss: 20.6176 - val_mse: 959.6829\n",
      "Epoch 4292/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9345 - mse: 943.0077 - val_loss: 20.5598 - val_mse: 931.4010\n",
      "Epoch 4293/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8814 - mse: 924.0760 - val_loss: 20.5942 - val_mse: 952.7069\n",
      "Epoch 4294/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9388 - mse: 927.6465 - val_loss: 20.6192 - val_mse: 960.0850\n",
      "Epoch 4295/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0081 - mse: 934.2339 - val_loss: 20.6258 - val_mse: 961.6517\n",
      "Epoch 4296/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9432 - mse: 937.9787 - val_loss: 20.6260 - val_mse: 961.7051\n",
      "Epoch 4297/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9067 - mse: 931.8110 - val_loss: 20.6403 - val_mse: 964.7277\n",
      "Epoch 4298/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9744 - mse: 940.1661 - val_loss: 20.5661 - val_mse: 939.2550\n",
      "Epoch 4299/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8426 - mse: 936.9717 - val_loss: 20.5801 - val_mse: 946.9764\n",
      "Epoch 4300/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9029 - mse: 931.3723 - val_loss: 20.5680 - val_mse: 940.6389\n",
      "Epoch 4301/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9970 - mse: 928.7653 - val_loss: 20.5705 - val_mse: 942.1385\n",
      "Epoch 4302/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9073 - mse: 932.7347 - val_loss: 20.5671 - val_mse: 940.0154\n",
      "Epoch 4303/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9086 - mse: 927.0723 - val_loss: 20.5657 - val_mse: 938.9714\n",
      "Epoch 4304/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9200 - mse: 936.7047 - val_loss: 20.5598 - val_mse: 931.5298\n",
      "Epoch 4305/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9003 - mse: 932.7109 - val_loss: 20.5765 - val_mse: 920.4478\n",
      "Epoch 4306/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9309 - mse: 926.4575 - val_loss: 20.5629 - val_mse: 936.7252\n",
      "Epoch 4307/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9608 - mse: 922.5145 - val_loss: 20.6091 - val_mse: 957.2646\n",
      "Epoch 4308/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9290 - mse: 930.6811 - val_loss: 20.5651 - val_mse: 938.5204\n",
      "Epoch 4309/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8327 - mse: 930.7940 - val_loss: 20.5875 - val_mse: 916.8763\n",
      "Epoch 4310/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8718 - mse: 927.3043 - val_loss: 20.6038 - val_mse: 955.6964\n",
      "Epoch 4311/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9239 - mse: 928.1968 - val_loss: 20.6643 - val_mse: 969.3186\n",
      "Epoch 4312/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9391 - mse: 935.9357 - val_loss: 20.5651 - val_mse: 938.5360\n",
      "Epoch 4313/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9414 - mse: 931.8525 - val_loss: 20.5953 - val_mse: 914.8026\n",
      "Epoch 4314/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9128 - mse: 926.9066 - val_loss: 20.5824 - val_mse: 948.0308\n",
      "Epoch 4315/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9791 - mse: 941.5815 - val_loss: 20.5857 - val_mse: 917.3553\n",
      "Epoch 4316/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8511 - mse: 924.2911 - val_loss: 20.5764 - val_mse: 920.4634\n",
      "Epoch 4317/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9147 - mse: 931.2970 - val_loss: 20.5608 - val_mse: 933.8875\n",
      "Epoch 4318/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8882 - mse: 921.8656 - val_loss: 20.6392 - val_mse: 964.5032\n",
      "Epoch 4319/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9510 - mse: 940.8815 - val_loss: 20.5668 - val_mse: 939.7934\n",
      "Epoch 4320/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8698 - mse: 926.6865 - val_loss: 20.6140 - val_mse: 958.6772\n",
      "Epoch 4321/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8471 - mse: 931.9143 - val_loss: 20.5821 - val_mse: 918.4744\n",
      "Epoch 4322/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9299 - mse: 928.6978 - val_loss: 20.6260 - val_mse: 961.7029\n",
      "Epoch 4323/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8898 - mse: 930.0497 - val_loss: 20.5638 - val_mse: 925.8029\n",
      "Epoch 4324/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9639 - mse: 935.2972 - val_loss: 20.5614 - val_mse: 935.0546\n",
      "Epoch 4325/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9035 - mse: 931.5948 - val_loss: 20.5723 - val_mse: 943.1558\n",
      "Epoch 4326/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.7811 - mse: 927.4552 - val_loss: 20.5615 - val_mse: 935.1635\n",
      "Epoch 4327/5000\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 20.8477 - mse: 924.6556 - val_loss: 20.6174 - val_mse: 959.6240\n",
      "Epoch 4328/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9907 - mse: 935.3702 - val_loss: 20.6218 - val_mse: 960.7328\n",
      "Epoch 4329/5000\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 20.9268 - mse: 928.3536 - val_loss: 20.6452 - val_mse: 965.7386\n",
      "Epoch 4330/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.7969 - mse: 934.6129 - val_loss: 20.5646 - val_mse: 925.4189\n",
      "Epoch 4331/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9491 - mse: 933.9969 - val_loss: 20.5604 - val_mse: 933.0092\n",
      "Epoch 4332/5000\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 20.9469 - mse: 932.0472 - val_loss: 20.5648 - val_mse: 938.2518\n",
      "Epoch 4333/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9143 - mse: 931.6496 - val_loss: 20.5614 - val_mse: 935.0835\n",
      "Epoch 4334/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9137 - mse: 931.7878 - val_loss: 20.5610 - val_mse: 927.6362\n",
      "Epoch 4335/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9197 - mse: 930.5632 - val_loss: 20.5724 - val_mse: 943.1799\n",
      "Epoch 4336/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8945 - mse: 930.0484 - val_loss: 20.5607 - val_mse: 933.5204\n",
      "Epoch 4337/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8505 - mse: 931.4368 - val_loss: 20.5900 - val_mse: 916.2073\n",
      "Epoch 4338/5000\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 20.9146 - mse: 925.1724 - val_loss: 20.6068 - val_mse: 956.5844\n",
      "Epoch 4339/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8819 - mse: 928.9228 - val_loss: 20.5604 - val_mse: 932.9308\n",
      "Epoch 4340/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9825 - mse: 934.3625 - val_loss: 20.5627 - val_mse: 936.5637\n",
      "Epoch 4341/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9223 - mse: 923.8152 - val_loss: 20.7439 - val_mse: 982.1260\n",
      "Epoch 4342/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9040 - mse: 942.5776 - val_loss: 20.5599 - val_mse: 929.7427\n",
      "Epoch 4343/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9082 - mse: 923.9411 - val_loss: 20.5803 - val_mse: 947.0715\n",
      "Epoch 4344/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8512 - mse: 921.7687 - val_loss: 20.7556 - val_mse: 983.9481\n",
      "Epoch 4345/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9073 - mse: 935.3000 - val_loss: 20.5603 - val_mse: 932.7277\n",
      "Epoch 4346/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9178 - mse: 938.4620 - val_loss: 20.5598 - val_mse: 930.9658\n",
      "Epoch 4347/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9690 - mse: 929.7056 - val_loss: 20.5699 - val_mse: 923.0740\n",
      "Epoch 4348/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8934 - mse: 924.6682 - val_loss: 20.5609 - val_mse: 934.0146\n",
      "Epoch 4349/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8765 - mse: 926.3793 - val_loss: 20.5643 - val_mse: 937.8864\n",
      "Epoch 4350/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8753 - mse: 928.3118 - val_loss: 20.5697 - val_mse: 941.6910\n",
      "Epoch 4351/5000\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 20.9974 - mse: 922.6268 - val_loss: 20.6699 - val_mse: 970.3073\n",
      "Epoch 4352/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9098 - mse: 933.9969 - val_loss: 20.6413 - val_mse: 964.9305\n",
      "Epoch 4353/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8940 - mse: 925.9681 - val_loss: 20.5612 - val_mse: 934.7795\n",
      "Epoch 4354/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8003 - mse: 927.6363 - val_loss: 20.5781 - val_mse: 946.0992\n",
      "Epoch 4355/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8567 - mse: 933.4348 - val_loss: 20.5773 - val_mse: 945.7025\n",
      "Epoch 4356/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9502 - mse: 932.0264 - val_loss: 20.5826 - val_mse: 948.1038\n",
      "Epoch 4357/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9366 - mse: 937.7744 - val_loss: 20.5761 - val_mse: 945.1418\n",
      "Epoch 4358/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9433 - mse: 936.0745 - val_loss: 20.5624 - val_mse: 936.2519\n",
      "Epoch 4359/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9888 - mse: 926.5870 - val_loss: 20.5603 - val_mse: 932.8084\n",
      "Epoch 4360/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8890 - mse: 930.5505 - val_loss: 20.5645 - val_mse: 938.0427\n",
      "Epoch 4361/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8624 - mse: 931.5972 - val_loss: 20.5733 - val_mse: 943.7039\n",
      "Epoch 4362/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9762 - mse: 936.7529 - val_loss: 20.6337 - val_mse: 963.3531\n",
      "Epoch 4363/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9361 - mse: 928.6373 - val_loss: 20.5641 - val_mse: 937.7352\n",
      "Epoch 4364/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9045 - mse: 934.2932 - val_loss: 20.5801 - val_mse: 946.9986\n",
      "Epoch 4365/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9482 - mse: 928.8790 - val_loss: 20.5689 - val_mse: 941.1784\n",
      "Epoch 4366/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8949 - mse: 927.8412 - val_loss: 20.5662 - val_mse: 939.3738\n",
      "Epoch 4367/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9425 - mse: 936.4106 - val_loss: 20.5854 - val_mse: 949.3942\n",
      "Epoch 4368/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9169 - mse: 938.0483 - val_loss: 20.5792 - val_mse: 919.4762\n",
      "Epoch 4369/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8682 - mse: 924.9143 - val_loss: 20.5890 - val_mse: 950.9005\n",
      "Epoch 4370/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9124 - mse: 932.4939 - val_loss: 20.5758 - val_mse: 945.0202\n",
      "Epoch 4371/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8966 - mse: 928.4153 - val_loss: 20.6006 - val_mse: 954.7505\n",
      "Epoch 4372/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9233 - mse: 928.4084 - val_loss: 20.5900 - val_mse: 951.2525\n",
      "Epoch 4373/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9528 - mse: 934.6821 - val_loss: 20.5704 - val_mse: 942.0547\n",
      "Epoch 4374/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9403 - mse: 935.7508 - val_loss: 20.5719 - val_mse: 942.8983\n",
      "Epoch 4375/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8506 - mse: 936.4495 - val_loss: 20.6044 - val_mse: 912.6281\n",
      "Epoch 4376/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9483 - mse: 934.3610 - val_loss: 20.5838 - val_mse: 917.9219\n",
      "Epoch 4377/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8715 - mse: 919.3597 - val_loss: 20.7314 - val_mse: 980.1986\n",
      "Epoch 4378/5000\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 20.8680 - mse: 935.0448 - val_loss: 20.6573 - val_mse: 968.0987\n",
      "Epoch 4379/5000\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 20.9881 - mse: 943.7870 - val_loss: 20.5812 - val_mse: 918.7653\n",
      "Epoch 4380/5000\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 20.9824 - mse: 935.3511 - val_loss: 20.5635 - val_mse: 937.2094\n",
      "Epoch 4381/5000\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 20.9275 - mse: 929.3195 - val_loss: 20.6159 - val_mse: 959.2148\n",
      "Epoch 4382/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9478 - mse: 935.7865 - val_loss: 20.6225 - val_mse: 960.8979\n",
      "Epoch 4383/5000\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 20.9137 - mse: 929.0852 - val_loss: 20.6478 - val_mse: 966.2587\n",
      "Epoch 4384/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 21.0219 - mse: 943.5416 - val_loss: 20.6296 - val_mse: 962.5095\n",
      "Epoch 4385/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9246 - mse: 932.0374 - val_loss: 20.5767 - val_mse: 945.4110\n",
      "Epoch 4386/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9225 - mse: 933.1373 - val_loss: 20.5656 - val_mse: 938.9054\n",
      "Epoch 4387/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9312 - mse: 924.9631 - val_loss: 20.5611 - val_mse: 934.4242\n",
      "Epoch 4388/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9486 - mse: 931.9119 - val_loss: 20.5646 - val_mse: 925.4457\n",
      "Epoch 4389/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9356 - mse: 926.4457 - val_loss: 20.7391 - val_mse: 981.3795\n",
      "Epoch 4390/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9386 - mse: 932.9034 - val_loss: 20.6570 - val_mse: 968.0412\n",
      "Epoch 4391/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8609 - mse: 942.8784 - val_loss: 20.5717 - val_mse: 922.3087\n",
      "Epoch 4392/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9415 - mse: 930.8839 - val_loss: 20.5740 - val_mse: 944.0917\n",
      "Epoch 4393/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9716 - mse: 940.4404 - val_loss: 20.5709 - val_mse: 942.3479\n",
      "Epoch 4394/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8838 - mse: 931.7882 - val_loss: 20.5643 - val_mse: 937.8702\n",
      "Epoch 4395/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9524 - mse: 930.7156 - val_loss: 20.6728 - val_mse: 970.8082\n",
      "Epoch 4396/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9569 - mse: 931.0075 - val_loss: 20.7161 - val_mse: 977.8177\n",
      "Epoch 4397/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9689 - mse: 935.6844 - val_loss: 20.5783 - val_mse: 919.7737\n",
      "Epoch 4398/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8598 - mse: 928.0643 - val_loss: 20.5864 - val_mse: 949.8364\n",
      "Epoch 4399/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8965 - mse: 929.7325 - val_loss: 20.6295 - val_mse: 962.4862\n",
      "Epoch 4400/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9008 - mse: 931.6835 - val_loss: 20.5764 - val_mse: 945.2919\n",
      "Epoch 4401/5000\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 20.8637 - mse: 937.2565 - val_loss: 20.6388 - val_mse: 906.0892\n",
      "Epoch 4402/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8975 - mse: 927.1463 - val_loss: 20.5608 - val_mse: 933.7571\n",
      "Epoch 4403/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8606 - mse: 925.8184 - val_loss: 20.5720 - val_mse: 942.9762\n",
      "Epoch 4404/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9374 - mse: 930.5023 - val_loss: 20.5666 - val_mse: 924.5284\n",
      "Epoch 4405/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9562 - mse: 933.5920 - val_loss: 20.5690 - val_mse: 941.2641\n",
      "Epoch 4406/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9721 - mse: 935.5857 - val_loss: 20.5731 - val_mse: 921.7598\n",
      "Epoch 4407/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9127 - mse: 927.1382 - val_loss: 20.5649 - val_mse: 925.2972\n",
      "Epoch 4408/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9147 - mse: 938.7230 - val_loss: 20.5765 - val_mse: 945.3414\n",
      "Epoch 4409/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8916 - mse: 934.0812 - val_loss: 20.5638 - val_mse: 925.7999\n",
      "Epoch 4410/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0108 - mse: 925.0763 - val_loss: 20.5607 - val_mse: 928.0813\n",
      "Epoch 4411/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 21.0058 - mse: 936.9854 - val_loss: 20.5604 - val_mse: 932.9059\n",
      "Epoch 4412/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8695 - mse: 931.8946 - val_loss: 20.5724 - val_mse: 943.1642\n",
      "Epoch 4413/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9474 - mse: 930.9854 - val_loss: 20.6122 - val_mse: 958.1699\n",
      "Epoch 4414/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9653 - mse: 935.8761 - val_loss: 20.5598 - val_mse: 931.1696\n",
      "Epoch 4415/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9809 - mse: 938.0666 - val_loss: 20.5726 - val_mse: 921.9512\n",
      "Epoch 4416/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8739 - mse: 921.9623 - val_loss: 20.5624 - val_mse: 936.2704\n",
      "Epoch 4417/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9263 - mse: 942.4449 - val_loss: 20.6290 - val_mse: 907.7367\n",
      "Epoch 4418/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9860 - mse: 923.3161 - val_loss: 20.5819 - val_mse: 947.7872\n",
      "Epoch 4419/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9196 - mse: 937.0168 - val_loss: 20.5598 - val_mse: 931.6335\n",
      "Epoch 4420/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9216 - mse: 925.7704 - val_loss: 20.5767 - val_mse: 945.4214\n",
      "Epoch 4421/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9476 - mse: 931.2405 - val_loss: 20.5662 - val_mse: 939.3344\n",
      "Epoch 4422/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9004 - mse: 928.6408 - val_loss: 20.5865 - val_mse: 949.8839\n",
      "Epoch 4423/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8641 - mse: 934.2692 - val_loss: 20.5696 - val_mse: 941.5856\n",
      "Epoch 4424/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9414 - mse: 928.8157 - val_loss: 20.5680 - val_mse: 940.6371\n",
      "Epoch 4425/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9088 - mse: 927.3813 - val_loss: 20.5682 - val_mse: 940.7211\n",
      "Epoch 4426/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8692 - mse: 927.2656 - val_loss: 20.6500 - val_mse: 966.6936\n",
      "Epoch 4427/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9070 - mse: 941.4996 - val_loss: 20.5613 - val_mse: 927.2940\n",
      "Epoch 4428/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9483 - mse: 931.8190 - val_loss: 20.5609 - val_mse: 927.7858\n",
      "Epoch 4429/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8992 - mse: 934.2354 - val_loss: 20.5648 - val_mse: 925.3569\n",
      "Epoch 4430/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9921 - mse: 926.0471 - val_loss: 20.6040 - val_mse: 955.7638\n",
      "Epoch 4431/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8746 - mse: 930.6144 - val_loss: 20.5995 - val_mse: 913.7280\n",
      "Epoch 4432/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8912 - mse: 929.1110 - val_loss: 20.5700 - val_mse: 923.0541\n",
      "Epoch 4433/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8550 - mse: 930.9504 - val_loss: 20.5614 - val_mse: 935.0439\n",
      "Epoch 4434/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9039 - mse: 931.8651 - val_loss: 20.5660 - val_mse: 924.8012\n",
      "Epoch 4435/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8195 - mse: 925.3908 - val_loss: 20.5657 - val_mse: 924.9479\n",
      "Epoch 4436/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9744 - mse: 937.3654 - val_loss: 20.5621 - val_mse: 935.9513\n",
      "Epoch 4437/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8742 - mse: 927.1872 - val_loss: 20.5598 - val_mse: 931.7444\n",
      "Epoch 4438/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8330 - mse: 924.2669 - val_loss: 20.5785 - val_mse: 919.7141\n",
      "Epoch 4439/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9869 - mse: 933.7590 - val_loss: 20.5633 - val_mse: 937.0587\n",
      "Epoch 4440/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9229 - mse: 934.0334 - val_loss: 20.5700 - val_mse: 923.0596\n",
      "Epoch 4441/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9019 - mse: 938.6669 - val_loss: 20.5664 - val_mse: 939.5068\n",
      "Epoch 4442/5000\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 20.9404 - mse: 929.8895 - val_loss: 20.5644 - val_mse: 937.9386\n",
      "Epoch 4443/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9119 - mse: 930.1268 - val_loss: 20.6511 - val_mse: 966.9189\n",
      "Epoch 4444/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8774 - mse: 925.8738 - val_loss: 20.5743 - val_mse: 944.2214\n",
      "Epoch 4445/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8833 - mse: 935.5595 - val_loss: 20.5793 - val_mse: 946.6471\n",
      "Epoch 4446/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8739 - mse: 925.7419 - val_loss: 20.5880 - val_mse: 950.4883\n",
      "Epoch 4447/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8957 - mse: 925.7495 - val_loss: 20.5629 - val_mse: 926.3163\n",
      "Epoch 4448/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9567 - mse: 936.7769 - val_loss: 20.5892 - val_mse: 916.4146\n",
      "Epoch 4449/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8644 - mse: 919.7864 - val_loss: 20.6297 - val_mse: 962.5333\n",
      "Epoch 4450/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8738 - mse: 926.7255 - val_loss: 20.6707 - val_mse: 970.4429\n",
      "Epoch 4451/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9578 - mse: 940.2831 - val_loss: 20.5607 - val_mse: 933.6844\n",
      "Epoch 4452/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9576 - mse: 932.0797 - val_loss: 20.5608 - val_mse: 933.7950\n",
      "Epoch 4453/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9029 - mse: 932.0038 - val_loss: 20.5737 - val_mse: 943.9521\n",
      "Epoch 4454/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9277 - mse: 938.4292 - val_loss: 20.5625 - val_mse: 926.5416\n",
      "Epoch 4455/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9639 - mse: 911.9886 - val_loss: 20.5933 - val_mse: 952.3756\n",
      "Epoch 4456/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9394 - mse: 947.4780 - val_loss: 20.5639 - val_mse: 925.7656\n",
      "Epoch 4457/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9183 - mse: 934.9346 - val_loss: 20.5799 - val_mse: 946.9034\n",
      "Epoch 4458/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8769 - mse: 927.7795 - val_loss: 20.6031 - val_mse: 955.4934\n",
      "Epoch 4459/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9672 - mse: 923.3257 - val_loss: 20.6761 - val_mse: 971.3640\n",
      "Epoch 4460/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9498 - mse: 938.0534 - val_loss: 20.6161 - val_mse: 959.2703\n",
      "Epoch 4461/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9070 - mse: 933.3370 - val_loss: 20.5609 - val_mse: 934.0092\n",
      "Epoch 4462/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8819 - mse: 933.2715 - val_loss: 20.5697 - val_mse: 941.6600\n",
      "Epoch 4463/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9657 - mse: 937.9009 - val_loss: 20.6074 - val_mse: 956.7619\n",
      "Epoch 4464/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9465 - mse: 924.4196 - val_loss: 20.5696 - val_mse: 941.6083\n",
      "Epoch 4465/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9359 - mse: 938.6995 - val_loss: 20.5666 - val_mse: 939.6492\n",
      "Epoch 4466/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9275 - mse: 935.8076 - val_loss: 20.5643 - val_mse: 937.8926\n",
      "Epoch 4467/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9907 - mse: 936.9604 - val_loss: 20.6084 - val_mse: 957.0479\n",
      "Epoch 4468/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8464 - mse: 920.0553 - val_loss: 20.5833 - val_mse: 948.4255\n",
      "Epoch 4469/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9147 - mse: 936.5172 - val_loss: 20.5997 - val_mse: 954.4755\n",
      "Epoch 4470/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8582 - mse: 932.0645 - val_loss: 20.5629 - val_mse: 926.3265\n",
      "Epoch 4471/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8734 - mse: 926.5284 - val_loss: 20.5598 - val_mse: 930.6888\n",
      "Epoch 4472/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8927 - mse: 933.5746 - val_loss: 20.5602 - val_mse: 929.0095\n",
      "Epoch 4473/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8611 - mse: 927.6887 - val_loss: 20.5632 - val_mse: 937.0069\n",
      "Epoch 4474/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 21.0588 - mse: 941.0034 - val_loss: 20.6035 - val_mse: 955.6119\n",
      "Epoch 4475/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9198 - mse: 923.6605 - val_loss: 20.7232 - val_mse: 978.9160\n",
      "Epoch 4476/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8667 - mse: 938.4222 - val_loss: 20.5622 - val_mse: 926.6938\n",
      "Epoch 4477/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8442 - mse: 929.2761 - val_loss: 20.5666 - val_mse: 939.6333\n",
      "Epoch 4478/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8804 - mse: 919.6658 - val_loss: 20.6639 - val_mse: 969.2412\n",
      "Epoch 4479/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8615 - mse: 927.2966 - val_loss: 20.5735 - val_mse: 943.8362\n",
      "Epoch 4480/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8615 - mse: 927.5267 - val_loss: 20.5982 - val_mse: 914.0304\n",
      "Epoch 4481/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9304 - mse: 922.5008 - val_loss: 20.5607 - val_mse: 933.6561\n",
      "Epoch 4482/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9285 - mse: 935.3162 - val_loss: 20.5778 - val_mse: 919.9814\n",
      "Epoch 4483/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9925 - mse: 935.4772 - val_loss: 20.5775 - val_mse: 945.8132\n",
      "Epoch 4484/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9199 - mse: 940.4659 - val_loss: 20.5598 - val_mse: 930.8875\n",
      "Epoch 4485/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9481 - mse: 926.4728 - val_loss: 20.5733 - val_mse: 943.7150\n",
      "Epoch 4486/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9974 - mse: 937.9276 - val_loss: 20.6335 - val_mse: 963.3193\n",
      "Epoch 4487/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9203 - mse: 933.0868 - val_loss: 20.5815 - val_mse: 947.6396\n",
      "Epoch 4488/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8867 - mse: 927.9196 - val_loss: 20.6048 - val_mse: 955.9846\n",
      "Epoch 4489/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9384 - mse: 933.4454 - val_loss: 20.7243 - val_mse: 979.0888\n",
      "Epoch 4490/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9729 - mse: 939.1310 - val_loss: 20.5842 - val_mse: 948.8642\n",
      "Epoch 4491/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9148 - mse: 927.4587 - val_loss: 20.5908 - val_mse: 951.5138\n",
      "Epoch 4492/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8834 - mse: 928.2386 - val_loss: 20.5766 - val_mse: 945.3804\n",
      "Epoch 4493/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9077 - mse: 939.4416 - val_loss: 20.6335 - val_mse: 906.9506\n",
      "Epoch 4494/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0937 - mse: 935.3107 - val_loss: 20.5604 - val_mse: 933.0100\n",
      "Epoch 4495/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8679 - mse: 928.2380 - val_loss: 20.5647 - val_mse: 938.2281\n",
      "Epoch 4496/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9219 - mse: 925.4307 - val_loss: 20.6003 - val_mse: 954.6600\n",
      "Epoch 4497/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8854 - mse: 932.0754 - val_loss: 20.5744 - val_mse: 944.3036\n",
      "Epoch 4498/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8978 - mse: 927.8556 - val_loss: 20.5598 - val_mse: 931.4952\n",
      "Epoch 4499/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8708 - mse: 934.1421 - val_loss: 20.5608 - val_mse: 933.8668\n",
      "Epoch 4500/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8363 - mse: 917.6841 - val_loss: 20.5789 - val_mse: 946.4612\n",
      "Epoch 4501/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9645 - mse: 943.3705 - val_loss: 20.5612 - val_mse: 934.6269\n",
      "Epoch 4502/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8429 - mse: 918.7916 - val_loss: 20.5784 - val_mse: 946.2020\n",
      "Epoch 4503/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8785 - mse: 928.5587 - val_loss: 20.5920 - val_mse: 951.9312\n",
      "Epoch 4504/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9378 - mse: 944.5328 - val_loss: 20.5607 - val_mse: 933.5544\n",
      "Epoch 4505/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9457 - mse: 928.2056 - val_loss: 20.6675 - val_mse: 969.8783\n",
      "Epoch 4506/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8585 - mse: 932.3159 - val_loss: 20.5835 - val_mse: 918.0231\n",
      "Epoch 4507/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8536 - mse: 924.0351 - val_loss: 20.5668 - val_mse: 939.7604\n",
      "Epoch 4508/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8741 - mse: 921.9369 - val_loss: 20.5742 - val_mse: 944.1931\n",
      "Epoch 4509/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9610 - mse: 929.5134 - val_loss: 20.5635 - val_mse: 937.2085\n",
      "Epoch 4510/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8822 - mse: 937.7260 - val_loss: 20.5631 - val_mse: 936.8644\n",
      "Epoch 4511/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0077 - mse: 932.8270 - val_loss: 20.5599 - val_mse: 930.3733\n",
      "Epoch 4512/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9816 - mse: 932.6000 - val_loss: 20.5599 - val_mse: 929.7467\n",
      "Epoch 4513/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9148 - mse: 926.8951 - val_loss: 20.5857 - val_mse: 949.5481\n",
      "Epoch 4514/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0202 - mse: 933.2951 - val_loss: 20.6238 - val_mse: 961.2056\n",
      "Epoch 4515/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8505 - mse: 929.1177 - val_loss: 20.5835 - val_mse: 948.5204\n",
      "Epoch 4516/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8720 - mse: 927.8774 - val_loss: 20.5860 - val_mse: 917.2906\n",
      "Epoch 4517/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8476 - mse: 920.0342 - val_loss: 20.5806 - val_mse: 947.2233\n",
      "Epoch 4518/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9597 - mse: 936.3796 - val_loss: 20.5623 - val_mse: 936.1283\n",
      "Epoch 4519/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9080 - mse: 930.2352 - val_loss: 20.5702 - val_mse: 941.9289\n",
      "Epoch 4520/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9386 - mse: 940.8131 - val_loss: 20.6211 - val_mse: 960.5613\n",
      "Epoch 4521/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8714 - mse: 920.4534 - val_loss: 20.6647 - val_mse: 969.3884\n",
      "Epoch 4522/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9729 - mse: 939.7633 - val_loss: 20.7800 - val_mse: 987.7613\n",
      "Epoch 4523/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9220 - mse: 935.0284 - val_loss: 20.5774 - val_mse: 945.7879\n",
      "Epoch 4524/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8589 - mse: 929.5699 - val_loss: 20.5611 - val_mse: 934.4930\n",
      "Epoch 4525/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8892 - mse: 934.7705 - val_loss: 20.5891 - val_mse: 950.9142\n",
      "Epoch 4526/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9240 - mse: 929.3361 - val_loss: 20.5789 - val_mse: 946.4277\n",
      "Epoch 4527/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9316 - mse: 925.1834 - val_loss: 20.5702 - val_mse: 941.9462\n",
      "Epoch 4528/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9498 - mse: 929.0778 - val_loss: 20.6669 - val_mse: 969.7723\n",
      "Epoch 4529/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9577 - mse: 943.9116 - val_loss: 20.5713 - val_mse: 942.5692\n",
      "Epoch 4530/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9787 - mse: 932.8779 - val_loss: 20.5618 - val_mse: 926.9396\n",
      "Epoch 4531/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8922 - mse: 926.9391 - val_loss: 20.5970 - val_mse: 953.5991\n",
      "Epoch 4532/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8319 - mse: 928.9445 - val_loss: 20.5615 - val_mse: 927.1702\n",
      "Epoch 4533/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9563 - mse: 933.9977 - val_loss: 20.5742 - val_mse: 921.3071\n",
      "Epoch 4534/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9583 - mse: 942.2791 - val_loss: 20.6094 - val_mse: 911.5314\n",
      "Epoch 4535/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9266 - mse: 923.1636 - val_loss: 20.5675 - val_mse: 940.2498\n",
      "Epoch 4536/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8623 - mse: 937.1358 - val_loss: 20.5609 - val_mse: 927.7532\n",
      "Epoch 4537/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9029 - mse: 926.7702 - val_loss: 20.5598 - val_mse: 930.8396\n",
      "Epoch 4538/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9520 - mse: 935.3020 - val_loss: 20.5606 - val_mse: 933.3396\n",
      "Epoch 4539/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9079 - mse: 934.8041 - val_loss: 20.5793 - val_mse: 919.4426\n",
      "Epoch 4540/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9237 - mse: 930.8072 - val_loss: 20.5635 - val_mse: 937.2150\n",
      "Epoch 4541/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8866 - mse: 936.2422 - val_loss: 20.5643 - val_mse: 937.9261\n",
      "Epoch 4542/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9013 - mse: 924.4735 - val_loss: 20.5690 - val_mse: 941.2548\n",
      "Epoch 4543/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8269 - mse: 927.7161 - val_loss: 20.5612 - val_mse: 934.8091\n",
      "Epoch 4544/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9236 - mse: 933.3270 - val_loss: 20.5664 - val_mse: 924.6099\n",
      "Epoch 4545/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8791 - mse: 928.0580 - val_loss: 20.5967 - val_mse: 953.4896\n",
      "Epoch 4546/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8769 - mse: 930.5463 - val_loss: 20.5708 - val_mse: 942.2997\n",
      "Epoch 4547/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9199 - mse: 936.9057 - val_loss: 20.5695 - val_mse: 923.2736\n",
      "Epoch 4548/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8901 - mse: 925.7281 - val_loss: 20.6006 - val_mse: 954.7272\n",
      "Epoch 4549/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9349 - mse: 926.4662 - val_loss: 20.7234 - val_mse: 978.9421\n",
      "Epoch 4550/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9239 - mse: 936.3503 - val_loss: 20.5677 - val_mse: 940.4233\n",
      "Epoch 4551/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9139 - mse: 934.2642 - val_loss: 20.6185 - val_mse: 909.6603\n",
      "Epoch 4552/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9981 - mse: 927.1221 - val_loss: 20.5650 - val_mse: 938.4302\n",
      "Epoch 4553/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8169 - mse: 934.4378 - val_loss: 20.5741 - val_mse: 921.3434\n",
      "Epoch 4554/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9844 - mse: 939.4716 - val_loss: 20.5896 - val_mse: 951.1141\n",
      "Epoch 4555/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9084 - mse: 927.4291 - val_loss: 20.5687 - val_mse: 941.0789\n",
      "Epoch 4556/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8486 - mse: 927.9771 - val_loss: 20.5833 - val_mse: 948.4393\n",
      "Epoch 4557/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8470 - mse: 928.9309 - val_loss: 20.5751 - val_mse: 944.6581\n",
      "Epoch 4558/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8256 - mse: 924.9282 - val_loss: 20.5652 - val_mse: 938.5561\n",
      "Epoch 4559/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 21.0215 - mse: 929.5012 - val_loss: 20.5680 - val_mse: 940.5875\n",
      "Epoch 4560/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9476 - mse: 937.4576 - val_loss: 20.5630 - val_mse: 936.8477\n",
      "Epoch 4561/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9518 - mse: 934.2883 - val_loss: 20.5707 - val_mse: 922.7554\n",
      "Epoch 4562/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8826 - mse: 929.1379 - val_loss: 20.5600 - val_mse: 929.3505\n",
      "Epoch 4563/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9615 - mse: 937.0607 - val_loss: 20.5637 - val_mse: 937.3801\n",
      "Epoch 4564/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8986 - mse: 934.6605 - val_loss: 20.5611 - val_mse: 927.4828\n",
      "Epoch 4565/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9080 - mse: 933.3157 - val_loss: 20.5826 - val_mse: 918.2835\n",
      "Epoch 4566/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8809 - mse: 927.0311 - val_loss: 20.5676 - val_mse: 940.3725\n",
      "Epoch 4567/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9075 - mse: 925.2608 - val_loss: 20.7269 - val_mse: 979.4899\n",
      "Epoch 4568/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8809 - mse: 933.4716 - val_loss: 20.5906 - val_mse: 951.4675\n",
      "Epoch 4569/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8240 - mse: 932.5732 - val_loss: 20.5988 - val_mse: 913.8814\n",
      "Epoch 4570/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8798 - mse: 917.2980 - val_loss: 20.6988 - val_mse: 975.1091\n",
      "Epoch 4571/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8294 - mse: 929.7621 - val_loss: 20.5617 - val_mse: 927.0017\n",
      "Epoch 4572/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8804 - mse: 925.1191 - val_loss: 20.5769 - val_mse: 945.5389\n",
      "Epoch 4573/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8800 - mse: 929.5070 - val_loss: 20.5684 - val_mse: 940.8566\n",
      "Epoch 4574/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9521 - mse: 928.2672 - val_loss: 20.5848 - val_mse: 949.1081\n",
      "Epoch 4575/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8843 - mse: 936.2772 - val_loss: 20.5599 - val_mse: 931.9654\n",
      "Epoch 4576/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8571 - mse: 919.8146 - val_loss: 20.5805 - val_mse: 947.1850\n",
      "Epoch 4577/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9147 - mse: 933.0818 - val_loss: 20.5695 - val_mse: 941.5450\n",
      "Epoch 4578/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9119 - mse: 932.5160 - val_loss: 20.5655 - val_mse: 938.8429\n",
      "Epoch 4579/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8839 - mse: 922.9597 - val_loss: 20.5827 - val_mse: 948.1791\n",
      "Epoch 4580/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8509 - mse: 936.5768 - val_loss: 20.5607 - val_mse: 933.5150\n",
      "Epoch 4581/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9572 - mse: 925.6231 - val_loss: 20.6353 - val_mse: 963.6998\n",
      "Epoch 4582/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9171 - mse: 937.9119 - val_loss: 20.5626 - val_mse: 936.4267\n",
      "Epoch 4583/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8773 - mse: 931.9467 - val_loss: 20.5601 - val_mse: 929.2908\n",
      "Epoch 4584/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8899 - mse: 921.2632 - val_loss: 20.5720 - val_mse: 942.9719\n",
      "Epoch 4585/5000\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 20.8789 - mse: 929.3082 - val_loss: 20.5614 - val_mse: 935.1102\n",
      "Epoch 4586/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9496 - mse: 936.6180 - val_loss: 20.5742 - val_mse: 944.1688\n",
      "Epoch 4587/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8957 - mse: 931.5842 - val_loss: 20.5667 - val_mse: 939.6931\n",
      "Epoch 4588/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9189 - mse: 935.3301 - val_loss: 20.5599 - val_mse: 930.3547\n",
      "Epoch 4589/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9452 - mse: 926.3898 - val_loss: 20.5615 - val_mse: 935.1802\n",
      "Epoch 4590/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9221 - mse: 934.3132 - val_loss: 20.5883 - val_mse: 916.6473\n",
      "Epoch 4591/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8713 - mse: 921.6962 - val_loss: 20.5952 - val_mse: 953.0264\n",
      "Epoch 4592/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8435 - mse: 929.6763 - val_loss: 20.5704 - val_mse: 942.0546\n",
      "Epoch 4593/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8817 - mse: 931.6367 - val_loss: 20.5633 - val_mse: 937.0567\n",
      "Epoch 4594/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9296 - mse: 931.6765 - val_loss: 20.5681 - val_mse: 940.6848\n",
      "Epoch 4595/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9079 - mse: 936.1506 - val_loss: 20.6067 - val_mse: 912.1056\n",
      "Epoch 4596/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9226 - mse: 926.9120 - val_loss: 20.5598 - val_mse: 931.7404\n",
      "Epoch 4597/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8993 - mse: 928.3825 - val_loss: 20.5612 - val_mse: 934.6968\n",
      "Epoch 4598/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9007 - mse: 934.2765 - val_loss: 20.6143 - val_mse: 958.7533\n",
      "Epoch 4599/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9607 - mse: 938.0545 - val_loss: 20.6107 - val_mse: 957.7121\n",
      "Epoch 4600/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8746 - mse: 931.6788 - val_loss: 20.5669 - val_mse: 924.3975\n",
      "Epoch 4601/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9252 - mse: 925.3876 - val_loss: 20.5897 - val_mse: 951.1299\n",
      "Epoch 4602/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9410 - mse: 932.2179 - val_loss: 20.5822 - val_mse: 918.4410\n",
      "Epoch 4603/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8914 - mse: 922.1152 - val_loss: 20.5945 - val_mse: 952.7850\n",
      "Epoch 4604/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9090 - mse: 929.2137 - val_loss: 20.5599 - val_mse: 930.4264\n",
      "Epoch 4605/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9386 - mse: 924.0851 - val_loss: 20.5606 - val_mse: 933.4802\n",
      "Epoch 4606/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9797 - mse: 942.9038 - val_loss: 20.6680 - val_mse: 969.9664\n",
      "Epoch 4607/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8834 - mse: 937.7401 - val_loss: 20.5606 - val_mse: 933.4289\n",
      "Epoch 4608/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9171 - mse: 937.8502 - val_loss: 20.5674 - val_mse: 940.2023\n",
      "Epoch 4609/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8978 - mse: 927.4454 - val_loss: 20.5719 - val_mse: 942.9313\n",
      "Epoch 4610/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8341 - mse: 924.4648 - val_loss: 20.5648 - val_mse: 925.3571\n",
      "Epoch 4611/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8632 - mse: 936.4007 - val_loss: 20.6082 - val_mse: 911.7813\n",
      "Epoch 4612/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9094 - mse: 920.7797 - val_loss: 20.5608 - val_mse: 933.8775\n",
      "Epoch 4613/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9344 - mse: 942.9738 - val_loss: 20.5649 - val_mse: 938.3696\n",
      "Epoch 4614/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8450 - mse: 922.0059 - val_loss: 20.5635 - val_mse: 937.2527\n",
      "Epoch 4615/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8562 - mse: 918.8664 - val_loss: 20.5834 - val_mse: 948.4713\n",
      "Epoch 4616/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9287 - mse: 929.9347 - val_loss: 20.5875 - val_mse: 950.2679\n",
      "Epoch 4617/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8681 - mse: 933.9078 - val_loss: 20.5601 - val_mse: 932.2625\n",
      "Epoch 4618/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8434 - mse: 921.9711 - val_loss: 20.6231 - val_mse: 961.0336\n",
      "Epoch 4619/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9458 - mse: 944.2005 - val_loss: 20.6078 - val_mse: 911.8738\n",
      "Epoch 4620/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9340 - mse: 928.8721 - val_loss: 20.5986 - val_mse: 954.1251\n",
      "Epoch 4621/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8764 - mse: 932.1423 - val_loss: 20.5943 - val_mse: 952.7234\n",
      "Epoch 4622/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9133 - mse: 927.1225 - val_loss: 20.5630 - val_mse: 936.8339\n",
      "Epoch 4623/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9212 - mse: 936.0340 - val_loss: 20.5608 - val_mse: 933.8959\n",
      "Epoch 4624/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8944 - mse: 927.7599 - val_loss: 20.5614 - val_mse: 935.0688\n",
      "Epoch 4625/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8819 - mse: 934.2333 - val_loss: 20.5680 - val_mse: 923.9319\n",
      "Epoch 4626/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8600 - mse: 928.4324 - val_loss: 20.5609 - val_mse: 934.0081\n",
      "Epoch 4627/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8863 - mse: 932.9806 - val_loss: 20.5685 - val_mse: 940.9481\n",
      "Epoch 4628/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8740 - mse: 930.1797 - val_loss: 20.6003 - val_mse: 913.5276\n",
      "Epoch 4629/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8560 - mse: 917.9042 - val_loss: 20.5999 - val_mse: 954.5148\n",
      "Epoch 4630/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9315 - mse: 945.1683 - val_loss: 20.5615 - val_mse: 935.2452\n",
      "Epoch 4631/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9264 - mse: 925.7166 - val_loss: 20.5702 - val_mse: 941.9740\n",
      "Epoch 4632/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9445 - mse: 932.8939 - val_loss: 20.5914 - val_mse: 915.8300\n",
      "Epoch 4633/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9139 - mse: 939.1655 - val_loss: 20.5611 - val_mse: 927.5008\n",
      "Epoch 4634/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8556 - mse: 915.8149 - val_loss: 20.6515 - val_mse: 966.9986\n",
      "Epoch 4635/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9167 - mse: 931.3853 - val_loss: 20.5699 - val_mse: 941.8102\n",
      "Epoch 4636/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9779 - mse: 933.8276 - val_loss: 20.5599 - val_mse: 929.8677\n",
      "Epoch 4637/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8414 - mse: 926.1774 - val_loss: 20.5615 - val_mse: 935.1459\n",
      "Epoch 4638/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8433 - mse: 933.7896 - val_loss: 20.6327 - val_mse: 907.0825\n",
      "Epoch 4639/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8639 - mse: 915.1949 - val_loss: 20.5702 - val_mse: 941.9678\n",
      "Epoch 4640/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9197 - mse: 925.4031 - val_loss: 20.5606 - val_mse: 928.1625\n",
      "Epoch 4641/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8449 - mse: 926.3806 - val_loss: 20.5793 - val_mse: 946.6053\n",
      "Epoch 4642/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9642 - mse: 938.9767 - val_loss: 20.5599 - val_mse: 930.1055\n",
      "Epoch 4643/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9275 - mse: 935.8011 - val_loss: 20.5849 - val_mse: 949.1711\n",
      "Epoch 4644/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9239 - mse: 928.3892 - val_loss: 20.5774 - val_mse: 920.1249\n",
      "Epoch 4645/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9403 - mse: 936.2508 - val_loss: 20.5792 - val_mse: 946.5883\n",
      "Epoch 4646/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9477 - mse: 933.6515 - val_loss: 20.5738 - val_mse: 943.9563\n",
      "Epoch 4647/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8954 - mse: 932.8237 - val_loss: 20.5677 - val_mse: 924.0500\n",
      "Epoch 4648/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8499 - mse: 926.2364 - val_loss: 20.5924 - val_mse: 952.0833\n",
      "Epoch 4649/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8885 - mse: 934.1819 - val_loss: 20.5604 - val_mse: 928.5185\n",
      "Epoch 4650/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9398 - mse: 929.1162 - val_loss: 20.5624 - val_mse: 936.2479\n",
      "Epoch 4651/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8001 - mse: 921.7829 - val_loss: 20.5652 - val_mse: 938.5682\n",
      "Epoch 4652/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9619 - mse: 926.6790 - val_loss: 20.6209 - val_mse: 960.5285\n",
      "Epoch 4653/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8328 - mse: 933.4659 - val_loss: 20.5627 - val_mse: 936.5009\n",
      "Epoch 4654/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9360 - mse: 935.1579 - val_loss: 20.5746 - val_mse: 944.3735\n",
      "Epoch 4655/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8981 - mse: 932.2659 - val_loss: 20.5624 - val_mse: 936.2861\n",
      "Epoch 4656/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9713 - mse: 932.8045 - val_loss: 20.6845 - val_mse: 972.7902\n",
      "Epoch 4657/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8813 - mse: 927.8635 - val_loss: 20.5765 - val_mse: 945.3521\n",
      "Epoch 4658/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9312 - mse: 935.0108 - val_loss: 20.5601 - val_mse: 929.0950\n",
      "Epoch 4659/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8449 - mse: 922.3629 - val_loss: 20.5984 - val_mse: 954.0533\n",
      "Epoch 4660/5000\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 20.8547 - mse: 933.3153 - val_loss: 20.5600 - val_mse: 929.3391\n",
      "Epoch 4661/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9189 - mse: 934.4195 - val_loss: 20.5604 - val_mse: 928.4827\n",
      "Epoch 4662/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8971 - mse: 925.5651 - val_loss: 20.5824 - val_mse: 948.0288\n",
      "Epoch 4663/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9211 - mse: 930.2288 - val_loss: 20.5605 - val_mse: 928.3834\n",
      "Epoch 4664/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9091 - mse: 934.5956 - val_loss: 20.5755 - val_mse: 944.8362\n",
      "Epoch 4665/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8970 - mse: 930.0641 - val_loss: 20.5696 - val_mse: 941.5893\n",
      "Epoch 4666/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8522 - mse: 934.4965 - val_loss: 20.5914 - val_mse: 915.8344\n",
      "Epoch 4667/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9153 - mse: 926.3263 - val_loss: 20.5638 - val_mse: 937.4688\n",
      "Epoch 4668/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9186 - mse: 932.1475 - val_loss: 20.5852 - val_mse: 949.2778\n",
      "Epoch 4669/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8550 - mse: 925.1815 - val_loss: 20.5853 - val_mse: 917.4712\n",
      "Epoch 4670/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9447 - mse: 933.7747 - val_loss: 20.5607 - val_mse: 928.0784\n",
      "Epoch 4671/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9227 - mse: 920.6454 - val_loss: 20.5599 - val_mse: 930.0204\n",
      "Epoch 4672/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9251 - mse: 941.7598 - val_loss: 20.5598 - val_mse: 930.9360\n",
      "Epoch 4673/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8310 - mse: 919.8124 - val_loss: 20.5666 - val_mse: 939.6270\n",
      "Epoch 4674/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8886 - mse: 936.4714 - val_loss: 20.5606 - val_mse: 933.2996\n",
      "Epoch 4675/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9778 - mse: 932.2990 - val_loss: 20.5796 - val_mse: 946.7831\n",
      "Epoch 4676/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9207 - mse: 928.5659 - val_loss: 20.5788 - val_mse: 946.3867\n",
      "Epoch 4677/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9346 - mse: 941.6515 - val_loss: 20.5895 - val_mse: 916.3456\n",
      "Epoch 4678/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8821 - mse: 930.1498 - val_loss: 20.5654 - val_mse: 925.0724\n",
      "Epoch 4679/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9061 - mse: 929.1841 - val_loss: 20.5992 - val_mse: 954.3209\n",
      "Epoch 4680/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9775 - mse: 926.3752 - val_loss: 20.7060 - val_mse: 976.2334\n",
      "Epoch 4681/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8906 - mse: 931.8445 - val_loss: 20.5841 - val_mse: 948.8139\n",
      "Epoch 4682/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9113 - mse: 933.7852 - val_loss: 20.5781 - val_mse: 946.0875\n",
      "Epoch 4683/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8764 - mse: 929.9009 - val_loss: 20.6487 - val_mse: 966.4395\n",
      "Epoch 4684/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9228 - mse: 932.6958 - val_loss: 20.5918 - val_mse: 915.7331\n",
      "Epoch 4685/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9008 - mse: 933.8675 - val_loss: 20.5715 - val_mse: 942.6889\n",
      "Epoch 4686/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9017 - mse: 925.3892 - val_loss: 20.6252 - val_mse: 961.5133\n",
      "Epoch 4687/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9085 - mse: 937.9991 - val_loss: 20.5611 - val_mse: 934.5694\n",
      "Epoch 4688/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9481 - mse: 926.7675 - val_loss: 20.5600 - val_mse: 929.4144\n",
      "Epoch 4689/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9160 - mse: 931.3433 - val_loss: 20.5619 - val_mse: 935.7852\n",
      "Epoch 4690/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8633 - mse: 929.2256 - val_loss: 20.5741 - val_mse: 944.1597\n",
      "Epoch 4691/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9375 - mse: 934.6871 - val_loss: 20.5861 - val_mse: 949.7175\n",
      "Epoch 4692/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9389 - mse: 922.7531 - val_loss: 20.5729 - val_mse: 943.4918\n",
      "Epoch 4693/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9023 - mse: 938.1118 - val_loss: 20.6004 - val_mse: 913.5144\n",
      "Epoch 4694/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9028 - mse: 930.4262 - val_loss: 20.5893 - val_mse: 916.3836\n",
      "Epoch 4695/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8922 - mse: 923.2205 - val_loss: 20.5771 - val_mse: 945.6494\n",
      "Epoch 4696/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8841 - mse: 925.1282 - val_loss: 20.5634 - val_mse: 937.1672\n",
      "Epoch 4697/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9112 - mse: 933.7935 - val_loss: 20.5746 - val_mse: 944.4164\n",
      "Epoch 4698/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9508 - mse: 931.4737 - val_loss: 20.5617 - val_mse: 927.0475\n",
      "Epoch 4699/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.9226 - mse: 929.0853 - val_loss: 20.5811 - val_mse: 947.4438\n",
      "Epoch 4700/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8769 - mse: 930.9071 - val_loss: 20.5667 - val_mse: 939.7076\n",
      "Epoch 4701/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8799 - mse: 925.3718 - val_loss: 20.7266 - val_mse: 979.4514\n",
      "Epoch 4702/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9081 - mse: 939.7821 - val_loss: 20.5639 - val_mse: 937.6217\n",
      "Epoch 4703/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9420 - mse: 941.6987 - val_loss: 20.5605 - val_mse: 933.0709\n",
      "Epoch 4704/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8895 - mse: 934.8195 - val_loss: 20.5698 - val_mse: 923.1485\n",
      "Epoch 4705/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9695 - mse: 931.5887 - val_loss: 20.5666 - val_mse: 939.6410\n",
      "Epoch 4706/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9351 - mse: 933.8055 - val_loss: 20.5599 - val_mse: 929.9804\n",
      "Epoch 4707/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9032 - mse: 931.1160 - val_loss: 20.5711 - val_mse: 922.5758\n",
      "Epoch 4708/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8940 - mse: 921.7496 - val_loss: 20.6197 - val_mse: 960.2275\n",
      "Epoch 4709/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8924 - mse: 938.8137 - val_loss: 20.5599 - val_mse: 930.1031\n",
      "Epoch 4710/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9041 - mse: 930.3378 - val_loss: 20.5666 - val_mse: 939.6171\n",
      "Epoch 4711/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8672 - mse: 922.6398 - val_loss: 20.5714 - val_mse: 942.6492\n",
      "Epoch 4712/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9634 - mse: 933.0885 - val_loss: 20.5866 - val_mse: 949.9022\n",
      "Epoch 4713/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9168 - mse: 930.5109 - val_loss: 20.5875 - val_mse: 950.2985\n",
      "Epoch 4714/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9325 - mse: 937.8038 - val_loss: 20.5716 - val_mse: 942.7358\n",
      "Epoch 4715/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9454 - mse: 935.1902 - val_loss: 20.5985 - val_mse: 954.1039\n",
      "Epoch 4716/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8436 - mse: 929.9261 - val_loss: 20.5670 - val_mse: 924.3584\n",
      "Epoch 4717/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9074 - mse: 931.3072 - val_loss: 20.5604 - val_mse: 932.9520\n",
      "Epoch 4718/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8825 - mse: 918.8731 - val_loss: 20.6895 - val_mse: 973.6252\n",
      "Epoch 4719/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9687 - mse: 931.5827 - val_loss: 20.5731 - val_mse: 943.5639\n",
      "Epoch 4720/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9165 - mse: 933.3022 - val_loss: 20.6152 - val_mse: 959.0181\n",
      "Epoch 4721/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8815 - mse: 937.4816 - val_loss: 20.5604 - val_mse: 932.8621\n",
      "Epoch 4722/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8618 - mse: 922.5806 - val_loss: 20.5606 - val_mse: 933.4100\n",
      "Epoch 4723/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9167 - mse: 932.2159 - val_loss: 20.6057 - val_mse: 956.2776\n",
      "Epoch 4724/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8816 - mse: 933.5714 - val_loss: 20.5653 - val_mse: 938.6925\n",
      "Epoch 4725/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8560 - mse: 930.4555 - val_loss: 20.5718 - val_mse: 942.8423\n",
      "Epoch 4726/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9150 - mse: 933.4760 - val_loss: 20.5679 - val_mse: 940.5089\n",
      "Epoch 4727/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8828 - mse: 933.8816 - val_loss: 20.5609 - val_mse: 933.9550\n",
      "Epoch 4728/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8455 - mse: 924.0632 - val_loss: 20.5598 - val_mse: 931.0171\n",
      "Epoch 4729/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8833 - mse: 926.5247 - val_loss: 20.5692 - val_mse: 941.3851\n",
      "Epoch 4730/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9069 - mse: 933.6390 - val_loss: 20.5598 - val_mse: 931.4517\n",
      "Epoch 4731/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9491 - mse: 934.5895 - val_loss: 20.5605 - val_mse: 928.2892\n",
      "Epoch 4732/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8987 - mse: 921.3536 - val_loss: 20.5630 - val_mse: 936.8092\n",
      "Epoch 4733/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8620 - mse: 926.3466 - val_loss: 20.5607 - val_mse: 933.5942\n",
      "Epoch 4734/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8799 - mse: 931.0107 - val_loss: 20.5613 - val_mse: 927.3173\n",
      "Epoch 4735/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9219 - mse: 941.3795 - val_loss: 20.5606 - val_mse: 928.1371\n",
      "Epoch 4736/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9097 - mse: 920.5023 - val_loss: 20.5865 - val_mse: 949.8737\n",
      "Epoch 4737/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8245 - mse: 927.2252 - val_loss: 20.5599 - val_mse: 930.5074\n",
      "Epoch 4738/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9502 - mse: 928.7928 - val_loss: 20.5629 - val_mse: 936.6939\n",
      "Epoch 4739/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8991 - mse: 929.6309 - val_loss: 20.5997 - val_mse: 954.4500\n",
      "Epoch 4740/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9153 - mse: 936.8402 - val_loss: 20.5651 - val_mse: 938.4902\n",
      "Epoch 4741/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8838 - mse: 927.4509 - val_loss: 20.5618 - val_mse: 935.6154\n",
      "Epoch 4742/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8597 - mse: 925.2356 - val_loss: 20.5712 - val_mse: 942.5250\n",
      "Epoch 4743/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9140 - mse: 924.4568 - val_loss: 20.5826 - val_mse: 948.1212\n",
      "Epoch 4744/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9270 - mse: 936.1665 - val_loss: 20.5616 - val_mse: 927.0861\n",
      "Epoch 4745/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9397 - mse: 931.1575 - val_loss: 20.5717 - val_mse: 942.8174\n",
      "Epoch 4746/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9074 - mse: 932.5716 - val_loss: 20.5645 - val_mse: 938.0613\n",
      "Epoch 4747/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8902 - mse: 923.4561 - val_loss: 20.5704 - val_mse: 942.0388\n",
      "Epoch 4748/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9251 - mse: 936.7910 - val_loss: 20.5738 - val_mse: 943.9906\n",
      "Epoch 4749/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9094 - mse: 937.0500 - val_loss: 20.5599 - val_mse: 929.9408\n",
      "Epoch 4750/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9372 - mse: 935.8082 - val_loss: 20.5852 - val_mse: 949.3162\n",
      "Epoch 4751/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9101 - mse: 919.1107 - val_loss: 20.5868 - val_mse: 950.0052\n",
      "Epoch 4752/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9601 - mse: 940.8089 - val_loss: 20.5626 - val_mse: 926.4840\n",
      "Epoch 4753/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8421 - mse: 923.3919 - val_loss: 20.5874 - val_mse: 950.2339\n",
      "Epoch 4754/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8948 - mse: 932.2790 - val_loss: 20.5624 - val_mse: 936.2595\n",
      "Epoch 4755/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9253 - mse: 925.5319 - val_loss: 20.5641 - val_mse: 937.7704\n",
      "Epoch 4756/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9181 - mse: 940.9202 - val_loss: 20.5615 - val_mse: 935.2508\n",
      "Epoch 4757/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9355 - mse: 931.8253 - val_loss: 20.5848 - val_mse: 949.1346\n",
      "Epoch 4758/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8737 - mse: 923.9182 - val_loss: 20.5940 - val_mse: 952.6219\n",
      "Epoch 4759/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8297 - mse: 932.4202 - val_loss: 20.5766 - val_mse: 945.4066\n",
      "Epoch 4760/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8831 - mse: 931.6440 - val_loss: 20.6088 - val_mse: 957.1617\n",
      "Epoch 4761/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9211 - mse: 933.7275 - val_loss: 20.5606 - val_mse: 933.3755\n",
      "Epoch 4762/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8359 - mse: 924.3114 - val_loss: 20.5819 - val_mse: 947.8086\n",
      "Epoch 4763/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8978 - mse: 931.3654 - val_loss: 20.5829 - val_mse: 948.2610\n",
      "Epoch 4764/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9196 - mse: 935.0408 - val_loss: 20.5677 - val_mse: 940.4283\n",
      "Epoch 4765/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8801 - mse: 931.5234 - val_loss: 20.5662 - val_mse: 939.3218\n",
      "Epoch 4766/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9941 - mse: 936.5641 - val_loss: 20.6117 - val_mse: 958.0163\n",
      "Epoch 4767/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8731 - mse: 931.0524 - val_loss: 20.5658 - val_mse: 939.0364\n",
      "Epoch 4768/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8907 - mse: 923.3136 - val_loss: 20.5792 - val_mse: 946.5648\n",
      "Epoch 4769/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9608 - mse: 940.1643 - val_loss: 20.5612 - val_mse: 934.7635\n",
      "Epoch 4770/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8926 - mse: 923.8340 - val_loss: 20.5700 - val_mse: 941.8594\n",
      "Epoch 4771/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9083 - mse: 939.8791 - val_loss: 20.5683 - val_mse: 923.8005\n",
      "Epoch 4772/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8540 - mse: 920.9698 - val_loss: 20.5671 - val_mse: 939.9725\n",
      "Epoch 4773/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9128 - mse: 926.4225 - val_loss: 20.5690 - val_mse: 941.2448\n",
      "Epoch 4774/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8489 - mse: 935.9427 - val_loss: 20.5671 - val_mse: 939.9642\n",
      "Epoch 4775/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9406 - mse: 925.5908 - val_loss: 20.6049 - val_mse: 956.0227\n",
      "Epoch 4776/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9179 - mse: 932.1843 - val_loss: 20.6159 - val_mse: 959.2214\n",
      "Epoch 4777/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9114 - mse: 931.5121 - val_loss: 20.5872 - val_mse: 950.1715\n",
      "Epoch 4778/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9038 - mse: 927.0994 - val_loss: 20.6332 - val_mse: 963.2628\n",
      "Epoch 4779/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8783 - mse: 932.0599 - val_loss: 20.5737 - val_mse: 943.9398\n",
      "Epoch 4780/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9271 - mse: 936.1551 - val_loss: 20.5712 - val_mse: 942.5128\n",
      "Epoch 4781/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9010 - mse: 935.5196 - val_loss: 20.5635 - val_mse: 937.2560\n",
      "Epoch 4782/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8765 - mse: 923.8220 - val_loss: 20.5741 - val_mse: 944.1154\n",
      "Epoch 4783/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8792 - mse: 928.7129 - val_loss: 20.5872 - val_mse: 950.1501\n",
      "Epoch 4784/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9017 - mse: 933.7170 - val_loss: 20.5610 - val_mse: 934.2944\n",
      "Epoch 4785/5000\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 20.8866 - mse: 930.8177 - val_loss: 20.5751 - val_mse: 944.6641\n",
      "Epoch 4786/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8862 - mse: 927.5710 - val_loss: 20.5621 - val_mse: 926.7718\n",
      "Epoch 4787/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9515 - mse: 933.2051 - val_loss: 20.5600 - val_mse: 932.1630\n",
      "Epoch 4788/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8959 - mse: 918.0529 - val_loss: 20.6621 - val_mse: 968.9271\n",
      "Epoch 4789/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8918 - mse: 943.9983 - val_loss: 20.5685 - val_mse: 923.6952\n",
      "Epoch 4790/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8813 - mse: 925.3524 - val_loss: 20.5688 - val_mse: 941.1427\n",
      "Epoch 4791/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8897 - mse: 931.9696 - val_loss: 20.5686 - val_mse: 940.9886\n",
      "Epoch 4792/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9494 - mse: 934.9336 - val_loss: 20.5673 - val_mse: 940.1231\n",
      "Epoch 4793/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8789 - mse: 917.6419 - val_loss: 20.5693 - val_mse: 941.4267\n",
      "Epoch 4794/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8946 - mse: 934.4565 - val_loss: 20.5648 - val_mse: 938.2394\n",
      "Epoch 4795/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9458 - mse: 934.6561 - val_loss: 20.5638 - val_mse: 925.8367\n",
      "Epoch 4796/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9500 - mse: 924.2946 - val_loss: 20.5598 - val_mse: 931.3702\n",
      "Epoch 4797/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8964 - mse: 930.3322 - val_loss: 20.5598 - val_mse: 930.8737\n",
      "Epoch 4798/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9207 - mse: 932.0912 - val_loss: 20.5603 - val_mse: 928.7877\n",
      "Epoch 4799/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8679 - mse: 936.5673 - val_loss: 20.5672 - val_mse: 940.0812\n",
      "Epoch 4800/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9030 - mse: 926.8621 - val_loss: 20.5705 - val_mse: 942.1115\n",
      "Epoch 4801/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8835 - mse: 932.1469 - val_loss: 20.6082 - val_mse: 911.7991\n",
      "Epoch 4802/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9119 - mse: 925.4492 - val_loss: 20.5851 - val_mse: 917.5132\n",
      "Epoch 4803/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9162 - mse: 928.6570 - val_loss: 20.5615 - val_mse: 935.1652\n",
      "Epoch 4804/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8718 - mse: 920.1887 - val_loss: 20.7065 - val_mse: 976.3148\n",
      "Epoch 4805/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9950 - mse: 938.6733 - val_loss: 20.5671 - val_mse: 924.3246\n",
      "Epoch 4806/5000\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 20.8867 - mse: 933.4070 - val_loss: 20.5731 - val_mse: 943.5836\n",
      "Epoch 4807/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8429 - mse: 932.5082 - val_loss: 20.5612 - val_mse: 934.6815\n",
      "Epoch 4808/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8594 - mse: 928.7581 - val_loss: 20.5836 - val_mse: 948.5701\n",
      "Epoch 4809/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8749 - mse: 928.3940 - val_loss: 20.5703 - val_mse: 942.0358\n",
      "Epoch 4810/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8815 - mse: 939.8629 - val_loss: 20.5601 - val_mse: 929.2434\n",
      "Epoch 4811/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9021 - mse: 918.9807 - val_loss: 20.5665 - val_mse: 939.5706\n",
      "Epoch 4812/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9321 - mse: 929.7448 - val_loss: 20.7178 - val_mse: 978.0834\n",
      "Epoch 4813/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0217 - mse: 938.5119 - val_loss: 20.6329 - val_mse: 963.2040\n",
      "Epoch 4814/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9344 - mse: 939.9134 - val_loss: 20.6030 - val_mse: 955.4650\n",
      "Epoch 4815/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9038 - mse: 936.4652 - val_loss: 20.6089 - val_mse: 957.1931\n",
      "Epoch 4816/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8787 - mse: 927.9336 - val_loss: 20.5616 - val_mse: 935.4017\n",
      "Epoch 4817/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8932 - mse: 927.1567 - val_loss: 20.5704 - val_mse: 942.0536\n",
      "Epoch 4818/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9704 - mse: 935.0870 - val_loss: 20.5642 - val_mse: 937.7860\n",
      "Epoch 4819/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9217 - mse: 928.8467 - val_loss: 20.5639 - val_mse: 925.7766\n",
      "Epoch 4820/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8578 - mse: 928.8575 - val_loss: 20.6149 - val_mse: 958.9402\n",
      "Epoch 4821/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9168 - mse: 937.7264 - val_loss: 20.5794 - val_mse: 946.6940\n",
      "Epoch 4822/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9695 - mse: 932.4344 - val_loss: 20.5637 - val_mse: 937.3896\n",
      "Epoch 4823/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9062 - mse: 926.8211 - val_loss: 20.5936 - val_mse: 952.4806\n",
      "Epoch 4824/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8953 - mse: 938.3608 - val_loss: 20.5620 - val_mse: 935.8859\n",
      "Epoch 4825/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8976 - mse: 929.8357 - val_loss: 20.5687 - val_mse: 923.5950\n",
      "Epoch 4826/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8958 - mse: 928.9261 - val_loss: 20.5688 - val_mse: 941.1340\n",
      "Epoch 4827/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9209 - mse: 928.3258 - val_loss: 20.5776 - val_mse: 945.8503\n",
      "Epoch 4828/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9300 - mse: 931.1501 - val_loss: 20.5600 - val_mse: 932.1025\n",
      "Epoch 4829/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9227 - mse: 932.0159 - val_loss: 20.5600 - val_mse: 929.3042\n",
      "Epoch 4830/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8659 - mse: 918.3917 - val_loss: 20.5774 - val_mse: 945.7571\n",
      "Epoch 4831/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8769 - mse: 948.1345 - val_loss: 20.5599 - val_mse: 929.6264\n",
      "Epoch 4832/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8201 - mse: 913.2023 - val_loss: 20.5674 - val_mse: 940.2165\n",
      "Epoch 4833/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9072 - mse: 930.3449 - val_loss: 20.5602 - val_mse: 932.4485\n",
      "Epoch 4834/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8743 - mse: 927.9623 - val_loss: 20.5725 - val_mse: 943.2281\n",
      "Epoch 4835/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9002 - mse: 937.5471 - val_loss: 20.5621 - val_mse: 935.9608\n",
      "Epoch 4836/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9115 - mse: 921.4807 - val_loss: 20.5874 - val_mse: 950.2498\n",
      "Epoch 4837/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8384 - mse: 924.2963 - val_loss: 20.5758 - val_mse: 945.0138\n",
      "Epoch 4838/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8730 - mse: 930.7419 - val_loss: 20.5720 - val_mse: 942.9531\n",
      "Epoch 4839/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9124 - mse: 930.9736 - val_loss: 20.5711 - val_mse: 922.5392\n",
      "Epoch 4840/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8599 - mse: 925.9957 - val_loss: 20.5620 - val_mse: 935.8898\n",
      "Epoch 4841/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8532 - mse: 924.5167 - val_loss: 20.5712 - val_mse: 942.5212\n",
      "Epoch 4842/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9036 - mse: 938.9720 - val_loss: 20.5598 - val_mse: 930.6538\n",
      "Epoch 4843/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9197 - mse: 929.6942 - val_loss: 20.5747 - val_mse: 944.4260\n",
      "Epoch 4844/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9156 - mse: 937.6010 - val_loss: 20.5629 - val_mse: 936.6950\n",
      "Epoch 4845/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8909 - mse: 926.5375 - val_loss: 20.5611 - val_mse: 927.5106\n",
      "Epoch 4846/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9063 - mse: 923.1499 - val_loss: 20.5846 - val_mse: 949.0437\n",
      "Epoch 4847/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9077 - mse: 935.9855 - val_loss: 20.5599 - val_mse: 931.8763\n",
      "Epoch 4848/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8538 - mse: 928.1619 - val_loss: 20.5648 - val_mse: 938.3076\n",
      "Epoch 4849/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8851 - mse: 925.1552 - val_loss: 20.5607 - val_mse: 933.5173\n",
      "Epoch 4850/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9156 - mse: 927.5221 - val_loss: 20.5782 - val_mse: 946.1475\n",
      "Epoch 4851/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8772 - mse: 936.7466 - val_loss: 20.5600 - val_mse: 932.1548\n",
      "Epoch 4852/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9132 - mse: 934.6592 - val_loss: 20.5982 - val_mse: 953.9915\n",
      "Epoch 4853/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8637 - mse: 933.8694 - val_loss: 20.5613 - val_mse: 927.3383\n",
      "Epoch 4854/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9507 - mse: 937.9647 - val_loss: 20.5697 - val_mse: 923.1592\n",
      "Epoch 4855/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9311 - mse: 922.6417 - val_loss: 20.5631 - val_mse: 936.8791\n",
      "Epoch 4856/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9068 - mse: 928.6930 - val_loss: 20.5615 - val_mse: 935.2722\n",
      "Epoch 4857/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8810 - mse: 926.8364 - val_loss: 20.5598 - val_mse: 930.8784\n",
      "Epoch 4858/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8768 - mse: 930.9806 - val_loss: 20.5605 - val_mse: 933.1239\n",
      "Epoch 4859/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8628 - mse: 929.5936 - val_loss: 20.5654 - val_mse: 938.7163\n",
      "Epoch 4860/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8659 - mse: 920.3322 - val_loss: 20.5893 - val_mse: 950.9741\n",
      "Epoch 4861/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8885 - mse: 933.3255 - val_loss: 20.5713 - val_mse: 942.5552\n",
      "Epoch 4862/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8701 - mse: 929.0503 - val_loss: 20.5612 - val_mse: 934.7796\n",
      "Epoch 4863/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8519 - mse: 931.6594 - val_loss: 20.5598 - val_mse: 931.6069\n",
      "Epoch 4864/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9264 - mse: 923.3124 - val_loss: 20.5605 - val_mse: 933.2235\n",
      "Epoch 4865/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9029 - mse: 929.6869 - val_loss: 20.5772 - val_mse: 945.6777\n",
      "Epoch 4866/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8678 - mse: 927.8932 - val_loss: 20.5618 - val_mse: 935.6125\n",
      "Epoch 4867/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8548 - mse: 925.6751 - val_loss: 20.5760 - val_mse: 945.0881\n",
      "Epoch 4868/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8918 - mse: 926.8887 - val_loss: 20.5683 - val_mse: 940.8303\n",
      "Epoch 4869/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9155 - mse: 926.7889 - val_loss: 20.5919 - val_mse: 951.9221\n",
      "Epoch 4870/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9175 - mse: 936.9336 - val_loss: 20.5623 - val_mse: 936.1789\n",
      "Epoch 4871/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9174 - mse: 931.3354 - val_loss: 20.5598 - val_mse: 931.1906\n",
      "Epoch 4872/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8640 - mse: 923.8506 - val_loss: 20.6330 - val_mse: 963.2077\n",
      "Epoch 4873/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8421 - mse: 930.7338 - val_loss: 20.5729 - val_mse: 943.4915\n",
      "Epoch 4874/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8859 - mse: 932.0384 - val_loss: 20.5685 - val_mse: 940.9222\n",
      "Epoch 4875/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8680 - mse: 931.0859 - val_loss: 20.5598 - val_mse: 931.0893\n",
      "Epoch 4876/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8804 - mse: 931.5993 - val_loss: 20.5684 - val_mse: 940.8533\n",
      "Epoch 4877/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9110 - mse: 932.3076 - val_loss: 20.5712 - val_mse: 942.5235\n",
      "Epoch 4878/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8603 - mse: 924.8038 - val_loss: 20.5599 - val_mse: 930.4805\n",
      "Epoch 4879/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9100 - mse: 934.2444 - val_loss: 20.5612 - val_mse: 934.6320\n",
      "Epoch 4880/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9116 - mse: 936.2144 - val_loss: 20.5696 - val_mse: 941.6017\n",
      "Epoch 4881/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9143 - mse: 923.2623 - val_loss: 20.5924 - val_mse: 952.0802\n",
      "Epoch 4882/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8590 - mse: 932.2125 - val_loss: 20.5640 - val_mse: 925.7142\n",
      "Epoch 4883/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9010 - mse: 922.2870 - val_loss: 20.5718 - val_mse: 922.2706\n",
      "Epoch 4884/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9223 - mse: 937.6396 - val_loss: 20.5904 - val_mse: 951.3685\n",
      "Epoch 4885/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8354 - mse: 927.7651 - val_loss: 20.5614 - val_mse: 927.2213\n",
      "Epoch 4886/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9213 - mse: 925.1569 - val_loss: 20.5776 - val_mse: 945.8853\n",
      "Epoch 4887/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9442 - mse: 933.5551 - val_loss: 20.5720 - val_mse: 942.9637\n",
      "Epoch 4888/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8293 - mse: 930.1810 - val_loss: 20.5772 - val_mse: 945.6650\n",
      "Epoch 4889/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8902 - mse: 935.0497 - val_loss: 20.5598 - val_mse: 931.4941\n",
      "Epoch 4890/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8629 - mse: 930.4255 - val_loss: 20.5847 - val_mse: 949.0848\n",
      "Epoch 4891/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8366 - mse: 927.9092 - val_loss: 20.5924 - val_mse: 952.0602\n",
      "Epoch 4892/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8923 - mse: 924.5563 - val_loss: 20.5688 - val_mse: 941.1004\n",
      "Epoch 4893/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8953 - mse: 936.7471 - val_loss: 20.5613 - val_mse: 934.9323\n",
      "Epoch 4894/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8180 - mse: 924.5449 - val_loss: 20.5599 - val_mse: 930.0391\n",
      "Epoch 4895/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8786 - mse: 922.8101 - val_loss: 20.6013 - val_mse: 954.9593\n",
      "Epoch 4896/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8905 - mse: 934.7484 - val_loss: 20.5653 - val_mse: 938.6573\n",
      "Epoch 4897/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8539 - mse: 932.1937 - val_loss: 20.5781 - val_mse: 919.8437\n",
      "Epoch 4898/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8758 - mse: 922.2742 - val_loss: 20.5614 - val_mse: 935.0016\n",
      "Epoch 4899/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8820 - mse: 935.7918 - val_loss: 20.5659 - val_mse: 924.8446\n",
      "Epoch 4900/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8895 - mse: 922.5363 - val_loss: 20.5673 - val_mse: 940.1371\n",
      "Epoch 4901/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8875 - mse: 922.1346 - val_loss: 20.5650 - val_mse: 938.4426\n",
      "Epoch 4902/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8751 - mse: 934.5071 - val_loss: 20.5686 - val_mse: 923.6403\n",
      "Epoch 4903/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8543 - mse: 929.0181 - val_loss: 20.5599 - val_mse: 931.7958\n",
      "Epoch 4904/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8736 - mse: 927.6680 - val_loss: 20.5724 - val_mse: 943.1884\n",
      "Epoch 4905/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9002 - mse: 929.4152 - val_loss: 20.5604 - val_mse: 928.4419\n",
      "Epoch 4906/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8662 - mse: 924.9463 - val_loss: 20.5685 - val_mse: 940.9250\n",
      "Epoch 4907/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9423 - mse: 928.9905 - val_loss: 20.5846 - val_mse: 949.0164\n",
      "Epoch 4908/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9161 - mse: 933.9766 - val_loss: 20.5652 - val_mse: 938.5623\n",
      "Epoch 4909/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8652 - mse: 925.3317 - val_loss: 20.5742 - val_mse: 944.1672\n",
      "Epoch 4910/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8546 - mse: 926.7508 - val_loss: 20.5608 - val_mse: 933.9286\n",
      "Epoch 4911/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.7996 - mse: 927.4315 - val_loss: 20.5638 - val_mse: 925.8208\n",
      "Epoch 4912/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9275 - mse: 928.3387 - val_loss: 20.5635 - val_mse: 926.0073\n",
      "Epoch 4913/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9159 - mse: 926.0073 - val_loss: 20.5880 - val_mse: 950.4996\n",
      "Epoch 4914/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8833 - mse: 935.6592 - val_loss: 20.5598 - val_mse: 931.3456\n",
      "Epoch 4915/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8646 - mse: 929.0521 - val_loss: 20.5718 - val_mse: 942.8771\n",
      "Epoch 4916/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9174 - mse: 927.9689 - val_loss: 20.5676 - val_mse: 940.3409\n",
      "Epoch 4917/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8990 - mse: 926.1584 - val_loss: 20.5877 - val_mse: 950.3411\n",
      "Epoch 4918/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9288 - mse: 934.0115 - val_loss: 20.5735 - val_mse: 943.8014\n",
      "Epoch 4919/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8502 - mse: 924.9691 - val_loss: 20.5782 - val_mse: 946.1407\n",
      "Epoch 4920/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8419 - mse: 930.7563 - val_loss: 20.5599 - val_mse: 930.3566\n",
      "Epoch 4921/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8666 - mse: 927.6922 - val_loss: 20.5658 - val_mse: 939.0627\n",
      "Epoch 4922/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8793 - mse: 931.5189 - val_loss: 20.5598 - val_mse: 930.6559\n",
      "Epoch 4923/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9596 - mse: 934.6861 - val_loss: 20.5712 - val_mse: 942.5349\n",
      "Epoch 4924/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8308 - mse: 926.9177 - val_loss: 20.5678 - val_mse: 940.4973\n",
      "Epoch 4925/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9072 - mse: 927.6873 - val_loss: 20.5924 - val_mse: 952.0610\n",
      "Epoch 4926/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9546 - mse: 942.5167 - val_loss: 20.5651 - val_mse: 925.2172\n",
      "Epoch 4927/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.7717 - mse: 918.8784 - val_loss: 20.5775 - val_mse: 945.8073\n",
      "Epoch 4928/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9064 - mse: 931.8400 - val_loss: 20.5730 - val_mse: 921.7848\n",
      "Epoch 4929/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8838 - mse: 932.2924 - val_loss: 20.5628 - val_mse: 936.6331\n",
      "Epoch 4930/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8937 - mse: 932.3337 - val_loss: 20.5676 - val_mse: 940.3187\n",
      "Epoch 4931/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8816 - mse: 934.3443 - val_loss: 20.5614 - val_mse: 934.9856\n",
      "Epoch 4932/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8895 - mse: 923.2106 - val_loss: 20.5601 - val_mse: 929.2312\n",
      "Epoch 4933/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9105 - mse: 940.2830 - val_loss: 20.5609 - val_mse: 927.7712\n",
      "Epoch 4934/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 21.0215 - mse: 935.7563 - val_loss: 20.5602 - val_mse: 929.0394\n",
      "Epoch 4935/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8617 - mse: 928.7541 - val_loss: 20.5682 - val_mse: 923.8325\n",
      "Epoch 4936/5000\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 20.9501 - mse: 930.1360 - val_loss: 20.5610 - val_mse: 927.6812\n",
      "Epoch 4937/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9246 - mse: 930.3332 - val_loss: 20.5659 - val_mse: 924.8398\n",
      "Epoch 4938/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8421 - mse: 921.7479 - val_loss: 20.5599 - val_mse: 930.1671\n",
      "Epoch 4939/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8650 - mse: 927.0840 - val_loss: 20.5907 - val_mse: 951.4789\n",
      "Epoch 4940/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8731 - mse: 937.7270 - val_loss: 20.5599 - val_mse: 929.8769\n",
      "Epoch 4941/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8623 - mse: 924.7306 - val_loss: 20.5599 - val_mse: 929.7860\n",
      "Epoch 4942/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9231 - mse: 933.9384 - val_loss: 20.5661 - val_mse: 939.2794\n",
      "Epoch 4943/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9250 - mse: 929.7777 - val_loss: 20.5648 - val_mse: 938.2599\n",
      "Epoch 4944/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8100 - mse: 921.3983 - val_loss: 20.5609 - val_mse: 934.1199\n",
      "Epoch 4945/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8438 - mse: 921.7402 - val_loss: 20.5768 - val_mse: 945.4667\n",
      "Epoch 4946/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8978 - mse: 935.6144 - val_loss: 20.5727 - val_mse: 943.3467\n",
      "Epoch 4947/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8965 - mse: 934.1450 - val_loss: 20.5649 - val_mse: 938.3813\n",
      "Epoch 4948/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8650 - mse: 919.4917 - val_loss: 20.5692 - val_mse: 941.3466\n",
      "Epoch 4949/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9210 - mse: 931.3727 - val_loss: 20.5782 - val_mse: 946.1533\n",
      "Epoch 4950/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8960 - mse: 923.7817 - val_loss: 20.5610 - val_mse: 934.3677\n",
      "Epoch 4951/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9241 - mse: 937.9092 - val_loss: 20.5607 - val_mse: 933.5740\n",
      "Epoch 4952/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8520 - mse: 928.6866 - val_loss: 20.5613 - val_mse: 934.8514\n",
      "Epoch 4953/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8691 - mse: 926.4279 - val_loss: 20.5605 - val_mse: 933.1607\n",
      "Epoch 4954/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8819 - mse: 924.5050 - val_loss: 20.5672 - val_mse: 940.0594\n",
      "Epoch 4955/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8848 - mse: 928.0843 - val_loss: 20.5599 - val_mse: 930.2917\n",
      "Epoch 4956/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8318 - mse: 917.3471 - val_loss: 20.5663 - val_mse: 939.3926\n",
      "Epoch 4957/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9158 - mse: 937.1736 - val_loss: 20.5859 - val_mse: 949.6052\n",
      "Epoch 4958/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9304 - mse: 928.2506 - val_loss: 20.5748 - val_mse: 944.4974\n",
      "Epoch 4959/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8720 - mse: 932.1996 - val_loss: 20.5627 - val_mse: 926.4100\n",
      "Epoch 4960/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9291 - mse: 932.8898 - val_loss: 20.5599 - val_mse: 929.7706\n",
      "Epoch 4961/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9703 - mse: 924.9686 - val_loss: 20.5716 - val_mse: 942.7504\n",
      "Epoch 4962/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9171 - mse: 934.5219 - val_loss: 20.5614 - val_mse: 927.2258\n",
      "Epoch 4963/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9094 - mse: 927.0979 - val_loss: 20.5609 - val_mse: 927.8132\n",
      "Epoch 4964/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8795 - mse: 930.7154 - val_loss: 20.5667 - val_mse: 939.7388\n",
      "Epoch 4965/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8848 - mse: 928.8625 - val_loss: 20.5651 - val_mse: 938.4850\n",
      "Epoch 4966/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8271 - mse: 923.6350 - val_loss: 20.5778 - val_mse: 945.9717\n",
      "Epoch 4967/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9193 - mse: 928.6172 - val_loss: 20.5677 - val_mse: 940.4310\n",
      "Epoch 4968/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.8425 - mse: 923.7560 - val_loss: 20.5635 - val_mse: 937.2296\n",
      "Epoch 4969/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8265 - mse: 934.2241 - val_loss: 20.5607 - val_mse: 933.5121\n",
      "Epoch 4970/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9249 - mse: 923.8622 - val_loss: 20.5645 - val_mse: 938.0604\n",
      "Epoch 4971/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9429 - mse: 934.6821 - val_loss: 20.5932 - val_mse: 952.3342\n",
      "Epoch 4972/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.9476 - mse: 929.9634 - val_loss: 20.5749 - val_mse: 944.5390\n",
      "Epoch 4973/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8525 - mse: 938.0602 - val_loss: 20.5620 - val_mse: 935.9034\n",
      "Epoch 4974/5000\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 20.9107 - mse: 924.8752 - val_loss: 20.5748 - val_mse: 944.4962\n",
      "Epoch 4975/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8878 - mse: 926.7474 - val_loss: 20.6040 - val_mse: 955.7468\n",
      "Epoch 4976/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8858 - mse: 934.8343 - val_loss: 20.5728 - val_mse: 921.8583\n",
      "Epoch 4977/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8805 - mse: 927.7460 - val_loss: 20.5611 - val_mse: 934.5543\n",
      "Epoch 4978/5000\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 20.8840 - mse: 932.4635 - val_loss: 20.5660 - val_mse: 939.2190\n",
      "Epoch 4979/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8320 - mse: 926.4232 - val_loss: 20.5680 - val_mse: 940.6183\n",
      "Epoch 4980/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.9237 - mse: 925.7264 - val_loss: 20.5706 - val_mse: 942.1841\n",
      "Epoch 4981/5000\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 20.8903 - mse: 936.8994 - val_loss: 20.5625 - val_mse: 936.3814\n",
      "Epoch 4982/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8603 - mse: 923.2543 - val_loss: 20.5710 - val_mse: 942.3891\n",
      "Epoch 4983/5000\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 20.9367 - mse: 920.6982 - val_loss: 20.6017 - val_mse: 955.0713\n",
      "Epoch 4984/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.8844 - mse: 931.2394 - val_loss: 20.5667 - val_mse: 939.6961\n",
      "Epoch 4985/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8843 - mse: 925.2212 - val_loss: 20.5606 - val_mse: 933.4380\n",
      "Epoch 4986/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8737 - mse: 931.9553 - val_loss: 20.5697 - val_mse: 941.6862\n",
      "Epoch 4987/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.9390 - mse: 934.4462 - val_loss: 20.5722 - val_mse: 922.1144\n",
      "Epoch 4988/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 21.0058 - mse: 938.7234 - val_loss: 20.5876 - val_mse: 950.3018\n",
      "Epoch 4989/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9101 - mse: 924.8318 - val_loss: 20.5697 - val_mse: 941.6786\n",
      "Epoch 4990/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8766 - mse: 937.4843 - val_loss: 20.5703 - val_mse: 922.9314\n",
      "Epoch 4991/5000\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 20.9676 - mse: 934.2143 - val_loss: 20.5690 - val_mse: 941.2187\n",
      "Epoch 4992/5000\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 20.8912 - mse: 931.5426 - val_loss: 20.5603 - val_mse: 928.8104\n",
      "Epoch 4993/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8972 - mse: 920.9843 - val_loss: 20.6014 - val_mse: 954.9706\n",
      "Epoch 4994/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8511 - mse: 928.5798 - val_loss: 20.5670 - val_mse: 939.9235\n",
      "Epoch 4995/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8551 - mse: 928.9213 - val_loss: 20.5636 - val_mse: 937.3029\n",
      "Epoch 4996/5000\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 20.9421 - mse: 929.3073 - val_loss: 20.6422 - val_mse: 965.1202\n",
      "Epoch 4997/5000\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 20.8919 - mse: 939.9639 - val_loss: 20.5602 - val_mse: 929.0154\n",
      "Epoch 4998/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8726 - mse: 927.3958 - val_loss: 20.5734 - val_mse: 943.7434\n",
      "Epoch 4999/5000\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 20.8719 - mse: 935.8268 - val_loss: 20.5599 - val_mse: 931.8718\n",
      "Epoch 5000/5000\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.8729 - mse: 919.3386 - val_loss: 20.5612 - val_mse: 934.6498\n"
     ]
    }
   ],
   "source": [
    "# + drop\n",
    "# 5 layers lr\n",
    "# more layers 5 hidden layers\n",
    "\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "      fivel_drop_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu', input_dim = 42),\n",
    "            tf.keras.layers.Dropout(0.25),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.25),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.25),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.25),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.25),\n",
    "            tf.keras.layers.Dense(512,kernel_initializer = 'uniform', activation='relu'),\n",
    "            tf.keras.layers.Dense(1,kernel_initializer = 'uniform')\n",
    "    ])\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    fivel_drop_model_history = model_compile_and_fit(X=X_train, \n",
    "                                            y=y_train,\n",
    "                                            model= fivel_drop_model,\n",
    "                                            name='fivel_drop_model',\n",
    "                                            optimizer='Adam', \n",
    "                                            max_epochs= EPOCHS )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee5f3ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 - 0s - loss: 21.6911 - mse: 1073.4172 - 125ms/epoch - 3ms/step\n",
      "Model MSE: 1073.417236328125\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 10:41:09.705203: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 32.76304532702929\n",
      "RMSE: 30.384570296360923\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    # plot MSE history \n",
    "    plot_metric(fivel_drop_model_history)\n",
    "\n",
    "    # Evaluate the small model on test set using .evaluate\n",
    "    loss, mse = fivel_drop_model.evaluate(X_test, y_test, verbose=2)\n",
    "    print(f'Model MSE: {mse}')\n",
    "    print('--------'*5)\n",
    "\n",
    "# Predict values for test set\n",
    "y_pred = fivel_drop_model.predict(X_test)\n",
    "y_pred_train = fivel_drop_model.predict(X_train)\n",
    "\n",
    "\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "test_results['fivel_drop model'] =  [rmse_train, rmse_test]\n",
    "\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0a1dfbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>RMSE Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fivel model</th>\n",
       "      <td>25.383008</td>\n",
       "      <td>27.879569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fivel_drop model</th>\n",
       "      <td>30.384570</td>\n",
       "      <td>32.763045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  RMSE Train  RMSE Test\n",
       "fivel model        25.383008  27.879569\n",
       "fivel_drop model   30.384570  32.763045"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test_results, index=['RMSE Train', 'RMSE Test']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25560d3a",
   "metadata": {},
   "source": [
    "## Model ensembling\n",
    "You have learned that models can be ensembled. What is possible in `scikit-learn` is also possible in TensorFlow, just a little different as it is relying on its computation graph. However, any model is callable like a `layer` by invoking it on either an `Input` or on the output of another layer. Furthermore, you can also stack outputs together.\n",
    "\n",
    "To produce an ensemble you can define a couple of models, than use their predictions as inputs for another model and produce a final output (using `keras.Model(input, output)`). But you can also start simple and use the mean predictions over all models and then compute the `argmax()` to assign them to a class in classification (via using `layers.average([model1_preds,model2_preds,...])`). You will be surprised how well this works. \n",
    "\n",
    "Now implement your own ensemble to improve your work even a little more and to have something more to polish up your ML project on `GitHub` ;) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cde4649",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========#\n",
    "# YOUR CODE #\n",
    "#===========#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e06d9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 17145), started 0:00:09 ago. (Use '!kill 17145' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ace7cc6beaba530a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ace7cc6beaba530a\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir=./my_logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
